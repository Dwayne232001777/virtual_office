import * as react_jsx_runtime from 'react/jsx-runtime';
import * as react from 'react';
import { ComponentType, ComponentProps, MouseEventHandler, FunctionComponent, PropsWithChildren, HTMLProps, Ref, ForwardRefExoticComponent, RefAttributes, MouseEvent, ElementRef, ReactNode, ReactElement } from 'react';
import { IDisposable as IDisposable$1, Nullable as Nullable$1, IReadonlyObservable as IReadonlyObservable$2, Scene as Scene$1, IInspectorOptions as IInspectorOptions$1 } from '@babylonjs/core/index.js';
import { IReadonlyObservable as IReadonlyObservable$1, Observable as Observable$1 } from '@babylonjs/core/Misc/observable.js';
import { Nullable as Nullable$2 } from '@babylonjs/core/types.js';
import { FluentProviderProps, PositioningImperativeRef, OnOpenChangeData, SpinnerProps } from '@fluentui/react-components';
import { Color3 as Color3$1, Color4 as Color4$1 } from '@babylonjs/core/Maths/math.color.js';
import { Vector3 as Vector3$1, Quaternion as Quaternion$1 } from '@babylonjs/core/Maths/math.vector.js';
import { IDisposable as IDisposable$2, Scene as Scene$2 } from '@babylonjs/core/scene.js';
import { TernaryDarkMode } from 'usehooks-ts';
import { DebugLayer as DebugLayer$1 } from '@babylonjs/core/Debug/debugLayer.js';
import { FluentIcon } from '@fluentui/react-icons';
import * as _fluentui_react_utilities from '@fluentui/react-utilities';

/**
 * Helper type to check if a type includes null or undefined
 */
type IsNullable<T> = null extends T ? true : undefined extends T ? true : false;
/**
 * Base props for BoundProperty
 */
type BaseBoundPropertyProps<TargetT extends object, PropertyKeyT extends keyof TargetT, ComponentT extends ComponentType<any>> = Omit<ComponentProps<ComponentT>, "value" | "onChange" | "nullable" | "defaultValue" | "ignoreNullable"> & {
    component: ComponentT;
    target: TargetT | null | undefined;
    propertyKey: PropertyKeyT;
    /** Optional propertyPath used to generate the copyString if path to property is not equal to entity.target */
    propertyPath?: string;
    convertTo?: (value: TargetT[PropertyKeyT]) => TargetT[PropertyKeyT];
    convertFrom?: (value: TargetT[PropertyKeyT]) => TargetT[PropertyKeyT];
};
/**
 * Enhanced BoundProperty props that enforces strict nullable handling
 */
type BoundPropertyProps<TargetT extends object, PropertyKeyT extends keyof TargetT, ComponentT extends ComponentType<any>> = BaseBoundPropertyProps<TargetT, PropertyKeyT, ComponentT> & (IsNullable<TargetT[PropertyKeyT]> extends true ? {
    defaultValue: null;
    nullable?: never;
    ignoreNullable?: never;
} | (ComponentProps<ComponentT> extends {
    nullable?: boolean;
} ? {
    nullable: true;
    defaultValue: NonNullable<TargetT[PropertyKeyT]>;
    ignoreNullable?: never;
} | {
    ignoreNullable: true;
    defaultValue: NonNullable<TargetT[PropertyKeyT]>;
    nullable?: never;
} : never) : {});
declare function BoundPropertyImpl<TargetT extends object, PropertyKeyT extends keyof TargetT, ComponentT extends ComponentType<any>>(props: BoundPropertyProps<TargetT, PropertyKeyT, ComponentT>, ref?: any): react_jsx_runtime.JSX.Element | null;
/**
 * Intercepts the passed in component's target[propertyKey] with useInterceptObservable and sets component state using useObservableState.
 * Renders the passed in component with value as the new observableState value and onChange as a callback to set the target[propertyKey] value.
 *
 * NOTE: BoundProperty has strict nullable enforcement!
 *
 * If Target[PropertyKey] is Nullable, caller has three options:
 * 1. `nullable: true` + `defaultValue: NonNullable<T>` - Shows enable/disable checkbox UI
 * 2. `ignoreNullable: true` + `defaultValue: NonNullable<T>` - Shows disabled state when null
 * 3. `defaultValue: null` - Skips nullable handling entirely, passes value through as-is
 *
 * @param props BoundPropertyProps with strict nullable validation
 * @returns JSX element
 */
declare const BoundProperty: typeof BoundPropertyImpl;
/**
 * Mutually exclusive propertyPath or functionPath - one required
 */
type RequiredPropertyPath = {
    propertyPath: string;
    functionPath?: never;
} | {
    functionPath: string;
    propertyPath?: never;
};
/**
 * Props for Property component - a simpler version of BoundProperty that only handles onCopy functionality
 * Pass in the full propertyPath from entity to property (e.g. "meshes[0].position.x") to ensure copyString is accurate
 * Use functionPath for function-based properties (e.g. "setEnabled" generates "debugNode.setEnabled(value)")
 */
type PropertyProps<ComponentT extends ComponentType<any>> = Omit<ComponentProps<ComponentT>, "onCopy"> & {
    component: ComponentT;
} & RequiredPropertyPath;
declare function PropertyImpl<ComponentT extends ComponentType<any>>(props: PropertyProps<ComponentT>, ref?: any): react_jsx_runtime.JSX.Element;
/**
 * A simpler version of BoundProperty that only provides the onCopy functionality.
 * Does not bind the value/onChange - those must be provided by the caller.
 * Use this when you need copy support but have custom value/onChange handling.
 *
 * @param props PropertyProps with propertyName for copy support
 * @returns JSX element
 */
declare const Property: typeof PropertyImpl;

type InfoLabelProps = {
    htmlFor: string;
    info?: JSX.Element;
    label: string;
    className?: string;
    /**
     * When true, applies flex layout styling to the label slot for proper truncation in flex containers
     */
    flexLabel?: boolean;
    /**
     * Handler for right-click context menu. Also triggers on Ctrl+click.
     */
    onContextMenu?: MouseEventHandler;
};
type InfoLabelParentProps = Omit<InfoLabelProps, "htmlFor">;
/**
 * Renders a label with an optional popup containing more info
 * @param props
 * @returns
 */
declare const InfoLabel: FunctionComponent<InfoLabelProps>;

type BasePrimitiveProps = {
    /**
     * Optional flag to disable the component, preventing any interaction.
     */
    disabled?: boolean;
    /**
     * Optional class name to apply custom styles to the component.
     */
    className?: string;
    /**
     * Optional style object to apply custom inline styles to the top-level HTML element.
     */
    style?: React.CSSProperties;
    /**
     * Optional title for the component, used for tooltips or accessibility.
     */
    title?: string;
};
type ImmutablePrimitiveProps<ValueT> = BasePrimitiveProps & {
    /**
     * The value of the property to be displayed and modified.
     */
    value: ValueT;
    /**
     * Optional information to display as an infoLabel popup aside the component.
     */
    infoLabel?: InfoLabelParentProps;
};
type PrimitiveProps<T> = ImmutablePrimitiveProps<T> & {
    /**
     * Called when the primitive value changes
     */
    onChange: (value: T) => void;
};

type BasePropertyLineProps = {
    /**
     * The name of the property to display in the property line.
     */
    label: string;
    /**
     * Optional description for the property, shown on hover of the info icon
     */
    description?: string;
    /**
     * Optional function returning a string to copy to clipboard.
     */
    onCopy?: () => string;
    /**
     * Link to the documentation for this property, available from the info icon either linked from the description (if provided) or default 'docs' text
     */
    docLink?: string;
};
type NullableProperty<ValueT> = {
    nullable: true;
    ignoreNullable: false;
    value: ValueT;
    onChange: (value: ValueT) => void;
    defaultValue?: ValueT;
};
type IgnoreNullable<ValueT> = {
    ignoreNullable: true;
    nullable: false;
    value: ValueT;
    onChange: (value: ValueT) => void;
    defaultValue: ValueT;
};
type NonNullableProperty = {
    nullable?: false;
    ignoreNullable?: false;
};
type ExpandableProperty = {
    /**
     * If supplied, an 'expand' icon will be shown which, when clicked, renders this component within the property line.
     */
    expandedContent: JSX.Element;
    /**
     * If true, the expanded content will be shown by default.
     */
    expandByDefault?: boolean;
};
type NonExpandableProperty = {
    expandedContent?: undefined;
};
type PropertyLineProps<ValueT> = BasePropertyLineProps & (NullableProperty<ValueT> | NonNullableProperty | IgnoreNullable<ValueT>) & (ExpandableProperty | NonExpandableProperty);
/**
 * A reusable component that renders a property line with a label and child content, and an optional description, copy button, and expandable section.
 *
 * @param props - The properties for the PropertyLine component.
 * @returns A React element representing the property line.
 *
 */
declare const PropertyLine: react.ForwardRefExoticComponent<PropsWithChildren<PropertyLineProps<any>> & react.RefAttributes<HTMLDivElement>>;
declare const LineContainer: react.ForwardRefExoticComponent<Omit<PropsWithChildren<HTMLProps<HTMLDivElement>>, "ref"> & react.RefAttributes<HTMLDivElement>>;
declare const PlaceholderPropertyLine: FunctionComponent<PrimitiveProps<any> & PropertyLineProps<any>>;

/**
 * A helper to create a service factory function from a class constructor.
 * @param constructor The class to create a factory function for.
 * @returns A factory function that creates an instance of the class.
 */
declare function ConstructorFactory<Class extends new (...args: any) => any>(constructor: Class): (...args: ConstructorParameters<Class>) => InstanceType<Class>;
declare const Contract: unique symbol;
/**
 * This interface must be implemented by all service contracts.
 */
interface IService<ContractIdentity extends symbol> {
    /**
     * @internal
     */
    readonly [Contract]?: ContractIdentity;
}
type ExtractContractIdentity<ServiceContract extends IService<symbol>> = ServiceContract extends IService<infer ContractIdentity> ? ContractIdentity : never;
type ExtractContractIdentities<ServiceContracts extends IService<symbol>[]> = {
    [Index in keyof ServiceContracts]: ExtractContractIdentity<ServiceContracts[Index]>;
};
type UnionToIntersection<Union> = (Union extends any ? (k: Union) => void : never) extends (k: infer Intersection) => void ? Intersection : never;
type MaybePromise<T> = T | Promise<T>;
/**
 * A factory function responsible for creating a service instance.
 * Consumed services are passed as arguments to the factory function.
 * The returned value must implement all produced services, and may IDisposable.
 * If not services are produced, the returned value may implement IDisposable, otherwise it may return void.
 */
type ServiceFactory<Produces extends IService<symbol>[], Consumes extends IService<symbol>[]> = (...dependencies: [...Consumes, abortSignal?: AbortSignal]) => MaybePromise<Produces extends [] ? Partial<IDisposable$1> | void : Partial<IDisposable$1> & UnionToIntersection<Produces[number]>>;
/**
 * Defines a service, which is a logical unit that consumes other services (dependencies), and optionally produces services that can be consumed by other services (dependents).
 */
type ServiceDefinition<Produces extends IService<symbol>[] = [], Consumes extends IService<symbol>[] = []> = {
    /**
     * A human readable name for the service to help with debugging.
     */
    friendlyName: string;
    /**
     * A function that instantiates the service.
     */
    factory: ServiceFactory<Produces, Consumes>;
} & (Produces extends [] ? {
    /**
     * An empty list or undefined, since the type specification has indicated no contracts are produced.
     */
    produces?: [];
} : {
    /**
     * The list of contract identities that this service produces for consumption by other services.
     */
    produces: ExtractContractIdentities<Produces>;
}) & (Consumes extends [] ? {
    /**
     * An empty list or undefined, since the type specification has indicated that no other services are consumed.
     */
    consumes?: [];
} : {
    /**
     * The list of contract identities of other services that this service consumes.
     */
    consumes: ExtractContractIdentities<Consumes>;
});

declare const SettingsContextIdentity: unique symbol;
/**
 * SettingsContext provides a set of settings used across the inspector.
 */
interface ISettingsContext extends IService<typeof SettingsContextIdentity> {
    /**
     * Use degrees instead of radians for angles.
     */
    useDegrees: boolean;
    /**
     * Ignore backfaces when picking.
     */
    ignoreBackfacesForPicking: boolean;
    /**
     * Only show Euler angles in rotation properties.
     */
    useEuler: boolean;
    /**
     * Shows the Properties pane when an entity is selected.
     */
    showPropertiesOnEntitySelection: boolean;
    /**
     * Observable that fires whenever a setting changes.
     */
    readonly settingsChangedObservable: IReadonlyObservable$1<ISettingsContext>;
}

type HorizontalLocation = "left" | "right";
type VerticalLocation = "top" | "bottom";
/**
 * Describes an item that can be added to one of the shell's toolbars.
 */
type ToolbarItemDefinition = {
    /**
     * A unique key for the toolbar item.
     */
    key: string;
    /**
     * The component to render for the toolbar item.
     */
    component: ComponentType;
    /**
     * An optional order for the toolbar item, relative to other items.
     * Defaults to 0.
     */
    order?: number;
    /**
     * The horizontal location of the toolbar item.
     * Can be either "left" or "right".
     * In "compact" toolbar mode, "left" and "right" mean the "compact" toolbars at the top/bottom of the left/right side panes.
     * In "full" toolbar mode, "left" and "right" mean the left side and right side of the full width toolbars above/below the side panes.
     */
    horizontalLocation: HorizontalLocation;
    /**
     * The vertical location of the toolbar item.
     * Can be either "top" or "bottom".
     */
    verticalLocation: VerticalLocation;
    /**
     * An optional display name for the toolbar item, used for teaching moments, tooltips, etc.
     */
    displayName?: string;
    /**
     * An optional flag to suppress the teaching moment for this toolbar item.
     * Defaults to false.
     * Teaching moments are more helpful for dynamically added items, possibly from extensions.
     */
    suppressTeachingMoment?: boolean;
};
/**
 * Describes a side pane that can be added to the shell's left or right side.
 */
type SidePaneDefinition = {
    /**
     * A unique key for the side pane.
     */
    key: string;
    /**
     * An icon component to render for the pane tab.
     */
    icon: ComponentType;
    /**
     * The component to render for the side pane's content.
     */
    content: ComponentType;
    /**
     * An optional order for the side pane, relative to other panes.
     * Defaults to 0.
     */
    order?: number;
    /**
     * The horizontal location of the side pane.
     * Can be either "left" or "right".
     */
    horizontalLocation: HorizontalLocation;
    /**
     * The vertical location of the side pane.
     * Can be either "top" or "bottom".
     */
    verticalLocation: VerticalLocation;
    /**
     * The title of the side pane, displayed as a standardized header at the top of the pane.
     */
    title: string;
    /**
     * An optional flag to suppress the teaching moment for this side pane.
     * Defaults to false.
     * Teaching moments are more helpful for dynamically added panes, possibly from extensions.
     */
    suppressTeachingMoment?: boolean;
};
type RegisteredSidePane = {
    readonly key: string;
    select(): void;
};
type SidePaneContainer$1 = {
    readonly isDocked: boolean;
    dock(): void;
    undock(): void;
};
/**
 * Describes content that can be added to the shell's central area (between the side panes and toolbars - e.g. the main content).
 */
type CentralContentDefinition = {
    /**
     * A unique key for the central content.
     */
    key: string;
    /**
     * The component to render for the central content.
     */
    component: ComponentType;
    /**
     * An optional order for content, relative to other central content.
     * Defaults to 0.
     */
    order?: number;
};
declare const ShellServiceIdentity: unique symbol;
/**
 * Provides a shell for the application, including toolbars, side panes, and central content.
 * This service allows adding toolbar items, side panes, and central content dynamically.
 */
interface IShellService extends IService<typeof ShellServiceIdentity> {
    /**
     * Adds a new item to one of the shell's toolbars.
     * @param item Defines the item to add.
     */
    addToolbarItem(item: Readonly<ToolbarItemDefinition>): IDisposable$1;
    /**
     * Adds a new side pane to the shell.
     * @param pane Defines the side pane to add.
     */
    addSidePane(pane: Readonly<SidePaneDefinition>): IDisposable$1;
    /**
     * Adds new central content to the shell.
     * @param content Defines the content area to add.
     */
    addCentralContent(content: Readonly<CentralContentDefinition>): IDisposable$1;
    /**
     * Resets the side pane layout to the default configuration.
     */
    resetSidePaneLayout(): void;
    /**
     * The left side pane container.
     */
    readonly leftSidePaneContainer: Nullable$1<SidePaneContainer$1>;
    /**
     * The right side pane container.
     */
    readonly rightSidePaneContainer: Nullable$1<SidePaneContainer$1>;
    /**
     * The side panes currently present in the shell.
     */
    readonly sidePanes: readonly RegisteredSidePane[];
}
type ToolbarMode = "full" | "compact";
/**
 * Options for configuring the shell service.
 */
type ShellServiceOptions = {
    /**
     * The default width of the left side pane.
     */
    leftPaneDefaultWidth?: number;
    /**
     * The minimum width of the left side pane.
     */
    leftPaneMinWidth?: number;
    /**
     * The default width of the right side pane.
     */
    rightPaneDefaultWidth?: number;
    /**
     * The minimum width of the right side pane.
     */
    rightPaneMinWidth?: number;
    /**
     * The mode of the toolbars.
     * Can be either "full" (default) or "compact".
     * In "full" mode, toolbars are displayed above and below the side panes.
     * In "compact" mode, toolbars are displayed at the top and bottom of the left and right side panes.
     */
    toolbarMode?: ToolbarMode;
    /**
     * A function that can remap the default location of side panes.
     * @param sidePane The side pane to remap.
     * @returns The new location for the side pane.
     */
    sidePaneRemapper?: (sidePane: Readonly<SidePaneDefinition>) => Nullable$1<{
        horizontalLocation: HorizontalLocation;
        verticalLocation: VerticalLocation;
    }>;
};

declare const SelectionServiceIdentity: unique symbol;
/**
 * Tracks the currently selected entity.
 */
interface ISelectionService extends IService<typeof SelectionServiceIdentity> {
    /**
     * Gets or sets the currently selected entity.
     */
    selectedEntity: Nullable$1<unknown>;
    /**
     * An observable that notifies when the selected entity changes.
     */
    readonly onSelectedEntityChanged: IReadonlyObservable$2<void>;
}
declare const SelectionServiceDefinition: ServiceDefinition<[ISelectionService], [IShellService, ISettingsContext]>;

type LinkToEntityProps = {
    entity: Nullable$2<{
        name: string;
        reservedDataStore?: Record<PropertyKey, unknown>;
    }>;
    selectionService: ISelectionService;
};
/**
 * A property line that links to a specific entity in the scene.
 * @param props an entity and a selection service
 * @returns A link property line component.
 */
declare const LinkToEntityPropertyLine: FunctionComponent<PropertyLineProps<string> & LinkToEntityProps>;

type EntityDisplayInfo = Partial<IDisposable$1> & Readonly<{
    /**
     * The name of the entity to display in the Scene Explorer tree.
     */
    name: string;
    /**
     * An observable that notifies when the display info (such as the name) changes.
     */
    onChange?: IReadonlyObservable$2<void>;
}>;
type SceneExplorerSection<T> = Readonly<{
    /**
     * The display name of the section (e.g. "Nodes", "Materials", etc.).
     */
    displayName: string;
    /**
     * An optional order for the section, relative to other sections.
     * Defaults to 0.
     */
    order?: number;
    /**
     * A function that returns the root entities for this section.
     */
    getRootEntities: () => readonly T[];
    /**
     * An optional function that returns the children of a given entity.
     */
    getEntityChildren?: (entity: T) => readonly T[];
    /**
     * Gets the display information for a given entity.
     * This is ideally "live" display info (e.g. updates to the display info are taken into account and communicated via the observable).
     * This means in many cases the display info will need to be disposed when it is no longer needed so observable registrations can be removed.
     */
    getEntityDisplayInfo: (entity: T) => EntityDisplayInfo;
    /**
     * An optional icon component to render for the entity.
     */
    entityIcon?: ComponentType<{
        entity: T;
    }>;
    /**
     * A function that returns an array of observables for when entities are added to the scene.
     */
    getEntityAddedObservables: () => readonly IReadonlyObservable$2<T>[];
    /**
     * A function that returns an array of observables for when entities are removed from the scene.
     */
    getEntityRemovedObservables: () => readonly IReadonlyObservable$2<T>[];
    /**
     * A function that returns an array of observables for when entities are moved (e.g. re-parented) within the scene.
     */
    getEntityMovedObservables?: () => readonly IReadonlyObservable$2<T>[];
}>;
type InlineCommand = {
    /**
     * An icon component to render for the command. Required for inline commands.
     */
    icon: ComponentType;
    /**
     * The mode of the command. Inline commands are shown directly in the tree item layout. Inline by default.
     */
    mode?: "inline";
};
type ContextMenuCommand = {
    /**
     * An icon component to render for the command. Optional for context menu commands.
     */
    icon?: ComponentType;
    /**
     * The mode of the command. Context menu commands are shown in the context menu for the tree item.
     */
    mode: "contextMenu";
};
type CommandMode = NonNullable<(InlineCommand | ContextMenuCommand)["mode"]>;
type CommandType = (ActionCommand | ToggleCommand)["type"];
type SceneExplorerCommand<ModeT extends CommandMode = CommandMode, TypeT extends CommandType = CommandType> = Partial<IDisposable$1> & Readonly<{
    /**
     * The display name of the command (e.g. "Delete", "Rename", etc.).
     */
    displayName: string;
    /**
     * An observable that notifies when the command state changes.
     */
    onChange?: IReadonlyObservable$2<unknown>;
}> & (ModeT extends "inline" ? InlineCommand : ContextMenuCommand) & (TypeT extends "action" ? ActionCommand : ToggleCommand);
type SceneExplorerCommandProvider<ContextT, ModeT extends CommandMode = CommandMode, TypeT extends CommandType = CommandType> = Readonly<{
    /**
     * An optional order for the section, relative to other commands.
     * Defaults to 0.
     */
    order?: number;
    /**
     * A predicate function that determines if the command is applicable to the given context.
     */
    predicate: (context: unknown) => context is ContextT;
    /**
     * Gets the command information for the given context.
     */
    getCommand: (context: ContextT) => SceneExplorerCommand<ModeT, TypeT>;
}>;
type ActionCommand = {
    readonly type: "action";
    /**
     * The function that executes the command.
     */
    execute(): void;
};
declare const ActionCommand: FunctionComponent<{
    command: SceneExplorerCommand<"inline", "action">;
}>;
type ToggleCommand = {
    readonly type: "toggle";
    /**
     * A boolean indicating if the command is enabled.
     */
    isEnabled: boolean;
};
declare const ToggleCommand: FunctionComponent<{
    command: SceneExplorerCommand<"inline", "toggle">;
}>;

type DynamicAccordionSection = Readonly<{
    /**
     * A unique identity for the section, which can be referenced by section content.
     */
    identity: string;
    /**
     * An optional order for the section, relative to other sections.
     * Defaults to 0.
     */
    order?: number;
    /**
     * An optional flag indicating whether the section should be collapsed by default.
     * Defaults to false.
     */
    collapseByDefault?: boolean;
}>;
type DynamicAccordionSectionContent<ContextT> = Readonly<{
    /**
     * A unique key for the the content.
     */
    key: string;
    /**
     * The section this content belongs to.
     */
    section: string;
    /**
     * An optional order for the content within the section.
     * Defaults to 0.
     */
    order?: number;
    /**
     * The React component that will be rendered for this content.
     */
    component: ComponentType<{
        context: ContextT;
    }>;
}>;
type SectionsImperativeRef = {
    highlightSections: (sections: readonly string[]) => void;
};
declare function ExtensibleAccordion<ContextT = unknown>(props: PropsWithChildren<{
    sections: readonly DynamicAccordionSection[];
    sectionContent: readonly DynamicAccordionSectionContent<ContextT>[];
    context: ContextT;
    sectionsRef?: Ref<SectionsImperativeRef>;
}>): react_jsx_runtime.JSX.Element;

/**
 * Used to apply common styles to panes.
 */
declare const SidePaneContainer: react.ForwardRefExoticComponent<Omit<react.DetailedHTMLProps<react.HTMLAttributes<HTMLDivElement>, HTMLDivElement>, "ref"> & react.RefAttributes<HTMLDivElement>>;

declare const Theme: FunctionComponent<FluentProviderProps & {
    invert?: boolean;
}>;

/**
 * Creates a hook for managing teaching moment state.
 * @param name The unique name of the teaching moment.
 * @returns A hook that returns the teaching moment state.
 */
declare function MakeTeachingMoment(name: string): (suppress?: boolean) => {
    readonly shouldDisplay: boolean;
    readonly onDismissed: () => void;
    readonly reset: () => void;
};
/**
 * Creates a hook for managing teaching moment state for a dialog.
 * @param name The unique name of the teaching moment.
 * @returns A hook that returns the teaching moment state for a dialog.
 */
declare function MakeDialogTeachingMoment(name: string): (suppress?: boolean) => {
    readonly shouldDisplay: boolean;
    readonly onOpenChange: (e: unknown, data: OnOpenChangeData) => void;
    readonly reset: () => void;
};
/**
 * Creates a hook for managing teaching moment state for a popover.
 * @param name The unique name of the teaching moment.
 * @returns A hook that returns the teaching moment state for a popover.
 */
declare function MakePopoverTeachingMoment(name: string): (suppress?: boolean) => {
    readonly shouldDisplay: boolean;
    readonly positioningRef: react.Dispatch<react.SetStateAction<Nullable$1<PositioningImperativeRef>>>;
    readonly targetRef: react.Dispatch<react.SetStateAction<Nullable$1<HTMLElement>>>;
    readonly onOpenChange: (e: unknown, data: OnOpenChangeData) => void;
    readonly reset: () => void;
};

type TeachingMomentState = ReturnType<ReturnType<typeof MakePopoverTeachingMoment>>;
type TeachingMomentProps = Pick<TeachingMomentState, "shouldDisplay" | "positioningRef" | "onOpenChange"> & {
    title: string;
    description: string;
};
/**
 * A component that displays a teaching moment popover.
 * @param props Props for the teaching moment popover.
 * @returns The teaching moment popover.
 */
declare const TeachingMoment: FunctionComponent<TeachingMomentProps>;

type WeaklyTypedServiceDefinition = Omit<ServiceDefinition<IService<symbol>[] | [], IService<symbol>[] | []>, "factory"> & {
    /**
     * A factory function responsible for creating a service instance.
     */
    factory: (...args: any) => ReturnType<ServiceDefinition<IService<symbol>[] | [], IService<symbol>[] | []>["factory"]>;
};

type PersonMetadata = {
    /**
     * The name of the person.
     */
    readonly name: string;
    /**
     * The email address of the person.
     */
    readonly email?: string;
    /**
     * The URL to the person's website.
     */
    readonly url?: string;
    /**
     * The Babylon forum username of the person.
     */
    readonly forumUserName?: string;
};
type ExtensionMetadata = {
    /**
     * The name of the extension.
     */
    readonly name: string;
    /**
     * The version of the extension (as valid semver).
     */
    readonly version?: string;
    /**
     * The description of the extension.
     */
    readonly description: string;
    /**
     * The keywords of the extension.
     */
    readonly keywords?: readonly string[];
    /**
     * The URL to the extension homepage.
     */
    readonly homepage?: string;
    /**
     * Specify the place where your code lives. This is helpful for people who want to contribute.
     */
    readonly repository?: string;
    /**
     * The URL to your extension's issue tracker and / or the email address to which issues should be reported. These are helpful for people who encounter issues with your extension.
     */
    readonly bugs?: string;
    /**
     * A license for your package so that people know how they are permitted to use it, and any restrictions you're placing on it.
     */
    readonly license?: string;
    /**
     * The primary author of the extension.
     */
    readonly author?: string | PersonMetadata;
    /**
     * The contributors to the extension.
     */
    readonly contributors?: readonly (string | PersonMetadata)[];
};
type ExtensionModule = {
    /**
     * The default export of the module (e.g. export default).
     */
    default: {
        /**
         * The services that are included with the extension.
         */
        serviceDefinitions?: readonly WeaklyTypedServiceDefinition[];
    };
};
/**
 * Represents a query to fetch subset ranges of extension metadata from a feed.
 */
interface IExtensionMetadataQuery {
    /**
     * The total number of extensions that satisfy the query.
     */
    readonly totalCount: number;
    /**
     * Fetches a range of extension metadata from the feed.
     * @param index The index of the first extension to fetch.
     * @param count The number of extensions to fetch.
     * @returns A promise that resolves to the extension metadata.
     */
    getExtensionMetadataAsync(index: number, count: number): Promise<readonly ExtensionMetadata[]>;
}
/**
 * Represents a feed/source of extensions.
 */
interface IExtensionFeed {
    /**
     * The name of the feed.
     */
    readonly name: string;
    /**
     * Creates an extension metadata query given a filter.
     * @param filter The filter to apply to the query.
     * @returns A promise that resolves to the extension metadata query.
     */
    queryExtensionsAsync(filter?: string): Promise<IExtensionMetadataQuery>;
    /**
     * Gets the extension module for the specified extension.
     * @param name The name of the extension.
     * @returns A promise that resolves to the extension module.
     */
    getExtensionModuleAsync(name: string): Promise<ExtensionModule | undefined>;
}

type BuiltInExtension = ExtensionMetadata & {
    /**
     * Gets the extension module, typically dynamically importing the extension.
     * @returns The extension module (e.g. a collection of ServiceDefinitions).
     */
    getExtensionModuleAsync(): Promise<ExtensionModule>;
};
/**
 * A simple extension feed implementation that provides a fixed set of "built in" extensions.
 * "Built in" in this context means extensions that are known at bundling time, and included
 * in the bundle. Each extension can be dynamically imported so they are split into separate
 * bundle chunks and downloaded only when first installed.
 */
declare class BuiltInsExtensionFeed implements IExtensionFeed {
    readonly name: string;
    private readonly _extensions;
    constructor(name: string, extensions: Iterable<BuiltInExtension>);
    queryExtensionsAsync(filter?: string): Promise<IExtensionMetadataQuery>;
    getExtensionModuleAsync(name: string): Promise<ExtensionModule | undefined>;
}

type PropertyKeys<TargetT, PropertyT> = {
    [PropertyKeyT in keyof TargetT]: TargetT[PropertyKeyT] extends PropertyT | null | undefined ? PropertyKeyT : never;
}[keyof TargetT];
declare function useProperty<TargetT extends object, PropertyKeyT extends keyof TargetT>(target: TargetT, propertyKey: PropertyKeyT): TargetT[PropertyKeyT];
declare function useProperty<TargetT extends object, PropertyKeyT extends keyof TargetT>(target: TargetT | null | undefined, propertyKey: PropertyKeyT): TargetT[PropertyKeyT] | undefined;
declare function useVector3Property<TargetT extends object, PropertyKeyT extends PropertyKeys<TargetT, Vector3$1>>(target: TargetT, propertyKey: PropertyKeyT): TargetT[PropertyKeyT];
declare function useVector3Property<TargetT extends object, PropertyKeyT extends PropertyKeys<TargetT, Vector3$1>>(target: TargetT | null | undefined, propertyKey: PropertyKeyT): TargetT[PropertyKeyT] | undefined;
declare function useColor3Property<TargetT extends object, PropertyKeyT extends PropertyKeys<TargetT, Color3$1>>(target: TargetT, propertyKey: PropertyKeyT): TargetT[PropertyKeyT];
declare function useColor3Property<TargetT extends object, PropertyKeyT extends PropertyKeys<TargetT, Color3$1>>(target: TargetT | null | undefined, propertyKey: PropertyKeyT): TargetT[PropertyKeyT] | undefined;
declare function useColor4Property<TargetT extends object, PropertyKeyT extends PropertyKeys<TargetT, Color4$1>>(target: TargetT, propertyKey: PropertyKeyT): TargetT[PropertyKeyT];
declare function useColor4Property<TargetT extends object, PropertyKeyT extends PropertyKeys<TargetT, Color4$1>>(target: TargetT | null | undefined, propertyKey: PropertyKeyT): TargetT[PropertyKeyT] | null;
declare function useQuaternionProperty<TargetT extends object, PropertyKeyT extends PropertyKeys<TargetT, Quaternion$1>>(target: TargetT, propertyKey: PropertyKeyT): TargetT[PropertyKeyT];
declare function useQuaternionProperty<TargetT extends object, PropertyKeyT extends PropertyKeys<TargetT, Quaternion$1>>(target: TargetT | null | undefined, propertyKey: PropertyKeyT): TargetT[PropertyKeyT] | undefined;
/**
 * Creates a hook for a concrete value. For example, if the value is a Vector3,
 * it will return a hook that can intercept a change to the Vector3 property or
 * any of its components (x, y, z).
 * @param value The current value of a property that will be hooked.
 * @returns A hook function that can be used to observe changes to the property.
 */
declare function MakePropertyHook(value: unknown): typeof useVector3Property;

/**
 * Provides an observable that fires when a specified function/property is called/set.
 * @param type The type of the interceptor, either "function" or "property".
 * @param target The object containing the function/property to intercept.
 * @param propertyKey The key of the function/property to intercept.
 * @returns An observable that fires when the function/property is called/set.
 */
declare function useInterceptObservable<T extends object>(type: "function" | "property", target: T | null | undefined, propertyKey: keyof T): IReadonlyObservable$2<void>;

/**
 * A collection of items that can be observed for changes.
 */
declare class ObservableCollection<T> {
    private readonly _items;
    private readonly _keys;
    private readonly _observable;
    /**
     * An observable that notifies observers when the collection changes.
     */
    get observable(): IReadonlyObservable$2<void>;
    /**
     * The items in the collection.
     */
    get items(): readonly T[];
    /**
     * Adds an item to the collection.
     * @param item The item to add.
     * @returns A disposable that removes the item from the collection when disposed.
     */
    add(item: T): IDisposable$1;
}

/**
 * Returns the current value of the accessor and updates it when the specified event is fired on the specified element.
 * @param accessor A function that returns the current value.
 * @param element The element to listen for the event on.
 * @param eventNames The names of the events to listen for.
 * @returns The current value of the accessor.
 *  * @remarks If the accessor function is not idempotent (e.g. it returns a different array or object instance each time it is called),
 * then there is a good chance it should be wrapped in a `useCallback` to prevent unnecessary re-renders or re-render infinite loops.
 */
declare function useEventfulState<T>(accessor: () => T, element: HTMLElement | null | undefined, ...eventNames: string[]): T;
/**
 * Returns the current value of the accessor and updates it when any of the specified observables change.
 * @param accessor A function that returns the current value.
 * @param observables The observables to listen for changes on.
 * @returns The current value of the accessor.
 * @remarks If the accessor function is not idempotent (e.g. it returns a different array or object instance each time it is called),
 * then there is a good chance it should be wrapped in a `useCallback` to prevent unnecessary re-renders or re-render infinite loops.
 */
declare function useObservableState<T>(accessor: () => T, ...observables: Array<IReadonlyObservable$2 | null | undefined>): T;
/**
 * Returns a copy of the items in the collection and updates it when the collection changes.
 * @param collection The collection to observe.
 * @returns A copy of the items in the collection.
 */
declare function useObservableCollection<T>(collection: ObservableCollection<T>): T[];
/**
 * Returns a copy of the items in the collection sorted by the order property and updates it when the collection changes.
 * @param collection The collection to observe.
 * @returns A copy of the items in the collection sorted by the order property.
 */
declare function useOrderedObservableCollection<T extends Readonly<{
    order?: number;
}>>(collection: ObservableCollection<T>): T[];

/**
 * Creates a polling observable that notifies its observers at a specified interval.
 * @param delay The polling interval in milliseconds.
 * @returns A readonly observable that can be used to subscribe to polling notifications.
 */
declare function usePollingObservable(delay: number): IReadonlyObservable$2<void>;

/**
 * Custom hook to manage a resource with automatic disposal. The resource is created once initially, and recreated
 * if the factory function changes. Whenever the resource is recreated, the previous instance is disposed. The final
 * instance is disposed when the component using this hook unmounts.
 * @param factory A function that creates the resource.
 * @returns The created resource.
 */
declare function useResource<T extends IDisposable$1>(factory: () => T): T;
/**
 * Custom hook to manage an asynchronous resource with automatic disposal. The resource is created once initially, and recreated
 * if the factory function changes. Whenever the resource is recreated, the previous instance is disposed. The final
 * instance is disposed when the component using this hook unmounts.
 * @param factory A function that creates the resource.
 * @returns The created resource.
 */
declare function useAsyncResource<T extends IDisposable$1>(factory: (abortSignal: AbortSignal) => Promise<T>): T | undefined;

/**
 * Gets the compact mode setting.
 * @returns A tuple containing the current compact mode value, a function to update it, and a function to reset it.
 */
declare function useCompactMode(): readonly [boolean, react.Dispatch<react.SetStateAction<boolean>>, () => void];
/**
 * Gets the disable copy setting.
 * @returns A tuple containing the current disable copy value, a function to update it, and a function to reset it.
 */
declare function useDisableCopy(): readonly [boolean, react.Dispatch<react.SetStateAction<boolean>>, () => void];
/**
 * Gets the side pane dock overrides configuration.
 * @returns A record mapping side pane IDs to their dock locations.
 */
declare function useSidePaneDockOverrides(): readonly [Record<string, Readonly<{
    horizontalLocation: HorizontalLocation;
    verticalLocation: VerticalLocation;
}> | undefined>, react.Dispatch<react.SetStateAction<Record<string, Readonly<{
    horizontalLocation: HorizontalLocation;
    verticalLocation: VerticalLocation;
}> | undefined>>>, () => void];
/**
 * Gets functions used to convert to/from display values for angles based on the current settings.
 * @param settings The settings context to use for determining if angles should be displayed in degrees or radians.
 * @returns A tuple containing the functions to convert to and from display values.
 */
declare function useAngleConverters(settings: ISettingsContext): readonly [(angle: number, wrap?: boolean) => number, (angle: number, wrap?: boolean) => number, boolean];

type FunctionHooks<Args extends unknown[] = unknown[]> = {
    /**
     * This function will be called after the hooked function is called.
     * @param args The arguments that were passed to the original function.
     */
    afterCall?: (...args: Args) => void;
};
/**
 * Intercepts a function on an object and allows you to add hooks that will be called during function execution.
 * @param target The object containing the function to intercept.
 * @param propertyKey The key of the property that is a function (this is the function that will be intercepted).
 * @param hooks The hooks to call during the function execution.
 * @returns A disposable that removes the hooks when disposed and returns the object to its original state.
 */
declare function InterceptFunction<T extends object, K extends keyof T>(target: T, propertyKey: string extends K ? never : number extends K ? never : symbol extends K ? never : K, hooks: NonNullable<T[K]> extends (...args: infer Args) => unknown ? FunctionHooks<Args> : FunctionHooks): IDisposable$1;
declare function InterceptFunction<T extends object>(target: T, propertyKey: keyof T, hooks: FunctionHooks): IDisposable$1;

/**
 * Gets the property descriptor for a property on an object, including inherited properties.
 * @param target The object containing the property.
 * @param propertyKey The key of the property to get the descriptor for.
 * @returns The owner of the property (which may be different from the target in the case of inheritance) along with the property descriptor, or null if the property is not found.
 */
declare function GetPropertyDescriptor<T extends object>(target: T, propertyKey: keyof T): Nullable$1<[owner: object, descriptor: PropertyDescriptor]>;
/**
 * Checks if a property is readonly.
 * @param propertyDescriptor The property descriptor to check.
 * @returns True if the property is readonly, false otherwise.
 */
declare function IsPropertyReadonly(propertyDescriptor: PropertyDescriptor): boolean;
type PropertyHooks<T = unknown> = {
    /**
     * This function will be called after the hooked property is set.
     * @param value The new value that was set on the property.
     */
    afterSet?: (value: T) => void;
};
/**
 * Intercepts a property on an object and allows you to add hooks that will be called when the property is get or set.
 * @param target The object containing the property to intercept.
 * @param propertyKey The key of the property to intercept.
 * @param hooks The hooks to call when the property is get or set.
 * @returns A disposable that removes the hooks when disposed and returns the object to its original state.
 */
declare function InterceptProperty<T extends object, K extends keyof T>(target: T, propertyKey: string extends K ? never : number extends K ? never : symbol extends K ? never : K, hooks: PropertyHooks<NonNullable<T[K]>>): IDisposable$1;
declare function InterceptProperty<T extends object>(target: T, propertyKey: keyof T, hooks: PropertyHooks): IDisposable$1;

type PropertyChangeInfo = {
    readonly entity: unknown;
    readonly propertyKey: PropertyKey;
    readonly oldValue: unknown;
    readonly newValue: unknown;
};

declare const PropertiesServiceIdentity: unique symbol;
type PropertiesSectionContent<EntityT> = {
    /**
     * A unique key for the the content.
     */
    key: string;
    /**
     * A predicate function to determine if the content applies to the given entity.
     */
    predicate: (entity: unknown) => entity is EntityT;
} & {
    content: readonly Omit<DynamicAccordionSectionContent<EntityT>, "key">[];
};
/**
 * Allows new sections or content to be added to the properties pane.
 */
interface IPropertiesService extends IService<typeof PropertiesServiceIdentity> {
    /**
     * Adds a new section (e.g. "General", "Transforms", etc.).
     * @param section A description of the section to add.
     */
    addSection(section: DynamicAccordionSection): IDisposable$1;
    /**
     * Adds content to one or more sections.
     * @param content A description of the content to add.
     */
    addSectionContent<EntityT>(content: PropertiesSectionContent<EntityT>): IDisposable$1;
    /**
     * Highlights the specified sections temporarily to draw the user's attention to them.
     * @remarks All other sections are collapsed (but can be expanded by the user) until a different entity is selected.
     * @param sectionIds The identities of the sections to highlight.
     */
    highlightSections(sectionIds: readonly string[]): void;
    /**
     * An observable that notifies when a property has been changed by the user.
     * @remarks This observable only fires for changes made through the properties pane.
     */
    readonly onPropertyChanged: IReadonlyObservable$2<PropertyChangeInfo>;
}

declare const SceneContextIdentity: unique symbol;
/**
 * SceneContext provides the current scene, but could have different implementations depending on the context (e.g. inspector, sandbox, etc.)
 */
interface ISceneContext extends IService<typeof SceneContextIdentity> {
    /**
     * Gets the current scene.
     */
    readonly currentScene: Nullable$1<Scene$1>;
    /**
     * Observable that fires whenever the current scene changes.
     */
    readonly currentSceneObservable: IReadonlyObservable$2<Nullable$1<Scene$1>>;
}

declare const SceneExplorerServiceIdentity: unique symbol;
/**
 * Allows new sections or commands to be added to the scene explorer pane.
 */
interface ISceneExplorerService extends IService<typeof SceneExplorerServiceIdentity> {
    /**
     * Adds a new section (e.g. "Nodes", "Materials", etc.) (this includes all descendants within the scene graph).
     * @param section A description of the section to add.
     */
    addSection<T>(section: SceneExplorerSection<T>): IDisposable$1;
    /**
     * Adds a new command (e.g. "Delete", "Rename", etc.) that can be executed on entities in the scene explorer.
     * @param command A description of the command to add.
     */
    addEntityCommand<T>(command: SceneExplorerCommandProvider<T>): IDisposable$1;
    /**
     * Adds a new command that can be executed on sections in the scene explorer.
     * @param command A description of the command to add.
     */
    addSectionCommand<T extends string>(command: SceneExplorerCommandProvider<T, "contextMenu">): IDisposable$1;
}

declare const DebugServiceIdentity: unique symbol;
/**
 * Allows new sections or content to be added to the debug pane.
 */
interface IDebugService extends IService<typeof DebugServiceIdentity> {
    /**
     * Adds a new section.
     * @param section A description of the section to add.
     */
    addSection(section: DynamicAccordionSection): IDisposable$1;
    /**
     * Adds content to one or more sections.
     * @param content A description of the content to add.
     */
    addSectionContent(content: DynamicAccordionSectionContent<Scene$1>): IDisposable$1;
}

declare const SettingsServiceIdentity: unique symbol;
/**
 * Allows new sections or content to be added to the Settings pane.
 */
interface ISettingsService extends IService<typeof SettingsServiceIdentity> {
    /**
     * Adds a new section.
     * @param section A description of the section to add.
     */
    addSection(section: DynamicAccordionSection): IDisposable$1;
    /**
     * Adds content to one or more sections.
     * @param content A description of the content to add.
     */
    addSectionContent(content: DynamicAccordionSectionContent<Scene$1>): IDisposable$1;
}

declare const StatsServiceIdentity: unique symbol;
/**
 * Allows new sections or content to be added to the stats pane.
 */
interface IStatsService extends IService<typeof StatsServiceIdentity> {
    /**
     * Adds a new section (e.g. "Count", "Frame Steps Duration", etc.).
     * @param section A description of the section to add.
     */
    addSection(section: DynamicAccordionSection): IDisposable$1;
    /**
     * Adds content to one or more sections.
     * @param content A description of the content to add.
     */
    addSectionContent(content: DynamicAccordionSectionContent<Scene$1>): IDisposable$1;
}

declare const ToolsServiceIdentity: unique symbol;
/**
 * A service that provides tools for the user to generate artifacts or perform actions on entities.
 */
interface IToolsService extends IService<typeof ToolsServiceIdentity> {
    /**
     * Adds a new section (e.g. "Export", "Capture", etc.).
     * @param section A description of the section to add.
     */
    addSection(section: DynamicAccordionSection): IDisposable$2;
    /**
     * Adds content to one or more sections.
     * @param content A description of the content to add.
     */
    addSectionContent(content: DynamicAccordionSectionContent<Scene$2>): IDisposable$2;
}

type ModularToolOptions = {
    /**
     * The container element where the tool will be rendered.
     */
    containerElement: HTMLElement;
    /**
     * The service definitions to be registered with the tool.
     */
    serviceDefinitions: readonly WeaklyTypedServiceDefinition[];
    /**
     * The theme mode to use. If not specified, the default is "system", which uses the system/browser preference, and the last used mode is persisted.
     */
    themeMode?: TernaryDarkMode;
    /**
     * Whether to show the theme selector in the toolbar. Default is true.
     */
    showThemeSelector?: boolean;
    /**
     * The extension feeds that provide optional extensions the user can install.
     */
    extensionFeeds?: readonly IExtensionFeed[];
} & ShellServiceOptions;

type LayoutMode = "inline" | "overlay";
type InspectorOptions = Omit<ModularToolOptions, "toolbarMode"> & {
    autoResizeEngine?: boolean;
    layoutMode?: LayoutMode;
};
type InspectorToken = IDisposable$1 & {
    readonly isDisposed: boolean;
    readonly onDisposed: IReadonlyObservable$2<void>;
};
declare function ShowInspector(scene: Scene$1, options?: Partial<InspectorOptions>): InspectorToken;

type PropertyChangedEvent = {
    object: any;
    property: string;
    value: any;
    initialValue: any;
    allowNullValue?: boolean;
};
/**
 * Converts Inspector v1 options to Inspector v2 options.
 * @param v1Options Inspector v1 options.
 * @returns Inspector v2 options.
 */
declare function ConvertOptions(v1Options: Partial<IInspectorOptions$1>): Partial<InspectorOptions>;
/**
 * @deprecated This class only exists for backward compatibility. Use the module-level ShowInspector function instead.
 */
declare class Inspector {
    private static _CurrentInstance;
    private static _PopupToggler;
    private static _SectionHighlighter;
    private static _SidePaneOpenCounter;
    private static get _OpenedPane();
    static readonly OnSelectionChangeObservable: Observable$1<any>;
    static readonly OnPropertyChangedObservable: Observable$1<PropertyChangedEvent>;
    static MarkLineContainerTitleForHighlighting(title: string): void;
    static MarkMultipleLineContainerTitlesForHighlighting(titles: string[]): void;
    static PopupEmbed(): void;
    static PopupSceneExplorer(): void;
    static PopupInspector(): void;
    static get IsVisible(): boolean;
    static Show(scene: Scene$1, userOptions: Partial<IInspectorOptions$1>): void;
    private static _Show;
    static Hide(): void;
    private static _SetNewScene;
}

declare class DebugLayerEx extends DebugLayer$1 {
    show(config?: IInspectorOptions$1): Promise<DebugLayer$1>;
}
declare const DebugLayerExKey: unique symbol;
declare module "@babylonjs/core/scene.js" {
    interface Scene {
        /**
         * @internal
         * Backing field
         */
        [DebugLayerExKey]?: DebugLayerEx;
    }
}
/**
 * Attaches Inspector v2 to Scene.debugLayer.
 */
declare function AttachDebugLayer(): void;
/**
 * Detaches Inspector v2 from Scene.debugLayer.
 */
declare function DetachDebugLayer(): void;

type AccordionSectionProps = {
    title: string;
    collapseByDefault?: boolean;
};
declare const AccordionSection: FunctionComponent<PropsWithChildren<AccordionSectionProps>>;
type AccordionProps = {
    highlightSections?: readonly string[];
};
declare const Accordion: ForwardRefExoticComponent<AccordionProps & {
    children?: react.ReactNode | undefined;
} & RefAttributes<HTMLDivElement>>;

type ButtonProps = BasePrimitiveProps & {
    onClick?: (e?: MouseEvent<HTMLButtonElement>) => unknown | Promise<unknown>;
    icon?: FluentIcon;
    appearance?: "subtle" | "transparent" | "primary" | "secondary";
    label?: string;
};
declare const Button: react.ForwardRefExoticComponent<BasePrimitiveProps & {
    onClick?: (e?: MouseEvent<HTMLButtonElement>) => unknown | Promise<unknown>;
    icon?: FluentIcon;
    appearance?: "subtle" | "transparent" | "primary" | "secondary";
    label?: string;
} & react.RefAttributes<HTMLButtonElement>>;

/**
 * This is a primitive fluent checkbox that can both read and write checked state
 * @param props
 * @returns Checkbox component
 */
declare const Checkbox: FunctionComponent<PrimitiveProps<boolean>>;

type CollapseProps = {
    visible: boolean;
    orientation?: "horizontal" | "vertical";
};
/**
 * Wraps the passed in children with a fluent collapse component, handling smooth animation when visible prop changes
 * NOTE: When passing in children, prefer react fragment over empty div to avoid bloating the react tree with an unnecessary div
 * @param props
 * @returns
 */
declare const Collapse: FunctionComponent<PropsWithChildren<CollapseProps>>;

/** Alias type for value that can be null */
type Nullable<T> = T | null;
/**
 * Alias type for number that are floats
 */
type float = number;
/**
 * Alias type for number that are integer
 */
type int = number;
/**
 * Empty
 */
type Empty = [];
/**
 * The length of T
 */
type Length<T> = T extends {
    length: number;
} ? T["length"] : never;
type _Tuple<T, N extends number, R extends unknown[] = Empty> = R["length"] extends N ? R : _Tuple<T, N, [T, ...R]>;
/**
 * Creates a tuple of T with length N
 */
type Tuple<T, N extends number> = _Tuple<T, N>;
/** Alias type for number array or Float32Array */
type FloatArray = number[] | Float32Array;
/** Alias type for number array or Float32Array or Int32Array or Uint32Array or Uint16Array */
type IndicesArray = number[] | Int32Array | Uint32Array | Uint16Array;
/**
 * Alias for types that can be used by a Buffer or VertexBuffer.
 */
type DataArray = number[] | ArrayBufferLike | ArrayBufferView;
/**
 * Alias type for primitive types
 */
type Primitive = undefined | null | boolean | string | number | Function | Element;
/**
 * Type modifier to make all the properties of an object Readonly
 */
type Immutable<T> = T extends Primitive ? T : T extends Array<infer U> ? ReadonlyArray<U> : DeepImmutable<T>;
/**
 * Type modifier to make all the properties of an object Readonly recursively
 */
type DeepImmutable<T> = T extends Primitive ? T : T extends Array<infer U> ? DeepImmutableArray<U> : DeepImmutableObject<T>;
/**
 * Type modifier to make all the properties of an object NonNullable
 */
type NonNullableFields<T> = {
    [P in keyof T]: NonNullable<T[P]>;
};
/**
 * Type modifier to make object properties readonly.
 */
type DeepImmutableObject<T> = {
    readonly [K in keyof T]: DeepImmutable<T[K]>;
};
/** @internal */
interface DeepImmutableArray<T> extends ReadonlyArray<DeepImmutable<T>> {
}
/**
 * Alias type for image sources
 */
type ImageSource = ImageBitmap | ImageData | HTMLImageElement | HTMLCanvasElement | HTMLVideoElement | OffscreenCanvas;

/**
 * @internal
 */
interface IColor3Like {
    r: float;
    g: float;
    b: float;
}
/**
 * @internal
 */
interface IColor4Like extends IColor3Like {
    a: float;
}
/**
 * @internal
 */
interface IVector2Like {
    x: float;
    y: float;
}
/**
 * @internal
 */
interface IVector3Like extends IVector2Like {
    z: float;
}
/**
 * @internal
 */
interface IVector3LikeInternal {
    _x: number;
    _y: number;
    _z: number;
    _isDirty?: boolean;
}
/**
 * @internal
 */
interface IVector4Like extends IVector3Like {
    w: float;
}
/**
 * @internal
 */
interface IQuaternionLike extends IVector3Like {
    w: float;
}
/**
 * @internal
 */
interface IPlaneLike {
    normal: IVector3Like;
    d: float;
    normalize(): void;
}
/**
 * @internal
 */
interface IMatrixLike {
    asArray(): Tuple<number, 16>;
    updateFlag: int;
}
/**
 * @internal
 */
interface IViewportLike {
    x: float;
    y: float;
    width: float;
    height: float;
}

/**
 * Computes the tensor dimension of a multi-dimensional array
 */
type Dimension<T> = T extends Array<infer U> ? [Length<T>, ...Dimension<U>] : T extends readonly [infer U, ...infer R] ? [Length<T>, ...Dimension<U>] : [];
/**
 * Possible values for a Tensor
 */
type TensorValue = number[] | TensorValue[];
type TensorNumberArray<V extends TensorValue> = Length<Dimension<V>> extends 2 ? Tuple<number, 16> : V;
/**
 * Describes a mathematical tensor.
 * @see https://wikipedia.org/wiki/Tensor
 */
interface Tensor<V extends TensorValue, I> {
    /**
     * An array of the size of each dimension.
     * For example, [3] for a Vector3 and [4,4] for a Matrix
     * @remarks
     * This is to allow implementations with using a getter
     */
    readonly dimension: Readonly<Dimension<V>>;
    /**
     * The rank of the tensor. This is the same as the length of the tensor's dimension array.
     * @remarks
     * This is to allow implementations with using a getter
     */
    readonly rank: number;
    /**
     * Gets class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets current instance hash code
     * @returns the instance hash code as a number
     */
    getHashCode(): number;
    /**
     * Sets the instance coordinates in the given array from the given index.
     * @param array defines the source array
     * @param index defines the offset in source array
     * @returns the current instance
     */
    toArray(array: FloatArray, index?: number): this;
    /**
     * Update the current instance from an array
     * @param array defines the destination array
     * @param index defines the offset in the destination array
     * @returns the current instance
     */
    fromArray(array: DeepImmutable<FloatArray>, index?: number): this;
    /**
     * Copy the current instance to an array
     * @returns a new array with the instance coordinates.
     */
    asArray(): TensorNumberArray<V>;
    /**
     * Sets the current instance coordinates with the given source coordinates
     * @param source defines the source instance
     * @returns the current updated instance
     */
    copyFrom(source: DeepImmutable<I>): this;
    /**
     * Sets the instance coordinates with the given floats
     * @returns the current updated instance
     */
    copyFromFloats(...floats: TensorNumberArray<V>): this;
    /**
     * Sets the instance coordinates with the given floats
     * @returns the current updated instance
     */
    set(...values: TensorNumberArray<V>): this;
    /**
     * Sets the instance coordinates to the given value
     * @returns the current updated instance
     */
    setAll(value: number): this;
    /**
     * Add another instance with the current one
     * @param other defines the other instance
     * @returns a new instance set with the addition of the current instance and the given one coordinates
     */
    add(other: DeepImmutable<I>): Tensor<V, I>;
    /**
     * Sets the "result" coordinates with the addition of the current instance and the given one coordinates
     * @param other defines the other instance
     * @param result defines the target instance
     * @returns result input
     */
    addToRef<R extends I>(other: DeepImmutable<I>, result: R): R;
    /**
     * Set the instance coordinates by adding the given instance coordinates
     * @param other defines the other instance
     * @returns the current updated instance
     */
    addInPlace(other: DeepImmutable<I>): this;
    /**
     * Adds the given coordinates to the current instance
     * @param floats the floats to add
     * @returns the current updated instance
     */
    addInPlaceFromFloats(...floats: TensorNumberArray<V>): this;
    /**
     * Returns a new instance set with the subtracted coordinates of other's coordinates from the current coordinates.
     * @param other defines the other instance
     * @returns a new instance
     */
    subtract(other: DeepImmutable<I>): Tensor<V, I>;
    /**
     * Sets the "result" coordinates with the subtraction of the other's coordinates from the current coordinates.
     * @param other defines the other instance
     * @param result defines the target instance
     * @returns result input
     */
    subtractToRef<R extends I>(other: DeepImmutable<I>, result: R): R;
    /**
     * Sets the current instance coordinates by subtracting from it the given one coordinates
     * @param other defines the other instance
     * @returns the current updated instance
     */
    subtractInPlace(other: DeepImmutable<I>): this;
    /**
     * Returns a new instance set with the subtraction of the given floats from the current instance coordinates
     * @param floats the coordinates to subtract
     * @returns the resulting instance
     */
    subtractFromFloats(...floats: TensorNumberArray<V>): Tensor<V, I>;
    /**
     * Subtracts the given floats from the current instance coordinates and set the given instance "result" with this result
     * Note: Implementation uses array magic so types may be confusing.
     * @param args the coordinates to subtract with the last element as the result
     * @returns the result
     */
    subtractFromFloatsToRef<R extends I>(...args: [...TensorNumberArray<V>, R]): R;
    /**
     * Returns a new instance set with the multiplication of the current instance and the given one coordinates
     * @param other defines the other instance
     * @returns a new instance
     */
    multiply(other: DeepImmutable<I>): Tensor<V, I>;
    /**
     * Sets "result" coordinates with the multiplication of the current instance and the given one coordinates
     * @param other defines the other instance
     * @param result defines the target instance
     * @returns result input
     */
    multiplyToRef<R extends I>(other: DeepImmutable<I>, result: R): R;
    /**
     * Multiplies in place the current instance coordinates by the given ones
     * @param other defines the other instance
     * @returns the current updated instance
     */
    multiplyInPlace(other: DeepImmutable<I>): this;
    /**
     * Gets a new instance set with the instance coordinates multiplied by the given floats
     * @returns a new instance
     */
    multiplyByFloats(...floats: TensorNumberArray<V>): Tensor<V, I>;
    /**
     * Returns a new instance set with the instance coordinates divided by the given one coordinates
     * @param other defines the other instance
     * @returns a new instance
     */
    divide(other: DeepImmutable<I>): Tensor<V, I>;
    /**
     * Sets the "result" coordinates with the instance coordinates divided by the given one coordinates
     * @param other defines the other instance
     * @param result defines the target instance
     * @returns result input
     */
    divideToRef<R extends I>(other: DeepImmutable<I>, result: R): R;
    /**
     * Divides the current instance coordinates by the given ones
     * @param other defines the other instance
     * @returns the current updated instance
     */
    divideInPlace(other: DeepImmutable<I>): this;
    /**
     * Updates the current instance with the minmal coordinate values between its and the given instance ones.
     * @param other defines the other instance
     * @returns this current updated instance
     */
    minimizeInPlace(other: DeepImmutable<I>): this;
    /**
     * Updates the current instance with the minmal coordinate values between its and the given floats.
     * @param floats defines the floats to compare against
     * @returns this current updated instance
     */
    minimizeInPlaceFromFloats(...floats: TensorNumberArray<V>): this;
    /**
     * Updates the current instance with the maximal coordinate values between its and the given instance ones.
     * @param other defines the other instance
     * @returns this current updated instance
     */
    maximizeInPlace(other: DeepImmutable<I>): this;
    /**
     * Updates the current instance with the maximal coordinate values between its and the given floats.
     * @param floats defines the floats to compare against
     * @returns this current updated instance
     */
    maximizeInPlaceFromFloats(...floats: TensorNumberArray<V>): this;
    /**
     * Gets a new instance with current instance negated coordinates
     * @returns a new instance
     */
    negate(): Tensor<V, I>;
    /**
     * Negate this instance in place
     * @returns this
     */
    negateInPlace(): this;
    /**
     * Negate the current instance and stores the result in the given instance "result" coordinates
     * @param result defines the instance object where to store the result
     * @returns the result
     */
    negateToRef<R extends I>(result: R): R;
    /**
     * Multiply the instance coordinates by
     * @param scale defines the scaling factor
     * @returns the current updated instance
     */
    scaleInPlace(scale: number): this;
    /**
     * Returns a new instance scaled by "scale" from the current instance
     * @param scale defines the scaling factor
     * @returns a new instance
     */
    scale(scale: number): Tensor<V, I>;
    /**
     * Scale the current instance values by a factor to a given instance
     * @param scale defines the scale factor
     * @param result defines the instance object where to store the result
     * @returns result input
     */
    scaleToRef<R extends I>(scale: number, result: R): R;
    /**
     * Scale the current instance values by a factor and add the result to a given instance
     * @param scale defines the scale factor
     * @param result defines the instance object where to store the result
     * @returns result input
     */
    scaleAndAddToRef<R extends I>(scale: number, result: R): R;
    /**
     * Gets a boolean if two instances are equals
     * @param other defines the other instance
     * @returns true if the given instance coordinates strictly equal the current instance ones
     */
    equals(other: DeepImmutable<I>): boolean;
    /**
     * Gets a boolean if two instances are equals (using an epsilon value)
     * @param other defines the other instance
     * @param epsilon defines the minimal distance to consider equality
     * @returns true if the given instance coordinates are close to the current ones by a distance of epsilon.
     */
    equalsWithEpsilon(other: DeepImmutable<I>, epsilon?: number): boolean;
    /**
     * Returns true if the current Vectoe coordinates equals the given floats
     * @param floats defines the coordinates to compare against
     * @returns true if both instances are equal
     */
    equalsToFloats(...floats: TensorNumberArray<V>): boolean;
    /**
     * Gets a new instance from current instance floored values
     * eg (1.2, 2.31) returns (1, 2)
     * @returns a new instance
     */
    floor(): Tensor<V, I>;
    /**
     * Gets the current instance's floored values and stores them in result
     * @param result the instance to store the result in
     * @returns the result instance
     */
    floorToRef<R extends I>(result: R): R;
    /**
     * Gets a new instance from current instance fractional values
     * eg (1.2, 2.31) returns (0.2, 0.31)
     * @returns a new instance
     */
    fract(): Tensor<V, I>;
    /**
     * Gets the current instance's fractional values and stores them in result
     * @param result the instance to store the result in
     * @returns the result instance
     */
    fractToRef<R extends I>(result: R): R;
    /**
     * Gets a new instance copied from the instance
     * @returns a new instance
     */
    clone(): Tensor<V, I>;
}

/**
 * Class used to hold a RGB color
 */
declare class Color3 implements Tensor<Tuple<number, 3>, IColor3Like>, IColor3Like {
    /**
     * [0] Defines the red component (between 0 and 1, default is 0)
     */
    r: number;
    /**
     * [0] Defines the green component (between 0 and 1, default is 0)
     */
    g: number;
    /**
     * [0] Defines the blue component (between 0 and 1, default is 0)
     */
    b: number;
    /**
     * If the first color is flagged with integers (as everything is 0,0,0), V8 stores all of the properties as integers internally because it doesn't know any better yet.
     * If subsequent colors are created with non-integer values, V8 determines that it would be best to represent these properties as doubles instead of integers,
     * and henceforth it will use floating-point representation for all color instances that it creates.
     * But the original color instances are unchanged and has a "deprecated map".
     * If we keep using the color instances from step 1, it will now be a poison pill which will mess up optimizations in any code it touches.
     */
    static _V8PerformanceHack: DeepImmutable<Color3>;
    /**
     * @see Tensor.dimension
     */
    readonly dimension: [3];
    /**
     * @see Tensor.rank
     */
    readonly rank: 1;
    /**
     * Creates a new Color3 object from red, green, blue values, all between 0 and 1
     * @param r defines the red component (between 0 and 1, default is 0)
     * @param g defines the green component (between 0 and 1, default is 0)
     * @param b defines the blue component (between 0 and 1, default is 0)
     */
    constructor(
    /**
     * [0] Defines the red component (between 0 and 1, default is 0)
     */
    r?: number, 
    /**
     * [0] Defines the green component (between 0 and 1, default is 0)
     */
    g?: number, 
    /**
     * [0] Defines the blue component (between 0 and 1, default is 0)
     */
    b?: number);
    /**
     * Creates a string with the Color3 current values
     * @returns the string representation of the Color3 object
     */
    toString(): string;
    /**
     * Returns the string "Color3"
     * @returns "Color3"
     */
    getClassName(): string;
    /**
     * Compute the Color3 hash code
     * @returns an unique number that can be used to hash Color3 objects
     */
    getHashCode(): number;
    /**
     * Stores in the given array from the given starting index the red, green, blue values as successive elements
     * @param array defines the array where to store the r,g,b components
     * @param index defines an optional index in the target array to define where to start storing values
     * @returns the current Color3 object
     */
    toArray(array: FloatArray, index?: number): this;
    /**
     * Update the current color with values stored in an array from the starting index of the given array
     * @param array defines the source array
     * @param offset defines an offset in the source array
     * @returns the current Color3 object
     */
    fromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): this;
    /**
     * Returns a new Color4 object from the current Color3 and the given alpha
     * @param alpha defines the alpha component on the new Color4 object (default is 1)
     * @returns a new Color4 object
     */
    toColor4(alpha?: number): Color4;
    /**
     * Returns a new array populated with 3 numeric elements : red, green and blue values
     * @returns the new array
     */
    asArray(): Tuple<number, 3>;
    /**
     * Returns the luminance value
     * @returns a float value
     */
    toLuminance(): number;
    /**
     * Multiply each Color3 rgb values by the given Color3 rgb values in a new Color3 object
     * @param otherColor defines the second operand
     * @returns the new Color3 object
     */
    multiply(otherColor: DeepImmutable<IColor3Like>): Color3;
    /**
     * Multiply the rgb values of the Color3 and the given Color3 and stores the result in the object "result"
     * @param otherColor defines the second operand
     * @param result defines the Color3 object where to store the result
     * @returns the result Color3
     */
    multiplyToRef<T extends IColor3Like>(otherColor: DeepImmutable<IColor3Like>, result: T): T;
    /**
     * Multiplies the current Color3 coordinates by the given ones
     * @param otherColor defines the second operand
     * @returns the current updated Color3
     */
    multiplyInPlace(otherColor: DeepImmutable<IColor3Like>): this;
    /**
     * Returns a new Color3 set with the result of the multiplication of the current Color3 coordinates by the given floats
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @returns the new Color3
     */
    multiplyByFloats(r: number, g: number, b: number): Color3;
    /**
     * @internal
     * Do not use
     */
    divide(_other: DeepImmutable<IColor3Like>): never;
    /**
     * @internal
     * Do not use
     */
    divideToRef(_other: DeepImmutable<IColor3Like>, _result: IColor3Like): never;
    /**
     * @internal
     * Do not use
     */
    divideInPlace(_other: DeepImmutable<IColor3Like>): never;
    /**
     * Updates the current Color3 with the minimal coordinate values between its and the given color ones
     * @param other defines the second operand
     * @returns the current updated Color3
     */
    minimizeInPlace(other: DeepImmutable<IColor3Like>): this;
    /**
     * Updates the current Color3 with the maximal coordinate values between its and the given color ones.
     * @param other defines the second operand
     * @returns the current updated Color3
     */
    maximizeInPlace(other: DeepImmutable<IColor3Like>): this;
    /**
     * Updates the current Color3 with the minimal coordinate values between its and the given coordinates
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @returns the current updated Color3
     */
    minimizeInPlaceFromFloats(r: number, g: number, b: number): this;
    /**
     * Updates the current Color3 with the maximal coordinate values between its and the given coordinates.
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @returns the current updated Color3
     */
    maximizeInPlaceFromFloats(r: number, g: number, b: number): this;
    /**
     * @internal
     * Do not use
     */
    floorToRef(_result: IColor3Like): never;
    /**
     * @internal
     * Do not use
     */
    floor(): never;
    /**
     * @internal
     * Do not use
     */
    fractToRef(_result: IColor3Like): never;
    /**
     * @internal
     * Do not use
     */
    fract(): never;
    /**
     * Determines equality between Color3 objects
     * @param otherColor defines the second operand
     * @returns true if the rgb values are equal to the given ones
     */
    equals(otherColor: DeepImmutable<IColor3Like>): boolean;
    /**
     * Alias for equalsToFloats
     * @param r red color component
     * @param g green color component
     * @param b blue color component
     * @returns boolean
     */
    equalsFloats(r: number, g: number, b: number): boolean;
    /**
     * Determines equality between the current Color3 object and a set of r,b,g values
     * @param r defines the red component to check
     * @param g defines the green component to check
     * @param b defines the blue component to check
     * @returns true if the rgb values are equal to the given ones
     */
    equalsToFloats(r: number, g: number, b: number): boolean;
    /**
     * Returns true if the current Color3 and the given color coordinates are distant less than epsilon
     * @param otherColor defines the second operand
     * @param epsilon defines the minimal distance to define values as equals
     * @returns true if both colors are distant less than epsilon
     */
    equalsWithEpsilon(otherColor: DeepImmutable<IColor3Like>, epsilon?: number): boolean;
    /**
     * @internal
     * Do not use
     */
    negate(): never;
    /**
     * @internal
     * Do not use
     */
    negateInPlace(): never;
    /**
     * @internal
     * Do not use
     */
    negateToRef(_result: IColor3Like): never;
    /**
     * Creates a new Color3 with the current Color3 values multiplied by scale
     * @param scale defines the scaling factor to apply
     * @returns a new Color3 object
     */
    scale(scale: number): Color3;
    /**
     * Multiplies the Color3 values by the float "scale"
     * @param scale defines the scaling factor to apply
     * @returns the current updated Color3
     */
    scaleInPlace(scale: number): this;
    /**
     * Multiplies the rgb values by scale and stores the result into "result"
     * @param scale defines the scaling factor
     * @param result defines the Color3 object where to store the result
     * @returns the result Color3
     */
    scaleToRef<T extends IColor3Like>(scale: number, result: T): T;
    /**
     * Scale the current Color3 values by a factor and add the result to a given Color3
     * @param scale defines the scale factor
     * @param result defines color to store the result into
     * @returns the result Color3
     */
    scaleAndAddToRef<T extends IColor3Like>(scale: number, result: T): T;
    /**
     * Clamps the rgb values by the min and max values and stores the result into "result"
     * @param min defines minimum clamping value (default is 0)
     * @param max defines maximum clamping value (default is 1)
     * @param result defines color to store the result into
     * @returns the result Color3
     */
    clampToRef<T extends IColor3Like>(min: number | undefined, max: number | undefined, result: T): T;
    /**
     * Creates a new Color3 set with the added values of the current Color3 and of the given one
     * @param otherColor defines the second operand
     * @returns the new Color3
     */
    add(otherColor: DeepImmutable<IColor3Like>): Color3;
    /**
     * Adds the given color to the current Color3
     * @param otherColor defines the second operand
     * @returns the current updated Color3
     */
    addInPlace(otherColor: DeepImmutable<IColor3Like>): this;
    /**
     * Adds the given coordinates to the current Color3
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @returns the current updated Color3
     */
    addInPlaceFromFloats(r: number, g: number, b: number): this;
    /**
     * Stores the result of the addition of the current Color3 and given one rgb values into "result"
     * @param otherColor defines the second operand
     * @param result defines Color3 object to store the result into
     * @returns the unmodified current Color3
     */
    addToRef<T extends IColor3Like>(otherColor: DeepImmutable<IColor3Like>, result: T): T;
    /**
     * Returns a new Color3 set with the subtracted values of the given one from the current Color3
     * @param otherColor defines the second operand
     * @returns the new Color3
     */
    subtract(otherColor: DeepImmutable<IColor3Like>): Color3;
    /**
     * Stores the result of the subtraction of given one from the current Color3 rgb values into "result"
     * @param otherColor defines the second operand
     * @param result defines Color3 object to store the result into
     * @returns the unmodified current Color3
     */
    subtractToRef<T extends IColor3Like>(otherColor: DeepImmutable<IColor3Like>, result: T): T;
    /**
     * Subtract the given color from the current Color3
     * @param otherColor defines the second operand
     * @returns the current updated Color3
     */
    subtractInPlace(otherColor: DeepImmutable<IColor3Like>): this;
    /**
     * Returns a new Color3 set with the subtraction of the given floats from the current Color3 coordinates
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @returns the resulting Color3
     */
    subtractFromFloats(r: number, g: number, b: number): Color3;
    /**
     * Subtracts the given floats from the current Color3 coordinates and set the given color "result" with this result
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @param result defines the Color3 object where to store the result
     * @returns the result
     */
    subtractFromFloatsToRef<T extends IColor3Like>(r: number, g: number, b: number, result: T): T;
    /**
     * Copy the current object
     * @returns a new Color3 copied the current one
     */
    clone(): Color3;
    /**
     * Copies the rgb values from the source in the current Color3
     * @param source defines the source Color3 object
     * @returns the updated Color3 object
     */
    copyFrom(source: DeepImmutable<IColor3Like>): this;
    /**
     * Updates the Color3 rgb values from the given floats
     * @param r defines the red component to read from
     * @param g defines the green component to read from
     * @param b defines the blue component to read from
     * @returns the current Color3 object
     */
    copyFromFloats(r: number, g: number, b: number): this;
    /**
     * Updates the Color3 rgb values from the given floats
     * @param r defines the red component to read from
     * @param g defines the green component to read from
     * @param b defines the blue component to read from
     * @returns the current Color3 object
     */
    set(r: number, g: number, b: number): this;
    /**
     * Copies the given float to the current Color3 coordinates
     * @param v defines the r, g and b coordinates of the operand
     * @returns the current updated Color3
     */
    setAll(v: number): this;
    /**
     * Compute the Color3 hexadecimal code as a string
     * @returns a string containing the hexadecimal representation of the Color3 object
     */
    toHexString(): string;
    /**
     * Updates the Color3 rgb values from the string containing valid hexadecimal values
     * @param hex defines a string containing valid hexadecimal values
     * @returns the current Color3 object
     */
    fromHexString(hex: string): this;
    /**
     * Converts current color in rgb space to HSV values
     * @returns a new color3 representing the HSV values
     */
    toHSV(): Color3;
    /**
     * Converts current color in rgb space to HSV values
     * @param result defines the Color3 where to store the HSV values
     * @returns the updated result
     */
    toHSVToRef<T extends IColor3Like>(result: T): T;
    /**
     * Computes a new Color3 converted from the current one to linear space
     * @param exact defines if the conversion will be done in an exact way which is slower but more accurate (default is false)
     * @returns a new Color3 object
     */
    toLinearSpace(exact?: boolean): Color3;
    /**
     * Converts the Color3 values to linear space and stores the result in "convertedColor"
     * @param convertedColor defines the Color3 object where to store the linear space version
     * @param exact defines if the conversion will be done in an exact way which is slower but more accurate (default is false)
     * @returns the unmodified Color3
     */
    toLinearSpaceToRef(convertedColor: IColor3Like, exact?: boolean): this;
    /**
     * Computes a new Color3 converted from the current one to gamma space
     * @param exact defines if the conversion will be done in an exact way which is slower but more accurate (default is false)
     * @returns a new Color3 object
     */
    toGammaSpace(exact?: boolean): Color3;
    /**
     * Converts the Color3 values to gamma space and stores the result in "convertedColor"
     * @param convertedColor defines the Color3 object where to store the gamma space version
     * @param exact defines if the conversion will be done in an exact way which is slower but more accurate (default is false)
     * @returns the unmodified Color3
     */
    toGammaSpaceToRef(convertedColor: IColor3Like, exact?: boolean): this;
    private static _BlackReadOnly;
    /**
     * Converts Hue, saturation and value to a Color3 (RGB)
     * @param hue defines the hue (value between 0 and 360)
     * @param saturation defines the saturation (value between 0 and 1)
     * @param value defines the value (value between 0 and 1)
     * @param result defines the Color3 where to store the RGB values
     * @returns the updated result
     */
    static HSVtoRGBToRef<T extends IColor3Like>(hue: number, saturation: number, value: number, result: T): T;
    /**
     * Converts Hue, saturation and value to a new Color3 (RGB)
     * @param hue defines the hue (value between 0 and 360)
     * @param saturation defines the saturation (value between 0 and 1)
     * @param value defines the value (value between 0 and 1)
     * @returns a new Color3 object
     */
    static FromHSV(hue: number, saturation: number, value: number): Color3;
    /**
     * Creates a new Color3 from the string containing valid hexadecimal values
     * @param hex defines a string containing valid hexadecimal values
     * @returns a new Color3 object
     */
    static FromHexString(hex: string): Color3;
    /**
     * Creates a new Color3 from the starting index of the given array
     * @param array defines the source array
     * @param offset defines an offset in the source array
     * @returns a new Color3 object
     */
    static FromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): Color3;
    /**
     * Creates a new Color3 from the starting index element of the given array
     * @param array defines the source array to read from
     * @param offset defines the offset in the source array
     * @param result defines the target Color3 object
     */
    static FromArrayToRef(array: DeepImmutable<ArrayLike<number>>, offset: number | undefined, result: Color3): void;
    /**
     * Creates a new Color3 from integer values (\< 256)
     * @param r defines the red component to read from (value between 0 and 255)
     * @param g defines the green component to read from (value between 0 and 255)
     * @param b defines the blue component to read from (value between 0 and 255)
     * @returns a new Color3 object
     */
    static FromInts(r: number, g: number, b: number): Color3;
    /**
     * Creates a new Color3 with values linearly interpolated of "amount" between the start Color3 and the end Color3
     * @param start defines the start Color3 value
     * @param end defines the end Color3 value
     * @param amount defines the gradient value between start and end
     * @returns a new Color3 object
     */
    static Lerp(start: DeepImmutable<Color3>, end: DeepImmutable<Color3>, amount: number): Color3;
    /**
     * Creates a new Color3 with values linearly interpolated of "amount" between the start Color3 and the end Color3
     * @param left defines the start value
     * @param right defines the end value
     * @param amount defines the gradient factor
     * @param result defines the Color3 object where to store the result
     */
    static LerpToRef(left: DeepImmutable<Color3>, right: DeepImmutable<Color3>, amount: number, result: Color3): void;
    /**
     * Returns a new Color3 located for "amount" (float) on the Hermite interpolation spline defined by the vectors "value1", "tangent1", "value2", "tangent2"
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent Color3
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent Color3
     * @param amount defines the amount on the interpolation spline (between 0 and 1)
     * @returns the new Color3
     */
    static Hermite(value1: DeepImmutable<Color3>, tangent1: DeepImmutable<Color3>, value2: DeepImmutable<Color3>, tangent2: DeepImmutable<Color3>, amount: number): Color3;
    /**
     * Returns a new Color3 which is the 1st derivative of the Hermite spline defined by the colors "value1", "value2", "tangent1", "tangent2".
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @returns 1st derivative
     */
    static Hermite1stDerivative(value1: DeepImmutable<Color3>, tangent1: DeepImmutable<Color3>, value2: DeepImmutable<Color3>, tangent2: DeepImmutable<Color3>, time: number): Color3;
    /**
     * Returns a new Color3 which is the 1st derivative of the Hermite spline defined by the colors "value1", "value2", "tangent1", "tangent2".
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @param result define where to store the derivative
     */
    static Hermite1stDerivativeToRef(value1: DeepImmutable<Color3>, tangent1: DeepImmutable<Color3>, value2: DeepImmutable<Color3>, tangent2: DeepImmutable<Color3>, time: number, result: Color3): void;
    /**
     * Returns a Color3 value containing a red color
     * @returns a new Color3 object
     */
    static Red(): Color3;
    /**
     * Returns a Color3 value containing a green color
     * @returns a new Color3 object
     */
    static Green(): Color3;
    /**
     * Returns a Color3 value containing a blue color
     * @returns a new Color3 object
     */
    static Blue(): Color3;
    /**
     * Returns a Color3 value containing a black color
     * @returns a new Color3 object
     */
    static Black(): Color3;
    /**
     * Gets a Color3 value containing a black color that must not be updated
     */
    static get BlackReadOnly(): DeepImmutable<Color3>;
    /**
     * Returns a Color3 value containing a white color
     * @returns a new Color3 object
     */
    static White(): Color3;
    /**
     * Returns a Color3 value containing a purple color
     * @returns a new Color3 object
     */
    static Purple(): Color3;
    /**
     * Returns a Color3 value containing a magenta color
     * @returns a new Color3 object
     */
    static Magenta(): Color3;
    /**
     * Returns a Color3 value containing a yellow color
     * @returns a new Color3 object
     */
    static Yellow(): Color3;
    /**
     * Returns a Color3 value containing a gray color
     * @returns a new Color3 object
     */
    static Gray(): Color3;
    /**
     * Returns a Color3 value containing a teal color
     * @returns a new Color3 object
     */
    static Teal(): Color3;
    /**
     * Returns a Color3 value containing a random color
     * @returns a new Color3 object
     */
    static Random(): Color3;
}
/**
 * Class used to hold a RBGA color
 */
declare class Color4 implements Tensor<Tuple<number, 4>, IColor4Like>, IColor4Like {
    /**
     * [0] Defines the red component (between 0 and 1, default is 0)
     */
    r: number;
    /**
     * [0] Defines the green component (between 0 and 1, default is 0)
     */
    g: number;
    /**
     * [0] Defines the blue component (between 0 and 1, default is 0)
     */
    b: number;
    /**
     * [1] Defines the alpha component (between 0 and 1, default is 1)
     */
    a: number;
    /**
     * If the first color is flagged with integers (as everything is 0,0,0,0), V8 stores all of the properties as integers internally because it doesn't know any better yet.
     * If subsequent colors are created with non-integer values, V8 determines that it would be best to represent these properties as doubles instead of integers,
     * and henceforth it will use floating-point representation for all color instances that it creates.
     * But the original color instances are unchanged and has a "deprecated map".
     * If we keep using the color instances from step 1, it will now be a poison pill which will mess up optimizations in any code it touches.
     */
    static _V8PerformanceHack: DeepImmutable<Color4>;
    /**
     * @see Tensor.dimension
     */
    readonly dimension: [4];
    /**
     * @see Tensor.rank
     */
    readonly rank: 1;
    /**
     * Creates a new Color4 object from red, green, blue values, all between 0 and 1
     * @param r defines the red component (between 0 and 1, default is 0)
     * @param g defines the green component (between 0 and 1, default is 0)
     * @param b defines the blue component (between 0 and 1, default is 0)
     * @param a defines the alpha component (between 0 and 1, default is 1)
     */
    constructor(
    /**
     * [0] Defines the red component (between 0 and 1, default is 0)
     */
    r?: number, 
    /**
     * [0] Defines the green component (between 0 and 1, default is 0)
     */
    g?: number, 
    /**
     * [0] Defines the blue component (between 0 and 1, default is 0)
     */
    b?: number, 
    /**
     * [1] Defines the alpha component (between 0 and 1, default is 1)
     */
    a?: number);
    /**
     * Creates a new array populated with 4 numeric elements : red, green, blue, alpha values
     * @returns the new array
     */
    asArray(): Tuple<number, 4>;
    /**
     * Stores from the starting index in the given array the Color4 successive values
     * @param array defines the array where to store the r,g,b components
     * @param index defines an optional index in the target array to define where to start storing values
     * @returns the current Color4 object
     */
    toArray(array: FloatArray, index?: number): this;
    /**
     * Update the current color with values stored in an array from the starting index of the given array
     * @param array defines the source array
     * @param offset defines an offset in the source array
     * @returns the current Color4 object
     */
    fromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): this;
    /**
     * Determines equality between Color4 objects
     * @param otherColor defines the second operand
     * @returns true if the rgba values are equal to the given ones
     */
    equals(otherColor: DeepImmutable<IColor4Like>): boolean;
    /**
     * Creates a new Color4 set with the added values of the current Color4 and of the given one
     * @param otherColor defines the second operand
     * @returns a new Color4 object
     */
    add(otherColor: DeepImmutable<IColor4Like>): Color4;
    /**
     * Updates the given color "result" with the result of the addition of the current Color4 and the given one.
     * @param otherColor the color to add
     * @param result the color to store the result
     * @returns result input
     */
    addToRef<T extends IColor4Like>(otherColor: DeepImmutable<IColor4Like>, result: T): T;
    /**
     * Adds in place the given Color4 values to the current Color4 object
     * @param otherColor defines the second operand
     * @returns the current updated Color4 object
     */
    addInPlace(otherColor: DeepImmutable<IColor4Like>): this;
    /**
     * Adds the given coordinates to the current Color4
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @param a defines the a coordinate of the operand
     * @returns the current updated Color4
     */
    addInPlaceFromFloats(r: number, g: number, b: number, a: number): this;
    /**
     * Creates a new Color4 set with the subtracted values of the given one from the current Color4
     * @param otherColor defines the second operand
     * @returns a new Color4 object
     */
    subtract(otherColor: DeepImmutable<IColor4Like>): Color4;
    /**
     * Subtracts the given ones from the current Color4 values and stores the results in "result"
     * @param otherColor defines the second operand
     * @param result defines the Color4 object where to store the result
     * @returns the result Color4 object
     */
    subtractToRef<T extends IColor4Like>(otherColor: DeepImmutable<IColor4Like>, result: T): T;
    /**
     * Subtract in place the given color from the current Color4.
     * @param otherColor the color to subtract
     * @returns the updated Color4.
     */
    subtractInPlace(otherColor: DeepImmutable<IColor4Like>): this;
    /**
     * Returns a new Color4 set with the result of the subtraction of the given floats from the current Color4 coordinates.
     * @param r value to subtract
     * @param g value to subtract
     * @param b value to subtract
     * @param a value to subtract
     * @returns new color containing the result
     */
    subtractFromFloats(r: number, g: number, b: number, a: number): Color4;
    /**
     * Sets the given color "result" set with the result of the subtraction of the given floats from the current Color4 coordinates.
     * @param r value to subtract
     * @param g value to subtract
     * @param b value to subtract
     * @param a value to subtract
     * @param result the color to store the result in
     * @returns result input
     */
    subtractFromFloatsToRef<T extends IColor4Like>(r: number, g: number, b: number, a: number, result: T): T;
    /**
     * Creates a new Color4 with the current Color4 values multiplied by scale
     * @param scale defines the scaling factor to apply
     * @returns a new Color4 object
     */
    scale(scale: number): Color4;
    /**
     * Multiplies the Color4 values by the float "scale"
     * @param scale defines the scaling factor to apply
     * @returns the current updated Color4
     */
    scaleInPlace(scale: number): this;
    /**
     * Multiplies the current Color4 values by scale and stores the result in "result"
     * @param scale defines the scaling factor to apply
     * @param result defines the Color4 object where to store the result
     * @returns the result Color4
     */
    scaleToRef<T extends IColor4Like>(scale: number, result: T): T;
    /**
     * Scale the current Color4 values by a factor and add the result to a given Color4
     * @param scale defines the scale factor
     * @param result defines the Color4 object where to store the result
     * @returns the result Color4
     */
    scaleAndAddToRef<T extends IColor4Like>(scale: number, result: T): T;
    /**
     * Clamps the rgb values by the min and max values and stores the result into "result"
     * @param min defines minimum clamping value (default is 0)
     * @param max defines maximum clamping value (default is 1)
     * @param result defines color to store the result into.
     * @returns the result Color4
     */
    clampToRef<T extends IColor4Like>(min: number | undefined, max: number | undefined, result: T): T;
    /**
     * Multiply an Color4 value by another and return a new Color4 object
     * @param color defines the Color4 value to multiply by
     * @returns a new Color4 object
     */
    multiply(color: DeepImmutable<IColor4Like>): Color4;
    /**
     * Multiply a Color4 value by another and push the result in a reference value
     * @param color defines the Color4 value to multiply by
     * @param result defines the Color4 to fill the result in
     * @returns the result Color4
     */
    multiplyToRef<T extends IColor4Like>(color: DeepImmutable<IColor4Like>, result: T): T;
    /**
     * Multiplies in place the current Color4 by the given one.
     * @param otherColor color to multiple with
     * @returns the updated Color4.
     */
    multiplyInPlace(otherColor: DeepImmutable<IColor4Like>): this;
    /**
     * Returns a new Color4 set with the multiplication result of the given floats and the current Color4 coordinates.
     * @param r value multiply with
     * @param g value multiply with
     * @param b value multiply with
     * @param a value multiply with
     * @returns resulting new color
     */
    multiplyByFloats(r: number, g: number, b: number, a: number): Color4;
    /**
     * @internal
     * Do not use
     */
    divide(_other: DeepImmutable<IColor4Like>): never;
    /**
     * @internal
     * Do not use
     */
    divideToRef(_other: DeepImmutable<IColor4Like>, _result: IColor4Like): never;
    /**
     * @internal
     * Do not use
     */
    divideInPlace(_other: DeepImmutable<IColor4Like>): never;
    /**
     * Updates the Color4 coordinates with the minimum values between its own and the given color ones
     * @param other defines the second operand
     * @returns the current updated Color4
     */
    minimizeInPlace(other: DeepImmutable<IColor4Like>): this;
    /**
     * Updates the Color4 coordinates with the maximum values between its own and the given color ones
     * @param other defines the second operand
     * @returns the current updated Color4
     */
    maximizeInPlace(other: DeepImmutable<IColor4Like>): this;
    /**
     * Updates the current Color4 with the minimal coordinate values between its and the given coordinates
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @param a defines the a coordinate of the operand
     * @returns the current updated Color4
     */
    minimizeInPlaceFromFloats(r: number, g: number, b: number, a: number): this;
    /**
     * Updates the current Color4 with the maximal coordinate values between its and the given coordinates.
     * @param r defines the r coordinate of the operand
     * @param g defines the g coordinate of the operand
     * @param b defines the b coordinate of the operand
     * @param a defines the a coordinate of the operand
     * @returns the current updated Color4
     */
    maximizeInPlaceFromFloats(r: number, g: number, b: number, a: number): this;
    /**
     * @internal
     * Do not use
     */
    floorToRef(_result: IColor4Like): never;
    /**
     * @internal
     * Do not use
     */
    floor(): never;
    /**
     * @internal
     * Do not use
     */
    fractToRef(_result: IColor4Like): never;
    /**
     * @internal
     * Do not use
     */
    fract(): never;
    /**
     * @internal
     * Do not use
     */
    negate(): never;
    /**
     * @internal
     * Do not use
     */
    negateInPlace(): never;
    /**
     * @internal
     * Do not use
     */
    negateToRef(_result: IColor4Like): never;
    /**
     * Boolean : True if the current Color4 coordinates are each beneath the distance "epsilon" from the given color ones.
     * @param otherColor color to compare against
     * @param epsilon (Default: very small number)
     * @returns true if they are equal
     */
    equalsWithEpsilon(otherColor: DeepImmutable<IColor4Like>, epsilon?: number): boolean;
    /**
     * Boolean : True if the given floats are strictly equal to the current Color4 coordinates.
     * @param x x value to compare against
     * @param y y value to compare against
     * @param z z value to compare against
     * @param w w value to compare against
     * @returns true if equal
     */
    equalsToFloats(x: number, y: number, z: number, w: number): boolean;
    /**
     * Creates a string with the Color4 current values
     * @returns the string representation of the Color4 object
     */
    toString(): string;
    /**
     * Returns the string "Color4"
     * @returns "Color4"
     */
    getClassName(): string;
    /**
     * Compute the Color4 hash code
     * @returns an unique number that can be used to hash Color4 objects
     */
    getHashCode(): number;
    /**
     * Creates a new Color4 copied from the current one
     * @returns a new Color4 object
     */
    clone(): Color4;
    /**
     * Copies the given Color4 values into the current one
     * @param source defines the source Color4 object
     * @returns the current updated Color4 object
     */
    copyFrom(source: DeepImmutable<IColor4Like>): this;
    /**
     * Copies the given float values into the current one
     * @param r defines the red component to read from
     * @param g defines the green component to read from
     * @param b defines the blue component to read from
     * @param a defines the alpha component to read from
     * @returns the current updated Color4 object
     */
    copyFromFloats(r: number, g: number, b: number, a: number): this;
    /**
     * Copies the given float values into the current one
     * @param r defines the red component to read from
     * @param g defines the green component to read from
     * @param b defines the blue component to read from
     * @param a defines the alpha component to read from
     * @returns the current updated Color4 object
     */
    set(r: number, g: number, b: number, a: number): this;
    /**
     * Copies the given float to the current Vector4 coordinates
     * @param v defines the r, g, b, and a coordinates of the operand
     * @returns the current updated Vector4
     */
    setAll(v: number): this;
    /**
     * Compute the Color4 hexadecimal code as a string
     * @param returnAsColor3 defines if the string should only contains RGB values (off by default)
     * @returns a string containing the hexadecimal representation of the Color4 object
     */
    toHexString(returnAsColor3?: boolean): string;
    /**
     * Updates the Color4 rgba values from the string containing valid hexadecimal values.
     *
     * A valid hex string is either in the format #RRGGBB or #RRGGBBAA.
     *
     * When a hex string without alpha is passed, the resulting Color4 keeps
     * its previous alpha value.
     *
     * An invalid string does not modify this object
     *
     * @param hex defines a string containing valid hexadecimal values
     * @returns the current updated Color4 object
     */
    fromHexString(hex: string): this;
    /**
     * Computes a new Color4 converted from the current one to linear space
     * @param exact defines if the conversion will be done in an exact way which is slower but more accurate (default is false)
     * @returns a new Color4 object
     */
    toLinearSpace(exact?: boolean): Color4;
    /**
     * Converts the Color4 values to linear space and stores the result in "convertedColor"
     * @param convertedColor defines the Color4 object where to store the linear space version
     * @param exact defines if the conversion will be done in an exact way which is slower but more accurate (default is false)
     * @returns the unmodified Color4
     */
    toLinearSpaceToRef(convertedColor: IColor4Like, exact?: boolean): this;
    /**
     * Computes a new Color4 converted from the current one to gamma space
     * @param exact defines if the conversion will be done in an exact way which is slower but more accurate (default is false)
     * @returns a new Color4 object
     */
    toGammaSpace(exact?: boolean): Color4;
    /**
     * Converts the Color4 values to gamma space and stores the result in "convertedColor"
     * @param convertedColor defines the Color4 object where to store the gamma space version
     * @param exact defines if the conversion will be done in an exact way which is slower but more accurate (default is false)
     * @returns the unmodified Color4
     */
    toGammaSpaceToRef(convertedColor: IColor4Like, exact?: boolean): this;
    /**
     * Creates a new Color4 from the string containing valid hexadecimal values.
     *
     * A valid hex string is either in the format #RRGGBB or #RRGGBBAA.
     *
     * When a hex string without alpha is passed, the resulting Color4 has
     * its alpha value set to 1.0.
     *
     * An invalid string results in a Color with all its channels set to 0.0,
     * i.e. "transparent black".
     *
     * @param hex defines a string containing valid hexadecimal values
     * @returns a new Color4 object
     */
    static FromHexString(hex: string): Color4;
    /**
     * Creates a new Color4 object set with the linearly interpolated values of "amount" between the left Color4 object and the right Color4 object
     * @param left defines the start value
     * @param right defines the end value
     * @param amount defines the gradient factor
     * @returns a new Color4 object
     */
    static Lerp(left: DeepImmutable<IColor4Like>, right: DeepImmutable<IColor4Like>, amount: number): Color4;
    /**
     * Set the given "result" with the linearly interpolated values of "amount" between the left Color4 object and the right Color4 object
     * @param left defines the start value
     * @param right defines the end value
     * @param amount defines the gradient factor
     * @param result defines the Color4 object where to store data
     * @returns the updated result
     */
    static LerpToRef<T extends IColor4Like>(left: DeepImmutable<IColor4Like>, right: DeepImmutable<IColor4Like>, amount: number, result: T): T;
    /**
     * Interpolate between two Color4 using Hermite interpolation
     * @param value1 defines first Color4
     * @param tangent1 defines the incoming tangent
     * @param value2 defines second Color4
     * @param tangent2 defines the outgoing tangent
     * @param amount defines the target Color4
     * @returns the new interpolated Color4
     */
    static Hermite(value1: DeepImmutable<IColor4Like>, tangent1: DeepImmutable<IColor4Like>, value2: DeepImmutable<IColor4Like>, tangent2: DeepImmutable<IColor4Like>, amount: number): Color4;
    /**
     * Returns a new Color4 which is the 1st derivative of the Hermite spline defined by the colors "value1", "value2", "tangent1", "tangent2".
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @returns 1st derivative
     */
    static Hermite1stDerivative(value1: DeepImmutable<IColor4Like>, tangent1: DeepImmutable<IColor4Like>, value2: DeepImmutable<IColor4Like>, tangent2: DeepImmutable<IColor4Like>, time: number): Color4;
    /**
     * Update a Color4 with the 1st derivative of the Hermite spline defined by the colors "value1", "value2", "tangent1", "tangent2".
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @param result define where to store the derivative
     */
    static Hermite1stDerivativeToRef(value1: DeepImmutable<IColor4Like>, tangent1: DeepImmutable<IColor4Like>, value2: DeepImmutable<IColor4Like>, tangent2: DeepImmutable<IColor4Like>, time: number, result: IColor4Like): void;
    /**
     * Creates a new Color4 from a Color3 and an alpha value
     * @param color3 defines the source Color3 to read from
     * @param alpha defines the alpha component (1.0 by default)
     * @returns a new Color4 object
     */
    static FromColor3(color3: DeepImmutable<IColor3Like>, alpha?: number): Color4;
    /**
     * Creates a new Color4 from the starting index element of the given array
     * @param array defines the source array to read from
     * @param offset defines the offset in the source array
     * @returns a new Color4 object
     */
    static FromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): Color4;
    /**
     * Creates a new Color4 from the starting index element of the given array
     * @param array defines the source array to read from
     * @param offset defines the offset in the source array
     * @param result defines the target Color4 object
     */
    static FromArrayToRef(array: DeepImmutable<ArrayLike<number>>, offset: number | undefined, result: Color4): void;
    /**
     * Creates a new Color3 from integer values (less than 256)
     * @param r defines the red component to read from (value between 0 and 255)
     * @param g defines the green component to read from (value between 0 and 255)
     * @param b defines the blue component to read from (value between 0 and 255)
     * @param a defines the alpha component to read from (value between 0 and 255)
     * @returns a new Color3 object
     */
    static FromInts(r: number, g: number, b: number, a: number): Color4;
    /**
     * Check the content of a given array and convert it to an array containing RGBA data
     * If the original array was already containing count * 4 values then it is returned directly
     * @param colors defines the array to check
     * @param count defines the number of RGBA data to expect
     * @returns an array containing count * 4 values (RGBA)
     */
    static CheckColors4(colors: number[], count: number): number[];
}

type ColorPickerProps<C extends Color3 | Color4> = {
    isLinearMode?: boolean;
} & PrimitiveProps<C>;
declare const ColorPickerPopup: react.ForwardRefExoticComponent<{
    isLinearMode?: boolean;
} & BasePrimitiveProps & {
    value: Color3 | Color4;
    infoLabel?: InfoLabelParentProps;
} & {
    onChange: (value: Color3 | Color4) => void;
} & react.RefAttributes<HTMLButtonElement>>;
type InputHexProps = PrimitiveProps<Color3 | Color4> & {
    linearHex?: boolean;
    isLinearMode?: boolean;
};
/**
 * Component which displays the passed in color's HEX value, either in linearSpace (if linearHex is true) or in gamma space
 * When the hex color is changed by user, component calculates the new Color3/4 value and calls onChange
 *
 * Component uses the isLinearMode boolean to display an informative label regarding linear / gamma space
 * @param props - The properties for the InputHexField component.
 * @returns
 */
declare const InputHexField: FunctionComponent<InputHexProps>;
type HsvKey = "h" | "s" | "v";
type InputHsvFieldProps = PrimitiveProps<Color3 | Color4> & {
    hsvKey: HsvKey;
    max: number;
    scale?: number;
};
/**
 * In the HSV (Hue, Saturation, Value) color model, Hue (H) ranges from 0 to 360 degrees, representing the color's position on the color wheel.
 * Saturation (S) ranges from 0 to 100%, indicating the intensity or purity of the color, with 0 being shades of gray and 100 being a fully saturated color.
 * Value (V) ranges from 0 to 100%, representing the brightness of the color, with 0 being black and 100 being the brightest.
 * @param props - The properties for the InputHsvField component.
 */
declare const InputHsvField: FunctionComponent<InputHsvFieldProps>;

/**
 * An option object for the ComboBox with separate label and value.
 */
type ComboBoxOption = {
    /**
     * Defines the visible part of the option
     */
    label: string;
    /**
     * Defines the value part of the option
     */
    value: string;
};
type ComboBoxProps = PrimitiveProps<string> & {
    /**
     * Label for the ComboBox
     */
    label: string;
    /**
     * Options to display as label/value pairs
     */
    options: ComboBoxOption[];
};
/**
 * Wrapper around a Fluent ComboBox that allows for filtering options.
 * @param props
 * @returns
 */
declare const ComboBox: FunctionComponent<ComboBoxProps>;

type DraggableLineProps = {
    format: string;
    data: string;
    tooltip: string;
    label: string;
    onDelete?: () => void;
};
declare const DraggableLine: React.FunctionComponent<DraggableLineProps>;

type AcceptedDropdownValue = string | number;
type DropdownOption<T extends AcceptedDropdownValue> = {
    /**
     * Defines the visible part of the option
     */
    label: string;
    /**
     * Defines the value part of the option
     */
    value: T;
};
type DropdownProps<V extends AcceptedDropdownValue> = PrimitiveProps<V> & {
    options: readonly DropdownOption<V>[];
};
/**
 * Renders a fluent UI dropdown component for the options passed in, and an additional 'Not Defined' option if null is set to true
 * This component can handle both null and undefined values
 * @param props
 * @returns dropdown component
 */
declare const Dropdown: FunctionComponent<DropdownProps<AcceptedDropdownValue>>;
declare const NumberDropdown: FunctionComponent<DropdownProps<number>>;
declare const StringDropdown: FunctionComponent<DropdownProps<string>>;

/** Interface used by value gradients (color, factor, ...) */
interface IValueGradient {
    /**
     * Gets or sets the gradient value (between 0 and 1)
     */
    gradient: number;
}
/** Class used to store color4 gradient */
declare class ColorGradient implements IValueGradient {
    /**
     * Gets or sets the gradient value (between 0 and 1)
     */
    gradient: number;
    /**
     * Gets or sets first associated color
     */
    color1: Color4;
    /**
     * Gets or sets second associated color
     */
    color2?: Color4 | undefined;
    /**
     * Creates a new color4 gradient
     * @param gradient gets or sets the gradient value (between 0 and 1)
     * @param color1 gets or sets first associated color
     * @param color2 gets or sets first second color
     */
    constructor(
    /**
     * Gets or sets the gradient value (between 0 and 1)
     */
    gradient: number, 
    /**
     * Gets or sets first associated color
     */
    color1: Color4, 
    /**
     * Gets or sets second associated color
     */
    color2?: Color4 | undefined);
    /**
     * Will get a color picked randomly between color1 and color2.
     * If color2 is undefined then color1 will be used
     * @param result defines the target Color4 to store the result in
     */
    getColorToRef(result: Color4): void;
}
/** Class used to store color 3 gradient */
declare class Color3Gradient implements IValueGradient {
    /**
     * Gets or sets the gradient value (between 0 and 1)
     */
    gradient: number;
    /**
     * Gets or sets the associated color
     */
    color: Color3;
    /**
     * Creates a new color3 gradient
     * @param gradient gets or sets the gradient value (between 0 and 1)
     * @param color gets or sets associated color
     */
    constructor(
    /**
     * Gets or sets the gradient value (between 0 and 1)
     */
    gradient: number, 
    /**
     * Gets or sets the associated color
     */
    color: Color3);
}
/** Class used to store factor gradient */
declare class FactorGradient implements IValueGradient {
    /**
     * Gets or sets the gradient value (between 0 and 1)
     */
    gradient: number;
    /**
     * Gets or sets first associated factor
     */
    factor1: number;
    /**
     * Gets or sets second associated factor
     */
    factor2?: number | undefined;
    /**
     * Creates a new factor gradient
     * @param gradient gets or sets the gradient value (between 0 and 1)
     * @param factor1 gets or sets first associated factor
     * @param factor2 gets or sets second associated factor
     */
    constructor(
    /**
     * Gets or sets the gradient value (between 0 and 1)
     */
    gradient: number, 
    /**
     * Gets or sets first associated factor
     */
    factor1: number, 
    /**
     * Gets or sets second associated factor
     */
    factor2?: number | undefined);
    /**
     * Will get a number picked randomly between factor1 and factor2.
     * If factor2 is undefined then factor1 will be used
     * @returns the picked number
     */
    getFactor(): number;
}

/**
 * Defines the kind of connection point for node based material
 */
declare enum NodeMaterialBlockConnectionPointTypes {
    /** Float */
    Float = 1,
    /** Int */
    Int = 2,
    /** Vector2 */
    Vector2 = 4,
    /** Vector3 */
    Vector3 = 8,
    /** Vector4 */
    Vector4 = 16,
    /** Color3 */
    Color3 = 32,
    /** Color4 */
    Color4 = 64,
    /** Matrix */
    Matrix = 128,
    /** Custom object */
    Object = 256,
    /** Detect type based on connection */
    AutoDetect = 1024,
    /** Output type that will be defined by input type */
    BasedOnInput = 2048,
    /** Bitmask of all types */
    All = 4095
}

/**
 * Enum used to define the target of a block
 */
declare enum NodeMaterialBlockTargets {
    /** Vertex shader */
    Vertex = 1,
    /** Fragment shader */
    Fragment = 2,
    /** Neutral */
    Neutral = 4,
    /** Vertex and Fragment */
    VertexAndFragment = 3
}

/**
 * Enum used to define system values e.g. values automatically provided by the system
 */
declare enum NodeMaterialSystemValues {
    /** World */
    World = 1,
    /** View */
    View = 2,
    /** Projection */
    Projection = 3,
    /** ViewProjection */
    ViewProjection = 4,
    /** WorldView */
    WorldView = 5,
    /** WorldViewProjection */
    WorldViewProjection = 6,
    /** CameraPosition */
    CameraPosition = 7,
    /** Fog Color */
    FogColor = 8,
    /** Delta time */
    DeltaTime = 9,
    /** Camera parameters */
    CameraParameters = 10,
    /** Material alpha */
    MaterialAlpha = 11,
    /** Projection */
    ProjectionInverse = 12,
    /** CameraForward */
    CameraForward = 13
}

/**
 * A class serves as a medium between the observable and its observers
 */
declare class EventState {
    /**
     * Create a new EventState
     * @param mask defines the mask associated with this state
     * @param skipNextObservers defines a flag which will instruct the observable to skip following observers when set to true
     * @param target defines the original target of the state
     * @param currentTarget defines the current target of the state
     */
    constructor(mask: number, skipNextObservers?: boolean, target?: any, currentTarget?: any);
    /**
     * Initialize the current event state
     * @param mask defines the mask associated with this state
     * @param skipNextObservers defines a flag which will instruct the observable to skip following observers when set to true
     * @param target defines the original target of the state
     * @param currentTarget defines the current target of the state
     * @returns the current event state
     */
    initialize(mask: number, skipNextObservers?: boolean, target?: any, currentTarget?: any): EventState;
    /**
     * An Observer can set this property to true to prevent subsequent observers of being notified
     */
    skipNextObservers: boolean;
    /**
     * Get the mask value that were used to trigger the event corresponding to this EventState object
     */
    mask: number;
    /**
     * The object that originally notified the event
     */
    target?: any;
    /**
     * The current object in the bubbling phase
     */
    currentTarget?: any;
    /**
     * This will be populated with the return value of the last function that was executed.
     * If it is the first function in the callback chain it will be the event data.
     */
    lastReturnValue?: any;
    /**
     * User defined information that will be sent to observers
     */
    userInfo?: any;
}
/**
 * Represent an observer registered to a given IObservable object.
 */
interface IObserver {
    /**
     * Remove the observer from its observable
     * @param defer if true, the removal will be deferred to avoid callback skipping (default: false)
     */
    remove(defer?: boolean): void;
}
/**
 * Represent an observer registered to a given Observable object.
 */
declare class Observer<T> implements IObserver {
    /**
     * Defines the callback to call when the observer is notified
     */
    callback: (eventData: T, eventState: EventState) => void;
    /**
     * Defines the mask of the observer (used to filter notifications)
     */
    mask: number;
    /**
     * [null] Defines the current scope used to restore the JS context
     */
    scope: any;
    /** @internal */
    _willBeUnregistered: boolean;
    /**
     * Gets or sets a property defining that the observer as to be unregistered after the next notification
     */
    unregisterOnNextCall: boolean;
    /**
     * this function can be used to remove the observer from the observable.
     * It will be set by the observable that the observer belongs to.
     * @internal
     */
    _remove: Nullable<(defer?: boolean) => void>;
    /**
     * Creates a new observer
     * @param callback defines the callback to call when the observer is notified
     * @param mask defines the mask of the observer (used to filter notifications)
     * @param scope defines the current scope used to restore the JS context
     */
    constructor(
    /**
     * Defines the callback to call when the observer is notified
     */
    callback: (eventData: T, eventState: EventState) => void, 
    /**
     * Defines the mask of the observer (used to filter notifications)
     */
    mask: number, 
    /**
     * [null] Defines the current scope used to restore the JS context
     */
    scope?: any);
    /**
     * Remove the observer from its observable
     * This can be used instead of using the observable's remove function.
     * @param defer if true, the removal will be deferred to avoid callback skipping (default: false)
     */
    remove(defer?: boolean): void;
}
/**
 * An interface that defines the reader side of an Observable (receive notifications).
 */
interface IReadonlyObservable<T = unknown> {
    /**
     * Create a new Observer with the specified callback
     * @param callback the callback that will be executed for that Observer
     * @param mask the mask used to filter observers
     * @param insertFirst if true the callback will be inserted at the first position, hence executed before the others ones. If false (default behavior) the callback will be inserted at the last position, executed after all the others already present.
     * @param scope optional scope for the callback to be called from
     * @param unregisterOnFirstCall defines if the observer as to be unregistered after the next notification
     * @returns the new observer created for the callback
     */
    add(callback: (eventData: T, eventState: EventState) => void, mask?: number, insertFirst?: boolean, scope?: unknown, unregisterOnFirstCall?: boolean): IObserver;
    /**
     * Create a new Observer with the specified callback and unregisters after the next notification
     * @param callback the callback that will be executed for that Observer
     * @returns the new observer created for the callback
     */
    addOnce(callback: (eventData: T, eventState: EventState) => void): IObserver;
}
/**
 * The Observable class is a simple implementation of the Observable pattern.
 *
 * There's one slight particularity though: a given Observable can notify its observer using a particular mask value, only the Observers registered with this mask value will be notified.
 * This enable a more fine grained execution without having to rely on multiple different Observable objects.
 * For instance you may have a given Observable that have four different types of notifications: Move (mask = 0x01), Stop (mask = 0x02), Turn Right (mask = 0X04), Turn Left (mask = 0X08).
 * A given observer can register itself with only Move and Stop (mask = 0x03), then it will only be notified when one of these two occurs and will never be for Turn Left/Right.
 */
declare class Observable<T> implements IReadonlyObservable<T> {
    /**
     * [false] If set to true the observable will notify when an observer was added if the observable was already triggered.
     * This is helpful to single-state observables like the scene onReady or the dispose observable.
     */
    notifyIfTriggered: boolean;
    private _observers;
    private _numObserversMarkedAsDeleted;
    private _hasNotified;
    private _lastNotifiedValue?;
    /**
     * @internal
     */
    _eventState: EventState;
    private _onObserverAdded;
    /**
     * Create an observable from a Promise.
     * @param promise a promise to observe for fulfillment.
     * @param onErrorObservable an observable to notify if a promise was rejected.
     * @returns the new Observable
     */
    static FromPromise<T, E = Error>(promise: Promise<T>, onErrorObservable?: Observable<E>): Observable<T>;
    /**
     * Gets the list of observers
     * Note that observers that were recently deleted may still be present in the list because they are only really deleted on the next javascript tick!
     */
    get observers(): Array<Observer<T>>;
    /**
     * Creates a new observable
     * @param onObserverAdded defines a callback to call when a new observer is added
     * @param notifyIfTriggered If set to true the observable will notify when an observer was added if the observable was already triggered.
     */
    constructor(onObserverAdded?: (observer: Observer<T>) => void, 
    /**
     * [false] If set to true the observable will notify when an observer was added if the observable was already triggered.
     * This is helpful to single-state observables like the scene onReady or the dispose observable.
     */
    notifyIfTriggered?: boolean);
    /**
     * Create a new Observer with the specified callback
     * @param callback the callback that will be executed for that Observer
     * @param mask the mask used to filter observers
     * @param insertFirst if true the callback will be inserted at the first position, hence executed before the others ones. If false (default behavior) the callback will be inserted at the last position, executed after all the others already present.
     * @param scope optional scope for the callback to be called from
     * @param unregisterOnFirstCall defines if the observer as to be unregistered after the next notification
     * @returns the new observer created for the callback
     */
    add(callback?: null, mask?: number, insertFirst?: boolean, scope?: any, unregisterOnFirstCall?: boolean): null;
    add(callback: (eventData: T, eventState: EventState) => void, mask?: number, insertFirst?: boolean, scope?: any, unregisterOnFirstCall?: boolean): Observer<T>;
    add(callback?: ((eventData: T, eventState: EventState) => void) | null, mask?: number, insertFirst?: boolean, scope?: any, unregisterOnFirstCall?: boolean): Nullable<Observer<T>>;
    /**
     * Create a new Observer with the specified callback and unregisters after the next notification
     * @param callback the callback that will be executed for that Observer
     * @returns the new observer created for the callback
     */
    addOnce(callback?: null): null;
    addOnce(callback: (eventData: T, eventState: EventState) => void): Observer<T>;
    addOnce(callback?: ((eventData: T, eventState: EventState) => void) | null): Nullable<Observer<T>>;
    /**
     * Remove an Observer from the Observable object
     * @param observer the instance of the Observer to remove
     * @returns false if it doesn't belong to this Observable
     */
    remove(observer: Nullable<Observer<T>>): boolean;
    /**
     * Remove a callback from the Observable object
     * @param callback the callback to remove
     * @param scope optional scope. If used only the callbacks with this scope will be removed
     * @returns false if it doesn't belong to this Observable
     */
    removeCallback(callback: (eventData: T, eventState: EventState) => void, scope?: any): boolean;
    /**
     * @internal
     */
    _deferUnregister(observer: Observer<T>): void;
    private _remove;
    /**
     * Moves the observable to the top of the observer list making it get called first when notified
     * @param observer the observer to move
     */
    makeObserverTopPriority(observer: Observer<T>): void;
    /**
     * Moves the observable to the bottom of the observer list making it get called last when notified
     * @param observer the observer to move
     */
    makeObserverBottomPriority(observer: Observer<T>): void;
    /**
     * Notify all Observers by calling their respective callback with the given data
     * Will return true if all observers were executed, false if an observer set skipNextObservers to true, then prevent the subsequent ones to execute
     * @param eventData defines the data to send to all observers
     * @param mask defines the mask of the current notification (observers with incompatible mask (ie mask & observer.mask === 0) will not be notified)
     * @param target defines the original target of the state
     * @param currentTarget defines the current target of the state
     * @param userInfo defines any user info to send to observers
     * @returns false if the complete observer chain was not processed (because one observer set the skipNextObservers to true)
     */
    notifyObservers(eventData: T, mask?: number, target?: any, currentTarget?: any, userInfo?: any): boolean;
    /**
     * Notify a specific observer
     * @param observer defines the observer to notify
     * @param eventData defines the data to be sent to each callback
     * @param mask is used to filter observers defaults to -1
     */
    notifyObserver(observer: Observer<T>, eventData: T, mask?: number): void;
    /**
     * Gets a boolean indicating if the observable has at least one observer
     * @returns true is the Observable has at least one Observer registered
     */
    hasObservers(): boolean;
    /**
     * Clear the list of observers
     */
    clear(): void;
    /**
     * Clean the last notified state - both the internal last value and the has-notified flag
     */
    cleanLastNotifiedState(): void;
    /**
     * Clone the current observable
     * @returns a new observable
     */
    clone(): Observable<T>;
    /**
     * Does this observable handles observer registered with a given mask
     * @param mask defines the mask to be tested
     * @returns whether or not one observer registered with the given mask is handled
     **/
    hasSpecificMask(mask?: number): boolean;
}

/**
 * This represents the main contract an easing function should follow.
 * Easing functions are used throughout the animation system.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#easing-functions
 */
interface IEasingFunction {
    /**
     * Given an input gradient between 0 and 1, this returns the corresponding value
     * of the easing function.
     * The link below provides some of the most common examples of easing functions.
     * @see https://easings.net/
     * @param gradient Defines the value between 0 and 1 we want the easing value for
     * @returns the corresponding value on the curve defined by the easing function
     */
    ease(gradient: number): number;
}
/**
 * Base class used for every default easing function.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#easing-functions
 */
declare class EasingFunction implements IEasingFunction {
    /**
     * Interpolation follows the mathematical formula associated with the easing function.
     */
    static readonly EASINGMODE_EASEIN = 0;
    /**
     * Interpolation follows 100% interpolation minus the output of the formula associated with the easing function.
     */
    static readonly EASINGMODE_EASEOUT = 1;
    /**
     * Interpolation uses EaseIn for the first half of the animation and EaseOut for the second half.
     */
    static readonly EASINGMODE_EASEINOUT = 2;
    private _easingMode;
    /**
     * Sets the easing mode of the current function.
     * @param easingMode Defines the willing mode (EASINGMODE_EASEIN, EASINGMODE_EASEOUT or EASINGMODE_EASEINOUT)
     */
    setEasingMode(easingMode: number): void;
    /**
     * Gets the current easing mode.
     * @returns the easing mode
     */
    getEasingMode(): number;
    /**
     * @internal
     */
    easeInCore(gradient: number): number;
    /**
     * Given an input gradient between 0 and 1, this returns the corresponding value
     * of the easing function.
     * @param gradient Defines the value between 0 and 1 we want the easing value for
     * @returns the corresponding value on the curve defined by the easing function
     */
    ease(gradient: number): number;
}

/**
 * Class used to represent a viewport on screen
 */
declare class Viewport implements IViewportLike {
    /** viewport left coordinate */
    x: number;
    /** viewport top coordinate */
    y: number;
    /**viewport width */
    width: number;
    /** viewport height */
    height: number;
    /**
     * Creates a Viewport object located at (x, y) and sized (width, height)
     * @param x defines viewport left coordinate
     * @param y defines viewport top coordinate
     * @param width defines the viewport width
     * @param height defines the viewport height
     */
    constructor(
    /** viewport left coordinate */
    x: number, 
    /** viewport top coordinate */
    y: number, 
    /**viewport width */
    width: number, 
    /** viewport height */
    height: number);
    /**
     * Creates a new viewport using absolute sizing (from 0-> width, 0-> height instead of 0->1)
     * @param renderWidth defines the rendering width
     * @param renderHeight defines the rendering height
     * @returns a new Viewport
     */
    toGlobal(renderWidth: number, renderHeight: number): Viewport;
    /**
     * Stores absolute viewport value into a target viewport (from 0-> width, 0-> height instead of 0->1)
     * @param renderWidth defines the rendering width
     * @param renderHeight defines the rendering height
     * @param ref defines the target viewport
     * @returns the current viewport
     */
    toGlobalToRef(renderWidth: number, renderHeight: number, ref: Viewport): Viewport;
    /**
     * Returns a new Viewport copied from the current one
     * @returns a new Viewport
     */
    clone(): Viewport;
}

/**
 * Represents a plane by the equation ax + by + cz + d = 0
 */
declare class Plane implements IPlaneLike {
    private static _TmpMatrix;
    /**
     * Normal of the plane (a,b,c)
     */
    normal: Vector3;
    /**
     * d component of the plane
     */
    d: number;
    /**
     * Creates a Plane object according to the given floats a, b, c, d and the plane equation : ax + by + cz + d = 0
     * @param a a component of the plane
     * @param b b component of the plane
     * @param c c component of the plane
     * @param d d component of the plane
     */
    constructor(a: number, b: number, c: number, d: number);
    /**
     * @returns the plane coordinates as a new array of 4 elements [a, b, c, d].
     */
    asArray(): number[];
    /**
     * @returns a new plane copied from the current Plane.
     */
    clone(): Plane;
    /**
     * @returns the string "Plane".
     */
    getClassName(): string;
    /**
     * @returns the Plane hash code.
     */
    getHashCode(): number;
    /**
     * Normalize the current Plane in place.
     * @returns the updated Plane.
     */
    normalize(): Plane;
    /**
     * Applies a transformation the plane and returns the result
     * @param transformation the transformation matrix to be applied to the plane
     * @returns a new Plane as the result of the transformation of the current Plane by the given matrix.
     */
    transform(transformation: DeepImmutable<Matrix>): Plane;
    /**
     * Compute the dot product between the point and the plane normal
     * @param point point to calculate the dot product with
     * @returns the dot product (float) of the point coordinates and the plane normal.
     */
    dotCoordinate(point: DeepImmutable<Vector3>): number;
    /**
     * Updates the current Plane from the plane defined by the three given points.
     * @param point1 one of the points used to construct the plane
     * @param point2 one of the points used to construct the plane
     * @param point3 one of the points used to construct the plane
     * @returns the updated Plane.
     */
    copyFromPoints(point1: DeepImmutable<Vector3>, point2: DeepImmutable<Vector3>, point3: DeepImmutable<Vector3>): Plane;
    /**
     * Checks if the plane is facing a given direction (meaning if the plane's normal is pointing in the opposite direction of the given vector).
     * Note that for this function to work as expected you should make sure that:
     *   - direction and the plane normal are normalized
     *   - epsilon is a number just bigger than -1, something like -0.99 for eg
     * @param direction the direction to check if the plane is facing
     * @param epsilon value the dot product is compared against (returns true if dot <= epsilon)
     * @returns True if the plane is facing the given direction
     */
    isFrontFacingTo(direction: DeepImmutable<Vector3>, epsilon: number): boolean;
    /**
     * Calculates the distance to a point
     * @param point point to calculate distance to
     * @returns the signed distance (float) from the given point to the Plane.
     */
    signedDistanceTo(point: DeepImmutable<Vector3>): number;
    /**
     * Creates a plane from an  array
     * @param array the array to create a plane from
     * @returns a new Plane from the given array.
     */
    static FromArray(array: DeepImmutable<ArrayLike<number>>): Plane;
    /**
     * Creates a plane from three points
     * @param point1 point used to create the plane
     * @param point2 point used to create the plane
     * @param point3 point used to create the plane
     * @returns a new Plane defined by the three given points.
     */
    static FromPoints(point1: DeepImmutable<Vector3>, point2: DeepImmutable<Vector3>, point3: DeepImmutable<Vector3>): Plane;
    /**
     * Creates a plane from an origin point and a normal
     * @param origin origin of the plane to be constructed
     * @param normal normal of the plane to be constructed
     * @returns a new Plane the normal vector to this plane at the given origin point.
     */
    static FromPositionAndNormal(origin: DeepImmutable<Vector3>, normal: Vector3): Plane;
    /**
     * Updates the given Plane "result" from an origin point and a normal.
     * @param origin origin of the plane to be constructed
     * @param normal the normalized normals of the plane to be constructed
     * @param result defines the Plane where to store the result
     * @returns result input
     */
    static FromPositionAndNormalToRef<T extends Plane>(origin: DeepImmutable<Vector3>, normal: DeepImmutable<Vector3>, result: T): T;
    /**
     * Calculates the distance from a plane and a point
     * @param origin origin of the plane to be constructed
     * @param normal normal of the plane to be constructed
     * @param point point to calculate distance to
     * @returns the signed distance between the plane defined by the normal vector at the "origin"" point and the given other point.
     */
    static SignedDistanceToPlaneFromPositionAndNormal(origin: DeepImmutable<Vector3>, normal: DeepImmutable<Vector3>, point: DeepImmutable<Vector3>): number;
}

/**
 * Defines an array and its length.
 * It can be helpful to group result from both Arrays and smart arrays in one structure.
 */
interface ISmartArrayLike<T> {
    /**
     * The data of the array.
     */
    data: Array<T>;
    /**
     * The active length of the array.
     */
    length: number;
}
/**
 * Defines an GC Friendly array where the backfield array do not shrink to prevent over allocations.
 */
declare class SmartArray<T> implements ISmartArrayLike<T> {
    /**
     * The full set of data from the array.
     */
    data: Array<T>;
    /**
     * The active length of the array.
     */
    length: number;
    protected _id: number;
    /**
     * Instantiates a Smart Array.
     * @param capacity defines the default capacity of the array.
     */
    constructor(capacity: number);
    /**
     * Pushes a value at the end of the active data.
     * @param value defines the object to push in the array.
     */
    push(value: T): void;
    /**
     * Iterates over the active data and apply the lambda to them.
     * @param func defines the action to apply on each value.
     */
    forEach(func: (content: T) => void): void;
    /**
     * Sorts the full sets of data.
     * @param compareFn defines the comparison function to apply.
     */
    sort(compareFn: (a: T, b: T) => number): void;
    /**
     * Resets the active data to an empty array.
     */
    reset(): void;
    /**
     * Releases all the data from the array as well as the array.
     */
    dispose(): void;
    /**
     * Concats the active data with a given array.
     * @param array defines the data to concatenate with.
     */
    concat(array: any): void;
    /**
     * Returns the position of a value in the active data.
     * @param value defines the value to find the index for
     * @returns the index if found in the active data otherwise -1
     */
    indexOf(value: T): number;
    /**
     * Returns whether an element is part of the active data.
     * @param value defines the value to look for
     * @returns true if found in the active data otherwise false
     */
    contains(value: T): boolean;
    private static _GlobalId;
}
/**
 * Defines an GC Friendly array where the backfield array do not shrink to prevent over allocations.
 * The data in this array can only be present once
 */
declare class SmartArrayNoDuplicate<T> extends SmartArray<T> {
    private _duplicateId;
    /**
     * Pushes a value at the end of the active data.
     * THIS DOES NOT PREVENT DUPPLICATE DATA
     * @param value defines the object to push in the array.
     */
    push(value: T): void;
    /**
     * Pushes a value at the end of the active data.
     * If the data is already present, it won t be added again
     * @param value defines the object to push in the array.
     * @returns true if added false if it was already present
     */
    pushNoDuplicate(value: T): boolean;
    /**
     * Resets the active data to an empty array.
     */
    reset(): void;
    /**
     * Concats the active data with a given array.
     * This ensures no duplicate will be present in the result.
     * @param array defines the data to concatenate with.
     */
    concatWithNoDuplicate(array: any): void;
}

/**
 * This is the contract to implement in order to create a new input class.
 * Inputs are dealing with listening to user actions and moving the camera accordingly.
 */
interface ICameraInput<Tcamera extends Camera> {
    /**
     * Defines the camera the input is attached to.
     */
    camera: Nullable<Tcamera>;
    /**
     * Gets the class name of the current input.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Get the friendly name associated with the input class.
     * @returns the input friendly name
     */
    getSimpleName(): string;
    /**
     * Attach the input controls to a specific dom element to get the input from.
     * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     */
    attachControl(noPreventDefault?: boolean): void;
    /**
     * Detach the current controls from the specified dom element.
     */
    detachControl(): void;
    /**
     * Update the current camera state depending on the inputs that have been used this frame.
     * This is a dynamically created lambda to avoid the performance penalty of looping for inputs in the render loop.
     */
    checkInputs?: () => void;
}
/**
 * Represents a map of input types to input instance or input index to input instance.
 */
interface CameraInputsMap<Tcamera extends Camera> {
    /**
     * Accessor to the input by input type.
     */
    [name: string]: ICameraInput<Tcamera>;
    /**
     * Accessor to the input by input index.
     */
    [idx: number]: ICameraInput<Tcamera>;
}
/**
 * This represents the input manager used within a camera.
 * It helps dealing with all the different kind of input attached to a camera.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
 */
declare class CameraInputsManager<Tcamera extends Camera> {
    /**
     * Defines the list of inputs attached to the camera.
     */
    attached: CameraInputsMap<Tcamera>;
    /**
     * Defines the dom element the camera is collecting inputs from.
     * This is null if the controls have not been attached.
     */
    attachedToElement: boolean;
    /**
     * Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     */
    noPreventDefault: boolean;
    /**
     * Defined the camera the input manager belongs to.
     */
    camera: Tcamera;
    /**
     * Update the current camera state depending on the inputs that have been used this frame.
     * This is a dynamically created lambda to avoid the performance penalty of looping for inputs in the render loop.
     */
    checkInputs: () => void;
    /**
     * Instantiate a new Camera Input Manager.
     * @param camera Defines the camera the input manager belongs to
     */
    constructor(camera: Tcamera);
    /**
     * Add an input method to a camera
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
     * @param input Camera input method
     */
    add(input: ICameraInput<Tcamera>): void;
    /**
     * Remove a specific input method from a camera
     * example: camera.inputs.remove(camera.inputs.attached.mouse);
     * @param inputToRemove camera input method
     */
    remove(inputToRemove: ICameraInput<Tcamera>): void;
    /**
     * Remove a specific input type from a camera
     * example: camera.inputs.remove("ArcRotateCameraGamepadInput");
     * @param inputType the type of the input to remove
     */
    removeByType(inputType: string): void;
    private _addCheckInputs;
    /**
     * Attach the input controls to the currently attached dom element to listen the events from.
     * @param input Defines the input to attach
     */
    attachInput(input: ICameraInput<Tcamera>): void;
    /**
     * Attach the current manager inputs controls to a specific dom element to listen the events from.
     * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     */
    attachElement(noPreventDefault?: boolean): void;
    /**
     * Detach the current manager inputs controls from a specific dom element.
     * @param disconnect Defines whether the input should be removed from the current list of attached inputs
     */
    detachElement(disconnect?: boolean): void;
    /**
     * Rebuild the dynamic inputCheck function from the current list of
     * defined inputs in the manager.
     */
    rebuildInputCheck(): void;
    /**
     * Remove all attached input methods from a camera
     */
    clear(): void;
    /**
     * Serialize the current input manager attached to a camera.
     * This ensures than once parsed,
     * the input associated to the camera will be identical to the current ones
     * @param serializedCamera Defines the camera serialization JSON the input serialization should write to
     */
    serialize(serializedCamera: any): void;
    /**
     * Parses an input manager serialized JSON to restore the previous list of inputs
     * and states associated to a camera.
     * @param parsedCamera Defines the JSON to parse
     */
    parse(parsedCamera: any): void;
}

/**
 * This class is used to track a performance counter which is number based.
 * The user has access to many properties which give statistics of different nature.
 *
 * The implementer can track two kinds of Performance Counter: time and count.
 * For time you can optionally call fetchNewFrame() to notify the start of a new frame to monitor, then call beginMonitoring() to start and endMonitoring() to record the lapsed time. endMonitoring takes a newFrame parameter for you to specify if the monitored time should be set for a new frame or accumulated to the current frame being monitored.
 * For count you first have to call fetchNewFrame() to notify the start of a new frame to monitor, then call addCount() how many time required to increment the count value you monitor.
 */
declare class PerfCounter {
    /**
     * Gets or sets a global boolean to turn on and off all the counters
     */
    static Enabled: boolean;
    /**
     * Returns the smallest value ever
     */
    get min(): number;
    /**
     * Returns the biggest value ever
     */
    get max(): number;
    /**
     * Returns the average value since the performance counter is running
     */
    get average(): number;
    /**
     * Returns the average value of the last second the counter was monitored
     */
    get lastSecAverage(): number;
    /**
     * Returns the current value
     */
    get current(): number;
    /**
     * Gets the accumulated total
     */
    get total(): number;
    /**
     * Gets the total value count
     */
    get count(): number;
    /**
     * Creates a new counter
     */
    constructor();
    /**
     * Call this method to start monitoring a new frame.
     * This scenario is typically used when you accumulate monitoring time many times for a single frame, you call this method at the start of the frame, then beginMonitoring to start recording and endMonitoring(false) to accumulated the recorded time to the PerfCounter or addCount() to accumulate a monitored count.
     */
    fetchNewFrame(): void;
    /**
     * Call this method to monitor a count of something (e.g. mesh drawn in viewport count)
     * @param newCount the count value to add to the monitored count
     * @param fetchResult true when it's the last time in the frame you add to the counter and you wish to update the statistics properties (min/max/average), false if you only want to update statistics.
     */
    addCount(newCount: number, fetchResult: boolean): void;
    /**
     * Start monitoring this performance counter
     */
    beginMonitoring(): void;
    /**
     * Compute the time lapsed since the previous beginMonitoring() call.
     * @param newFrame true by default to fetch the result and monitor a new frame, if false the time monitored will be added to the current frame counter
     */
    endMonitoring(newFrame?: boolean): void;
    /**
     * Call this method to end the monitoring of a frame.
     * This scenario is typically used when you accumulate monitoring time many times for a single frame, you call this method at the end of the frame, after beginMonitoring to start recording and endMonitoring(false) to accumulated the recorded time to the PerfCounter or addCount() to accumulate a monitored count.
     */
    endFrame(): void;
    /** @internal */
    _fetchResult(): void;
    private _startMonitoringTime;
    private _min;
    private _max;
    private _average;
    private _current;
    private _totalValueCount;
    private _totalAccumulated;
    private _lastSecAverage;
    private _lastSecAccumulated;
    private _lastSecTime;
    private _lastSecValueCount;
}

/**
 * Enum that determines the text-wrapping mode to use.
 */
declare const enum InspectableType {
    /**
     * Checkbox for booleans
     */
    Checkbox = 0,
    /**
     * Sliders for numbers
     */
    Slider = 1,
    /**
     * Vector3
     */
    Vector3 = 2,
    /**
     * Quaternions
     */
    Quaternion = 3,
    /**
     * Color3
     */
    Color3 = 4,
    /**
     * String
     */
    String = 5,
    /**
     * Button
     */
    Button = 6,
    /**
     * Options
     */
    Options = 7,
    /**
     * Tab
     */
    Tab = 8,
    /**
     * File button
     */
    FileButton = 9,
    /**
     * Vector2
     */
    Vector2 = 10
}
/**
 * Interface used to define custom inspectable options in "Options" mode.
 * This interface is used by the inspector to display the list of options
 */
interface IInspectableOptions {
    /**
     * Defines the visible part of the option
     */
    label: string;
    /**
     * Defines the value part of the option (returned through the callback)
     */
    value: number | string;
    /**
     * Defines if the option should be selected or not
     */
    selected?: boolean;
}
/**
 * Interface used to define custom inspectable properties.
 * This interface is used by the inspector to display custom property grids
 * @see https://doc.babylonjs.com/toolsAndResources/inspector#extensibility
 */
interface IInspectable {
    /**
     * Gets the label to display
     */
    label: string;
    /**
     * Gets the name of the property to edit
     */
    propertyName: string;
    /**
     * Gets the type of the editor to use
     */
    type: InspectableType;
    /**
     * Gets the minimum value of the property when using in "slider" mode
     */
    min?: number;
    /**
     * Gets the maximum value of the property when using in "slider" mode
     */
    max?: number;
    /**
     * Gets the setp to use when using in "slider" mode
     */
    step?: number;
    /**
     * Gets the callback function when using "Button" mode
     */
    callback?: () => void;
    /**
     * Gets the callback function when using "FileButton" mode
     */
    fileCallback?: (file: File) => void;
    /**
     * Gets the list of options when using "Option" mode
     */
    options?: IInspectableOptions[];
    /**
     * Gets the extensions to accept when using "FileButton" mode.
     * The value should be a comma separated string with the list of extensions to accept e.g., ".jpg, .png, .tga, .dds, .env".
     */
    accept?: string;
}

/**
 * Class used to store gfx data (like WebGLBuffer)
 */
declare class DataBuffer {
    private static _Counter;
    /**
     * Gets or sets the number of objects referencing this buffer
     */
    references: number;
    /** Gets or sets the size of the underlying buffer */
    capacity: number;
    /**
     * Gets or sets a boolean indicating if the buffer contains 32bits indices
     */
    is32Bits: boolean;
    /**
     * Gets the underlying buffer
     */
    get underlyingResource(): any;
    /**
     * Gets the unique id of this buffer
     */
    readonly uniqueId: number;
    /**
     * Constructs the buffer
     */
    constructor();
}

/**
 * Class used to store data that will be store in GPU memory
 */
declare class Buffer$1 {
    private _engine;
    private _buffer;
    /** @internal */
    _data: Nullable<DataArray>;
    private _updatable;
    private _instanced;
    private _divisor;
    private _isAlreadyOwned;
    private _isDisposed;
    private _label?;
    /**
     * Gets a boolean indicating if the Buffer is disposed
     */
    get isDisposed(): boolean;
    /**
     * Gets the byte stride.
     */
    readonly byteStride: number;
    /**
     * Constructor
     * @param engine the engine
     * @param data the data to use for this buffer
     * @param updatable whether the data is updatable
     * @param stride the stride (optional)
     * @param postponeInternalCreation whether to postpone creating the internal WebGL buffer (optional)
     * @param instanced whether the buffer is instanced (optional)
     * @param useBytes set to true if the stride in in bytes (optional)
     * @param divisor sets an optional divisor for instances (1 by default)
     * @param label defines the label of the buffer (for debug purpose)
     */
    constructor(engine: AbstractEngine, data: DataArray | DataBuffer, updatable: boolean, stride?: number, postponeInternalCreation?: boolean, instanced?: boolean, useBytes?: boolean, divisor?: number, label?: string);
    /**
     * Create a new VertexBuffer based on the current buffer
     * @param kind defines the vertex buffer kind (position, normal, etc.)
     * @param offset defines offset in the buffer (0 by default)
     * @param size defines the size in floats of attributes (position is 3 for instance)
     * @param stride defines the stride size in floats in the buffer (the offset to apply to reach next value when data is interleaved)
     * @param instanced defines if the vertex buffer contains indexed data
     * @param useBytes defines if the offset and stride are in bytes     *
     * @param divisor sets an optional divisor for instances (1 by default)
     * @returns the new vertex buffer
     */
    createVertexBuffer(kind: string, offset: number, size: number, stride?: number, instanced?: boolean, useBytes?: boolean, divisor?: number): VertexBuffer;
    /**
     * Gets a boolean indicating if the Buffer is updatable?
     * @returns true if the buffer is updatable
     */
    isUpdatable(): boolean;
    /**
     * Gets current buffer's data
     * @returns a DataArray or null
     */
    getData(): Nullable<DataArray>;
    /**
     * Gets underlying native buffer
     * @returns underlying native buffer
     */
    getBuffer(): Nullable<DataBuffer>;
    /**
     * Gets the stride in float32 units (i.e. byte stride / 4).
     * May not be an integer if the byte stride is not divisible by 4.
     * @returns the stride in float32 units
     * @deprecated Please use byteStride instead.
     */
    getStrideSize(): number;
    /**
     * Store data into the buffer. Creates the buffer if not used already.
     * If the buffer was already used, it will be updated only if it is updatable, otherwise it will do nothing.
     * @param data defines the data to store
     */
    create(data?: Nullable<DataArray>): void;
    /** @internal */
    _rebuild(): void;
    /**
     * Update current buffer data
     * @param data defines the data to store
     */
    update(data: DataArray): void;
    /**
     * Updates the data directly.
     * @param data the new data
     * @param offset the new offset
     * @param vertexCount the vertex count (optional)
     * @param useBytes set to true if the offset is in bytes
     */
    updateDirectly(data: DataArray, offset: number, vertexCount?: number, useBytes?: boolean): void;
    /** @internal */
    _increaseReferences(): void;
    /**
     * Release all resources
     */
    dispose(): void;
}
/**
 * Options to be used when creating a vertex buffer
 */
interface IVertexBufferOptions {
    /**
     * whether the data is updatable (default: false)
     */
    updatable?: boolean;
    /**
     * whether to postpone creating the internal WebGL buffer (default: false)
     */
    postponeInternalCreation?: boolean;
    /**
     * the stride (will be automatically computed from the kind parameter if not specified)
     */
    stride?: number;
    /**
     * whether the buffer is instanced (default: false)
     */
    instanced?: boolean;
    /**
     * the offset of the data (default: 0)
     */
    offset?: number;
    /**
     * the number of components (will be automatically computed from the kind parameter if not specified)
     */
    size?: number;
    /**
     * the type of the component (will be deduce from the data parameter if not specified)
     */
    type?: number;
    /**
     * whether the data contains normalized data (default: false)
     */
    normalized?: boolean;
    /**
     * set to true if stride and offset are in bytes (default: false)
     */
    useBytes?: boolean;
    /**
     * defines the instance divisor to use (default: 1, only used if instanced is true)
     */
    divisor?: number;
    /**
     * defines if the buffer should be released when the vertex buffer is disposed (default: false)
     */
    takeBufferOwnership?: boolean;
    /**
     * label to use for this vertex buffer (debugging purpose)
     */
    label?: string;
}
/**
 * Specialized buffer used to store vertex data
 */
declare class VertexBuffer {
    private static _Counter;
    /** @internal */
    _buffer: Buffer$1;
    /** @internal */
    _validOffsetRange: boolean;
    private _kind;
    private _size;
    /** @internal */
    _ownsBuffer: boolean;
    private _instanced;
    private _instanceDivisor;
    /** @internal */
    _isDisposed: boolean;
    /** @internal */
    _label?: string;
    /**
     * The byte type.
     */
    static readonly BYTE: number;
    /**
     * The unsigned byte type.
     */
    static readonly UNSIGNED_BYTE: number;
    /**
     * The short type.
     */
    static readonly SHORT: number;
    /**
     * The unsigned short type.
     */
    static readonly UNSIGNED_SHORT: number;
    /**
     * The integer type.
     */
    static readonly INT: number;
    /**
     * The unsigned integer type.
     */
    static readonly UNSIGNED_INT: number;
    /**
     * The float type.
     */
    static readonly FLOAT: number;
    /**
     * Gets a boolean indicating if the Buffer is disposed
     */
    get isDisposed(): boolean;
    /**
     * Gets or sets the instance divisor when in instanced mode
     */
    get instanceDivisor(): number;
    set instanceDivisor(value: number);
    /**
     * Gets the byte stride.
     */
    readonly byteStride: number;
    /**
     * Gets the byte offset.
     */
    readonly byteOffset: number;
    /**
     * Gets whether integer data values should be normalized into a certain range when being casted to a float.
     */
    readonly normalized: boolean;
    /**
     * Gets the data type of each component in the array.
     */
    readonly type: number;
    /**
     * Gets the unique id of this vertex buffer
     */
    readonly uniqueId: number;
    /**
     * Gets a hash code representing the format (type, normalized, size, instanced, stride) of this buffer
     * All buffers with the same format will have the same hash code
     */
    readonly hashCode: number;
    /**
     * Gets the engine associated with the buffer
     */
    readonly engine: AbstractEngine;
    /**
     * Gets the max possible amount of vertices stored within the current vertex buffer.
     * We do not have the end offset or count so this will be too big for concatenated vertex buffers.
     * @internal
     */
    get _maxVerticesCount(): number;
    /**
     * Constructor
     * @param engine the engine
     * @param data the data to use for this vertex buffer
     * @param kind the vertex buffer kind
     * @param updatable whether the data is updatable
     * @param postponeInternalCreation whether to postpone creating the internal WebGL buffer (optional)
     * @param stride the stride (optional)
     * @param instanced whether the buffer is instanced (optional)
     * @param offset the offset of the data (optional)
     * @param size the number of components (optional)
     * @param type the type of the component (optional)
     * @param normalized whether the data contains normalized data (optional)
     * @param useBytes set to true if stride and offset are in bytes (optional)
     * @param divisor defines the instance divisor to use (1 by default)
     * @param takeBufferOwnership defines if the buffer should be released when the vertex buffer is disposed
     */
    constructor(engine: AbstractEngine, data: DataArray | Buffer$1 | DataBuffer, kind: string, updatable: boolean, postponeInternalCreation?: boolean, stride?: number, instanced?: boolean, offset?: number, size?: number, type?: number, normalized?: boolean, useBytes?: boolean, divisor?: number, takeBufferOwnership?: boolean);
    /**
     * Constructor
     * @param engine the engine
     * @param data the data to use for this vertex buffer
     * @param kind the vertex buffer kind
     * @param options defines the rest of the options used to create the buffer
     */
    constructor(engine: AbstractEngine, data: DataArray | Buffer$1 | DataBuffer, kind: string, options?: IVertexBufferOptions);
    private _computeHashCode;
    /** @internal */
    _rebuild(): void;
    /**
     * Returns the kind of the VertexBuffer (string)
     * @returns a string
     */
    getKind(): string;
    /**
     * Gets a boolean indicating if the VertexBuffer is updatable?
     * @returns true if the buffer is updatable
     */
    isUpdatable(): boolean;
    /**
     * Gets the raw data from the underlying buffer.
     * Note: The data may include more than just this vertex buffer's values.
     * @returns the buffer data as a DataArray, or null.
     */
    getData(): Nullable<DataArray>;
    /**
     * Gets this vertex buffer's data as a float array. Float data is constructed if the vertex buffer data cannot be returned directly.
     * @param totalVertices number of vertices in the buffer to take into account
     * @param forceCopy defines a boolean indicating that the returned array must be cloned upon returning it
     * @returns a float array containing vertex data
     */
    getFloatData(totalVertices: number, forceCopy?: boolean): Nullable<FloatArray>;
    /**
     * Gets underlying native buffer
     * @returns underlying native buffer
     */
    getBuffer(): Nullable<DataBuffer>;
    /**
     * Gets the Buffer instance that wraps the native GPU buffer
     * @returns the wrapper buffer
     */
    getWrapperBuffer(): Buffer$1;
    /**
     * Gets the stride in float32 units (i.e. byte stride / 4).
     * May not be an integer if the byte stride is not divisible by 4.
     * @returns the stride in float32 units
     * @deprecated Please use byteStride instead.
     */
    getStrideSize(): number;
    /**
     * Returns the offset as a multiple of the type byte length.
     * @returns the offset in bytes
     * @deprecated Please use byteOffset instead.
     */
    getOffset(): number;
    /**
     * Returns the number of components or the byte size per vertex attribute
     * @param sizeInBytes If true, returns the size in bytes or else the size in number of components of the vertex attribute (default: false)
     * @returns the number of components
     */
    getSize(sizeInBytes?: boolean): number;
    /**
     * Gets a boolean indicating is the internal buffer of the VertexBuffer is instanced
     * @returns true if this buffer is instanced
     */
    getIsInstanced(): boolean;
    /**
     * Returns the instancing divisor, zero for non-instanced (integer).
     * @returns a number
     */
    getInstanceDivisor(): number;
    /**
     * Store data into the buffer. If the buffer was already used it will be either recreated or updated depending on isUpdatable property
     * @param data defines the data to store
     */
    create(data?: DataArray): void;
    /**
     * Updates the underlying buffer according to the passed numeric array or Float32Array.
     * This function will create a new buffer if the current one is not updatable
     * @param data defines the data to store
     */
    update(data: DataArray): void;
    /**
     * Updates directly the underlying WebGLBuffer according to the passed numeric array or Float32Array.
     * Returns the directly updated WebGLBuffer.
     * @param data the new data
     * @param offset the new offset
     * @param useBytes set to true if the offset is in bytes
     */
    updateDirectly(data: DataArray, offset: number, useBytes?: boolean): void;
    /**
     * Disposes the VertexBuffer and the underlying WebGLBuffer.
     */
    dispose(): void;
    /**
     * Enumerates each value of this vertex buffer as numbers.
     * @param count the number of values to enumerate
     * @param callback the callback function called for each value
     */
    forEach(count: number, callback: (value: number, index: number) => void): void;
    /**
     * Positions
     */
    static readonly PositionKind: string;
    /**
     * Normals
     */
    static readonly NormalKind: string;
    /**
     * Tangents
     */
    static readonly TangentKind: string;
    /**
     * Texture coordinates
     */
    static readonly UVKind: string;
    /**
     * Texture coordinates 2
     */
    static readonly UV2Kind: string;
    /**
     * Texture coordinates 3
     */
    static readonly UV3Kind: string;
    /**
     * Texture coordinates 4
     */
    static readonly UV4Kind: string;
    /**
     * Texture coordinates 5
     */
    static readonly UV5Kind: string;
    /**
     * Texture coordinates 6
     */
    static readonly UV6Kind: string;
    /**
     * Colors
     */
    static readonly ColorKind: string;
    /**
     * Instance Colors
     */
    static readonly ColorInstanceKind: string;
    /**
     * Matrix indices (for bones)
     */
    static readonly MatricesIndicesKind: string;
    /**
     * Matrix weights (for bones)
     */
    static readonly MatricesWeightsKind: string;
    /**
     * Additional matrix indices (for bones)
     */
    static readonly MatricesIndicesExtraKind: string;
    /**
     * Additional matrix weights (for bones)
     */
    static readonly MatricesWeightsExtraKind: string;
    /**
     * Deduces the stride given a kind.
     * @param kind The kind string to deduce
     * @returns The deduced stride
     */
    static DeduceStride(kind: string): number;
    /**
     * Gets the vertex buffer type of the given data array.
     * @param data the data array
     * @returns the vertex buffer type
     */
    static GetDataType(data: DataArray): number;
    /**
     * Gets the byte length of the given type.
     * @param type the type
     * @returns the number of bytes
     * @deprecated Use `getTypeByteLength` from `bufferUtils` instead
     */
    static GetTypeByteLength(type: number): number;
    /**
     * Enumerates each value of the given parameters as numbers.
     * @param data the data to enumerate
     * @param byteOffset the byte offset of the data
     * @param byteStride the byte stride of the data
     * @param componentCount the number of components per element
     * @param componentType the type of the component
     * @param count the number of values to enumerate
     * @param normalized whether the data is normalized
     * @param callback the callback function called for each value
     * @deprecated Use `EnumerateFloatValues` from `bufferUtils` instead
     */
    static ForEach(data: DataArray, byteOffset: number, byteStride: number, componentCount: number, componentType: number, count: number, normalized: boolean, callback: (value: number, index: number) => void): void;
    /**
     * Gets the given data array as a float array. Float data is constructed if the data array cannot be returned directly.
     * @param data the input data array
     * @param size the number of components
     * @param type the component type
     * @param byteOffset the byte offset of the data
     * @param byteStride the byte stride of the data
     * @param normalized whether the data is normalized
     * @param totalVertices number of vertices in the buffer to take into account
     * @param forceCopy defines a boolean indicating that the returned array must be cloned upon returning it
     * @returns a float array containing vertex data
     * @deprecated Use `GetFloatData` from `bufferUtils` instead
     */
    static GetFloatData(data: DataArray, size: number, type: number, byteOffset: number, byteStride: number, normalized: boolean, totalVertices: number, forceCopy?: boolean): FloatArray;
}

/**
 * A Coroutine<T> is the intersection of:
 * 1. An Iterator that yields void, returns a T, and is not passed values with calls to next.
 * 2. An IterableIterator of void (since it only yields void).
 */
type CoroutineBase<TStep, TReturn> = Iterator<TStep, TReturn, void> & IterableIterator<TStep>;
/** @internal */
type Coroutine<T> = CoroutineBase<void, T>;
/** @internal */
type AsyncCoroutine<T> = CoroutineBase<void | Promise<void>, T>;
/** @internal */
type CoroutineStep<T> = IteratorResult<void, T>;
/** @internal */
type CoroutineScheduler<T> = (coroutine: AsyncCoroutine<T>, onStep: (stepResult: CoroutineStep<T>) => void, onError: (stepError: any) => void) => void;

/**
 * Class used to store bounding sphere information
 */
declare class BoundingSphere {
    /**
     * Gets the center of the bounding sphere in local space
     */
    readonly center: Vector3;
    /**
     * Radius of the bounding sphere in local space
     */
    radius: number;
    /**
     * Gets the center of the bounding sphere in world space
     */
    readonly centerWorld: Vector3;
    /**
     * Radius of the bounding sphere in world space
     */
    radiusWorld: number;
    /**
     * Gets the minimum vector in local space
     */
    readonly minimum: Vector3;
    /**
     * Gets the maximum vector in local space
     */
    readonly maximum: Vector3;
    private _worldMatrix;
    private static readonly _TmpVector3;
    /**
     * Creates a new bounding sphere
     * @param min defines the minimum vector (in local space)
     * @param max defines the maximum vector (in local space)
     * @param worldMatrix defines the new world matrix
     */
    constructor(min: DeepImmutable<Vector3>, max: DeepImmutable<Vector3>, worldMatrix?: DeepImmutable<Matrix>);
    /**
     * Recreates the entire bounding sphere from scratch as if we call the constructor in place
     * @param min defines the new minimum vector (in local space)
     * @param max defines the new maximum vector (in local space)
     * @param worldMatrix defines the new world matrix
     */
    reConstruct(min: DeepImmutable<Vector3>, max: DeepImmutable<Vector3>, worldMatrix?: DeepImmutable<Matrix>): void;
    /**
     * Scale the current bounding sphere by applying a scale factor
     * @param factor defines the scale factor to apply
     * @returns the current bounding box
     */
    scale(factor: number): BoundingSphere;
    /**
     * Gets the world matrix of the bounding box
     * @returns a matrix
     */
    getWorldMatrix(): DeepImmutable<Matrix>;
    /**
     * @internal
     */
    _update(worldMatrix: DeepImmutable<Matrix>): void;
    /**
     * Tests if the bounding sphere is intersecting the frustum planes
     * @param frustumPlanes defines the frustum planes to test
     * @returns true if there is an intersection
     */
    isInFrustum(frustumPlanes: Array<DeepImmutable<Plane>>): boolean;
    /**
     * Tests if the bounding sphere center is in between the frustum planes.
     * Used for optimistic fast inclusion.
     * @param frustumPlanes defines the frustum planes to test
     * @returns true if the sphere center is in between the frustum planes
     */
    isCenterInFrustum(frustumPlanes: Array<DeepImmutable<Plane>>): boolean;
    /**
     * Tests if a point is inside the bounding sphere
     * @param point defines the point to test
     * @returns true if the point is inside the bounding sphere
     */
    intersectsPoint(point: DeepImmutable<Vector3>): boolean;
    /**
     * Checks if two sphere intersect
     * @param sphere0 sphere 0
     * @param sphere1 sphere 1
     * @returns true if the spheres intersect
     */
    static Intersects(sphere0: DeepImmutable<BoundingSphere>, sphere1: DeepImmutable<BoundingSphere>): boolean;
    /**
     * Creates a sphere from a center and a radius
     * @param center The center
     * @param radius radius
     * @param matrix Optional worldMatrix
     * @returns The sphere
     */
    static CreateFromCenterAndRadius(center: DeepImmutable<Vector3>, radius: number, matrix?: DeepImmutable<Matrix>): BoundingSphere;
}

/**
 * Interface representing a draw context at the GPU level (draw call)
 */
interface IDrawContext {
    /**
     * Unique identifier for the draw context.
     */
    uniqueId: number;
    /**
     * True if instances are used in the draw calls
     */
    useInstancing: boolean;
    /**
     * Indicates if the draw should be an indirect draw.
     */
    enableIndirectDraw: boolean;
    /**
     * Buffer used for the indirect draw call when enableIndirectDraw is true.
     */
    indirectDrawBuffer?: GPUBuffer;
    /**
     * Data for the indirect draw call (only used when enableIndirectDraw is true).
     * @param indexOrVertexCount - The number of indices (if indexed draw) or vertices (if non-indexed draw).
     * @param instanceCount - The number of instances to draw.
     * @param firstIndexOrVertex - The index (if indexed draw) or vertex (if non-indexed draw) offset to start drawing from.
     * @param forceUpdate - If true, forces the update of the indirect draw data even if instanceCount is the same as in the previous call.
     */
    setIndirectData(indexOrVertexCount: number, instanceCount: number, firstIndexOrVertex: number, forceUpdate?: boolean): void;
    /**
     * Resets the draw context to its initial state.
     */
    reset(): void;
    /**
     * Disposes the draw context and its resources.
     */
    dispose(): void;
}

/** @internal */
interface IMaterialContext {
    uniqueId: number;
    useVertexPulling: boolean;
    reset(): void;
}

/**
 * Manages the defines for the Material
 */
declare class MaterialDefines {
    VERTEXOUTPUT_INVARIANT: boolean;
    /** @internal */
    protected _keys: string[];
    private _isDirty;
    /** @internal */
    _renderId: number;
    /** @internal */
    _areLightsDirty: boolean;
    /** @internal */
    _areLightsDisposed: boolean;
    /** @internal */
    _areAttributesDirty: boolean;
    /** @internal */
    _areTexturesDirty: boolean;
    /** @internal */
    _areFresnelDirty: boolean;
    /** @internal */
    _areMiscDirty: boolean;
    /** @internal */
    _arePrePassDirty: boolean;
    /** @internal */
    _areImageProcessingDirty: boolean;
    /** @internal */
    _normals: boolean;
    /** @internal */
    _uvs: boolean;
    /** @internal */
    _needNormals: boolean;
    /** @internal */
    _needUVs: boolean;
    protected _externalProperties?: {
        [name: string]: {
            type: string;
            default: any;
        };
    };
    [id: string]: any;
    /**
     * Creates a new instance
     * @param externalProperties list of external properties to inject into the object
     */
    constructor(externalProperties?: {
        [name: string]: {
            type: string;
            default: any;
        };
    });
    /**
     * Specifies if the material needs to be re-calculated
     */
    get isDirty(): boolean;
    /**
     * Marks the material to indicate that it has been re-calculated
     */
    markAsProcessed(): void;
    /**
     * Marks the material to indicate that it needs to be re-calculated
     */
    markAsUnprocessed(): void;
    /**
     * Marks the material to indicate all of its defines need to be re-calculated
     */
    markAllAsDirty(): void;
    /**
     * Marks the material to indicate that image processing needs to be re-calculated
     */
    markAsImageProcessingDirty(): void;
    /**
     * Marks the material to indicate the lights need to be re-calculated
     * @param disposed Defines whether the light is dirty due to dispose or not
     */
    markAsLightDirty(disposed?: boolean): void;
    /**
     * Marks the attribute state as changed
     */
    markAsAttributesDirty(): void;
    /**
     * Marks the texture state as changed
     */
    markAsTexturesDirty(): void;
    /**
     * Marks the fresnel state as changed
     */
    markAsFresnelDirty(): void;
    /**
     * Marks the misc state as changed
     */
    markAsMiscDirty(): void;
    /**
     * Marks the prepass state as changed
     */
    markAsPrePassDirty(): void;
    /**
     * Rebuilds the material defines
     */
    rebuild(): void;
    /**
     * Specifies if two material defines are equal
     * @param other - A material define instance to compare to
     * @returns - Boolean indicating if the material defines are equal (true) or not (false)
     */
    isEqual(other: MaterialDefines): boolean;
    /**
     * Clones this instance's defines to another instance
     * @param other - material defines to clone values to
     */
    cloneTo(other: MaterialDefines): void;
    /**
     * Resets the material define values
     */
    reset(): void;
    private _setDefaultValue;
    /**
     * Converts the material define values to a string
     * @returns - String of material define information
     */
    toString(): string;
}

/**
 * Wrapper for an effect and its associated material context and draw context.
 * This class is meant to encapsulate the effect and its related contexts, allowing for easier management of rendering states.
 */
declare class DrawWrapper {
    /**
     * The effect associated with this wrapper.
     */
    effect: Nullable<Effect>;
    /**
     * The defines associated with this wrapper.
     */
    defines: Nullable<string | MaterialDefines>;
    /**
     * The material context associated with this wrapper.
     */
    materialContext?: IMaterialContext;
    /**
     * The draw context associated with this wrapper.
     */
    drawContext?: IDrawContext;
    /**
     * @internal
     * Specifies if the effect was previously ready
     */
    _wasPreviouslyReady: boolean;
    /**
     * @internal
     * Forces the code from bindForSubMesh to be fully run the next time it is called
     */
    _forceRebindOnNextCall: boolean;
    /**
     * @internal
     * Specifies if the effect was previously using instances
     */
    _wasPreviouslyUsingInstances: Nullable<boolean>;
    /**
     * Retrieves the effect from a DrawWrapper or Effect instance.
     * @param effect The effect or DrawWrapper instance to retrieve the effect from.
     * @returns The effect associated with the given instance, or null if not found.
     */
    static GetEffect(effect: Effect | DrawWrapper): Nullable<Effect>;
    /**
     * Creates a new DrawWrapper instance.
     * Note that drawContext is always created (but may end up being undefined if the engine doesn't need draw contexts), but materialContext is optional.
     * @param engine The engine to create the draw wrapper for.
     * @param createMaterialContext If true, creates a material context for this wrapper (default is true).
     */
    constructor(engine: AbstractEngine, createMaterialContext?: boolean);
    /**
     * Sets the effect and its associated defines for this wrapper.
     * @param effect The effect to associate with this wrapper.
     * @param defines The defines to associate with this wrapper.
     * @param resetContext If true, resets the draw context (default is true).
     */
    setEffect(effect: Nullable<Effect>, defines?: Nullable<string | MaterialDefines>, resetContext?: boolean): void;
    /**
     * Disposes the effect wrapper and its resources
     * @param immediate if the effect should be disposed immediately or on the next frame.
     * If dispose() is not called during a scene or engine dispose, we want to delay the dispose of the underlying effect. Mostly to give a chance to user code to reuse the effect in some way.
     */
    dispose(immediate?: boolean): void;
}

/**
 * Class used to store bounding box information
 */
declare class BoundingBox implements ICullable {
    /**
     * Gets the 8 vectors representing the bounding box in local space
     */
    readonly vectors: Vector3[];
    /**
     * Gets the center of the bounding box in local space
     */
    readonly center: Vector3;
    /**
     * Gets the center of the bounding box in world space
     */
    readonly centerWorld: Vector3;
    /**
     * Gets half the size of the extent in local space. Multiply by 2 to obtain the full size of the box!
     */
    readonly extendSize: Vector3;
    /**
     * Gets half the size of the extent in world space. Multiply by 2 to obtain the full size of the box!
     */
    readonly extendSizeWorld: Vector3;
    /**
     * Gets the OBB (object bounding box) directions
     */
    readonly directions: Vector3[];
    /**
     * Gets the 8 vectors representing the bounding box in world space
     */
    readonly vectorsWorld: Vector3[];
    /**
     * Gets the minimum vector in world space
     */
    readonly minimumWorld: Vector3;
    /**
     * Gets the maximum vector in world space
     */
    readonly maximumWorld: Vector3;
    /**
     * Gets the minimum vector in local space
     */
    readonly minimum: Vector3;
    /**
     * Gets the maximum vector in local space
     */
    readonly maximum: Vector3;
    private _worldMatrix;
    private static readonly _TmpVector3;
    /**
     * @internal
     */
    _tag: number;
    /** @internal */
    _drawWrapperFront: Nullable<DrawWrapper>;
    /** @internal */
    _drawWrapperBack: Nullable<DrawWrapper>;
    /**
     * Creates a new bounding box
     * @param min defines the minimum vector (in local space)
     * @param max defines the maximum vector (in local space)
     * @param worldMatrix defines the new world matrix
     */
    constructor(min: DeepImmutable<Vector3>, max: DeepImmutable<Vector3>, worldMatrix?: DeepImmutable<Matrix>);
    /**
     * Recreates the entire bounding box from scratch as if we call the constructor in place
     * @param min defines the new minimum vector (in local space)
     * @param max defines the new maximum vector (in local space)
     * @param worldMatrix defines the new world matrix
     */
    reConstruct(min: DeepImmutable<Vector3>, max: DeepImmutable<Vector3>, worldMatrix?: DeepImmutable<Matrix>): void;
    /**
     * Scale the current bounding box by applying a scale factor
     * @param factor defines the scale factor to apply
     * @returns the current bounding box
     */
    scale(factor: number): BoundingBox;
    /**
     * Gets the world matrix of the bounding box
     * @returns a matrix
     */
    getWorldMatrix(): DeepImmutable<Matrix>;
    /**
     * @internal
     */
    _update(world: DeepImmutable<Matrix>): void;
    /**
     * Tests if the bounding box is intersecting the frustum planes
     * @param frustumPlanes defines the frustum planes to test
     * @returns true if there is an intersection
     */
    isInFrustum(frustumPlanes: Array<DeepImmutable<Plane>>): boolean;
    /**
     * Tests if the bounding box is entirely inside the frustum planes
     * @param frustumPlanes defines the frustum planes to test
     * @returns true if there is an inclusion
     */
    isCompletelyInFrustum(frustumPlanes: Array<DeepImmutable<Plane>>): boolean;
    /**
     * Tests if a point is inside the bounding box
     * @param point defines the point to test
     * @returns true if the point is inside the bounding box
     */
    intersectsPoint(point: DeepImmutable<Vector3>): boolean;
    /**
     * Tests if the bounding box intersects with a bounding sphere
     * @param sphere defines the sphere to test
     * @returns true if there is an intersection
     */
    intersectsSphere(sphere: DeepImmutable<BoundingSphere>): boolean;
    /**
     * Tests if the bounding box intersects with a box defined by a min and max vectors
     * @param min defines the min vector to use
     * @param max defines the max vector to use
     * @returns true if there is an intersection
     */
    intersectsMinMax(min: DeepImmutable<Vector3>, max: DeepImmutable<Vector3>): boolean;
    /**
     * Disposes the resources of the class
     */
    dispose(): void;
    /**
     * Tests if two bounding boxes are intersections
     * @param box0 defines the first box to test
     * @param box1 defines the second box to test
     * @returns true if there is an intersection
     */
    static Intersects(box0: DeepImmutable<BoundingBox>, box1: DeepImmutable<BoundingBox>): boolean;
    /**
     * Tests if a bounding box defines by a min/max vectors intersects a sphere
     * @param minPoint defines the minimum vector of the bounding box
     * @param maxPoint defines the maximum vector of the bounding box
     * @param sphereCenter defines the sphere center
     * @param sphereRadius defines the sphere radius
     * @returns true if there is an intersection
     */
    static IntersectsSphere(minPoint: DeepImmutable<Vector3>, maxPoint: DeepImmutable<Vector3>, sphereCenter: DeepImmutable<Vector3>, sphereRadius: number): boolean;
    /**
     * Tests if a bounding box defined with 8 vectors is entirely inside frustum planes
     * @param boundingVectors defines an array of 8 vectors representing a bounding box
     * @param frustumPlanes defines the frustum planes to test
     * @returns true if there is an inclusion
     */
    static IsCompletelyInFrustum(boundingVectors: Array<DeepImmutable<Vector3>>, frustumPlanes: Array<DeepImmutable<Plane>>): boolean;
    /**
     * Tests if a bounding box defined with 8 vectors intersects frustum planes
     * @param boundingVectors defines an array of 8 vectors representing a bounding box
     * @param frustumPlanes defines the frustum planes to test
     * @returns true if there is an intersection
     */
    static IsInFrustum(boundingVectors: Array<DeepImmutable<Vector3>>, frustumPlanes: Array<DeepImmutable<Plane>>): boolean;
}

/** @internal */
declare class Collider {
    /** Define if a collision was found */
    collisionFound: boolean;
    /**
     * Define last intersection point in local space
     */
    intersectionPoint: Vector3;
    /**
     * Define last collided mesh
     */
    collidedMesh: Nullable<AbstractMesh>;
    /**
     * If true, it check for double sided faces and only returns 1 collision instead of 2
     */
    static DoubleSidedCheck: boolean;
    private _collisionPoint;
    private _planeIntersectionPoint;
    private _tempVector;
    private _tempVector2;
    private _tempVector3;
    private _tempVector4;
    private _edge;
    private _baseToVertex;
    private _destinationPoint;
    private _slidePlaneNormal;
    private _displacementVector;
    /** @internal */
    _radius: Vector3;
    /** @internal */
    _retry: number;
    private _velocity;
    private _basePoint;
    private _epsilon;
    /** @internal */
    _velocityWorldLength: number;
    /** @internal */
    _basePointWorld: Vector3;
    private _velocityWorld;
    private _normalizedVelocity;
    /** @internal */
    _initialVelocity: Vector3;
    /** @internal */
    _initialPosition: Vector3;
    private _nearestDistance;
    private _collisionMask;
    private _velocitySquaredLength;
    private _nearestDistanceSquared;
    get collisionMask(): number;
    set collisionMask(mask: number);
    /**
     * Gets the plane normal used to compute the sliding response (in local space)
     */
    get slidePlaneNormal(): Vector3;
    /**
     * @internal
     */
    _initialize(source: Vector3, dir: Vector3, e: number): void;
    /**
     * @internal
     */
    _checkPointInTriangle(point: Vector3, pa: Vector3, pb: Vector3, pc: Vector3, n: Vector3): boolean;
    /**
     * @internal
     */
    _canDoCollision(sphereCenter: Vector3, sphereRadius: number, vecMin: Vector3, vecMax: Vector3): boolean;
    /**
     * @internal
     */
    _testTriangle(faceIndex: number, trianglePlaneArray: Array<Plane>, p1: Vector3, p2: Vector3, p3: Vector3, hasMaterial: boolean, hostMesh: AbstractMesh): void;
    /**
     * @internal
     */
    _collide(trianglePlaneArray: Array<Plane>, pts: Vector3[], indices: IndicesArray, indexStart: number, indexEnd: number, decal: number, hasMaterial: boolean, hostMesh: AbstractMesh, invertTriangles?: boolean, triangleStrip?: boolean): void;
    /**
     * @internal
     */
    _getResponse(pos: Vector3, vel: Vector3, slideOnCollide: boolean): void;
}

/**
 * Interface for cullable objects
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction#back-face-culling
 */
interface ICullable {
    /**
     * Checks if the object or part of the object is in the frustum
     * @param frustumPlanes Camera near/planes
     * @returns true if the object is in frustum otherwise false
     */
    isInFrustum(frustumPlanes: Plane[]): boolean;
    /**
     * Checks if a cullable object (mesh...) is in the camera frustum
     * Unlike isInFrustum this checks the full bounding box
     * @param frustumPlanes Camera near/planes
     * @returns true if the object is in frustum otherwise false
     */
    isCompletelyInFrustum(frustumPlanes: Plane[]): boolean;
}
/**
 * Info for a bounding data of a mesh
 */
declare class BoundingInfo implements ICullable {
    /**
     * Bounding box for the mesh
     */
    readonly boundingBox: BoundingBox;
    /**
     * Bounding sphere for the mesh
     */
    readonly boundingSphere: BoundingSphere;
    private _isLocked;
    private static readonly _TmpVector3;
    /**
     * Constructs bounding info
     * @param minimum min vector of the bounding box/sphere
     * @param maximum max vector of the bounding box/sphere
     * @param worldMatrix defines the new world matrix
     */
    constructor(minimum: DeepImmutable<Vector3>, maximum: DeepImmutable<Vector3>, worldMatrix?: DeepImmutable<Matrix>);
    /**
     * Recreates the entire bounding info from scratch as if we call the constructor in place
     * @param min defines the new minimum vector (in local space)
     * @param max defines the new maximum vector (in local space)
     * @param worldMatrix defines the new world matrix
     */
    reConstruct(min: DeepImmutable<Vector3>, max: DeepImmutable<Vector3>, worldMatrix?: DeepImmutable<Matrix>): void;
    /**
     * min vector of the bounding box/sphere
     */
    get minimum(): Vector3;
    /**
     * max vector of the bounding box/sphere
     */
    get maximum(): Vector3;
    /**
     * If the info is locked and won't be updated to avoid perf overhead
     */
    get isLocked(): boolean;
    set isLocked(value: boolean);
    /**
     * Updates the bounding sphere and box
     * @param world world matrix to be used to update
     */
    update(world: DeepImmutable<Matrix>): void;
    /**
     * Recreate the bounding info to be centered around a specific point given a specific extend.
     * @param center New center of the bounding info
     * @param extend New extend of the bounding info
     * @returns the current bounding info
     */
    centerOn(center: DeepImmutable<Vector3>, extend: DeepImmutable<Vector3>): BoundingInfo;
    /**
     * Grows the bounding info to include the given point.
     * @param point The point that will be included in the current bounding info (in local space)
     * @returns the current bounding info
     */
    encapsulate(point: Vector3): BoundingInfo;
    /**
     * Grows the bounding info to encapsulate the given bounding info.
     * @param toEncapsulate The bounding info that will be encapsulated in the current bounding info
     * @returns the current bounding info
     */
    encapsulateBoundingInfo(toEncapsulate: BoundingInfo): BoundingInfo;
    /**
     * Scale the current bounding info by applying a scale factor
     * @param factor defines the scale factor to apply
     * @returns the current bounding info
     */
    scale(factor: number): BoundingInfo;
    /**
     * Returns `true` if the bounding info is within the frustum defined by the passed array of planes.
     * @param frustumPlanes defines the frustum to test
     * @param strategy defines the strategy to use for the culling (default is BABYLON.AbstractMesh.CULLINGSTRATEGY_STANDARD)
     * The different strategies available are:
     * * BABYLON.AbstractMesh.CULLINGSTRATEGY_STANDARD most accurate but slower @see https://doc.babylonjs.com/typedoc/classes/BABYLON.AbstractMesh#CULLINGSTRATEGY_STANDARD
     * * BABYLON.AbstractMesh.CULLINGSTRATEGY_BOUNDINGSPHERE_ONLY faster but less accurate @see https://doc.babylonjs.com/typedoc/classes/BABYLON.AbstractMesh#CULLINGSTRATEGY_BOUNDINGSPHERE_ONLY
     * * BABYLON.AbstractMesh.CULLINGSTRATEGY_OPTIMISTIC_INCLUSION can be faster if always visible @see https://doc.babylonjs.com/typedoc/classes/BABYLON.AbstractMesh#CULLINGSTRATEGY_OPTIMISTIC_INCLUSION
     * * BABYLON.AbstractMesh.CULLINGSTRATEGY_OPTIMISTIC_INCLUSION_THEN_BSPHERE_ONLY can be faster if always visible @see https://doc.babylonjs.com/typedoc/classes/BABYLON.AbstractMesh#CULLINGSTRATEGY_OPTIMISTIC_INCLUSION_THEN_BSPHERE_ONLY
     * @returns true if the bounding info is in the frustum planes
     */
    isInFrustum(frustumPlanes: Array<DeepImmutable<Plane>>, strategy?: number): boolean;
    /**
     * Gets the world distance between the min and max points of the bounding box
     */
    get diagonalLength(): number;
    /**
     * Checks if a cullable object (mesh...) is in the camera frustum
     * Unlike isInFrustum this checks the full bounding box
     * @param frustumPlanes Camera near/planes
     * @returns true if the object is in frustum otherwise false
     */
    isCompletelyInFrustum(frustumPlanes: Array<DeepImmutable<Plane>>): boolean;
    /**
     * @internal
     */
    _checkCollision(collider: Collider): boolean;
    /**
     * Checks if a point is inside the bounding box and bounding sphere or the mesh
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/interactions/mesh_intersect
     * @param point the point to check intersection with
     * @returns if the point intersects
     */
    intersectsPoint(point: DeepImmutable<Vector3>): boolean;
    /**
     * Checks if another bounding info intersects the bounding box and bounding sphere or the mesh
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/interactions/mesh_intersect
     * @param boundingInfo the bounding info to check intersection with
     * @param precise if the intersection should be done using OBB
     * @returns if the bounding info intersects
     */
    intersects(boundingInfo: DeepImmutable<BoundingInfo>, precise: boolean): boolean;
}

/** Defines supported spaces */
declare const enum Space {
    /** Local (object) space */
    LOCAL = 0,
    /** World space */
    WORLD = 1,
    /** Bone space */
    BONE = 2
}
/** Defines the 3 main axes */
declare class Axis {
    /** X axis */
    static X: Vector3;
    /** Y axis */
    static Y: Vector3;
    /** Z axis */
    static Z: Vector3;
}
/**
 * Defines cartesian components.
 */
declare const enum Coordinate {
    /** X axis */
    X = 0,
    /** Y axis */
    Y = 1,
    /** Z axis */
    Z = 2
}

/**
 * Class used to override all child animations of a given target
 */
declare class AnimationPropertiesOverride {
    /**
     * Gets or sets a value indicating if animation blending must be used
     */
    enableBlending: boolean;
    /**
     * Gets or sets the blending speed to use when enableBlending is true
     */
    blendingSpeed: number;
    /**
     * Gets or sets the default loop mode to use
     */
    loopMode: number;
}

/**
 * Class used to store bone information
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/bonesSkeletons
 */
declare class Bone extends Node {
    /**
     * defines the bone name
     */
    name: string;
    private static _TmpVecs;
    private static _TmpQuat;
    private static _TmpMats;
    /**
     * Gets the list of child bones
     */
    children: Bone[];
    /** Gets the animations associated with this bone */
    animations: Animation[];
    /**
     * Gets or sets bone length
     */
    length: number;
    /**
     * @internal Internal only
     * Set this value to map this bone to a different index in the transform matrices
     * Set this value to -1 to exclude the bone from the transform matrices
     */
    _index: Nullable<number>;
    private _skeleton;
    private _localMatrix;
    private _absoluteMatrix;
    private _bindMatrix;
    private _absoluteBindMatrix;
    private _absoluteInverseBindMatrix;
    private _finalMatrix;
    private _restMatrix;
    private _scalingDeterminant;
    private _localScaling;
    private _localRotation;
    private _localPosition;
    private _needToDecompose;
    private _needToCompose;
    /** @internal */
    _linkedTransformNode: Nullable<TransformNode>;
    /** @internal */
    _waitingTransformNodeId: Nullable<string>;
    /** @internal */
    get _matrix(): Matrix;
    /** @internal */
    set _matrix(value: Matrix);
    /**
     * Create a new bone
     * @param name defines the bone name
     * @param skeleton defines the parent skeleton
     * @param parentBone defines the parent (can be null if the bone is the root)
     * @param localMatrix defines the local matrix (default: identity)
     * @param restMatrix defines the rest matrix (default: localMatrix)
     * @param bindMatrix defines the bind matrix (default: localMatrix)
     * @param index defines index of the bone in the hierarchy (default: null)
     */
    constructor(
    /**
     * defines the bone name
     */
    name: string, skeleton: Skeleton, parentBone?: Nullable<Bone>, localMatrix?: Nullable<Matrix>, restMatrix?: Nullable<Matrix>, bindMatrix?: Nullable<Matrix>, index?: Nullable<number>);
    /**
     * Gets the current object class name.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the parent skeleton
     * @returns a skeleton
     */
    getSkeleton(): Skeleton;
    get parent(): Bone;
    /**
     * Gets parent bone
     * @returns a bone or null if the bone is the root of the bone hierarchy
     */
    getParent(): Nullable<Bone>;
    /**
     * Returns an array containing the children of the bone
     * @returns an array containing the children of the bone (can be empty if the bone has no children)
     */
    getChildren(): Array<Bone>;
    /**
     * Gets the node index in matrix array generated for rendering
     * @returns the node index
     */
    getIndex(): number;
    set parent(newParent: Nullable<Bone>);
    /**
     * Sets the parent bone
     * @param parent defines the parent (can be null if the bone is the root)
     * @param updateAbsoluteBindMatrices defines if the absolute bind and absolute inverse bind matrices must be updated
     */
    setParent(parent: Nullable<Bone>, updateAbsoluteBindMatrices?: boolean): void;
    /**
     * Gets the local matrix
     * @returns the local matrix
     */
    getLocalMatrix(): Matrix;
    /**
     * Gets the bind matrix
     * @returns the bind matrix
     */
    getBindMatrix(): Matrix;
    /**
     * Gets the bind matrix.
     * @returns the bind matrix
     * @deprecated Please use getBindMatrix instead
     */
    getBaseMatrix(): Matrix;
    /**
     * Gets the rest matrix
     * @returns the rest matrix
     */
    getRestMatrix(): Matrix;
    /**
     * Gets the rest matrix
     * @returns the rest matrix
     * @deprecated Please use getRestMatrix instead
     */
    getRestPose(): Matrix;
    /**
     * Sets the rest matrix
     * @param matrix the local-space rest matrix to set for this bone
     */
    setRestMatrix(matrix: Matrix): void;
    /**
     * Sets the rest matrix
     * @param matrix the local-space rest to set for this bone
     * @deprecated Please use setRestMatrix instead
     */
    setRestPose(matrix: Matrix): void;
    /**
     * Gets the bind matrix
     * @returns the bind matrix
     * @deprecated Please use getBindMatrix instead
     */
    getBindPose(): Matrix;
    /**
     * Sets the bind matrix
     * This will trigger a recomputation of the absolute bind and absolute inverse bind matrices for this bone and its children
     * Note that the local matrix will also be set with the matrix passed in parameter!
     * @param matrix the local-space bind matrix to set for this bone
     */
    setBindMatrix(matrix: Matrix): void;
    /**
     * Sets the bind matrix
     * @param matrix the local-space bind to set for this bone
     * @deprecated Please use setBindMatrix instead
     */
    setBindPose(matrix: Matrix): void;
    /**
     * Gets the matrix used to store the final world transformation of the bone (ie. the matrix sent to shaders)
     * @returns the final world matrix
     */
    getFinalMatrix(): Matrix;
    /**
     * Gets the matrix used to store the final world transformation of the bone (ie. the matrix sent to shaders)
     * @deprecated Please use getFinalMatrix instead
     * @returns the final world matrix
     */
    getWorldMatrix(): Matrix;
    /**
     * Sets the local matrix to the rest matrix
     */
    returnToRest(): void;
    /**
     * Gets the inverse of the bind matrix, in world space (relative to the skeleton root)
     * @returns the inverse bind matrix, in world space
     */
    getAbsoluteInverseBindMatrix(): Matrix;
    /**
     * Gets the inverse of the bind matrix, in world space (relative to the skeleton root)
     * @returns the inverse bind matrix, in world space
     * @deprecated Please use getAbsoluteInverseBindMatrix instead
     */
    getInvertedAbsoluteTransform(): Matrix;
    /**
     * Gets the bone matrix, in world space (relative to the skeleton root)
     * @returns the bone matrix, in world space
     */
    getAbsoluteMatrix(): Matrix;
    /**
     * Gets the bone matrix, in world space (relative to the skeleton root)
     * @returns the bone matrix, in world space
     * @deprecated Please use getAbsoluteMatrix instead
     */
    getAbsoluteTransform(): Matrix;
    /**
     * Links with the given transform node.
     * The local matrix of this bone is overwritten by the transform of the node every frame.
     * @param transformNode defines the transform node to link to
     */
    linkTransformNode(transformNode: Nullable<TransformNode>): void;
    /**
     * Gets the node used to drive the bone's transformation
     * @returns a transform node or null
     */
    getTransformNode(): Nullable<TransformNode>;
    /** Gets or sets current position (in local space) */
    get position(): Vector3;
    set position(newPosition: Vector3);
    /** Gets or sets current rotation (in local space) */
    get rotation(): Vector3;
    set rotation(newRotation: Vector3);
    /** Gets or sets current rotation quaternion (in local space) */
    get rotationQuaternion(): Quaternion;
    set rotationQuaternion(newRotation: Quaternion);
    /** Gets or sets current scaling (in local space) */
    get scaling(): Vector3;
    set scaling(newScaling: Vector3);
    /**
     * Gets the animation properties override
     */
    get animationPropertiesOverride(): Nullable<AnimationPropertiesOverride>;
    private _decompose;
    private _compose;
    /**
     * Update the bind (and optionally the local) matrix
     * @param bindMatrix defines the new matrix to set to the bind/local matrix, in local space
     * @param updateAbsoluteBindMatrices defines if the absolute bind and absolute inverse bind matrices must be recomputed (default: true)
     * @param updateLocalMatrix defines if the local matrix should also be updated with the matrix passed in parameter (default: true)
     */
    updateMatrix(bindMatrix: Matrix, updateAbsoluteBindMatrices?: boolean, updateLocalMatrix?: boolean): void;
    /**
     * @internal
     */
    _updateAbsoluteBindMatrices(bindMatrix?: Matrix, updateChildren?: boolean): void;
    /**
     * Flag the bone as dirty (Forcing it to update everything)
     * @returns this bone
     */
    markAsDirty(): Bone;
    /** @internal */
    _markAsDirtyAndCompose(): void;
    private _markAsDirtyAndDecompose;
    private _updatePosition;
    /**
     * Translate the bone in local or world space
     * @param vec The amount to translate the bone
     * @param space The space that the translation is in (default: Space.LOCAL)
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    translate(vec: Vector3, space?: Space, tNode?: TransformNode): void;
    /**
     * Set the position of the bone in local or world space
     * @param position The position to set the bone
     * @param space The space that the position is in (default: Space.LOCAL)
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    setPosition(position: Vector3, space?: Space, tNode?: TransformNode): void;
    /**
     * Set the absolute position of the bone (world space)
     * @param position The position to set the bone
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    setAbsolutePosition(position: Vector3, tNode?: TransformNode): void;
    /**
     * Scale the bone on the x, y and z axes (in local space)
     * @param x The amount to scale the bone on the x axis
     * @param y The amount to scale the bone on the y axis
     * @param z The amount to scale the bone on the z axis
     * @param scaleChildren sets this to true if children of the bone should be scaled as well (false by default)
     */
    scale(x: number, y: number, z: number, scaleChildren?: boolean): void;
    /**
     * Set the bone scaling in local space
     * @param scale defines the scaling vector
     */
    setScale(scale: Vector3): void;
    /**
     * Gets the current scaling in local space
     * @returns the current scaling vector
     */
    getScale(): Vector3;
    /**
     * Gets the current scaling in local space and stores it in a target vector
     * @param result defines the target vector
     */
    getScaleToRef(result: Vector3): void;
    /**
     * Set the yaw, pitch, and roll of the bone in local or world space
     * @param yaw The rotation of the bone on the y axis
     * @param pitch The rotation of the bone on the x axis
     * @param roll The rotation of the bone on the z axis
     * @param space The space that the axes of rotation are in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    setYawPitchRoll(yaw: number, pitch: number, roll: number, space?: Space, tNode?: TransformNode): void;
    /**
     * Add a rotation to the bone on an axis in local or world space
     * @param axis The axis to rotate the bone on
     * @param amount The amount to rotate the bone
     * @param space The space that the axis is in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    rotate(axis: Vector3, amount: number, space?: Space, tNode?: TransformNode): void;
    /**
     * Set the rotation of the bone to a particular axis angle in local or world space
     * @param axis The axis to rotate the bone on
     * @param angle The angle that the bone should be rotated to
     * @param space The space that the axis is in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    setAxisAngle(axis: Vector3, angle: number, space?: Space, tNode?: TransformNode): void;
    /**
     * Set the euler rotation of the bone in local or world space
     * @param rotation The euler rotation that the bone should be set to
     * @param space The space that the rotation is in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    setRotation(rotation: Vector3, space?: Space, tNode?: TransformNode): void;
    /**
     * Set the quaternion rotation of the bone in local or world space
     * @param quat The quaternion rotation that the bone should be set to
     * @param space The space that the rotation is in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    setRotationQuaternion(quat: Quaternion, space?: Space, tNode?: TransformNode): void;
    /**
     * Set the rotation matrix of the bone in local or world space
     * @param rotMat The rotation matrix that the bone should be set to
     * @param space The space that the rotation is in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     */
    setRotationMatrix(rotMat: Matrix, space?: Space, tNode?: TransformNode): void;
    private _rotateWithMatrix;
    private _getAbsoluteInverseMatrixUnscaledToRef;
    /**
     * Get the position of the bone in local or world space
     * @param space The space that the returned position is in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @returns The position of the bone
     */
    getPosition(space?: Space, tNode?: Nullable<TransformNode>): Vector3;
    /**
     * Copy the position of the bone to a vector3 in local or world space
     * @param space The space that the returned position is in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @param result The vector3 to copy the position to
     */
    getPositionToRef(space: Space | undefined, tNode: Nullable<TransformNode>, result: Vector3): void;
    /**
     * Get the absolute position of the bone (world space)
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @returns The absolute position of the bone
     */
    getAbsolutePosition(tNode?: Nullable<TransformNode>): Vector3;
    /**
     * Copy the absolute position of the bone (world space) to the result param
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @param result The vector3 to copy the absolute position to
     */
    getAbsolutePositionToRef(tNode: TransformNode, result: Vector3): void;
    /**
     * Compute the absolute matrices of this bone and its children
     */
    computeAbsoluteMatrices(): void;
    /**
     * Compute the absolute matrices of this bone and its children
     * @deprecated Please use computeAbsoluteMatrices instead
     */
    computeAbsoluteTransforms(): void;
    /**
     * Get the world direction from an axis that is in the local space of the bone
     * @param localAxis The local direction that is used to compute the world direction
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @returns The world direction
     */
    getDirection(localAxis: Vector3, tNode?: Nullable<TransformNode>): Vector3;
    /**
     * Copy the world direction to a vector3 from an axis that is in the local space of the bone
     * @param localAxis The local direction that is used to compute the world direction
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @param result The vector3 that the world direction will be copied to
     */
    getDirectionToRef(localAxis: Vector3, tNode: Nullable<TransformNode> | undefined, result: Vector3): void;
    /**
     * Get the euler rotation of the bone in local or world space
     * @param space The space that the rotation should be in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @returns The euler rotation
     */
    getRotation(space?: Space, tNode?: Nullable<TransformNode>): Vector3;
    /**
     * Copy the euler rotation of the bone to a vector3.  The rotation can be in either local or world space
     * @param space The space that the rotation should be in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @param result The vector3 that the rotation should be copied to
     */
    getRotationToRef(space: Space | undefined, tNode: Nullable<TransformNode> | undefined, result: Vector3): void;
    /**
     * Get the quaternion rotation of the bone in either local or world space
     * @param space The space that the rotation should be in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @returns The quaternion rotation
     */
    getRotationQuaternion(space?: Space, tNode?: Nullable<TransformNode>): Quaternion;
    /**
     * Copy the quaternion rotation of the bone to a quaternion.  The rotation can be in either local or world space
     * @param space The space that the rotation should be in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @param result The quaternion that the rotation should be copied to
     */
    getRotationQuaternionToRef(space: Space | undefined, tNode: Nullable<TransformNode> | undefined, result: Quaternion): void;
    /**
     * Get the rotation matrix of the bone in local or world space
     * @param space The space that the rotation should be in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @returns The rotation matrix
     */
    getRotationMatrix(space: Space | undefined, tNode: TransformNode): Matrix;
    /**
     * Copy the rotation matrix of the bone to a matrix.  The rotation can be in either local or world space
     * @param space The space that the rotation should be in
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @param result The quaternion that the rotation should be copied to
     */
    getRotationMatrixToRef(space: Space | undefined, tNode: TransformNode, result: Matrix): void;
    /**
     * Get the world position of a point that is in the local space of the bone
     * @param position The local position
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @returns The world position
     */
    getAbsolutePositionFromLocal(position: Vector3, tNode?: Nullable<TransformNode>): Vector3;
    /**
     * Get the world position of a point that is in the local space of the bone and copy it to the result param
     * @param position The local position
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @param result The vector3 that the world position should be copied to
     */
    getAbsolutePositionFromLocalToRef(position: Vector3, tNode: Nullable<TransformNode> | undefined, result: Vector3): void;
    /**
     * Get the local position of a point that is in world space
     * @param position The world position
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @returns The local position
     */
    getLocalPositionFromAbsolute(position: Vector3, tNode?: Nullable<TransformNode>): Vector3;
    /**
     * Get the local position of a point that is in world space and copy it to the result param
     * @param position The world position
     * @param tNode A TransformNode whose world matrix is to be applied to the calculated absolute matrix. In most cases, you'll want to pass the mesh associated with the skeleton from which this bone comes. Used only when space=Space.WORLD
     * @param result The vector3 that the local position should be copied to
     */
    getLocalPositionFromAbsoluteToRef(position: Vector3, tNode: Nullable<TransformNode> | undefined, result: Vector3): void;
    /**
     * Set the current local matrix as the restMatrix for this bone.
     */
    setCurrentPoseAsRest(): void;
    /**
     * Releases associated resources
     */
    dispose(): void;
}

/**
 * Class used to abstract a canvas
 */
interface ICanvas {
    /**
     * Canvas width.
     */
    width: number;
    /**
     * Canvas height.
     */
    height: number;
    /**
     * returns a drawing context on the canvas.
     * @param contextType context identifier.
     * @param contextAttributes context attributes.
     * @returns ICanvasRenderingContext object.
     */
    getContext(contextType: string, contextAttributes?: any): ICanvasRenderingContext;
    /**
     * returns a data URI containing a representation of the image in the format specified by the type parameter.
     * @param mime the image format.
     * @returns string containing the requested data URI.
     */
    toDataURL(mime: string): string;
    /**
     * Removes the canvas from the document.
     * Offscreen canvases don't have the remove function, so we need to make it optional.
     */
    remove?(): void;
}
/**
 * Class used to abstract am image to use with the canvas and its context
 */
interface IImage {
    /**
     * onload callback.
     */
    onload: ((this: GlobalEventHandlers, ev: Event) => any) | null;
    /**
     * Error callback.
     */
    onerror: ((this: GlobalEventHandlers, ev: Event) => any) | null;
    /**
     * Image source.
     */
    src: string;
    /**
     * Image width.
     */
    readonly width: number;
    /**
     * Image height.
     */
    readonly height: number;
    /**
     * The original height of the image resource before sizing.
     */
    readonly naturalHeight: number;
    /**
     * The original width of the image resource before sizing.
     */
    readonly naturalWidth: number;
    /**
     * provides support for CORS, defining how the element handles crossorigin requests,
     * thereby enabling the configuration of the CORS requests for the element's fetched data.
     */
    crossOrigin: string | null;
    /**
     * provides support for referrer policy on xhr load request,
     * it is used to control the request header.
     */
    referrerPolicy: string;
}
/**
 * Class used to abstract a 2D path to use with the canvas and its context
 */
interface IPath2D {
    /**
     * Adds a path to the current path.
     * @param path A Path2D path to add.
     * @param transform A DOMMatrix to be used as the transformation matrix for the path that is added.
     */
    addPath(path: IPath2D, transform?: DOMMatrix): void;
    /**
     * Causes the point of the pen to move back to the start of the current sub-path. It tries to draw a straight line from the current point to the start.
     * If the shape has already been closed or has only one point, this function does nothing.
     */
    closePath(): void;
    /**
     * Moves the starting point of a new sub-path to the (x, y) coordinates.
     * @param x The x-axis (horizontal) coordinate of the point.
     * @param y The y-axis (vertical) coordinate of the point.
     */
    moveTo(x: number, y: number): void;
    /**
     * Connects the last point in the current sub-path to the specified (x, y) coordinates with a straight line.
     * @param x The x-axis coordinate of the line's end point.
     * @param y The y-axis coordinate of the line's end point.
     */
    lineTo(x: number, y: number): void;
    /**
     * Adds a cubic Bzier curve to the current path.
     * @param cp1x The x-axis coordinate of the first control point.
     * @param cp1y The y-axis coordinate of the first control point.
     * @param cp2x The x-axis coordinate of the second control point.
     * @param cp2y The y-axis coordinate of the second control point.
     * @param x The x-axis coordinate of the end point.
     * @param y The y-axis coordinate of the end point.
     */
    bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number): void;
    /**
     * Adds a quadratic Bzier curve to the current path.
     * @param cpx The x-axis coordinate of the control point.
     * @param cpy The y-axis coordinate of the control point.
     * @param x The x-axis coordinate of the end point.
     * @param y The y-axis coordinate of the end point.
     */
    quadraticCurveTo(cpx: number, cpy: number, x: number, y: number): void;
    /**
     * Adds a circular arc to the current path.
     * @param x The horizontal coordinate of the arc's center.
     * @param y The vertical coordinate of the arc's center.
     * @param radius The arc's radius. Must be positive.
     * @param startAngle The angle at which the arc starts in radians, measured from the positive x-axis.
     * @param endAngle The angle at which the arc ends in radians, measured from the positive x-axis.
     * @param counterclockwise An optional Boolean. If true, draws the arc counter-clockwise between the start and end angles. The default is false (clockwise).
     */
    arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise?: boolean): void;
    /**
     * Adds a circular arc to the current sub-path, using the given control points and radius.
     * @param x1 The x-axis coordinate of the first control point.
     * @param y1 The y-axis coordinate of the first control point.
     * @param x2 The x-axis coordinate of the second control point.
     * @param y2 The y-axis coordinate of the second control point.
     * @param radius The arc's radius. Must be non-negative.
     */
    arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): void;
    /**
     * Creates an elliptical arc centered at (x, y) with the radii radiusX and radiusY. The path starts at startAngle and ends at endAngle, and travels in the direction given by counterclockwise.
     * @param x The x-axis (horizontal) coordinate of the ellipse's center.
     * @param y The y-axis (vertical) coordinate of the ellipse's center.
     * @param radiusX The ellipse's major-axis radius. Must be non-negative.
     * @param radiusY The ellipse's minor-axis radius. Must be non-negative.
     * @param rotation The rotation of the ellipse, expressed in radians.
     * @param startAngle The eccentric angle at which the ellipse starts, measured clockwise from the positive x-axis and expressed in radians.
     * @param endAngle The eccentric angle at which the ellipse ends, measured clockwise from the positive x-axis and expressed in radians.
     * @param counterclockwise An optional boolean value which, if true, draws the ellipse counterclockwise (anticlockwise). The default value is false (clockwise).
     */
    ellipse(x: number, y: number, radiusX: number, radiusY: number, rotation: number, startAngle: number, endAngle: number, counterclockwise?: boolean): void;
    /**
     * Creates a path for a rectangle at position (x, y) with a size that is determined by width and height.
     * @param x The x-axis coordinate of the rectangle's starting point.
     * @param y The y-axis coordinate of the rectangle's starting point.
     * @param width The rectangle's width. Positive values are to the right, and negative to the left.
     * @param height The rectangle's height. Positive values are down, and negative are up.
     */
    rect(x: number, y: number, width: number, height: number): void;
    /**
     * Adds a rounded rectangle to the current path.
     * @param x The x-axis coordinate of the rectangle's starting point, in pixels.
     * @param y The y-axis coordinate of the rectangle's starting point, in pixels.
     * @param width The rectangle's width. Positive values are to the right, and negative to the left.
     * @param height The rectangle's height. Positive values are down, and negative are up.
     * @param radii A number specifying the radii of the circular arc to be used for the corners of the rectangle. The number and order of the radii function in the same way as the border-radius CSS property when width and height are positive:
     */
    roundRect(x: number, y: number, width: number, height: number, radii: number): void;
}
/**
 * Class used to abstract a canvas gradient
 */
interface ICanvasGradient {
    /**
     * adds a new color stop, defined by an offset and a color, to a given canvas gradient.
     * @param offset A number between 0 and 1, inclusive, representing the position of the color stop. 0 represents the start of the gradient and 1 represents the end.
     * @param color value representing the color of the stop.
     */
    addColorStop(offset: number, color: string): void;
}
/**
 * Class used to abstract a text measurement
 */
interface ITextMetrics {
    /**
     * Text width.
     */
    readonly width: number;
    /**
     * distance (in pixels) parallel to the baseline from the alignment point given by the CanvasRenderingContext2D.textAlign
     * property to the left side of the bounding rectangle of the given text
     */
    readonly actualBoundingBoxLeft: number;
    /**
     * distance (in pixels) parallel to the baseline from the alignment point given by the CanvasRenderingContext2D.textAlign
     * property to the right side of the bounding rectangle of the given text
     */
    readonly actualBoundingBoxRight: number;
    /**
     * distance (in pixels) from the horizontal line indicated by the CanvasRenderingContext2D.textBaseline
     * property to the top side of the bounding rectangle of the given text
     */
    readonly actualBoundingBoxAscent: number;
    /**
     * distance (in pixels) from the horizontal line indicated by the CanvasRenderingContext2D.textBaseline
     * property to the bottom side of the bounding rectangle of the given text
     */
    readonly actualBoundingBoxDescent: number;
}
/**
 * Class used to abstract a matrix
 */
interface DOMMatrix {
    /**
     * A Boolean flag whose value is true if the matrix was initialized as a 2D matrix. If false, the matrix is 3D.
     */
    is2D: boolean;
    /**
     * A Boolean whose value is true if the matrix is the identity matrix. The identity matrix is one in which every value is 0 except those on the main diagonal from top-left to bottom-right corner (in other words, where the offsets in each direction are equal).
     */
    isIdentity: boolean;
    /**
     * The following double-precision floating-point values represent the components of a matrix which are required in order to perform 2D rotations and translations.
     */
    a: number;
    /**
     * The following double-precision floating-point values represent the components of a matrix which are required in order to perform 2D rotations and translations.
     */
    b: number;
    /**
     * The following double-precision floating-point values represent the components of a matrix which are required in order to perform 2D rotations and translations.
     */
    c: number;
    /**
     * The following double-precision floating-point values represent the components of a matrix which are required in order to perform 2D rotations and translations.
     */
    d: number;
    /**
     * The following double-precision floating-point values represent the components of a matrix which are required in order to perform 2D rotations and translations.
     */
    e: number;
    /**
     * The following double-precision floating-point values represent the components of a matrix which are required in order to perform 2D rotations and translations.
     */
    f: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m11: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m12: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m13: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m14: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m21: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m22: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m23: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m24: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m31: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m32: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m33: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m34: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m41: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m42: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m43: number;
    /**
     * The following are double-precision floating-point values representing each component of a 44 matrix, where m11 through m14 are the first column, m21 through m24 are the second column, and so forth.
     */
    m44: number;
}
/**
 * Class used to abstract canvas rendering
 */
interface ICanvasRenderingContext {
    /**
     * Defines the type of corners where two lines meet. Possible values: round, bevel, miter (default).
     */
    lineJoin: string;
    /**
     * Miter limit ratio. Default 10.
     */
    miterLimit: number;
    /**
     * Font setting. Default value 10px sans-serif.
     */
    font: string;
    /**
     * Color or style to use for the lines around shapes. Default #000 (black).
     */
    strokeStyle: string | ICanvasGradient;
    /**
     * Color or style to use inside shapes. Default #000 (black).
     */
    fillStyle: string | ICanvasGradient;
    /**
     * Provides filter effects such as blurring and grayscaling. It is similar to the CSS filter property and accepts the same values.
     */
    filter: string;
    /**
     * Alpha value that is applied to shapes and images before they are composited onto the canvas. Default 1.0 (opaque).
     */
    globalAlpha: number;
    /**
     * Color of the shadow. Default: fully-transparent black.
     */
    shadowColor: string;
    /**
     * Specifies the blurring effect. Default: 0.
     */
    shadowBlur: number;
    /**
     * Horizontal distance the shadow will be offset. Default: 0.
     */
    shadowOffsetX: number;
    /**
     * Vertical distance the shadow will be offset. Default: 0.
     */
    shadowOffsetY: number;
    /**
     * Width of lines. Default 1.0.
     */
    lineWidth: number;
    /**
     * canvas is a read-only reference to ICanvas.
     */
    readonly canvas: ICanvas;
    /**
     * Sets all pixels in the rectangle defined by starting point (x, y) and size (width, height) to transparent black, erasing any previously drawn content.
     * @param x The x-axis coordinate of the rectangle's starting point.
     * @param y The y-axis coordinate of the rectangle's starting point.
     * @param width The rectangle's width. Positive values are to the right, and negative to the left.
     * @param height The rectangle's height. Positive values are down, and negative are up.
     */
    clearRect(x: number, y: number, width: number, height: number): void;
    /**
     * Saves the current drawing style state using a stack so you can revert any change you make to it using restore().
     */
    save(): void;
    /**
     * Restores the drawing style state to the last element on the 'state stack' saved by save().
     */
    restore(): void;
    /**
     * Draws a filled rectangle at (x, y) position whose size is determined by width and height.
     * @param x The x-axis coordinate of the rectangle's starting point.
     * @param y The y-axis coordinate of the rectangle's starting point.
     * @param width The rectangle's width. Positive values are to the right, and negative to the left.
     * @param height The rectangle's height. Positive values are down, and negative are up.
     */
    fillRect(x: number, y: number, width: number, height: number): void;
    /**
     * Adds a scaling transformation to the canvas units by x horizontally and by y vertically.
     * @param x Scaling factor in the horizontal direction. A negative value flips pixels across the vertical axis. A value of 1 results in no horizontal scaling.
     * @param y Scaling factor in the vertical direction. A negative value flips pixels across the horizontal axis. A value of 1 results in no vertical scaling.
     */
    scale(x: number, y: number): void;
    /**
     * Adds a rotation to the transformation matrix. The angle argument represents a clockwise rotation angle and is expressed in radians.
     * @param angle The rotation angle, clockwise in radians. You can use degree * Math.PI / 180 to calculate a radian from a degree.
     */
    rotate(angle: number): void;
    /**
     * Adds a translation transformation by moving the canvas and its origin x horizontally and y vertically on the grid.
     * @param x Distance to move in the horizontal direction. Positive values are to the right, and negative to the left.
     * @param y Distance to move in the vertical direction. Positive values are down, and negative are up.
     */
    translate(x: number, y: number): void;
    /**
     * Paints a rectangle which has a starting point at (x, y) and has a w width and an h height onto the canvas, using the current stroke style.
     * @param x The x-axis coordinate of the rectangle's starting point.
     * @param y The y-axis coordinate of the rectangle's starting point.
     * @param width The rectangle's width. Positive values are to the right, and negative to the left.
     * @param height The rectangle's height. Positive values are down, and negative are up.
     */
    strokeRect(x: number, y: number, width: number, height: number): void;
    /**
     * Creates a path for a rectangle at position (x, y) with a size that is determined by width and height.
     * @param x The x-axis coordinate of the rectangle's starting point.
     * @param y The y-axis coordinate of the rectangle's starting point.
     * @param width The rectangle's width. Positive values are to the right, and negative to the left.
     * @param height The rectangle's height. Positive values are down, and negative are up.
     */
    rect(x: number, y: number, width: number, height: number): void;
    /**
     * Creates a clipping path from the current sub-paths. Everything drawn after clip() is called appears inside the clipping path only.
     */
    clip(): void;
    /**
     * Paints data from the given ImageData object onto the bitmap. If a dirty rectangle is provided, only the pixels from that rectangle are painted.
     * @param imageData An ImageData object containing the array of pixel values.
     * @param dx Horizontal position (x coordinate) at which to place the image data in the destination canvas.
     * @param dy Vertical position (y coordinate) at which to place the image data in the destination canvas.
     */
    putImageData(imageData: ImageData, dx: number, dy: number): void;
    /**
     * Adds a circular arc to the current path.
     * @param x The horizontal coordinate of the arc's center.
     * @param y The vertical coordinate of the arc's center.
     * @param radius The arc's radius. Must be positive.
     * @param startAngle The angle at which the arc starts in radians, measured from the positive x-axis.
     * @param endAngle The angle at which the arc ends in radians, measured from the positive x-axis.
     * @param anticlockwise An optional Boolean. If true, draws the arc counter-clockwise between the start and end angles. The default is false (clockwise).
     */
    arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, anticlockwise?: boolean): void;
    /**
     * Starts a new path by emptying the list of sub-paths. Call this method when you want to create a new path.
     */
    beginPath(): void;
    /**
     * Causes the point of the pen to move back to the start of the current sub-path. It tries to draw a straight line from the current point to the start.
     * If the shape has already been closed or has only one point, this function does nothing.
     */
    closePath(): void;
    /**
     * Moves the starting point of a new sub-path to the (x, y) coordinates.
     * @param x The x-axis (horizontal) coordinate of the point.
     * @param y The y-axis (vertical) coordinate of the point.
     */
    moveTo(x: number, y: number): void;
    /**
     * Connects the last point in the current sub-path to the specified (x, y) coordinates with a straight line.
     * @param x The x-axis coordinate of the line's end point.
     * @param y The y-axis coordinate of the line's end point.
     */
    lineTo(x: number, y: number): void;
    /**
     * Adds a quadratic Bzier curve to the current path.
     * @param cpx The x-axis coordinate of the control point.
     * @param cpy The y-axis coordinate of the control point.
     * @param x The x-axis coordinate of the end point.
     * @param y The y-axis coordinate of the end point.
     */
    quadraticCurveTo(cpx: number, cpy: number, x: number, y: number): void;
    /**
     * Returns a TextMetrics object.
     * @param text The text String to measure.
     * @returns ITextMetrics A ITextMetrics object.
     */
    measureText(text: string): ITextMetrics;
    /**
     * Strokes the current sub-paths with the current stroke style.
     * @param path Optional Path2D.
     */
    stroke(path?: IPath2D): void;
    /**
     * Fills the current sub-paths with the current fill style.
     */
    fill(): void;
    /**
     * Draws the specified image. This method is available in multiple formats, providing a great deal of flexibility in its use.
     * @param image An element to draw into the context.
     * @param sx The x-axis coordinate of the top left corner of the sub-rectangle of the source image to draw into the destination context.
     * @param sy The y-axis coordinate of the top left corner of the sub-rectangle of the source image to draw into the destination context.
     * @param sWidth The width of the sub-rectangle of the source image to draw into the destination context. If not specified, the entire rectangle from the coordinates specified by sx and sy to the bottom-right corner of the image is used.
     * @param sHeight The height of the sub-rectangle of the source image to draw into the destination context.
     * @param dx The x-axis coordinate in the destination canvas at which to place the top-left corner of the source image.
     * @param dy The y-axis coordinate in the destination canvas at which to place the top-left corner of the source image.
     * @param dWidth The width to draw the image in the destination canvas. This allows scaling of the drawn image. If not specified, the image is not scaled in width when drawn.
     * @param dHeight The height to draw the image in the destination canvas. This allows scaling of the drawn image. If not specified, the image is not scaled in height when drawn.
     */
    drawImage(image: any, sx: number, sy: number, sWidth: number, sHeight: number, dx: number, dy: number, dWidth: number, dHeight: number): void;
    /**
     * Draws the specified image. This method is available in multiple formats, providing a great deal of flexibility in its use.
     * @param image An element to draw into the context.
     * @param dx The x-axis coordinate in the destination canvas at which to place the top-left corner of the source image.
     * @param dy The y-axis coordinate in the destination canvas at which to place the top-left corner of the source image.
     * @param dWidth The width to draw the image in the destination canvas. This allows scaling of the drawn image. If not specified, the image is not scaled in width when drawn.
     * @param dHeight The height to draw the image in the destination canvas. This allows scaling of the drawn image. If not specified, the image is not scaled in height when drawn.
     */
    drawImage(image: any, dx: number, dy: number, dWidth: number, dHeight: number): void;
    /**
     * Draws the specified image. This method is available in multiple formats, providing a great deal of flexibility in its use.
     * @param image An element to draw into the context.
     * @param dx The x-axis coordinate in the destination canvas at which to place the top-left corner of the source image.
     * @param dy The y-axis coordinate in the destination canvas at which to place the top-left corner of the source image.
     */
    drawImage(image: any, dx: number, dy: number): void;
    /**
     * Returns an ImageData object representing the underlying pixel data for the area of the canvas denoted by the rectangle which starts at (sx, sy) and has an sw width and sh height.
     * @param sx The x-axis coordinate of the top-left corner of the rectangle from which the ImageData will be extracted.
     * @param sy The y-axis coordinate of the top-left corner of the rectangle from which the ImageData will be extracted.
     * @param sw The width of the rectangle from which the ImageData will be extracted. Positive values are to the right, and negative to the left.
     * @param sh The height of the rectangle from which the ImageData will be extracted. Positive values are down, and negative are up.
     * @returns ImageData An ImageData object containing the image data for the rectangle of the canvas specified.
     */
    getImageData(sx: number, sy: number, sw: number, sh: number): ImageData;
    /**
     * Sets the current line dash pattern.
     * @param segments An Array of numbers that specify distances to alternately draw a line and a gap (in coordinate space units).
     */
    setLineDash(segments: Array<number>): void;
    /**
     * Draws (fills) a given text at the given (x, y) position.
     * @param text A String specifying the text string to render into the context. The text is rendered using the settings specified by font, textAlign, textBaseline, and direction.
     * @param x The x-axis coordinate of the point at which to begin drawing the text, in pixels.
     * @param y The y-axis coordinate of the baseline on which to begin drawing the text, in pixels.
     * @param maxWidth The maximum number of pixels wide the text may be once rendered. If not specified, there is no limit to the width of the text.
     */
    fillText(text: string, x: number, y: number, maxWidth?: number): void;
    /**
     * Draws (strokes) a given text at the given (x, y) position.
     * @param text A String specifying the text string to render into the context. The text is rendered using the settings specified by font, textAlign, textBaseline, and direction.
     * @param x The x-axis coordinate of the point at which to begin drawing the text, in pixels.
     * @param y The y-axis coordinate of the baseline on which to begin drawing the text, in pixels.
     * @param maxWidth The maximum number of pixels wide the text may be once rendered. If not specified, there is no limit to the width of the text.
     */
    strokeText(text: string, x: number, y: number, maxWidth?: number): void;
    /**
     * Creates a linear gradient along the line given by the coordinates represented by the parameters.
     * @param x0 The x-axis coordinate of the start point.
     * @param y0 The y-axis coordinate of the start point.
     * @param x1 The x-axis coordinate of the end point.
     * @param y1 The y-axis coordinate of the end point.
     * @returns ICanvasGradient A linear ICanvasGradient initialized with the specified line.
     */
    createLinearGradient(x0: number, y0: number, x1: number, y1: number): ICanvasGradient;
    /**
     * Creates a linear gradient along the line given by the coordinates represented by the parameters.
     * @param x0 The x-axis coordinate of the start circle.
     * @param y0 The y-axis coordinate of the start circle.
     * @param r0 The radius of the start circle. Must be non-negative and finite.
     * @param x1 The x-axis coordinate of the end point.
     * @param y1 The y-axis coordinate of the end point.
     * @param r1 The radius of the end circle. Must be non-negative and finite.
     * @returns ICanvasGradient A linear ICanvasGradient initialized with the two specified circles.
     */
    createRadialGradient(x0: number, y0: number, r0: number, x1: number, y1: number, r1: number): ICanvasGradient;
    /**
     * Resets the current transform to matrix composed with a, b, c, d, e, f.
     * @param a Horizontal scaling. A value of 1 results in no scaling.
     * @param b Vertical skewing.
     * @param c Horizontal skewing.
     * @param d Vertical scaling. A value of 1 results in no scaling.
     * @param e Horizontal translation (moving).
     * @param f Vertical translation (moving).
     */
    setTransform(a: number, b: number, c: number, d: number, e: number, f: number): void;
    /**
     * Retrieves the current transformation matrix being applied to the context.
     */
    getTransform(): DOMMatrix;
}

/** @internal */
interface IHardwareTextureWrapper {
    underlyingResource: any;
    set(hardwareTexture: any): void;
    setUsage(textureSource: number, generateMipMaps: boolean, is2DArray: boolean, isCube: boolean, is3D: boolean, width: number, height: number, depth: number): void;
    reset(): void;
    release(): void;
}

/**
 * Class used to store a texture sampler data
 */
declare class TextureSampler {
    /**
     * Gets the sampling mode of the texture
     */
    samplingMode: number;
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    get wrapU(): Nullable<number>;
    set wrapU(value: Nullable<number>);
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    get wrapV(): Nullable<number>;
    set wrapV(value: Nullable<number>);
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    get wrapR(): Nullable<number>;
    set wrapR(value: Nullable<number>);
    /**
     * With compliant hardware and browser (supporting anisotropic filtering)
     * this defines the level of anisotropic filtering in the texture.
     * The higher the better but the slower.
     */
    get anisotropicFilteringLevel(): Nullable<number>;
    set anisotropicFilteringLevel(value: Nullable<number>);
    /**
     * Gets or sets the comparison function (Constants.LESS, Constants.EQUAL, etc). Set 0 to not use a comparison function
     */
    get comparisonFunction(): number;
    set comparisonFunction(value: number);
    protected _useMipMaps: Nullable<boolean>;
    /**
     * Indicates to use the mip maps (if available on the texture).
     * Thanks to this flag, you can instruct the sampler to not sample the mipmaps even if they exist (and if the sampling mode is set to a value that normally samples the mipmaps!)
     */
    get useMipMaps(): Nullable<boolean>;
    set useMipMaps(value: Nullable<boolean>);
    /** @internal */
    _cachedWrapU: Nullable<number>;
    /** @internal */
    _cachedWrapV: Nullable<number>;
    /** @internal */
    _cachedWrapR: Nullable<number>;
    /** @internal */
    _cachedAnisotropicFilteringLevel: Nullable<number>;
    /** @internal */
    _comparisonFunction: number;
    /**
     * General label used for debugging or storing a name.
     */
    label?: string;
    /**
     * Creates a Sampler instance
     */
    constructor();
    /**
     * Sets all the parameters of the sampler
     * @param wrapU u address mode (default: TEXTURE_WRAP_ADDRESSMODE)
     * @param wrapV v address mode (default: TEXTURE_WRAP_ADDRESSMODE)
     * @param wrapR r address mode (default: TEXTURE_WRAP_ADDRESSMODE)
     * @param anisotropicFilteringLevel anisotropic level (default: 1)
     * @param samplingMode sampling mode (default: Constants.TEXTURE_BILINEAR_SAMPLINGMODE)
     * @param comparisonFunction comparison function (default: 0 - no comparison function)
     * @returns the current sampler instance
     */
    setParameters(wrapU?: number, wrapV?: number, wrapR?: number, anisotropicFilteringLevel?: number, samplingMode?: number, comparisonFunction?: number): TextureSampler;
    /**
     * Compares this sampler with another one
     * @param other sampler to compare with
     * @returns true if the samplers have the same parametres, else false
     */
    compareSampler(other: TextureSampler): boolean;
}

/**
 * Class representing spherical harmonics coefficients to the 3rd degree
 */
declare class SphericalHarmonics {
    /**
     * Defines whether or not the harmonics have been prescaled for rendering.
     */
    preScaled: boolean;
    /**
     * The l0,0 coefficients of the spherical harmonics
     */
    l00: Vector3;
    /**
     * The l1,-1 coefficients of the spherical harmonics
     */
    l1_1: Vector3;
    /**
     * The l1,0 coefficients of the spherical harmonics
     */
    l10: Vector3;
    /**
     * The l1,1 coefficients of the spherical harmonics
     */
    l11: Vector3;
    /**
     * The l2,-2 coefficients of the spherical harmonics
     */
    l2_2: Vector3;
    /**
     * The l2,-1 coefficients of the spherical harmonics
     */
    l2_1: Vector3;
    /**
     * The l2,0 coefficients of the spherical harmonics
     */
    l20: Vector3;
    /**
     * The l2,1 coefficients of the spherical harmonics
     */
    l21: Vector3;
    /**
     * The l2,2 coefficients of the spherical harmonics
     */
    l22: Vector3;
    /**
     * Adds a light to the spherical harmonics
     * @param direction the direction of the light
     * @param color the color of the light
     * @param deltaSolidAngle the delta solid angle of the light
     */
    addLight(direction: Vector3, color: Color3, deltaSolidAngle: number): void;
    /**
     * Scales the spherical harmonics by the given amount
     * @param scale the amount to scale
     */
    scaleInPlace(scale: number): void;
    /**
     * Convert from incident radiance (Li) to irradiance (E) by applying convolution with the cosine-weighted hemisphere.
     *
     * ```
     * E_lm = A_l * L_lm
     * ```
     *
     * In spherical harmonics this convolution amounts to scaling factors for each frequency band.
     * This corresponds to equation 5 in "An Efficient Representation for Irradiance Environment Maps", where
     * the scaling factors are given in equation 9.
     */
    convertIncidentRadianceToIrradiance(): void;
    /**
     * Convert from irradiance to outgoing radiance for Lambertian BDRF, suitable for efficient shader evaluation.
     *
     * ```
     * L = (1/pi) * E * rho
     * ```
     *
     * This is done by an additional scale by 1/pi, so is a fairly trivial operation but important conceptually.
     */
    convertIrradianceToLambertianRadiance(): void;
    /**
     * Integrates the reconstruction coefficients directly in to the SH preventing further
     * required operations at run time.
     *
     * This is simply done by scaling back the SH with Ylm constants parameter.
     * The trigonometric part being applied by the shader at run time.
     */
    preScaleForRendering(): void;
    /**
     * update the spherical harmonics coefficients from the given array
     * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
     * @returns the spherical harmonics (this)
     */
    updateFromArray(data: ArrayLike<ArrayLike<number>>): SphericalHarmonics;
    /**
     * update the spherical harmonics coefficients from the given floats array
     * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
     * @returns the spherical harmonics (this)
     */
    updateFromFloatsArray(data: ArrayLike<number>): SphericalHarmonics;
    /**
     * Constructs a spherical harmonics from an array.
     * @param data defines the 9x3 coefficients (l00, l1-1, l10, l11, l2-2, l2-1, l20, l21, l22)
     * @returns the spherical harmonics
     */
    static FromArray(data: ArrayLike<ArrayLike<number>>): SphericalHarmonics;
    /**
     * Gets the spherical harmonics from polynomial
     * @param polynomial the spherical polynomial
     * @returns the spherical harmonics
     */
    static FromPolynomial(polynomial: SphericalPolynomial): SphericalHarmonics;
}
/**
 * Class representing spherical polynomial coefficients to the 3rd degree
 */
declare class SphericalPolynomial {
    private _harmonics;
    /**
     * The spherical harmonics used to create the polynomials.
     */
    get preScaledHarmonics(): SphericalHarmonics;
    /**
     * The x coefficients of the spherical polynomial
     */
    x: Vector3;
    /**
     * The y coefficients of the spherical polynomial
     */
    y: Vector3;
    /**
     * The z coefficients of the spherical polynomial
     */
    z: Vector3;
    /**
     * The xx coefficients of the spherical polynomial
     */
    xx: Vector3;
    /**
     * The yy coefficients of the spherical polynomial
     */
    yy: Vector3;
    /**
     * The zz coefficients of the spherical polynomial
     */
    zz: Vector3;
    /**
     * The xy coefficients of the spherical polynomial
     */
    xy: Vector3;
    /**
     * The yz coefficients of the spherical polynomial
     */
    yz: Vector3;
    /**
     * The zx coefficients of the spherical polynomial
     */
    zx: Vector3;
    /**
     * Adds an ambient color to the spherical polynomial
     * @param color the color to add
     */
    addAmbient(color: Color3): void;
    /**
     * Scales the spherical polynomial by the given amount
     * @param scale the amount to scale
     */
    scaleInPlace(scale: number): void;
    /**
     * Updates the spherical polynomial from harmonics
     * @param harmonics the spherical harmonics
     * @returns the spherical polynomial
     */
    updateFromHarmonics(harmonics: SphericalHarmonics): SphericalPolynomial;
    /**
     * Gets the spherical polynomial from harmonics
     * @param harmonics the spherical harmonics
     * @returns the spherical polynomial
     */
    static FromHarmonics(harmonics: SphericalHarmonics): SphericalPolynomial;
    /**
     * Constructs a spherical polynomial from an array.
     * @param data defines the 9x3 coefficients (x, y, z, xx, yy, zz, yz, zx, xy)
     * @returns the spherical polynomial
     */
    static FromArray(data: ArrayLike<ArrayLike<number>>): SphericalPolynomial;
}

/**
 * Defines the source of the internal texture
 */
declare const enum InternalTextureSource {
    /**
     * The source of the texture data is unknown
     */
    Unknown = 0,
    /**
     * Texture data comes from an URL
     */
    Url = 1,
    /**
     * Texture data is only used for temporary storage
     */
    Temp = 2,
    /**
     * Texture data comes from raw data (ArrayBuffer)
     */
    Raw = 3,
    /**
     * Texture content is dynamic (video or dynamic texture)
     */
    Dynamic = 4,
    /**
     * Texture content is generated by rendering to it
     */
    RenderTarget = 5,
    /**
     * Texture content is part of a multi render target process
     */
    MultiRenderTarget = 6,
    /**
     * Texture data comes from a cube data file
     */
    Cube = 7,
    /**
     * Texture data comes from a raw cube data
     */
    CubeRaw = 8,
    /**
     * Texture data come from a prefiltered cube data file
     */
    CubePrefiltered = 9,
    /**
     * Texture content is raw 3D data
     */
    Raw3D = 10,
    /**
     * Texture content is raw 2D array data
     */
    Raw2DArray = 11,
    /**
     * Texture content is a depth/stencil texture
     */
    DepthStencil = 12,
    /**
     * Texture data comes from a raw cube data encoded with RGBD
     */
    CubeRawRGBD = 13,
    /**
     * Texture content is a depth texture
     */
    Depth = 14
}
/**
 * Class used to store data associated with WebGL texture data for the engine
 * This class should not be used directly
 */
declare class InternalTexture extends TextureSampler {
    /**
     * Defines if the texture is ready
     */
    isReady: boolean;
    /**
     * Defines if the texture is a cube texture
     */
    isCube: boolean;
    /**
     * Defines if the texture contains 3D data
     */
    is3D: boolean;
    /**
     * Defines if the texture contains 2D array data
     */
    is2DArray: boolean;
    /**
     * Defines if the texture contains multiview data
     */
    isMultiview: boolean;
    /**
     * Gets the URL used to load this texture
     */
    url: string;
    /** @internal */
    _originalUrl: string;
    /**
     * Gets a boolean indicating if the texture needs mipmaps generation
     */
    generateMipMaps: boolean;
    protected _useMipMaps: Nullable<boolean>;
    /**
     * Indicates to use the mip maps (if available on the texture).
     * Thanks to this flag, you can instruct the sampler to not sample the mipmaps even if they exist (and if the sampling mode is set to a value that normally samples the mipmaps!)
     * If useMipMaps is null, the value of generateMipMaps is returned by the getter (for backward compatibility)
     */
    get useMipMaps(): Nullable<boolean>;
    set useMipMaps(value: Nullable<boolean>);
    /**
     * Gets the number of mip levels for this texture.
     * Note: This property has the correct value only if the texture was created through
     * `createRawTexture` or `createRawTexture2DArray`.
     */
    mipLevelCount: number;
    /**
     * Gets the number of samples used by the texture (WebGL2+ only)
     */
    samples: number;
    /**
     * Gets the type of the texture (int, float...)
     */
    type: number;
    /**
     * Gets the format of the texture (RGB, RGBA...)
     */
    format: number;
    /**
     * Observable called when the texture is loaded
     */
    onLoadedObservable: Observable<InternalTexture>;
    /**
     * Observable called when the texture load is raising an error
     */
    onErrorObservable: Observable<Partial<{
        message: string;
        exception: any;
    }>>;
    /**
     * If this callback is defined it will be called instead of the default _rebuild function
     */
    onRebuildCallback: Nullable<(internalTexture: InternalTexture) => {
        proxy: Nullable<InternalTexture | Promise<InternalTexture>>;
        isReady: boolean;
        isAsync: boolean;
    }>;
    /**
     * Gets the width of the texture
     */
    width: number;
    /**
     * Gets the height of the texture
     */
    height: number;
    /**
     * Gets the depth of the texture
     */
    depth: number;
    /**
     * Gets the initial width of the texture (It could be rescaled if the current system does not support non power of two textures)
     */
    baseWidth: number;
    /**
     * Gets the initial height of the texture (It could be rescaled if the current system does not support non power of two textures)
     */
    baseHeight: number;
    /**
     * Gets the initial depth of the texture (It could be rescaled if the current system does not support non power of two textures)
     */
    baseDepth: number;
    /**
     * Gets a boolean indicating if the texture is inverted on Y axis
     */
    invertY: boolean;
    /** @internal */
    _invertVScale: boolean;
    /** @internal */
    _associatedChannel: number;
    /** @internal */
    _source: InternalTextureSource;
    /** @internal */
    _buffer: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>;
    /** @internal */
    _bufferView: Nullable<ArrayBufferView>;
    /** @internal */
    _bufferViewArray: Nullable<ArrayBufferView[]>;
    /** @internal */
    _bufferViewArrayArray: Nullable<ArrayBufferView[][]>;
    /** @internal */
    _size: number;
    /** @internal */
    _extension: string;
    /** @internal */
    _files: Nullable<string[]>;
    /** @internal */
    _workingCanvas: Nullable<ICanvas>;
    /** @internal */
    _workingContext: Nullable<ICanvasRenderingContext>;
    /** @internal */
    _cachedCoordinatesMode: Nullable<number>;
    /** @internal */
    _isDisabled: boolean;
    /** @internal */
    _compression: Nullable<string>;
    /** @internal */
    _sphericalPolynomial: Nullable<SphericalPolynomial>;
    /** @internal */
    _sphericalPolynomialPromise: Nullable<Promise<SphericalPolynomial>>;
    /** @internal */
    _sphericalPolynomialComputed: boolean;
    /** @internal */
    _lodGenerationScale: number;
    /** @internal */
    _lodGenerationOffset: number;
    /** @internal */
    _useSRGBBuffer: boolean;
    /** @internal */
    _creationFlags: number;
    /** @internal */
    _originalFormat?: number;
    /** @internal */
    _lodTextureHigh: Nullable<BaseTexture>;
    /** @internal */
    _lodTextureMid: Nullable<BaseTexture>;
    /** @internal */
    _lodTextureLow: Nullable<BaseTexture>;
    /** @internal */
    _isRGBD: boolean;
    /** @internal */
    _linearSpecularLOD: boolean;
    /** @internal */
    _irradianceTexture: Nullable<BaseTexture>;
    /** @internal */
    _hardwareTexture: Nullable<IHardwareTextureWrapper>;
    /** @internal */
    _maxLodLevel: Nullable<number>;
    /** @internal */
    _references: number;
    /** @internal */
    _gammaSpace: Nullable<boolean>;
    /** @internal */
    _premulAlpha: boolean;
    /** @internal */
    _dynamicTextureSource: Nullable<ImageSource>;
    /** @internal */
    _autoMSAAManagement: boolean;
    private _engine;
    private _uniqueId;
    /** @internal */
    static _Counter: number;
    /** Gets the unique id of the internal texture */
    get uniqueId(): number;
    /** @internal */
    _setUniqueId(id: number): void;
    /**
     * Gets the Engine the texture belongs to.
     * @returns The babylon engine
     */
    getEngine(): AbstractEngine;
    /**
     * Gets the data source type of the texture
     */
    get source(): InternalTextureSource;
    /**
     * Creates a new InternalTexture
     * @param engine defines the engine to use
     * @param source defines the type of data that will be used
     * @param delayAllocation if the texture allocation should be delayed (default: false)
     */
    constructor(engine: AbstractEngine, source: InternalTextureSource, delayAllocation?: boolean);
    /**
     * Increments the number of references (ie. the number of Texture that point to it)
     */
    incrementReferences(): void;
    /**
     * Change the size of the texture (not the size of the content)
     * @param width defines the new width
     * @param height defines the new height
     * @param depth defines the new depth (1 by default)
     */
    updateSize(width: int, height: int, depth?: int): void;
    /** @internal */
    _rebuild(): void;
    /**
     * @internal
     */
    _swapAndDie(target: InternalTexture, swapAll?: boolean): void;
    /**
     * Dispose the current allocated resources
     */
    dispose(): void;
}

/**
 * Interface used to define the mechanism to get data from the network
 */
interface IWebRequest {
    /**
     * Returns client's response url
     */
    responseURL: string;
    /**
     * Returns client's status
     */
    status: number;
    /**
     * Returns client's status as a text
     */
    statusText: string;
}

/**
 * Extended version of XMLHttpRequest with support for customizations (headers, ...)
 */
declare class WebRequest implements IWebRequest {
    private readonly _xhr;
    /**
     * Custom HTTP Request Headers to be sent with XMLHttpRequests
     * i.e. when loading files, where the server/service expects an Authorization header
     */
    static CustomRequestHeaders: {
        [key: string]: string;
    };
    /**
     * Add callback functions in this array to update all the requests before they get sent to the network
     */
    static CustomRequestModifiers: ((request: XMLHttpRequest, url: string) => string | void)[];
    /**
     * If set to true, requests to Babylon.js CDN requests will not be modified
     */
    static SkipRequestModificationForBabylonCDN: boolean;
    /**
     * This function can be called to check if there are request modifiers for network requests
     * @returns true if there are any custom requests available
     */
    static get IsCustomRequestAvailable(): boolean;
    private _requestURL;
    /**
     * Returns the requested URL once open has been called
     */
    get requestURL(): string;
    private _injectCustomRequestHeaders;
    private _shouldSkipRequestModifications;
    /**
     * Gets or sets a function to be called when loading progress changes
     */
    get onprogress(): ((this: XMLHttpRequest, ev: ProgressEvent) => any) | null;
    set onprogress(value: ((this: XMLHttpRequest, ev: ProgressEvent) => any) | null);
    /**
     * Returns client's state
     */
    get readyState(): number;
    /**
     * Returns client's status
     */
    get status(): number;
    /**
     * Returns client's status as a text
     */
    get statusText(): string;
    /**
     * Returns client's response
     */
    get response(): any;
    /**
     * Returns client's response url
     */
    get responseURL(): string;
    /**
     * Returns client's response as text
     */
    get responseText(): string;
    /**
     * Gets or sets the expected response type
     */
    get responseType(): XMLHttpRequestResponseType;
    set responseType(value: XMLHttpRequestResponseType);
    /**
     * Gets or sets the timeout value in milliseconds
     */
    get timeout(): number;
    set timeout(value: number);
    /** @internal */
    addEventListener<K extends keyof XMLHttpRequestEventMap>(type: K, listener: (this: XMLHttpRequest, ev: XMLHttpRequestEventMap[K]) => any, options?: boolean | AddEventListenerOptions): void;
    /** @internal */
    removeEventListener<K extends keyof XMLHttpRequestEventMap>(type: K, listener: (this: XMLHttpRequest, ev: XMLHttpRequestEventMap[K]) => any, options?: boolean | EventListenerOptions): void;
    /**
     * Cancels any network activity
     */
    abort(): void;
    /**
     * Initiates the request. The optional argument provides the request body. The argument is ignored if request method is GET or HEAD
     * @param body defines an optional request body
     */
    send(body?: Document | XMLHttpRequestBodyInit | null): void;
    /**
     * Sets the request method, request URL
     * @param method defines the method to use (GET, POST, etc..)
     * @param url defines the url to connect with
     */
    open(method: string, url: string): void;
    /**
     * Sets the value of a request header.
     * @param name The name of the header whose value is to be set
     * @param value The value to set as the body of the header
     */
    setRequestHeader(name: string, value: string): void;
    /**
     * Get the string containing the text of a particular header's value.
     * @param name The name of the header
     * @returns The string containing the text of the given header name
     */
    getResponseHeader(name: string): Nullable<string>;
}

/**
 * Class used to enable access to offline support
 * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimizeCached
 */
interface IOfflineProvider {
    /**
     * Gets a boolean indicating if scene must be saved in the database
     */
    enableSceneOffline: boolean;
    /**
     * Gets a boolean indicating if textures must be saved in the database
     */
    enableTexturesOffline: boolean;
    /**
     * Open the offline support and make it available
     * @param successCallback defines the callback to call on success
     * @param errorCallback defines the callback to call on error
     */
    open(successCallback: () => void, errorCallback: () => void): void;
    /**
     * Loads an image from the offline support
     * @param url defines the url to load from
     * @param image defines the target DOM image
     */
    loadImage(url: string, image: HTMLImageElement): void;
    /**
     * Loads a file from offline support
     * @param url defines the URL to load from
     * @param sceneLoaded defines a callback to call on success
     * @param progressCallBack defines a callback to call when progress changed
     * @param errorCallback defines a callback to call on error
     * @param useArrayBuffer defines a boolean to use array buffer instead of text string
     */
    loadFile(url: string, sceneLoaded: (data: any) => void, progressCallBack?: (data: any) => void, errorCallback?: () => void, useArrayBuffer?: boolean): void;
}

/**
 * File request interface
 */
interface IFileRequest {
    /**
     * Raised when the request is complete (success or error).
     */
    onCompleteObservable: Observable<IFileRequest>;
    /**
     * Aborts the request for a file.
     */
    abort: () => void;
}

/**
 * Base error. Due to limitations of typedoc-check and missing documentation
 * in lib.es5.d.ts, cannot extend Error directly for RuntimeError.
 * @ignore
 */
declare abstract class BaseError extends Error {
    protected static _setPrototypeOf: (o: any, proto: object | null) => any;
}
/**
 * Error codes for BaseError
 */
declare const ErrorCodes: {
    /** Invalid or empty mesh vertex positions. */
    readonly MeshInvalidPositionsError: 0;
    /** Unsupported texture found. */
    readonly UnsupportedTextureError: 1000;
    /** Unexpected magic number found in GLTF file header. */
    readonly GLTFLoaderUnexpectedMagicError: 2000;
    /** SceneLoader generic error code. Ideally wraps the inner exception. */
    readonly SceneLoaderError: 3000;
    /** Load file error */
    readonly LoadFileError: 4000;
    /** Request file error */
    readonly RequestFileError: 4001;
    /** Read file error */
    readonly ReadFileError: 4002;
};
/**
 * Error code type
 */
type ErrorCodesType = (typeof ErrorCodes)[keyof typeof ErrorCodes];
/**
 * Application runtime error
 */
declare class RuntimeError extends BaseError {
    /**
     * The error code
     */
    errorCode: ErrorCodesType;
    /**
     * The error that caused this outer error
     */
    innerError?: Error;
    /**
     * Creates a new RuntimeError
     * @param message defines the message of the error
     * @param errorCode the error code
     * @param innerError the error that caused the outer error
     */
    constructor(message: string, errorCode: ErrorCodesType, innerError?: Error);
}

/** @ignore */
declare class LoadFileError extends RuntimeError {
    request?: WebRequest;
    file?: File;
    /**
     * Creates a new LoadFileError
     * @param message defines the message of the error
     * @param object defines the optional web request
     */
    constructor(message: string, object?: WebRequest | File);
}
/** @ignore */
declare class RequestFileError extends RuntimeError {
    request: WebRequest;
    /**
     * Creates a new LoadFileError
     * @param message defines the message of the error
     * @param request defines the optional web request
     */
    constructor(message: string, request: WebRequest);
}
/** @ignore */
declare class ReadFileError extends RuntimeError {
    file: File;
    /**
     * Creates a new ReadFileError
     * @param message defines the message of the error
     * @param file defines the optional file
     */
    constructor(message: string, file: File);
}

/**
 * Interface for the size containing width and height
 */
interface ISize {
    /**
     * Width
     */
    width: number;
    /**
     * Height
     */
    height: number;
}
/**
 * Size containing width and height
 */
declare class Size implements ISize {
    /**
     * Width
     */
    width: number;
    /**
     * Height
     */
    height: number;
    /**
     * Creates a Size object from the given width and height (floats).
     * @param width width of the new size
     * @param height height of the new size
     */
    constructor(width: number, height: number);
    /**
     * Returns a string with the Size width and height
     * @returns a string with the Size width and height
     */
    toString(): string;
    /**
     * "Size"
     * @returns the string "Size"
     */
    getClassName(): string;
    /**
     * Returns the Size hash code.
     * @returns a hash code for a unique width and height
     */
    getHashCode(): number;
    /**
     * Updates the current size from the given one.
     * @param src the given size
     */
    copyFrom(src: Size): void;
    /**
     * Updates in place the current Size from the given floats.
     * @param width width of the new size
     * @param height height of the new size
     * @returns the updated Size.
     */
    copyFromFloats(width: number, height: number): Size;
    /**
     * Updates in place the current Size from the given floats.
     * @param width width to set
     * @param height height to set
     * @returns the updated Size.
     */
    set(width: number, height: number): Size;
    /**
     * Multiplies the width and height by numbers
     * @param w factor to multiple the width by
     * @param h factor to multiple the height by
     * @returns a new Size set with the multiplication result of the current Size and the given floats.
     */
    multiplyByFloats(w: number, h: number): Size;
    /**
     * Clones the size
     * @returns a new Size copied from the given one.
     */
    clone(): Size;
    /**
     * True if the current Size and the given one width and height are strictly equal.
     * @param other the other size to compare against
     * @returns True if the current Size and the given one width and height are strictly equal.
     */
    equals(other: Size): boolean;
    /**
     * The surface of the Size : width * height (float).
     */
    get surface(): number;
    /**
     * Create a new size of zero
     * @returns a new Size set to (0.0, 0.0)
     */
    static Zero(): Size;
    /**
     * Sums the width and height of two sizes
     * @param otherSize size to add to this size
     * @returns a new Size set as the addition result of the current Size and the given one.
     */
    add(otherSize: Size): Size;
    /**
     * Subtracts the width and height of two
     * @param otherSize size to subtract to this size
     * @returns a new Size set as the subtraction result of  the given one from the current Size.
     */
    subtract(otherSize: Size): Size;
    /**
     * Scales the width and height
     * @param scale the scale to multiply the width and height by
     * @returns a new Size set with the multiplication result of the current Size and the given floats.
     */
    scale(scale: number): Size;
    /**
     * Creates a new Size set at the linear interpolation "amount" between "start" and "end"
     * @param start starting size to lerp between
     * @param end end size to lerp between
     * @param amount amount to lerp between the start and end values
     * @returns a new Size set at the linear interpolation "amount" between "start" and "end"
     */
    static Lerp(start: Size, end: Size, amount: number): Size;
}

/**
 * Define options used to create an internal texture
 */
interface InternalTextureCreationOptions {
    /** Specifies if mipmaps must be created. If undefined, the value from generateMipMaps is taken instead */
    createMipMaps?: boolean;
    /** Specifies if mipmaps must be generated */
    generateMipMaps?: boolean;
    /** Defines texture type (unsigned byte by default) */
    type?: number;
    /** Defines sampling mode (trilinear by default) */
    samplingMode?: number;
    /** Defines format (RGBA by default) */
    format?: number;
    /** Defines sample count (1 by default) */
    samples?: number;
    /** Texture creation flags */
    creationFlags?: number;
    /** Creates the RTT in sRGB space */
    useSRGBBuffer?: boolean;
    /** Label of the texture (used for debugging only) */
    label?: string;
    /** If the MSAA texture must be created right away (default: false) */
    createMSAATexture?: boolean;
    /** Comparison function. Used only for depth textures (default: 0) */
    comparisonFunction?: number;
    /** If the created texture is a cube texture */
    isCube?: boolean;
}
/**
 * Define options used to create a render target texture
 */
interface RenderTargetCreationOptions extends InternalTextureCreationOptions {
    /** Specifies whether or not a depth should be allocated in the texture (true by default) */
    generateDepthBuffer?: boolean;
    /** Specifies whether or not a stencil should be allocated in the texture (false by default)*/
    generateStencilBuffer?: boolean;
    /** Specifies that no color target should be bound to the render target (useful if you only want to write to the depth buffer, for eg) */
    noColorAttachment?: boolean;
    /** Specifies the internal texture to use directly instead of creating one (ignores `noColorAttachment` flag when set) **/
    colorAttachment?: InternalTexture;
}
/**
 * Define options used to create a depth texture
 */
interface DepthTextureCreationOptions {
    /** Specifies whether or not a stencil should be allocated in the texture. Not used if depthTextureFormat is supplied, in which case stencil creation will depend on this value. */
    generateStencil?: boolean;
    /** Specifies whether or not bilinear filtering is enable on the texture */
    bilinearFiltering?: boolean;
    /** Specifies the comparison function to set on the texture. If 0 or undefined, the texture is not in comparison mode */
    comparisonFunction?: number;
    /** Specifies if the created texture is a cube texture */
    isCube?: boolean;
    /** Specifies the sample count of the depth/stencil texture texture */
    samples?: number;
    /** Specifies the depth texture format to use */
    depthTextureFormat?: number;
    /** Label of the texture (used for debugging only) */
    label?: string;
}
/**
 * Type used to define a texture size (either with a number or with a rect width and height)
 */
type TextureSize = number | {
    width: number;
    height: number;
    depth?: number;
    layers?: number;
};

/**
 * An interface enforcing the renderTarget accessor to used by render target textures.
 */
interface IRenderTargetTexture {
    /**
     * Entry point to access the wrapper on a texture.
     */
    renderTarget: Nullable<RenderTargetWrapper>;
}
/**
 * Wrapper around a render target (either single or multi textures)
 */
declare class RenderTargetWrapper {
    protected _engine: AbstractEngine;
    private _size;
    private _isCube;
    private _isMulti;
    private _textures;
    private _faceIndices;
    private _layerIndices;
    private _depthStencilTextureLabel?;
    /** @internal */
    _samples: number;
    /** @internal */
    _attachments: Nullable<number[]>;
    /** @internal */
    _generateStencilBuffer: boolean;
    /** @internal */
    _generateDepthBuffer: boolean;
    /** @internal */
    _depthStencilTexture: Nullable<InternalTexture>;
    /** @internal */
    _depthStencilTextureWithStencil: boolean;
    /**
     * Gets or sets the label of the render target wrapper (optional, for debugging purpose)
     */
    label?: string;
    /**
     * Gets the depth/stencil texture
     */
    get depthStencilTexture(): Nullable<InternalTexture>;
    /**
     * Sets the depth/stencil texture
     * @param texture The depth/stencil texture to set
     * @param disposeExisting True to dispose the existing depth/stencil texture (if any) before replacing it (default: true)
     */
    setDepthStencilTexture(texture: Nullable<InternalTexture>, disposeExisting?: boolean): void;
    /**
     * Indicates if the depth/stencil texture has a stencil aspect
     */
    get depthStencilTextureWithStencil(): boolean;
    /**
     * Defines if the render target wrapper is for a cube texture or if false a 2d texture
     */
    get isCube(): boolean;
    /**
     * Defines if the render target wrapper is for a single or multi target render wrapper
     */
    get isMulti(): boolean;
    /**
     * Defines if the render target wrapper is for a single or an array of textures
     */
    get is2DArray(): boolean;
    /**
     * Defines if the render target wrapper is for a 3D texture
     */
    get is3D(): boolean;
    /**
     * Gets the size of the render target wrapper (used for cubes, as width=height in this case)
     */
    get size(): number;
    /**
     * Gets the width of the render target wrapper
     */
    get width(): number;
    /**
     * Gets the height of the render target wrapper
     */
    get height(): number;
    /**
     * Gets the number of layers of the render target wrapper (only used if is2DArray is true and wrapper is not a multi render target)
     */
    get layers(): number;
    /**
     * Gets the depth of the render target wrapper (only used if is3D is true and wrapper is not a multi render target)
     */
    get depth(): number;
    /**
     * Gets the render texture. If this is a multi render target, gets the first texture
     */
    get texture(): Nullable<InternalTexture>;
    /**
     * Gets the list of render textures. If we are not in a multi render target, the list will be null (use the texture getter instead)
     */
    get textures(): Nullable<InternalTexture[]>;
    /**
     * Gets the face indices that correspond to the list of render textures. If we are not in a multi render target, the list will be null
     */
    get faceIndices(): Nullable<number[]>;
    /**
     * Gets the layer indices that correspond to the list of render textures. If we are not in a multi render target, the list will be null
     */
    get layerIndices(): Nullable<number[]>;
    /**
     * Sets this property to true to disable the automatic MSAA resolve that happens when the render target wrapper is unbound (default is false)
     */
    disableAutomaticMSAAResolve: boolean;
    /**
     * Indicates if MSAA color texture(s) should be resolved when a resolve occur (either automatically by the engine or manually by the user) (default is true)
     * Note that you can trigger a MSAA resolve at any time by calling resolveMSAATextures()
     */
    resolveMSAAColors: boolean;
    /**
     * Indicates if MSAA depth texture should be resolved when a resolve occur (either automatically by the engine or manually by the user) (default is false)
     */
    resolveMSAADepth: boolean;
    /**
     * Indicates if MSAA stencil texture should be resolved when a resolve occur (either automatically by the engine or manually by the user) (default is false)
     */
    resolveMSAAStencil: boolean;
    /**
     * Indicates if the depth texture is in read-only mode (may allow some optimizations in WebGPU)
     */
    depthReadOnly: boolean;
    /**
     * Indicates if the stencil texture is in read-only mode (may allow some optimizations in WebGPU)
     */
    stencilReadOnly: boolean;
    /**
     * Gets the base array layer of a texture in the textures array
     * This is an number that is calculated based on the layer and face indices set for this texture at that index
     * @param index The index of the texture in the textures array to get the base array layer for
     * @returns the base array layer of the texture at the given index
     */
    getBaseArrayLayer(index: number): number;
    /**
     * Gets the sample count of the render target
     */
    get samples(): number;
    /**
     * Sets the sample count of the render target
     * @param value sample count
     * @param initializeBuffers If set to true, the engine will make an initializing call to drawBuffers (only used when isMulti=true).
     * @param force true to force calling the update sample count engine function even if the current sample count is equal to value
     * @returns the sample count that has been set
     */
    setSamples(value: number, initializeBuffers?: boolean, force?: boolean): number;
    /**
     * Resolves the MSAA textures into their non-MSAA version.
     * Note that if samples equals 1 (no MSAA), no resolve is performed.
     */
    resolveMSAATextures(): void;
    /**
     * Generates mipmaps for each texture of the render target
     */
    generateMipMaps(): void;
    /**
     * Initializes the render target wrapper
     * @param isMulti true if the wrapper is a multi render target
     * @param isCube true if the wrapper should render to a cube texture
     * @param size size of the render target (width/height/layers)
     * @param engine engine used to create the render target
     * @param label defines the label to use for the wrapper (for debugging purpose only)
     */
    constructor(isMulti: boolean, isCube: boolean, size: TextureSize, engine: AbstractEngine, label?: string);
    /**
     * Sets the render target texture(s)
     * @param textures texture(s) to set
     */
    setTextures(textures: Nullable<InternalTexture> | Nullable<InternalTexture[]>): void;
    /**
     * Set a texture in the textures array
     * @param texture The texture to set
     * @param index The index in the textures array to set
     * @param disposePrevious If this function should dispose the previous texture
     */
    setTexture(texture: InternalTexture, index?: number, disposePrevious?: boolean): void;
    /**
     * Sets the layer and face indices of every render target texture bound to each color attachment
     * @param layers The layers of each texture to be set
     * @param faces The faces of each texture to be set
     */
    setLayerAndFaceIndices(layers: number[], faces: number[]): void;
    /**
     * Sets the layer and face indices of a texture in the textures array that should be bound to each color attachment
     * @param index The index of the texture in the textures array to modify
     * @param layer The layer of the texture to be set
     * @param face The face of the texture to be set
     */
    setLayerAndFaceIndex(index?: number, layer?: number, face?: number): void;
    /**
     * Creates the depth/stencil texture
     * @param comparisonFunction Comparison function to use for the texture
     * @param bilinearFiltering true if bilinear filtering should be used when sampling the texture
     * @param generateStencil Not used anymore. "format" will be used to determine if stencil should be created
     * @param samples sample count to use when creating the texture (default: 1)
     * @param format format of the depth texture (default: Constants.TEXTUREFORMAT_DEPTH32_FLOAT)
     * @param label defines the label to use for the texture (for debugging purpose only)
     * @returns the depth/stencil created texture
     */
    createDepthStencilTexture(comparisonFunction?: number, bilinearFiltering?: boolean, generateStencil?: boolean, samples?: number, format?: number, label?: string): InternalTexture;
    /**
     * @deprecated Use shareDepth instead
     * @param renderTarget Destination renderTarget
     */
    _shareDepth(renderTarget: RenderTargetWrapper): void;
    /**
     * Shares the depth buffer of this render target with another render target.
     * @param renderTarget Destination renderTarget
     */
    shareDepth(renderTarget: RenderTargetWrapper): void;
    /**
     * @internal
     */
    _swapAndDie(target: InternalTexture): void;
    protected _cloneRenderTargetWrapper(): Nullable<RenderTargetWrapper>;
    protected _swapRenderTargetWrapper(target: RenderTargetWrapper): void;
    /** @internal */
    _rebuild(): void;
    /**
     * Releases the internal render textures
     */
    releaseTextures(): void;
    /**
     * Disposes the whole render target wrapper
     * @param disposeOnlyFramebuffers true if only the frame buffers should be released (used for the WebGL engine). If false, all the textures will also be released
     */
    dispose(disposeOnlyFramebuffers?: boolean): void;
}

/**
 * Base class of all the textures in babylon.
 * It groups all the common properties required to work with Thin Engine.
 */
declare class ThinTexture {
    protected _wrapU: number;
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    get wrapU(): number;
    set wrapU(value: number);
    protected _wrapV: number;
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    get wrapV(): number;
    set wrapV(value: number);
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    wrapR: number;
    /**
     * With compliant hardware and browser (supporting anisotropic filtering)
     * this defines the level of anisotropic filtering in the texture.
     * The higher the better but the slower. This defaults to 4 as it seems to be the best tradeoff.
     */
    anisotropicFilteringLevel: number;
    /**
     * Define the current state of the loading sequence when in delayed load mode.
     */
    delayLoadState: number;
    /**
     * How a texture is mapped.
     * Unused in thin texture mode.
     */
    get coordinatesMode(): number;
    /**
     * Define if the texture is a cube texture or if false a 2d texture.
     */
    get isCube(): boolean;
    protected set isCube(value: boolean);
    /**
     * Define if the texture is a 3d texture (webgl 2) or if false a 2d texture.
     */
    get is3D(): boolean;
    protected set is3D(value: boolean);
    /**
     * Define if the texture is a 2d array texture (webgl 2) or if false a 2d texture.
     */
    get is2DArray(): boolean;
    protected set is2DArray(value: boolean);
    /**
     * Get the class name of the texture.
     * @returns "ThinTexture"
     */
    getClassName(): string;
    /** @internal */
    _texture: Nullable<InternalTexture>;
    protected _engine: Nullable<AbstractEngine>;
    private _cachedSize;
    private _cachedBaseSize;
    private static _IsRenderTargetWrapper;
    /**
     * Instantiates a new ThinTexture.
     * Base class of all the textures in babylon.
     * This can be used as an internal texture wrapper in AbstractEngine to benefit from the cache
     * @param internalTexture Define the internalTexture to wrap. You can also pass a RenderTargetWrapper, in which case the texture will be the render target's texture
     */
    constructor(internalTexture: Nullable<InternalTexture | RenderTargetWrapper>);
    /**
     * Get if the texture is ready to be used (downloaded, converted, mip mapped...).
     * @returns true if fully ready
     */
    isReady(): boolean;
    /**
     * Triggers the load sequence in delayed load mode.
     */
    delayLoad(): void;
    /**
     * Get the underlying lower level texture from Babylon.
     * @returns the internal texture
     */
    getInternalTexture(): Nullable<InternalTexture>;
    /**
     * Get the size of the texture.
     * @returns the texture size.
     */
    getSize(): ISize;
    /**
     * Get the base size of the texture.
     * It can be different from the size if the texture has been resized for POT for instance
     * @returns the base size
     */
    getBaseSize(): ISize;
    /** @internal */
    protected _initialSamplingMode: number;
    /**
     * Get the current sampling mode associated with the texture.
     */
    get samplingMode(): number;
    /**
     * Update the sampling mode of the texture.
     * Default is Trilinear mode.
     *
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 1     | NEAREST_SAMPLINGMODE or NEAREST_NEAREST_MIPLINEAR  | Nearest is: mag = nearest, min = nearest, mip = linear |
     * | 2     | BILINEAR_SAMPLINGMODE or LINEAR_LINEAR_MIPNEAREST | Bilinear is: mag = linear, min = linear, mip = nearest |
     * | 3     | TRILINEAR_SAMPLINGMODE or LINEAR_LINEAR_MIPLINEAR | Trilinear is: mag = linear, min = linear, mip = linear |
     * | 4     | NEAREST_NEAREST_MIPNEAREST |             |
     * | 5    | NEAREST_LINEAR_MIPNEAREST |             |
     * | 6    | NEAREST_LINEAR_MIPLINEAR |             |
     * | 7    | NEAREST_LINEAR |             |
     * | 8    | NEAREST_NEAREST |             |
     * | 9   | LINEAR_NEAREST_MIPNEAREST |             |
     * | 10   | LINEAR_NEAREST_MIPLINEAR |             |
     * | 11   | LINEAR_LINEAR |             |
     * | 12   | LINEAR_NEAREST |             |
     *
     *    > _mag_: magnification filter (close to the viewer)
     *    > _min_: minification filter (far from the viewer)
     *    > _mip_: filter used between mip map levels
     *@param samplingMode Define the new sampling mode of the texture
     *@param generateMipMaps Define if the texture should generate mip maps or not. Default is false.
     */
    updateSamplingMode(samplingMode: number, generateMipMaps?: boolean): void;
    /**
     * Release and destroy the underlying lower level texture aka internalTexture.
     */
    releaseInternalTexture(): void;
    /**
     * Dispose the texture and release its associated resources.
     */
    dispose(): void;
}

/**
 * Base class of all the textures in babylon.
 * It groups all the common properties the materials, post process, lights... might need
 * in order to make a correct use of the texture.
 */
declare class BaseTexture extends ThinTexture implements IAnimatable {
    /**
     * Default anisotropic filtering level for the application.
     * It is set to 4 as a good tradeoff between perf and quality.
     */
    static DEFAULT_ANISOTROPIC_FILTERING_LEVEL: number;
    /**
     * Gets or sets the unique id of the texture
     */
    uniqueId: number;
    /**
     * Define the name of the texture.
     */
    name: string;
    /**
     * Define the display name of the texture, which is used as tree item name of the dedicated node in the inspector
     */
    displayName: string;
    /**
     * Gets or sets an object used to store user defined information.
     */
    metadata: any;
    /** @internal */
    _internalMetadata: any;
    /**
     * For internal use only. Please do not use.
     */
    reservedDataStore: any;
    private _hasAlpha;
    /**
     * Define if the texture is having a usable alpha value (can be use for transparency or glossiness for instance).
     */
    set hasAlpha(value: boolean);
    get hasAlpha(): boolean;
    private _getAlphaFromRGB;
    /**
     * Defines if the alpha value should be determined via the rgb values.
     * If true the luminance of the pixel might be used to find the corresponding alpha value.
     */
    set getAlphaFromRGB(value: boolean);
    get getAlphaFromRGB(): boolean;
    /**
     * Intensity or strength of the texture.
     * It is commonly used by materials to fine tune the intensity of the texture
     */
    level: number;
    protected _coordinatesIndex: number;
    /**
     * Gets or sets a boolean indicating that the texture should try to reduce shader code if there is no UV manipulation.
     * (ie. when texture.getTextureMatrix().isIdentityAs3x2() returns true)
     */
    optimizeUVAllocation: boolean;
    /**
     * Define the UV channel to use starting from 0 and defaulting to 0.
     * This is part of the texture as textures usually maps to one uv set.
     */
    set coordinatesIndex(value: number);
    get coordinatesIndex(): number;
    protected _coordinatesMode: number;
    /**
     * How a texture is mapped.
     *
     * | Value | Type                                | Description |
     * | ----- | ----------------------------------- | ----------- |
     * | 0     | EXPLICIT_MODE                       |             |
     * | 1     | SPHERICAL_MODE                      |             |
     * | 2     | PLANAR_MODE                         |             |
     * | 3     | CUBIC_MODE                          |             |
     * | 4     | PROJECTION_MODE                     |             |
     * | 5     | SKYBOX_MODE                         |             |
     * | 6     | INVCUBIC_MODE                       |             |
     * | 7     | EQUIRECTANGULAR_MODE                |             |
     * | 8     | FIXED_EQUIRECTANGULAR_MODE          |             |
     * | 9     | FIXED_EQUIRECTANGULAR_MIRRORED_MODE |             |
     */
    set coordinatesMode(value: number);
    get coordinatesMode(): number;
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    get wrapU(): number;
    set wrapU(value: number);
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    get wrapV(): number;
    set wrapV(value: number);
    /**
     * | Value | Type               | Description |
     * | ----- | ------------------ | ----------- |
     * | 0     | CLAMP_ADDRESSMODE  |             |
     * | 1     | WRAP_ADDRESSMODE   |             |
     * | 2     | MIRROR_ADDRESSMODE |             |
     */
    wrapR: number;
    /**
     * With compliant hardware and browser (supporting anisotropic filtering)
     * this defines the level of anisotropic filtering in the texture.
     * The higher the better but the slower. This defaults to 4 as it seems to be the best tradeoff.
     */
    anisotropicFilteringLevel: number;
    /** @internal */
    _isCube: boolean;
    /**
     * Define if the texture is a cube texture or if false a 2d texture.
     */
    get isCube(): boolean;
    protected set isCube(value: boolean);
    /**
     * Define if the texture is a 3d texture (webgl 2) or if false a 2d texture.
     */
    get is3D(): boolean;
    protected set is3D(value: boolean);
    /**
     * Define if the texture is a 2d array texture (webgl 2) or if false a 2d texture.
     */
    get is2DArray(): boolean;
    protected set is2DArray(value: boolean);
    /** @internal */
    protected _gammaSpace: boolean;
    /**
     * Define if the texture contains data in gamma space (most of the png/jpg aside bump).
     * HDR texture are usually stored in linear space.
     * This only impacts the PBR and Background materials
     */
    get gammaSpace(): boolean;
    set gammaSpace(gamma: boolean);
    /**
     * Gets or sets whether or not the texture contains RGBD data.
     */
    get isRGBD(): boolean;
    set isRGBD(value: boolean);
    /**
     * Is Z inverted in the texture (useful in a cube texture).
     */
    invertZ: boolean;
    /**
     * Are mip maps generated for this texture or not.
     */
    get noMipmap(): boolean;
    /**
     * @internal
     */
    lodLevelInAlpha: boolean;
    /**
     * With prefiltered texture, defined the offset used during the prefiltering steps.
     */
    get lodGenerationOffset(): number;
    set lodGenerationOffset(value: number);
    /**
     * With prefiltered texture, defined the scale used during the prefiltering steps.
     */
    get lodGenerationScale(): number;
    set lodGenerationScale(value: number);
    /**
     * With prefiltered texture, defined if the specular generation is based on a linear ramp.
     * By default we are using a log2 of the linear roughness helping to keep a better resolution for
     * average roughness values.
     */
    get linearSpecularLOD(): boolean;
    set linearSpecularLOD(value: boolean);
    /**
     * In case a better definition than spherical harmonics is required for the diffuse part of the environment.
     * You can set the irradiance texture to rely on a texture instead of the spherical approach.
     * This texture need to have the same characteristics than its parent (Cube vs 2d, coordinates mode, Gamma/Linear, RGBD).
     */
    get irradianceTexture(): Nullable<BaseTexture>;
    set irradianceTexture(value: Nullable<BaseTexture>);
    /**
     * Indicates the average direction of light in an environment map. This
     * can be treated as the most dominant direction but it's magnitude also
     * tells you something about how dominant that direction is.
     */
    /** @internal */
    _dominantDirection: Nullable<Vector3>;
    /**
     * Define if the texture is a render target.
     */
    isRenderTarget: boolean;
    /**
     * Define the unique id of the texture in the scene.
     */
    get uid(): string;
    /** @internal */
    _prefiltered: boolean;
    /** @internal */
    _forceSerialize: boolean;
    /**
     * Return a string representation of the texture.
     * @returns the texture as a string
     */
    toString(): string;
    /**
     * Get the class name of the texture.
     * @returns "BaseTexture"
     */
    getClassName(): string;
    /**
     * Define the list of animation attached to the texture.
     */
    animations: Animation[];
    /**
     * An event triggered when the texture is disposed.
     */
    onDisposeObservable: Observable<BaseTexture>;
    private _onDisposeObserver;
    /**
     * Callback triggered when the texture has been disposed.
     * Kept for back compatibility, you can use the onDisposeObservable instead.
     */
    set onDispose(callback: () => void);
    protected _scene: Nullable<Scene>;
    /** @internal */
    private _uid;
    /**
     * Define if the texture is preventing a material to render or not.
     * If not and the texture is not ready, the engine will use a default black texture instead.
     */
    get isBlocking(): boolean;
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    protected _loadingError: boolean;
    protected _errorObject?: {
        message?: string;
        exception?: any;
    };
    /**
     * Was there any loading error?
     */
    get loadingError(): boolean;
    /**
     * If a loading error occurred this object will be populated with information about the error.
     */
    get errorObject(): {
        message?: string;
        exception?: any;
    } | undefined;
    /**
     * Instantiates a new BaseTexture.
     * Base class of all the textures in babylon.
     * It groups all the common properties the materials, post process, lights... might need
     * in order to make a correct use of the texture.
     * @param sceneOrEngine Define the scene or engine the texture belongs to
     * @param internalTexture Define the internal texture associated with the texture
     */
    constructor(sceneOrEngine?: Nullable<Scene | AbstractEngine>, internalTexture?: Nullable<InternalTexture>);
    /**
     * Get the scene the texture belongs to.
     * @returns the scene or null if undefined
     */
    getScene(): Nullable<Scene>;
    /** @internal */
    protected _getEngine(): Nullable<AbstractEngine>;
    /**
     * Get the texture transform matrix used to offset tile the texture for instance.
     * @returns the transformation matrix
     */
    getTextureMatrix(): Matrix;
    /**
     * Get the texture reflection matrix used to rotate/transform the reflection.
     * @returns the reflection matrix
     */
    getReflectionTextureMatrix(): Matrix;
    /**
     * Gets a suitable rotate/transform matrix when the texture is used for refraction.
     * There's a separate function from getReflectionTextureMatrix because refraction requires a special configuration of the matrix in right-handed mode.
     * @returns The refraction matrix
     */
    getRefractionTextureMatrix(): Matrix;
    /**
     * Get if the texture is ready to be consumed (either it is ready or it is not blocking)
     * @returns true if ready, not blocking or if there was an error loading the texture
     */
    isReadyOrNotBlocking(): boolean;
    /**
     * Scales the texture if is `canRescale()`
     * @param ratio the resize factor we want to use to rescale
     */
    scale(ratio: number): void;
    /**
     * Get if the texture can rescale.
     */
    get canRescale(): boolean;
    /**
     * @internal
     */
    _getFromCache(url: Nullable<string>, noMipmap: boolean, sampling?: number, invertY?: boolean, useSRGBBuffer?: boolean, isCube?: boolean): Nullable<InternalTexture>;
    /** @internal */
    _rebuild(_fromContextLost?: boolean): void;
    /**
     * Clones the texture.
     * @returns the cloned texture
     */
    clone(): Nullable<BaseTexture>;
    /**
     * Get the texture underlying type (INT, FLOAT...)
     */
    get textureType(): number;
    /**
     * Get the texture underlying format (RGB, RGBA...)
     */
    get textureFormat(): number;
    /**
     * Indicates that textures need to be re-calculated for all materials
     */
    protected _markAllSubMeshesAsTexturesDirty(): void;
    /**
     * Reads the pixels stored in the webgl texture and returns them as an ArrayBuffer.
     * This will returns an RGBA array buffer containing either in values (0-255) or
     * float values (0-1) depending of the underlying buffer type.
     * @param faceIndex defines the face of the texture to read (in case of cube texture)
     * @param level defines the LOD level of the texture to read (in case of Mip Maps)
     * @param buffer defines a user defined buffer to fill with data (can be null)
     * @param flushRenderer true to flush the renderer from the pending commands before reading the pixels
     * @param noDataConversion false to convert the data to Uint8Array (if texture type is UNSIGNED_BYTE) or to Float32Array (if texture type is anything but UNSIGNED_BYTE). If true, the type of the generated buffer (if buffer==null) will depend on the type of the texture
     * @param x defines the region x coordinates to start reading from (default to 0)
     * @param y defines the region y coordinates to start reading from (default to 0)
     * @param width defines the region width to read from (default to the texture size at level)
     * @param height defines the region width to read from (default to the texture size at level)
     * @returns The Array buffer promise containing the pixels data.
     */
    readPixels(faceIndex?: number, level?: number, buffer?: Nullable<ArrayBufferView>, flushRenderer?: boolean, noDataConversion?: boolean, x?: number, y?: number, width?: number, height?: number): Nullable<Promise<ArrayBufferView>>;
    /**
     * @internal
     */
    _readPixelsSync(faceIndex?: number, level?: number, buffer?: Nullable<ArrayBufferView>, flushRenderer?: boolean, noDataConversion?: boolean): Nullable<ArrayBufferView>;
    /** @internal */
    get _lodTextureHigh(): Nullable<BaseTexture>;
    /** @internal */
    get _lodTextureMid(): Nullable<BaseTexture>;
    /** @internal */
    get _lodTextureLow(): Nullable<BaseTexture>;
    /**
     * Dispose the texture and release its associated resources.
     */
    dispose(): void;
    /**
     * Serialize the texture into a JSON representation that can be parsed later on.
     * @param allowEmptyName True to force serialization even if name is empty. Default: false
     * @returns the JSON representation of the texture
     */
    serialize(allowEmptyName?: boolean): any;
    /**
     * Helper function to be called back once a list of texture contains only ready textures.
     * @param textures Define the list of textures to wait for
     * @param callback Define the callback triggered once the entire list will be ready
     */
    static WhenAllReady(textures: BaseTexture[], callback: () => void): void;
    private static _IsScene;
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /** @internal */
        createCubeTextureBase(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any, createPolynomials: boolean, lodScale: number, lodOffset: number, fallback: Nullable<InternalTexture>, beforeLoadCubeDataCallback: Nullable<(texture: InternalTexture, data: ArrayBufferView | ArrayBufferView[]) => void>, imageHandler: Nullable<(texture: InternalTexture, imgs: HTMLImageElement[] | ImageBitmap[]) => void>, useSRGBBuffer: boolean, buffer: Nullable<ArrayBufferView>): InternalTexture;
        /** @internal */
        _partialLoadFile(url: string, index: number, loadedFiles: ArrayBuffer[], onfinish: (files: ArrayBuffer[]) => void, onErrorCallBack: Nullable<(message?: string, exception?: any) => void>): void;
        /** @internal */
        _cascadeLoadFiles(scene: Nullable<Scene>, onfinish: (images: ArrayBuffer[]) => void, files: string[], onError: Nullable<(message?: string, exception?: any) => void>): void;
        /** @internal */
        _cascadeLoadImgs(scene: Nullable<Scene>, texture: InternalTexture, onfinish: Nullable<(texture: InternalTexture, images: HTMLImageElement[] | ImageBitmap[]) => void>, files: string[], onError: Nullable<(message?: string, exception?: any) => void>, mimeType?: string): void;
        /** @internal */
        _partialLoadImg(url: string, index: number, loadedImages: HTMLImageElement[] | ImageBitmap[], scene: Nullable<Scene>, texture: InternalTexture, onfinish: Nullable<(texture: InternalTexture, images: HTMLImageElement[] | ImageBitmap[]) => void>, onErrorCallBack: Nullable<(message?: string, exception?: any) => void>, mimeType?: string): void;
    }
}

/**
 * Defines the available options when creating a cube texture
 */
interface ICubeTextureCreationOptions {
    /** Defines the suffixes add to the picture name in case six images are in use like _px.jpg */
    extensions?: string[];
    /** noMipmap defines if mipmaps should be created or not */
    noMipmap?: boolean;
    /** files defines the six files to load for the different faces in that order: px, py, pz, nx, ny, nz */
    files?: string[];
    /** buffer to load instead of loading the data from the url */
    buffer?: ArrayBufferView;
    /** onLoad defines a callback triggered at the end of the file load if no errors occurred */
    onLoad?: () => void;
    /** onError defines a callback triggered in case of error during load */
    onError?: (message?: string, exception?: any) => void;
    /** format defines the internal format to use for the texture once loaded */
    format?: number;
    /** prefiltered defines whether or not the texture is created from prefiltered data */
    prefiltered?: boolean;
    /** forcedExtension defines the extensions to use (force a special type of file to load) in case it is different from the file name */
    forcedExtension?: any;
    /** createPolynomials defines whether or not to create polynomial harmonics from the texture data if necessary */
    createPolynomials?: boolean;
    /** lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness */
    lodScale?: number;
    /** lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness */
    lodOffset?: number;
    /** loaderOptions options to be passed to the loader */
    loaderOptions?: any;
    /** useSRGBBuffer Defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU) (default: false) */
    useSRGBBuffer?: boolean;
}
/**
 * Class for creating a cube texture
 */
declare class CubeTexture extends BaseTexture {
    private _delayedOnLoad;
    private _delayedOnError;
    private _lodScale;
    private _lodOffset;
    /**
     * Observable triggered once the texture has been loaded.
     */
    onLoadObservable: Observable<CubeTexture>;
    /**
     * The url of the texture
     */
    url: string;
    /**
     * Gets or sets the center of the bounding box associated with the cube texture.
     * It must define where the camera used to render the texture was set
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#using-local-cubemap-mode
     */
    boundingBoxPosition: Vector3;
    private _boundingBoxSize;
    /**
     * Gets or sets the size of the bounding box associated with the cube texture
     * When defined, the cubemap will switch to local mode
     * @see https://community.arm.com/graphics/b/blog/posts/reflections-based-on-local-cubemaps-in-unity
     * @example https://www.babylonjs-playground.com/#RNASML
     */
    set boundingBoxSize(value: Vector3);
    /**
     * Returns the bounding box size
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#using-local-cubemap-mode
     */
    get boundingBoxSize(): Vector3;
    protected _rotationY: number;
    /**
     * Sets texture matrix rotation angle around Y axis in radians.
     */
    set rotationY(value: number);
    /**
     * Gets texture matrix rotation angle around Y axis radians.
     */
    get rotationY(): number;
    /**
     * Are mip maps generated for this texture or not.
     */
    get noMipmap(): boolean;
    private _noMipmap;
    /** @internal */
    _files: Nullable<string[]>;
    protected _forcedExtension: Nullable<string>;
    /**
     * Gets the forced extension (if any)
     */
    get forcedExtension(): Nullable<string>;
    private _extensions;
    private _textureMatrix;
    private _textureMatrixRefraction;
    private _format;
    private _createPolynomials;
    private _loaderOptions;
    private _useSRGBBuffer?;
    private _buffer;
    /**
     * Creates a cube texture from an array of image urls
     * @param files defines an array of image urls
     * @param scene defines the hosting scene
     * @param noMipmap specifies if mip maps are not used
     * @returns a cube texture
     */
    static CreateFromImages(files: string[], scene: Scene, noMipmap?: boolean): CubeTexture;
    /**
     * Creates and return a texture created from prefilterd data by tools like IBL Baker or Lys.
     * @param url defines the url of the prefiltered texture
     * @param scene defines the scene the texture is attached to
     * @param forcedExtension defines the extension of the file if different from the url
     * @param createPolynomials defines whether or not to create polynomial harmonics from the texture data if necessary
     * @returns the prefiltered texture
     */
    static CreateFromPrefilteredData(url: string, scene: Scene, forcedExtension?: any, createPolynomials?: boolean): CubeTexture;
    /**
     * Creates a cube texture to use with reflection for instance. It can be based upon dds or six images as well
     * as prefiltered data.
     * @param rootUrl defines the url of the texture or the root name of the six images
     * @param sceneOrEngine defines the scene or engine the texture is attached to
     * @param extensionsOrOptions defines the suffixes add to the picture name in case six images are in use like _px.jpg or set of all options to create the cube texture
     * @param noMipmap defines if mipmaps should be created or not
     * @param files defines the six files to load for the different faces in that order: px, py, pz, nx, ny, nz
     * @param onLoad defines a callback triggered at the end of the file load if no errors occurred
     * @param onError defines a callback triggered in case of error during load
     * @param format defines the internal format to use for the texture once loaded
     * @param prefiltered defines whether or not the texture is created from prefiltered data
     * @param forcedExtension defines the extensions to use (force a special type of file to load) in case it is different from the file name
     * @param createPolynomials defines whether or not to create polynomial harmonics from the texture data if necessary
     * @param lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness
     * @param lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness
     * @param loaderOptions options to be passed to the loader
     * @param useSRGBBuffer Defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU) (default: false)
     * @returns the cube texture
     */
    constructor(rootUrl: string, sceneOrEngine: Scene | AbstractEngine, extensionsOrOptions?: Nullable<string[] | ICubeTextureCreationOptions>, noMipmap?: boolean, files?: Nullable<string[]>, onLoad?: Nullable<() => void>, onError?: Nullable<(message?: string, exception?: any) => void>, format?: number, prefiltered?: boolean, forcedExtension?: any, createPolynomials?: boolean, lodScale?: number, lodOffset?: number, loaderOptions?: any, useSRGBBuffer?: boolean);
    /**
     * Get the current class name of the texture useful for serialization or dynamic coding.
     * @returns "CubeTexture"
     */
    getClassName(): string;
    /**
     * Update the url (and optional buffer) of this texture if url was null during construction.
     * @param url the url of the texture
     * @param forcedExtension defines the extension to use
     * @param onLoad callback called when the texture is loaded  (defaults to null)
     * @param prefiltered Defines whether the updated texture is prefiltered or not
     * @param onError callback called if there was an error during the loading process (defaults to null)
     * @param extensions defines the suffixes add to the picture name in case six images are in use like _px.jpg...
     * @param delayLoad defines if the texture should be loaded now (false by default)
     * @param files defines the six files to load for the different faces in that order: px, py, pz, nx, ny, nz
     * @param buffer the buffer to use instead of loading from the url
     */
    updateURL(url: string, forcedExtension?: Nullable<string>, onLoad?: Nullable<() => void>, prefiltered?: boolean, onError?: Nullable<(message?: string, exception?: any) => void>, extensions?: Nullable<string[]>, delayLoad?: boolean, files?: Nullable<string[]>, buffer?: Nullable<ArrayBufferView>): void;
    /**
     * Delays loading of the cube texture
     * @param forcedExtension defines the extension to use
     */
    delayLoad(forcedExtension?: string): void;
    /**
     * Returns the reflection texture matrix
     * @returns the reflection texture matrix
     */
    getReflectionTextureMatrix(): Matrix;
    /**
     * Sets the reflection texture matrix
     * @param value Reflection texture matrix
     */
    setReflectionTextureMatrix(value: Matrix): void;
    /**
     * Gets a suitable rotate/transform matrix when the texture is used for refraction.
     * There's a separate function from getReflectionTextureMatrix because refraction requires a special configuration of the matrix in right-handed mode.
     * @returns The refraction matrix
     */
    getRefractionTextureMatrix(): Matrix;
    private _loadTexture;
    /**
     * Parses text to create a cube texture
     * @param parsedTexture define the serialized text to read from
     * @param scene defines the hosting scene
     * @param rootUrl defines the root url of the cube texture
     * @returns a cube texture
     */
    static Parse(parsedTexture: any, scene: Scene, rootUrl: string): CubeTexture;
    /**
     * Makes a clone, or deep copy, of the cube texture
     * @returns a new cube texture
     */
    clone(): CubeTexture;
}

/**
 * @internal
 */
declare class IntersectionInfo {
    bu: Nullable<number>;
    bv: Nullable<number>;
    distance: number;
    faceId: number;
    subMeshId: number;
    _internalSubMeshId: number;
    constructor(bu: Nullable<number>, bv: Nullable<number>, distance: number);
}

/**
 * Uniform buffer objects.
 *
 * Handles blocks of uniform on the GPU.
 *
 * If WebGL 2 is not available, this class falls back on traditional setUniformXXX calls.
 *
 * For more information, please refer to :
 * https://www.khronos.org/opengl/wiki/Uniform_Buffer_Object
 */
declare class UniformBuffer {
    /** @internal */
    static _UpdatedUbosInFrame: {
        [name: string]: number;
    };
    private _engine;
    private _buffer;
    private _buffers;
    private _bufferIndex;
    private _bufferUpdatedLastFrame;
    private _createBufferOnWrite;
    private _data;
    private _bufferData;
    private _dynamic;
    private _uniformLocations;
    private _uniformSizes;
    private _uniformArraySizes;
    private _uniformNames;
    private _uniformLocationPointer;
    private _needSync;
    private _noUBO;
    private _currentEffect;
    private _currentEffectName;
    private _name;
    private _currentFrameId;
    private _trackUBOsInFrame;
    private static _MAX_UNIFORM_SIZE;
    private static _TempBuffer;
    private static _TempBufferInt32View;
    private static _TempBufferUInt32View;
    /**
     * Lambda to Update a 3x3 Matrix in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateMatrix3x3: (name: string, matrix: Float32Array) => void;
    /**
     * Lambda to Update a 2x2 Matrix in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateMatrix2x2: (name: string, matrix: Float32Array) => void;
    /**
     * Lambda to Update a single float in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateFloat: (name: string, x: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec2 of float in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateFloat2: (name: string, x: number, y: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec3 of float in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateFloat3: (name: string, x: number, y: number, z: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec4 of float in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateFloat4: (name: string, x: number, y: number, z: number, w: number, suffix?: string) => void;
    /**
     * Lambda to Update an array of float in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateFloatArray: (name: string, array: Float32Array, suffix?: string) => void;
    /**
     * Lambda to Update an array of number in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateArray: (name: string, array: number[]) => void;
    /**
     * Lambda to Update an array of number in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateIntArray: (name: string, array: Int32Array) => void;
    /**
     * Lambda to Update an array of number in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateUIntArray: (name: string, array: Uint32Array) => void;
    /**
     * Lambda to Update a 4x4 Matrix in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateMatrix: (name: string, mat: IMatrixLike) => void;
    /**
     * Lambda to Update an array of 4x4 Matrix in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateMatrices: (name: string, mat: Float32Array) => void;
    /**
     * Lambda to Update vec3 of float from a Vector in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateVector3: (name: string, vector: IVector3Like) => void;
    /**
     * Lambda to Update vec4 of float from a Vector in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateVector4: (name: string, vector: IVector4Like) => void;
    /**
     * Lambda to Update vec3 of float from a Color in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateColor3: (name: string, color: IColor3Like, suffix?: string) => void;
    /**
     * Lambda to Update vec4 of float from a Color in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateColor4: (name: string, color: IColor3Like, alpha: number, suffix?: string) => void;
    /**
     * Lambda to Update vec4 of float from a Color in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateDirectColor4: (name: string, color: IColor4Like, suffix?: string) => void;
    /**
     * Lambda to Update a int a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateInt: (name: string, x: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec2 of int in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateInt2: (name: string, x: number, y: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec3 of int in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateInt3: (name: string, x: number, y: number, z: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec4 of int in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateInt4: (name: string, x: number, y: number, z: number, w: number, suffix?: string) => void;
    /**
     * Lambda to Update a unsigned int a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateUInt: (name: string, x: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec2 of unsigned int in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateUInt2: (name: string, x: number, y: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec3 of unsigned int in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateUInt3: (name: string, x: number, y: number, z: number, suffix?: string) => void;
    /**
     * Lambda to Update a vec4 of unsigned int in a uniform buffer.
     * This is dynamic to allow compat with webgl 1 and 2.
     * You will need to pass the name of the uniform as well as the value.
     */
    updateUInt4: (name: string, x: number, y: number, z: number, w: number, suffix?: string) => void;
    /**
     * Instantiates a new Uniform buffer objects.
     *
     * Handles blocks of uniform on the GPU.
     *
     * If WebGL 2 is not available, this class falls back on traditional setUniformXXX calls.
     *
     * For more information, please refer to :
     * @see https://www.khronos.org/opengl/wiki/Uniform_Buffer_Object
     * @param engine Define the engine the buffer is associated with
     * @param data Define the data contained in the buffer
     * @param dynamic Define if the buffer is updatable
     * @param name to assign to the buffer (debugging purpose)
     * @param forceNoUniformBuffer define that this object must not rely on UBO objects
     * @param trackUBOsInFrame define if the UBOs should be tracked in the frame (default: undefined - will use the value from Engine._features.trackUbosInFrame)
     */
    constructor(engine: AbstractEngine, data?: number[], dynamic?: boolean, name?: string, forceNoUniformBuffer?: boolean, trackUBOsInFrame?: boolean);
    /**
     * Indicates if the buffer is using the WebGL2 UBO implementation,
     * or just falling back on setUniformXXX calls.
     */
    get useUbo(): boolean;
    /**
     * Indicates if the WebGL underlying uniform buffer is in sync
     * with the javascript cache data.
     */
    get isSync(): boolean;
    /**
     * Indicates if the WebGL underlying uniform buffer is dynamic.
     * Also, a dynamic UniformBuffer will disable cache verification and always
     * update the underlying WebGL uniform buffer to the GPU.
     * @returns if Dynamic, otherwise false
     */
    isDynamic(): boolean;
    /**
     * The data cache on JS side.
     * @returns the underlying data as a float array
     */
    getData(): Float32Array;
    /**
     * The underlying WebGL Uniform buffer.
     * @returns the webgl buffer
     */
    getBuffer(): Nullable<DataBuffer>;
    /**
     * The names of the uniforms in the buffer.
     * @returns an array of uniform names
     */
    getUniformNames(): string[];
    /**
     * std140 layout specifies how to align data within an UBO structure.
     * See https://khronos.org/registry/OpenGL/specs/gl/glspec45.core.pdf#page=159
     * for specs.
     * @param size
     */
    private _fillAlignment;
    /**
     * Adds an uniform in the buffer.
     * Warning : the subsequents calls of this function must be in the same order as declared in the shader
     * for the layout to be correct ! The addUniform function only handles types like float, vec2, vec3, vec4, mat4,
     * meaning size=1,2,3,4 or 16. It does not handle struct types.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     * @param size Data size, or data directly.
     * @param arraySize The number of elements in the array, 0 if not an array.
     */
    addUniform(name: string, size: number | number[], arraySize?: number): void;
    /**
     * Adds a Matrix 4x4 to the uniform buffer.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     * @param mat A 4x4 matrix.
     */
    addMatrix(name: string, mat: IMatrixLike): void;
    /**
     * Adds a vec2 to the uniform buffer.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     * @param x Define the x component value of the vec2
     * @param y Define the y component value of the vec2
     */
    addFloat2(name: string, x: number, y: number): void;
    /**
     * Adds a vec3 to the uniform buffer.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     * @param x Define the x component value of the vec3
     * @param y Define the y component value of the vec3
     * @param z Define the z component value of the vec3
     */
    addFloat3(name: string, x: number, y: number, z: number): void;
    /**
     * Adds a vec3 to the uniform buffer.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     * @param color Define the vec3 from a Color
     */
    addColor3(name: string, color: IColor3Like): void;
    /**
     * Adds a vec4 to the uniform buffer.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     * @param color Define the rgb components from a Color
     * @param alpha Define the a component of the vec4
     */
    addColor4(name: string, color: IColor3Like, alpha: number): void;
    /**
     * Adds a vec3 to the uniform buffer.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     * @param vector Define the vec3 components from a Vector
     */
    addVector3(name: string, vector: IVector3Like): void;
    /**
     * Adds a Matrix 3x3 to the uniform buffer.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     */
    addMatrix3x3(name: string): void;
    /**
     * Adds a Matrix 2x2 to the uniform buffer.
     * @param name Name of the uniform, as used in the uniform block in the shader.
     */
    addMatrix2x2(name: string): void;
    /**
     * Effectively creates the WebGL Uniform Buffer, once layout is completed with `addUniform`.
     */
    create(): void;
    private _getNamesDebug;
    /** @internal */
    _rebuild(): void;
    /** @internal */
    _rebuildAfterContextLost(): void;
    /** @internal */
    get _numBuffers(): number;
    /** @internal */
    get _indexBuffer(): number;
    /** Gets or sets the name of this buffer */
    get name(): string;
    set name(value: string);
    /** Gets the current effect */
    get currentEffect(): Nullable<Effect>;
    private _buffersEqual;
    private _copyBuffer;
    /**
     * Updates the WebGL Uniform Buffer on the GPU.
     * If the `dynamic` flag is set to true, no cache comparison is done.
     * Otherwise, the buffer will be updated only if the cache differs.
     */
    update(): void;
    private _createNewBuffer;
    private _checkNewFrame;
    /**
     * Updates the value of an uniform. The `update` method must be called afterwards to make it effective in the GPU.
     * @param uniformName Define the name of the uniform, as used in the uniform block in the shader.
     * @param data Define the flattened data
     * @param size Define the size of the data.
     */
    updateUniform(uniformName: string, data: FloatArray, size: number): void;
    /**
     * Updates the value of an uniform. The `update` method must be called afterwards to make it effective in the GPU.
     * @param uniformName Define the name of the uniform, as used in the uniform block in the shader.
     * @param data Define the flattened data
     * @param size Define the size of the data.
     */
    updateUniformArray(uniformName: string, data: FloatArray, size: number): void;
    private _valueCache;
    private _cacheMatrix;
    private _updateMatrix3x3ForUniform;
    private _updateMatrix3x3ForEffect;
    private _updateMatrix2x2ForEffect;
    private _updateMatrix2x2ForUniform;
    private _updateFloatForEffect;
    private _updateFloatForUniform;
    private _updateFloat2ForEffect;
    private _updateFloat2ForUniform;
    private _updateFloat3ForEffect;
    private _updateFloat3ForUniform;
    private _updateFloat4ForEffect;
    private _updateFloat4ForUniform;
    private _updateFloatArrayForEffect;
    private _updateFloatArrayForUniform;
    private _updateArrayForEffect;
    private _updateArrayForUniform;
    private _updateIntArrayForEffect;
    private _updateIntArrayForUniform;
    private _updateUIntArrayForEffect;
    private _updateUIntArrayForUniform;
    private _updateMatrixForEffect;
    private _updateMatrixForUniform;
    private _updateMatricesForEffect;
    private _updateMatricesForUniform;
    private _updateVector3ForEffect;
    private _updateVector3ForUniform;
    private _updateVector4ForEffect;
    private _updateVector4ForUniform;
    private _updateColor3ForEffect;
    private _updateColor3ForUniform;
    private _updateColor4ForEffect;
    private _updateDirectColor4ForEffect;
    private _updateColor4ForUniform;
    private _updateDirectColor4ForUniform;
    private _updateIntForEffect;
    private _updateIntForUniform;
    private _updateInt2ForEffect;
    private _updateInt2ForUniform;
    private _updateInt3ForEffect;
    private _updateInt3ForUniform;
    private _updateInt4ForEffect;
    private _updateInt4ForUniform;
    private _updateUIntForEffect;
    private _updateUIntForUniform;
    private _updateUInt2ForEffect;
    private _updateUInt2ForUniform;
    private _updateUInt3ForEffect;
    private _updateUInt3ForUniform;
    private _updateUInt4ForEffect;
    private _updateUInt4ForUniform;
    /**
     * Sets a sampler uniform on the effect.
     * @param name Define the name of the sampler.
     * @param texture Define the texture to set in the sampler
     */
    setTexture(name: string, texture: Nullable<ThinTexture>): void;
    /**
     * Sets an array of sampler uniforms on the effect.
     * @param name Define the name of uniform.
     * @param textures Define the textures to set in the array of samplers
     */
    setTextureArray(name: string, textures: ThinTexture[]): void;
    /**
     * Sets a sampler uniform on the effect.
     * @param name Define the name of the sampler.
     * @param texture Define the (internal) texture to set in the sampler
     */
    bindTexture(name: string, texture: Nullable<InternalTexture>): void;
    /**
     * Directly updates the value of the uniform in the cache AND on the GPU.
     * @param uniformName Define the name of the uniform, as used in the uniform block in the shader.
     * @param data Define the flattened data
     */
    updateUniformDirectly(uniformName: string, data: FloatArray): void;
    /**
     * Associates an effect to this uniform buffer
     * @param effect Define the effect to associate the buffer to
     * @param name Name of the uniform block in the shader.
     */
    bindToEffect(effect: Effect, name: string): void;
    /**
     * Binds the current (GPU) buffer to the effect
     */
    bindUniformBuffer(): void;
    /**
     * Dissociates the current effect from this uniform buffer
     */
    unbindEffect(): void;
    /**
     * Sets the current state of the class (_bufferIndex, _buffer) to point to the data buffer passed in parameter if this buffer is one of the buffers handled by the class (meaning if it can be found in the _buffers array)
     * This method is meant to be able to update a buffer at any time: just call setDataBuffer to set the class in the right state, call some updateXXX methods and then call udpate() => that will update the GPU buffer on the graphic card
     * @param dataBuffer buffer to look for
     * @returns true if the buffer has been found and the class internal state points to it, else false
     */
    setDataBuffer(dataBuffer: DataBuffer): boolean;
    /**
     * Checks if the uniform buffer has a uniform with the given name.
     * @param name Name of the uniform to check
     * @returns True if the uniform exists, false otherwise.
     */
    has(name: string): boolean;
    /**
     * Disposes the uniform buffer.
     */
    dispose(): void;
}

/**
 * Defines the common interface of sortable lights
 */
interface ISortableLight {
    /**
     * Gets or sets whether or not the shadows are enabled for this light. This can help turning off/on shadow without detaching
     * the current shadow generator.
     */
    shadowEnabled: boolean;
    /**
     * Defines the rendering priority of the lights. It can help in case of fallback or number of lights
     * exceeding the number allowed of the materials.
     */
    renderPriority: number;
}

/**
 * Base class of all the lights in Babylon. It groups all the generic information about lights.
 * Lights are used, as you would expect, to affect how meshes are seen, in terms of both illumination and colour.
 * All meshes allow light to pass through them unless shadow generation is activated. The default number of lights allowed is four but this can be increased.
 */
declare abstract class Light extends Node implements ISortableLight {
    /**
     * Falloff Default: light is falling off following the material specification:
     * standard material is using standard falloff whereas pbr material can request special falloff per materials.
     */
    static readonly FALLOFF_DEFAULT = 0;
    /**
     * Falloff Physical: light is falling off following the inverse squared distance law.
     */
    static readonly FALLOFF_PHYSICAL = 1;
    /**
     * Falloff gltf: light is falling off as described in the gltf moving to PBR document
     * to enhance interoperability with other engines.
     */
    static readonly FALLOFF_GLTF = 2;
    /**
     * Falloff Standard: light is falling off like in the standard material
     * to enhance interoperability with other materials.
     */
    static readonly FALLOFF_STANDARD = 3;
    /**
     * If every light affecting the material is in this lightmapMode,
     * material.lightmapTexture adds or multiplies
     * (depends on material.useLightmapAsShadowmap)
     * after every other light calculations.
     */
    static readonly LIGHTMAP_DEFAULT = 0;
    /**
     * material.lightmapTexture as only diffuse lighting from this light
     * adds only specular lighting from this light
     * adds dynamic shadows
     */
    static readonly LIGHTMAP_SPECULAR = 1;
    /**
     * material.lightmapTexture as only lighting
     * no light calculation from this light
     * only adds dynamic shadows from this light
     */
    static readonly LIGHTMAP_SHADOWSONLY = 2;
    /**
     * Each light type uses the default quantity according to its type:
     *      point/spot lights use luminous intensity
     *      directional lights use illuminance
     */
    static readonly INTENSITYMODE_AUTOMATIC = 0;
    /**
     * lumen (lm)
     */
    static readonly INTENSITYMODE_LUMINOUSPOWER = 1;
    /**
     * candela (lm/sr)
     */
    static readonly INTENSITYMODE_LUMINOUSINTENSITY = 2;
    /**
     * lux (lm/m^2)
     */
    static readonly INTENSITYMODE_ILLUMINANCE = 3;
    /**
     * nit (cd/m^2)
     */
    static readonly INTENSITYMODE_LUMINANCE = 4;
    /**
     * Light type const id of the point light.
     */
    static readonly LIGHTTYPEID_POINTLIGHT = 0;
    /**
     * Light type const id of the directional light.
     */
    static readonly LIGHTTYPEID_DIRECTIONALLIGHT = 1;
    /**
     * Light type const id of the spot light.
     */
    static readonly LIGHTTYPEID_SPOTLIGHT = 2;
    /**
     * Light type const id of the hemispheric light.
     */
    static readonly LIGHTTYPEID_HEMISPHERICLIGHT = 3;
    /**
     * Light type const id of the area light.
     */
    static readonly LIGHTTYPEID_RECT_AREALIGHT = 4;
    /**
     * Diffuse gives the basic color to an object.
     */
    diffuse: Color3;
    /**
     * Specular produces a highlight color on an object.
     * Note: This is not affecting PBR materials.
     */
    specular: Color3;
    /**
     * Defines the falloff type for this light. This lets overriding how punctual light are
     * falling off base on range or angle.
     * This can be set to any values in Light.FALLOFF_x.
     *
     * Note: This is only useful for PBR Materials at the moment. This could be extended if required to
     * other types of materials.
     */
    falloffType: number;
    /**
     * Strength of the light.
     * Note: By default it is define in the framework own unit.
     * Note: In PBR materials the intensityMode can be use to chose what unit the intensity is defined in.
     */
    intensity: number;
    private _range;
    /** @internal */
    _inverseSquaredRange: number;
    /**
     * Defines how far from the source the light is impacting in scene units.
     * Note: Unused in PBR material as the distance light falloff is defined following the inverse squared falloff.
     */
    get range(): number;
    /**
     * Defines how far from the source the light is impacting in scene units.
     * Note: Unused in PBR material as the distance light falloff is defined following the inverse squared falloff.
     */
    set range(value: number);
    /**
     * Cached photometric scale default to 1.0 as the automatic intensity mode defaults to 1.0 for every type
     * of light.
     */
    private _photometricScale;
    private _intensityMode;
    /**
     * Gets the photometric scale used to interpret the intensity.
     * This is only relevant with PBR Materials where the light intensity can be defined in a physical way.
     */
    get intensityMode(): number;
    /**
     * Sets the photometric scale used to interpret the intensity.
     * This is only relevant with PBR Materials where the light intensity can be defined in a physical way.
     */
    set intensityMode(value: number);
    private _radius;
    /**
     * Gets the light radius used by PBR Materials to simulate soft area lights.
     */
    get radius(): number;
    /**
     * sets the light radius used by PBR Materials to simulate soft area lights.
     */
    set radius(value: number);
    private _renderPriority;
    /**
     * Defines the rendering priority of the lights. It can help in case of fallback or number of lights
     * exceeding the number allowed of the materials.
     */
    renderPriority: number;
    private _shadowEnabled;
    /**
     * Gets whether or not the shadows are enabled for this light. This can help turning off/on shadow without detaching
     * the current shadow generator.
     */
    get shadowEnabled(): boolean;
    /**
     * Sets whether or not the shadows are enabled for this light. This can help turning off/on shadow without detaching
     * the current shadow generator.
     */
    set shadowEnabled(value: boolean);
    private _includedOnlyMeshes;
    /**
     * Gets the only meshes impacted by this light.
     */
    get includedOnlyMeshes(): AbstractMesh[];
    /**
     * Sets the only meshes impacted by this light.
     */
    set includedOnlyMeshes(value: AbstractMesh[]);
    private _excludedMeshes;
    /**
     * Gets the meshes not impacted by this light.
     */
    get excludedMeshes(): AbstractMesh[];
    /**
     * Sets the meshes not impacted by this light.
     */
    set excludedMeshes(value: AbstractMesh[]);
    private _excludeWithLayerMask;
    /**
     * Gets the layer id use to find what meshes are not impacted by the light.
     * Inactive if 0
     */
    get excludeWithLayerMask(): number;
    /**
     * Sets the layer id use to find what meshes are not impacted by the light.
     * Inactive if 0
     */
    set excludeWithLayerMask(value: number);
    private _includeOnlyWithLayerMask;
    /**
     * Gets the layer id use to find what meshes are impacted by the light.
     * Inactive if 0
     */
    get includeOnlyWithLayerMask(): number;
    /**
     * Sets the layer id use to find what meshes are impacted by the light.
     * Inactive if 0
     */
    set includeOnlyWithLayerMask(value: number);
    private _lightmapMode;
    /**
     * Gets the lightmap mode of this light (should be one of the constants defined by Light.LIGHTMAP_x)
     */
    get lightmapMode(): number;
    /**
     * Sets the lightmap mode of this light (should be one of the constants defined by Light.LIGHTMAP_x)
     */
    set lightmapMode(value: number);
    /**
     * Returns the view matrix.
     * @param _faceIndex The index of the face for which we want to extract the view matrix. Only used for point light types.
     * @returns The view matrix. Can be null, if a view matrix cannot be defined for the type of light considered (as for a hemispherical light, for example).
     */
    getViewMatrix(_faceIndex?: number): Nullable<Matrix>;
    /**
     * Returns the projection matrix.
     * Note that viewMatrix and renderList are optional and are only used by lights that calculate the projection matrix from a list of meshes (e.g. directional lights with automatic extents calculation).
     * @param _viewMatrix The view transform matrix of the light (optional).
     * @param _renderList The list of meshes to take into account when calculating the projection matrix (optional).
     * @returns The projection matrix. Can be null, if a projection matrix cannot be defined for the type of light considered (as for a hemispherical light, for example).
     */
    getProjectionMatrix(_viewMatrix?: Matrix, _renderList?: Array<AbstractMesh>): Nullable<Matrix>;
    /**
     * Shadow generators associated to the light.
     * @internal Internal use only.
     */
    _shadowGenerators: Nullable<Map<Nullable<Camera>, IShadowGenerator>>;
    /**
     * @internal Internal use only.
     */
    _excludedMeshesIds: string[];
    /**
     * @internal Internal use only.
     */
    _includedOnlyMeshesIds: string[];
    /**
     * The current light uniform buffer.
     * @internal Internal use only.
     */
    _uniformBuffer: UniformBuffer;
    /** @internal */
    _renderId: number;
    private _lastUseSpecular;
    /**
     * Used internally by ClusteredLight to sort lights
     * @internal
     */
    _currentViewDepth: number;
    /**
     * Creates a Light object in the scene.
     * Documentation : https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
     * @param name The friendly name of the light
     * @param scene The scene the light belongs too
     * @param dontAddToScene True to not add the light to the scene
     */
    constructor(name: string, scene?: Scene, dontAddToScene?: boolean);
    protected abstract _buildUniformLayout(): void;
    /**
     * Sets the passed Effect "effect" with the Light information.
     * @param effect The effect to update
     * @param lightIndex The index of the light in the effect to update
     * @returns The light
     */
    abstract transferToEffect(effect: Effect, lightIndex: string): Light;
    /**
     * Sets the passed Effect "effect" with the Light textures.
     * @param effect The effect to update
     * @param lightIndex The index of the light in the effect to update
     * @returns The light
     */
    transferTexturesToEffect(effect: Effect, lightIndex: string): Light;
    /**
     * Binds the lights information from the scene to the effect for the given mesh.
     * @param lightIndex Light index
     * @param scene The scene where the light belongs to
     * @param effect The effect we are binding the data to
     * @param useSpecular Defines if specular is supported
     * @param receiveShadows Defines if the effect (mesh) we bind the light for receives shadows
     */
    _bindLight(lightIndex: number, scene: Scene, effect: Effect, useSpecular: boolean, receiveShadows?: boolean): void;
    /**
     * Sets the passed Effect "effect" with the Light information.
     * @param effect The effect to update
     * @param lightDataUniformName The uniform used to store light data (position or direction)
     * @returns The light
     */
    abstract transferToNodeMaterialEffect(effect: Effect, lightDataUniformName: string): Light;
    /**
     * Returns the string "Light".
     * @returns the class name
     */
    getClassName(): string;
    /** @internal */
    readonly _isLight = true;
    /**
     * Converts the light information to a readable string for debug purpose.
     * @param fullDetails Supports for multiple levels of logging within scene loading
     * @returns the human readable light info
     */
    toString(fullDetails?: boolean): string;
    /** @internal */
    protected _syncParentEnabledState(): void;
    /**
     * Set the enabled state of this node.
     * @param value - the new enabled state
     */
    setEnabled(value: boolean): void;
    /**
     * Returns the Light associated shadow generator if any.
     * @param camera Camera for which the shadow generator should be retrieved (default: null). If null, retrieves the default shadow generator
     * @returns the associated shadow generator.
     */
    getShadowGenerator(camera?: Nullable<Camera>): Nullable<IShadowGenerator>;
    /**
     * Returns all the shadow generators associated to this light
     * @returns
     */
    getShadowGenerators(): Nullable<Map<Nullable<Camera>, IShadowGenerator>>;
    /**
     * Returns a Vector3, the absolute light position in the World.
     * @returns the world space position of the light
     */
    getAbsolutePosition(): Vector3;
    /**
     * Specifies if the light will affect the passed mesh.
     * @param mesh The mesh to test against the light
     * @returns true the mesh is affected otherwise, false.
     */
    canAffectMesh(mesh: AbstractMesh): boolean;
    /**
     * Releases resources associated with this node.
     * @param doNotRecurse Set to true to not recurse into each children (recurse into each children by default)
     * @param disposeMaterialAndTextures Set to true to also dispose referenced materials and textures (false by default)
     */
    dispose(doNotRecurse?: boolean, disposeMaterialAndTextures?: boolean): void;
    /**
     * Returns the light type ID (integer).
     * @returns The light Type id as a constant defines in Light.LIGHTTYPEID_x
     */
    getTypeID(): number;
    /**
     * Returns the intensity scaled by the Photometric Scale according to the light type and intensity mode.
     * @returns the scaled intensity in intensity mode unit
     */
    getScaledIntensity(): number;
    /**
     * Returns a new Light object, named "name", from the current one.
     * @param name The name of the cloned light
     * @param newParent The parent of this light, if it has one
     * @returns the new created light
     */
    clone(name: string, newParent?: Nullable<Node>): Nullable<Light>;
    /**
     * Serializes the current light into a Serialization object.
     * @returns the serialized object.
     */
    serialize(): any;
    /**
     * Creates a new typed light from the passed type (integer) : point light = 0, directional light = 1, spot light = 2, hemispheric light = 3.
     * This new light is named "name" and added to the passed scene.
     * @param type Type according to the types available in Light.LIGHTTYPEID_x
     * @param name The friendly name of the light
     * @param scene The scene the new light will belong to
     * @returns the constructor function
     */
    static GetConstructorFromName(type: number, name: string, scene: Scene): Nullable<() => Light>;
    /**
     * Parses the passed "parsedLight" and returns a new instanced Light from this parsing.
     * @param parsedLight The JSON representation of the light
     * @param scene The scene to create the parsed light in
     * @returns the created light after parsing
     */
    static Parse(parsedLight: any, scene: Scene): Nullable<Light>;
    private _hookArrayForExcluded;
    private _hookArrayForIncludedOnly;
    private _resyncMeshes;
    /**
     * Forces the meshes to update their light related information in their rendering used effects
     * @internal Internal Use Only
     */
    _markMeshesAsLightDirty(): void;
    /**
     * Recomputes the cached photometric scale if needed.
     */
    private _computePhotometricScale;
    /**
     * @returns the Photometric Scale according to the light type and intensity mode.
     */
    private _getPhotometricScale;
    /**
     * Reorder the light in the scene according to their defined priority.
     * @internal Internal Use Only
     */
    _reorderLightsInScene(): void;
    /**
     * Prepares the list of defines specific to the light type.
     * @param defines the list of defines
     * @param lightIndex defines the index of the light for the effect
     */
    abstract prepareLightSpecificDefines(defines: any, lightIndex: number): void;
    /**
     * @internal
     */
    _isReady(): boolean;
}

/**
 * Interface describing all the common properties and methods a shadow light needs to implement.
 * This helps both the shadow generator and materials to generate the corresponding shadow maps
 * as well as binding the different shadow properties to the effects.
 */
interface IShadowLight extends Light {
    /**
     * The light id in the scene (used in scene.getLightById for instance)
     */
    id: string;
    /**
     * The position the shadow will be casted from.
     */
    position: Vector3;
    /**
     * In 2d mode (needCube being false), the direction used to cast the shadow.
     */
    direction: Vector3;
    /**
     * The transformed position. Position of the light in world space taking parenting in account.
     */
    transformedPosition: Vector3;
    /**
     * The transformed direction. Direction of the light in world space taking parenting in account.
     */
    transformedDirection: Vector3;
    /**
     * The friendly name of the light in the scene.
     */
    name: string;
    /**
     * Defines the shadow projection clipping minimum z value.
     */
    shadowMinZ: number;
    /**
     * Defines the shadow projection clipping maximum z value.
     */
    shadowMaxZ: number;
    /**
     * Computes the transformed information (transformedPosition and transformedDirection in World space) of the current light
     * @returns true if the information has been computed, false if it does not need to (no parenting)
     */
    computeTransformedInformation(): boolean;
    /**
     * Gets the scene the light belongs to.
     * @returns The scene
     */
    getScene(): Scene;
    /**
     * Callback defining a custom Projection Matrix Builder.
     * This can be used to override the default projection matrix computation.
     */
    customProjectionMatrixBuilder: (viewMatrix: Matrix, renderList: Array<AbstractMesh>, result: Matrix) => void;
    /**
     * Sets the shadow projection matrix in parameter to the generated projection matrix.
     * @param matrix The matrix to update with the projection information
     * @param viewMatrix The transform matrix of the light
     * @param renderList The list of mesh to render in the map
     * @returns The current light
     */
    setShadowProjectionMatrix(matrix: Matrix, viewMatrix: Matrix, renderList: Array<AbstractMesh>): IShadowLight;
    /**
     * Gets the current depth scale used in ESM.
     * @returns The scale
     */
    getDepthScale(): number;
    /**
     * Returns whether or not the shadow generation require a cube texture or a 2d texture.
     * @returns true if a cube texture needs to be use
     */
    needCube(): boolean;
    /**
     * Detects if the projection matrix requires to be recomputed this frame.
     * @returns true if it requires to be recomputed otherwise, false.
     */
    needProjectionMatrixCompute(): boolean;
    /**
     * Forces the shadow generator to recompute the projection matrix even if position and direction did not changed.
     */
    forceProjectionMatrixCompute(): void;
    /**
     * Get the direction to use to render the shadow map. In case of cube texture, the face index can be passed.
     * @param faceIndex The index of the face we are computed the direction to generate shadow
     * @returns The set direction in 2d mode otherwise the direction to the cubemap face if needCube() is true
     */
    getShadowDirection(faceIndex?: number): Vector3;
    /**
     * Gets the minZ used for shadow according to both the scene and the light.
     * @param activeCamera The camera we are returning the min for
     * @returns the depth min z
     */
    getDepthMinZ(activeCamera: Nullable<Camera>): number;
    /**
     * Gets the maxZ used for shadow according to both the scene and the light.
     * @param activeCamera The camera we are returning the max for
     * @returns the depth max z
     */
    getDepthMaxZ(activeCamera: Nullable<Camera>): number;
}
/**
 * Base implementation IShadowLight
 * It groups all the common behaviour in order to reduce duplication and better follow the DRY pattern.
 */
declare abstract class ShadowLight extends Light implements IShadowLight {
    protected abstract _setDefaultShadowProjectionMatrix(matrix: Matrix, viewMatrix: Matrix, renderList: Array<AbstractMesh>): void;
    protected _position: Vector3;
    protected _setPosition(value: Vector3): void;
    /**
     * Sets the position the shadow will be casted from. Also use as the light position for both
     * point and spot lights.
     */
    get position(): Vector3;
    /**
     * Sets the position the shadow will be casted from. Also use as the light position for both
     * point and spot lights.
     */
    set position(value: Vector3);
    protected _direction: Vector3;
    protected _setDirection(value: Vector3): void;
    /**
     * In 2d mode (needCube being false), gets the direction used to cast the shadow.
     * Also use as the light direction on spot and directional lights.
     */
    get direction(): Vector3;
    /**
     * In 2d mode (needCube being false), sets the direction used to cast the shadow.
     * Also use as the light direction on spot and directional lights.
     */
    set direction(value: Vector3);
    protected _shadowMinZ: number;
    /**
     * Gets the shadow projection clipping minimum z value.
     */
    get shadowMinZ(): number;
    /**
     * Sets the shadow projection clipping minimum z value.
     */
    set shadowMinZ(value: number);
    protected _shadowMaxZ: number;
    /**
     * Sets the shadow projection clipping maximum z value.
     */
    get shadowMaxZ(): number;
    /**
     * Gets the shadow projection clipping maximum z value.
     */
    set shadowMaxZ(value: number);
    /**
     * Callback defining a custom Projection Matrix Builder.
     * This can be used to override the default projection matrix computation.
     */
    customProjectionMatrixBuilder: (viewMatrix: Matrix, renderList: Array<AbstractMesh>, result: Matrix) => void;
    /**
     * The transformed position. Position of the light in world space taking parenting in account. Needs to be computed by calling computeTransformedInformation.
     */
    transformedPosition: Vector3;
    /**
     * The transformed direction. Direction of the light in world space taking parenting in account.
     */
    transformedDirection: Vector3;
    private _needProjectionMatrixCompute;
    /**
     * Computes the transformed information (transformedPosition and transformedDirection in World space) of the current light
     * @returns true if the information has been computed, false if it does not need to (no parenting)
     */
    computeTransformedInformation(): boolean;
    /**
     * Return the depth scale used for the shadow map.
     * @returns the depth scale.
     */
    getDepthScale(): number;
    /**
     * Get the direction to use to render the shadow map. In case of cube texture, the face index can be passed.
     * @param faceIndex The index of the face we are computed the direction to generate shadow
     * @returns The set direction in 2d mode otherwise the direction to the cubemap face if needCube() is true
     */
    getShadowDirection(faceIndex?: number): Vector3;
    /**
     * If computeTransformedInformation has been called, returns the ShadowLight absolute position in the world. Otherwise, returns the local position.
     * @returns the position vector in world space
     */
    getAbsolutePosition(): Vector3;
    /**
     * Sets the ShadowLight direction toward the passed target.
     * @param target The point to target in local space
     * @returns the updated ShadowLight direction
     */
    setDirectionToTarget(target: Vector3): Vector3;
    /**
     * Returns the light rotation in euler definition.
     * @returns the x y z rotation in local space.
     */
    getRotation(): Vector3;
    /**
     * Returns whether or not the shadow generation require a cube texture or a 2d texture.
     * @returns true if a cube texture needs to be use
     */
    needCube(): boolean;
    /**
     * Detects if the projection matrix requires to be recomputed this frame.
     * @returns true if it requires to be recomputed otherwise, false.
     */
    needProjectionMatrixCompute(): boolean;
    /**
     * Forces the shadow generator to recompute the projection matrix even if position and direction did not changed.
     */
    forceProjectionMatrixCompute(): void;
    /** @internal */
    _initCache(): void;
    /** @internal */
    _isSynchronized(): boolean;
    /**
     * Computes the world matrix of the node
     * @param force defines if the cache version should be invalidated forcing the world matrix to be created from scratch
     * @returns the world matrix
     */
    computeWorldMatrix(force?: boolean): Matrix;
    /**
     * Gets the minZ used for shadow according to both the scene and the light.
     * @param activeCamera The camera we are returning the min for
     * @returns the depth min z
     */
    getDepthMinZ(activeCamera: Nullable<Camera>): number;
    /**
     * Gets the maxZ used for shadow according to both the scene and the light.
     * @param activeCamera The camera we are returning the max for
     * @returns the depth max z
     */
    getDepthMaxZ(activeCamera: Nullable<Camera>): number;
    /**
     * Sets the shadow projection matrix in parameter to the generated projection matrix.
     * @param matrix The matrix to updated with the projection information
     * @param viewMatrix The transform matrix of the light
     * @param renderList The list of mesh to render in the map
     * @returns The current light
     */
    setShadowProjectionMatrix(matrix: Matrix, viewMatrix: Matrix, renderList: Array<AbstractMesh>): IShadowLight;
    /** @internal */
    protected _syncParentEnabledState(): void;
    protected _viewMatrix: Matrix;
    protected _projectionMatrix: Matrix;
    /**
     * Returns the view matrix.
     * @param faceIndex The index of the face for which we want to extract the view matrix. Only used for point light types.
     * @returns The view matrix. Can be null, if a view matrix cannot be defined for the type of light considered (as for a hemispherical light, for example).
     */
    getViewMatrix(faceIndex?: number): Nullable<Matrix>;
    /**
     * Returns the projection matrix.
     * Note that viewMatrix and renderList are optional and are only used by lights that calculate the projection matrix from a list of meshes (e.g. directional lights with automatic extents calculation).
     * @param viewMatrix The view transform matrix of the light (optional).
     * @param renderList The list of meshes to take into account when calculating the projection matrix (optional).
     * @returns The projection matrix. Can be null, if a projection matrix cannot be defined for the type of light considered (as for a hemispherical light, for example).
     */
    getProjectionMatrix(viewMatrix?: Matrix, renderList?: Array<AbstractMesh>): Nullable<Matrix>;
}

/**
 * Language of the shader code
 */
declare const enum ShaderLanguage {
    /** language is GLSL (used by WebGL) */
    GLSL = 0,
    /** language is WGSL (used by WebGPU) */
    WGSL = 1
}

/**
 * Defines the options associated with the creation of a custom shader for a shadow generator.
 */
interface ICustomShaderOptions {
    /**
     * Gets or sets the custom shader name to use
     */
    shaderName: string;
    /**
     * The list of attribute names used in the shader
     */
    attributes?: string[];
    /**
     * The list of uniform names used in the shader
     */
    uniforms?: string[];
    /**
     * The list of sampler names used in the shader
     */
    samplers?: string[];
    /**
     * The list of defines used in the shader
     */
    defines?: string[];
}
/**
 * Interface to implement to create a shadow generator compatible with BJS.
 */
interface IShadowGenerator {
    /** Gets or set the id of the shadow generator. It will be the one from the light if not defined */
    id: string;
    /**
     * Specifies if the `ShadowGenerator` should be serialized, `true` to skip serialization.
     * Note a `ShadowGenerator` will not be serialized if its light has `doNotSerialize=true`
     */
    doNotSerialize?: boolean;
    /**
     * Gets the main RTT containing the shadow map (usually storing depth from the light point of view).
     * @returns The render target texture if present otherwise, null
     */
    getShadowMap(): Nullable<RenderTargetTexture>;
    /**
     * Determine whether the shadow generator is ready or not (mainly all effects and related post processes needs to be ready).
     * @param subMesh The submesh we want to render in the shadow map
     * @param useInstances Defines whether will draw in the map using instances
     * @param isTransparent Indicates that isReady is called for a transparent subMesh
     * @returns true if ready otherwise, false
     */
    isReady(subMesh: SubMesh, useInstances: boolean, isTransparent: boolean): boolean;
    /**
     * Prepare all the defines in a material relying on a shadow map at the specified light index.
     * @param defines Defines of the material we want to update
     * @param lightIndex Index of the light in the enabled light list of the material
     */
    prepareDefines(defines: MaterialDefines, lightIndex: number): void;
    /**
     * Binds the shadow related information inside of an effect (information like near, far, darkness...
     * defined in the generator but impacting the effect).
     * It implies the uniforms available on the materials are the standard BJS ones.
     * @param lightIndex Index of the light in the enabled light list of the material owning the effect
     * @param effect The effect we are binding the information for
     */
    bindShadowLight(lightIndex: string, effect: Effect): void;
    /**
     * Gets the transformation matrix used to project the meshes into the map from the light point of view.
     * (eq to shadow projection matrix * light transform matrix)
     * @returns The transform matrix used to create the shadow map
     */
    getTransformMatrix(): Matrix;
    /**
     * Recreates the shadow map dependencies like RTT and post processes. This can be used during the switch between
     * Cube and 2D textures for instance.
     */
    recreateShadowMap(): void;
    /**
     * Forces all the attached effect to compile to enable rendering only once ready vs. lazily compiling effects.
     * @param onCompiled Callback triggered at the and of the effects compilation
     * @param options Sets of optional options forcing the compilation with different modes
     */
    forceCompilation(onCompiled?: (generator: IShadowGenerator) => void, options?: Partial<{
        useInstances: boolean;
    }>): void;
    /**
     * Forces all the attached effect to compile to enable rendering only once ready vs. lazily compiling effects.
     * @param options Sets of optional options forcing the compilation with different modes
     * @returns A promise that resolves when the compilation completes
     */
    forceCompilationAsync(options?: Partial<{
        useInstances: boolean;
    }>): Promise<void>;
    /**
     * Serializes the shadow generator setup to a json object.
     * @returns The serialized JSON object
     */
    serialize(): any;
    /**
     * Disposes the Shadow map and related Textures and effects.
     */
    dispose(): void;
}
/**
 * Default implementation IShadowGenerator.
 * This is the main object responsible of generating shadows in the framework.
 * Documentation: https://doc.babylonjs.com/features/featuresDeepDive/lights/shadows
 * @see [WebGL](https://playground.babylonjs.com/#IFYDRS#0)
 * @see [WebGPU](https://playground.babylonjs.com/#IFYDRS#835)
 */
declare class ShadowGenerator implements IShadowGenerator {
    /**
     * Name of the shadow generator class
     */
    static CLASSNAME: string;
    /**
     * Force all the shadow generators to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * Shadow generator mode None: no filtering applied.
     */
    static readonly FILTER_NONE = 0;
    /**
     * Shadow generator mode ESM: Exponential Shadow Mapping.
     * (http://developer.download.nvidia.com/presentations/2008/GDC/GDC08_SoftShadowMapping.pdf)
     */
    static readonly FILTER_EXPONENTIALSHADOWMAP = 1;
    /**
     * Shadow generator mode Poisson Sampling: Percentage Closer Filtering.
     * (Multiple Tap around evenly distributed around the pixel are used to evaluate the shadow strength)
     */
    static readonly FILTER_POISSONSAMPLING = 2;
    /**
     * Shadow generator mode ESM: Blurred Exponential Shadow Mapping.
     * (http://developer.download.nvidia.com/presentations/2008/GDC/GDC08_SoftShadowMapping.pdf)
     */
    static readonly FILTER_BLUREXPONENTIALSHADOWMAP = 3;
    /**
     * Shadow generator mode ESM: Exponential Shadow Mapping using the inverse of the exponential preventing
     * edge artifacts on steep falloff.
     * (http://developer.download.nvidia.com/presentations/2008/GDC/GDC08_SoftShadowMapping.pdf)
     */
    static readonly FILTER_CLOSEEXPONENTIALSHADOWMAP = 4;
    /**
     * Shadow generator mode ESM: Blurred Exponential Shadow Mapping using the inverse of the exponential preventing
     * edge artifacts on steep falloff.
     * (http://developer.download.nvidia.com/presentations/2008/GDC/GDC08_SoftShadowMapping.pdf)
     */
    static readonly FILTER_BLURCLOSEEXPONENTIALSHADOWMAP = 5;
    /**
     * Shadow generator mode PCF: Percentage Closer Filtering
     * benefits from Webgl 2 shadow samplers. Fallback to Poisson Sampling in Webgl 1
     * (https://developer.nvidia.com/gpugems/GPUGems/gpugems_ch11.html)
     */
    static readonly FILTER_PCF = 6;
    /**
     * Shadow generator mode PCSS: Percentage Closering Soft Shadow.
     * benefits from Webgl 2 shadow samplers. Fallback to Poisson Sampling in Webgl 1
     * Contact Hardening
     */
    static readonly FILTER_PCSS = 7;
    /**
     * Reserved for PCF and PCSS
     * Highest Quality.
     *
     * Execute PCF on a 5*5 kernel improving a lot the shadow aliasing artifacts.
     *
     * Execute PCSS with 32 taps blocker search and 64 taps PCF.
     */
    static readonly QUALITY_HIGH = 0;
    /**
     * Reserved for PCF and PCSS
     * Good tradeoff for quality/perf cross devices
     *
     * Execute PCF on a 3*3 kernel.
     *
     * Execute PCSS with 16 taps blocker search and 32 taps PCF.
     */
    static readonly QUALITY_MEDIUM = 1;
    /**
     * Reserved for PCF and PCSS
     * The lowest quality but the fastest.
     *
     * Execute PCF on a 1*1 kernel.
     *
     * Execute PCSS with 16 taps blocker search and 16 taps PCF.
     */
    static readonly QUALITY_LOW = 2;
    /**
     * Defines the default alpha cutoff value used for transparent alpha tested materials.
     */
    static DEFAULT_ALPHA_CUTOFF: number;
    /** Gets or set the id of the shadow generator. It will be the one from the light if not defined */
    id: string;
    /** Gets or sets the custom shader name to use */
    customShaderOptions: ICustomShaderOptions;
    /** Gets or sets a custom function to allow/disallow rendering a sub mesh in the shadow map */
    customAllowRendering: (subMesh: SubMesh) => boolean;
    /**
     * Observable triggered before the shadow is rendered. Can be used to update internal effect state
     */
    onBeforeShadowMapRenderObservable: Observable<Effect>;
    /**
     * Observable triggered after the shadow is rendered. Can be used to restore internal effect state
     */
    onAfterShadowMapRenderObservable: Observable<Effect>;
    /**
     * Observable triggered before a mesh is rendered in the shadow map.
     * Can be used to update internal effect state (that you can get from the onBeforeShadowMapRenderObservable)
     */
    onBeforeShadowMapRenderMeshObservable: Observable<Mesh>;
    /**
     * Observable triggered after a mesh is rendered in the shadow map.
     * Can be used to update internal effect state (that you can get from the onAfterShadowMapRenderObservable)
     */
    onAfterShadowMapRenderMeshObservable: Observable<Mesh>;
    /**
     * Specifies if the `ShadowGenerator` should be serialized, `true` to skip serialization.
     * Note a `ShadowGenerator` will not be serialized if its light has `doNotSerialize=true`
     */
    doNotSerialize: boolean;
    protected _bias: number;
    /**
     * Gets the bias: offset applied on the depth preventing acnea (in light direction).
     */
    get bias(): number;
    /**
     * Sets the bias: offset applied on the depth preventing acnea (in light direction).
     */
    set bias(bias: number);
    protected _normalBias: number;
    /**
     * Gets the normalBias: offset applied on the depth preventing acnea (along side the normal direction and proportional to the light/normal angle).
     */
    get normalBias(): number;
    /**
     * Sets the normalBias: offset applied on the depth preventing acnea (along side the normal direction and proportional to the light/normal angle).
     */
    set normalBias(normalBias: number);
    protected _blurBoxOffset: number;
    /**
     * Gets the blur box offset: offset applied during the blur pass.
     * Only useful if useKernelBlur = false
     */
    get blurBoxOffset(): number;
    /**
     * Sets the blur box offset: offset applied during the blur pass.
     * Only useful if useKernelBlur = false
     */
    set blurBoxOffset(value: number);
    protected _blurScale: number;
    /**
     * Gets the blur scale: scale of the blurred texture compared to the main shadow map.
     * 2 means half of the size.
     */
    get blurScale(): number;
    /**
     * Sets the blur scale: scale of the blurred texture compared to the main shadow map.
     * 2 means half of the size.
     */
    set blurScale(value: number);
    protected _blurKernel: number;
    /**
     * Gets the blur kernel: kernel size of the blur pass.
     * Only useful if useKernelBlur = true
     */
    get blurKernel(): number;
    /**
     * Sets the blur kernel: kernel size of the blur pass.
     * Only useful if useKernelBlur = true
     */
    set blurKernel(value: number);
    protected _useKernelBlur: boolean;
    /**
     * Gets whether the blur pass is a kernel blur (if true) or box blur.
     * Only useful in filtered mode (useBlurExponentialShadowMap...)
     */
    get useKernelBlur(): boolean;
    /**
     * Sets whether the blur pass is a kernel blur (if true) or box blur.
     * Only useful in filtered mode (useBlurExponentialShadowMap...)
     */
    set useKernelBlur(value: boolean);
    protected _depthScale: number;
    /**
     * Gets the depth scale used in ESM mode.
     */
    get depthScale(): number;
    /**
     * Sets the depth scale used in ESM mode.
     * This can override the scale stored on the light.
     */
    set depthScale(value: number);
    protected _validateFilter(filter: number): number;
    protected _filter: number;
    /**
     * Gets the current mode of the shadow generator (normal, PCF, ESM...).
     * The returned value is a number equal to one of the available mode defined in ShadowMap.FILTER_x like _FILTER_NONE
     */
    get filter(): number;
    /**
     * Sets the current mode of the shadow generator (normal, PCF, ESM...).
     * The returned value is a number equal to one of the available mode defined in ShadowMap.FILTER_x like _FILTER_NONE
     */
    set filter(value: number);
    /**
     * Gets if the current filter is set to Poisson Sampling.
     */
    get usePoissonSampling(): boolean;
    /**
     * Sets the current filter to Poisson Sampling.
     */
    set usePoissonSampling(value: boolean);
    /**
     * Gets if the current filter is set to ESM.
     */
    get useExponentialShadowMap(): boolean;
    /**
     * Sets the current filter is to ESM.
     */
    set useExponentialShadowMap(value: boolean);
    /**
     * Gets if the current filter is set to filtered ESM.
     */
    get useBlurExponentialShadowMap(): boolean;
    /**
     * Gets if the current filter is set to filtered  ESM.
     */
    set useBlurExponentialShadowMap(value: boolean);
    /**
     * Gets if the current filter is set to "close ESM" (using the inverse of the
     * exponential to prevent steep falloff artifacts).
     */
    get useCloseExponentialShadowMap(): boolean;
    /**
     * Sets the current filter to "close ESM" (using the inverse of the
     * exponential to prevent steep falloff artifacts).
     */
    set useCloseExponentialShadowMap(value: boolean);
    /**
     * Gets if the current filter is set to filtered "close ESM" (using the inverse of the
     * exponential to prevent steep falloff artifacts).
     */
    get useBlurCloseExponentialShadowMap(): boolean;
    /**
     * Sets the current filter to filtered "close ESM" (using the inverse of the
     * exponential to prevent steep falloff artifacts).
     */
    set useBlurCloseExponentialShadowMap(value: boolean);
    /**
     * Gets if the current filter is set to "PCF" (percentage closer filtering).
     */
    get usePercentageCloserFiltering(): boolean;
    /**
     * Sets the current filter to "PCF" (percentage closer filtering).
     */
    set usePercentageCloserFiltering(value: boolean);
    protected _filteringQuality: number;
    /**
     * Gets the PCF or PCSS Quality.
     * Only valid if usePercentageCloserFiltering or usePercentageCloserFiltering is true.
     */
    get filteringQuality(): number;
    /**
     * Sets the PCF or PCSS Quality.
     * Only valid if usePercentageCloserFiltering or usePercentageCloserFiltering is true.
     */
    set filteringQuality(filteringQuality: number);
    /**
     * Gets if the current filter is set to "PCSS" (contact hardening).
     */
    get useContactHardeningShadow(): boolean;
    /**
     * Sets the current filter to "PCSS" (contact hardening).
     */
    set useContactHardeningShadow(value: boolean);
    protected _contactHardeningLightSizeUVRatio: number;
    /**
     * Gets the Light Size (in shadow map uv unit) used in PCSS to determine the blocker search area and the penumbra size.
     * Using a ratio helps keeping shape stability independently of the map size.
     *
     * It does not account for the light projection as it was having too much
     * instability during the light setup or during light position changes.
     *
     * Only valid if useContactHardeningShadow is true.
     */
    get contactHardeningLightSizeUVRatio(): number;
    /**
     * Sets the Light Size (in shadow map uv unit) used in PCSS to determine the blocker search area and the penumbra size.
     * Using a ratio helps keeping shape stability independently of the map size.
     *
     * It does not account for the light projection as it was having too much
     * instability during the light setup or during light position changes.
     *
     * Only valid if useContactHardeningShadow is true.
     */
    set contactHardeningLightSizeUVRatio(contactHardeningLightSizeUVRatio: number);
    protected _darkness: number;
    /** Gets or sets the actual darkness of a shadow */
    get darkness(): number;
    set darkness(value: number);
    /**
     * Returns the darkness value (float). This can only decrease the actual darkness of a shadow.
     * 0 means strongest and 1 would means no shadow.
     * @returns the darkness.
     */
    getDarkness(): number;
    /**
     * Sets the darkness value (float). This can only decrease the actual darkness of a shadow.
     * @param darkness The darkness value 0 means strongest and 1 would means no shadow.
     * @returns the shadow generator allowing fluent coding.
     */
    setDarkness(darkness: number): ShadowGenerator;
    protected _transparencyShadow: boolean;
    /** Gets or sets the ability to have transparent shadow */
    get transparencyShadow(): boolean;
    set transparencyShadow(value: boolean);
    /**
     * Sets the ability to have transparent shadow (boolean).
     * @param transparent True if transparent else False
     * @returns the shadow generator allowing fluent coding
     */
    setTransparencyShadow(transparent: boolean): ShadowGenerator;
    /**
     * Enables or disables shadows with varying strength based on the transparency
     * When it is enabled, the strength of the shadow is taken equal to mesh.visibility
     * If you enabled an alpha texture on your material, the alpha value red from the texture is also combined to compute the strength:
     *          mesh.visibility * alphaTexture.a
     * The texture used is the diffuse by default, but it can be set to the opacity by setting useOpacityTextureForTransparentShadow
     * Note that by definition transparencyShadow must be set to true for enableSoftTransparentShadow to work!
     */
    enableSoftTransparentShadow: boolean;
    /**
     * If this is true, use the opacity texture's alpha channel for transparent shadows instead of the diffuse one
     */
    useOpacityTextureForTransparentShadow: boolean;
    protected _shadowMap: Nullable<RenderTargetTexture>;
    protected _shadowMap2: Nullable<RenderTargetTexture>;
    /**
     * Gets the main RTT containing the shadow map (usually storing depth from the light point of view).
     * @returns The render target texture if present otherwise, null
     */
    getShadowMap(): Nullable<RenderTargetTexture>;
    /**
     * Gets the RTT used during rendering (can be a blurred version of the shadow map or the shadow map itself).
     * @returns The render target texture if the shadow map is present otherwise, null
     */
    getShadowMapForRendering(): Nullable<RenderTargetTexture>;
    /**
     * Gets the class name of that object
     * @returns "ShadowGenerator"
     */
    getClassName(): string;
    /**
     * Helper function to add a mesh and its descendants to the list of shadow casters.
     * @param mesh Mesh to add
     * @param includeDescendants boolean indicating if the descendants should be added. Default to true
     * @returns the Shadow Generator itself
     */
    addShadowCaster(mesh: AbstractMesh, includeDescendants?: boolean): ShadowGenerator;
    /**
     * Helper function to remove a mesh and its descendants from the list of shadow casters
     * @param mesh Mesh to remove
     * @param includeDescendants boolean indicating if the descendants should be removed. Default to true
     * @returns the Shadow Generator itself
     */
    removeShadowCaster(mesh: AbstractMesh, includeDescendants?: boolean): ShadowGenerator;
    /**
     * Controls the extent to which the shadows fade out at the edge of the frustum
     */
    frustumEdgeFalloff: number;
    protected _light: IShadowLight;
    /**
     * Returns the associated light object.
     * @returns the light generating the shadow
     */
    getLight(): IShadowLight;
    /** Shader language used by the generator */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this generator.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * If true the shadow map is generated by rendering the back face of the mesh instead of the front face.
     * This can help with self-shadowing as the geometry making up the back of objects is slightly offset.
     * It might on the other hand introduce peter panning.
     */
    forceBackFacesOnly: boolean;
    protected _camera: Nullable<Camera>;
    protected _getCamera(): Nullable<Camera>;
    protected _scene: Scene;
    protected _useRedTextureType: boolean;
    protected _lightDirection: Vector3;
    protected _viewMatrix: Matrix;
    protected _projectionMatrix: Matrix;
    protected _transformMatrix: Matrix;
    protected _cachedPosition: Vector3;
    protected _cachedDirection: Vector3;
    protected _cachedDefines: string;
    protected _currentRenderId: number;
    protected _boxBlurPostprocess: Nullable<PostProcess>;
    protected _kernelBlurXPostprocess: Nullable<PostProcess>;
    protected _kernelBlurYPostprocess: Nullable<PostProcess>;
    protected _blurPostProcesses: PostProcess[];
    protected _mapSize: number;
    protected _currentFaceIndex: number;
    protected _currentFaceIndexCache: number;
    protected _textureType: number;
    protected _defaultTextureMatrix: Matrix;
    protected _storedUniqueId: Nullable<number>;
    protected _useUBO: boolean;
    protected _sceneUBOs: UniformBuffer[];
    protected _currentSceneUBO: UniformBuffer;
    protected _opacityTexture: Nullable<BaseTexture>;
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    /**
     * Gets or sets the size of the texture what stores the shadows
     */
    get mapSize(): number;
    set mapSize(size: number);
    /**
     * Creates a ShadowGenerator object.
     * A ShadowGenerator is the required tool to use the shadows.
     * Each light casting shadows needs to use its own ShadowGenerator.
     * Documentation : https://doc.babylonjs.com/features/featuresDeepDive/lights/shadows
     * @param mapSize The size of the texture what stores the shadows. Example : 1024.
     * @param light The light object generating the shadows.
     * @param usefullFloatFirst By default the generator will try to use half float textures but if you need precision (for self shadowing for instance), you can use this option to enforce full float texture.
     * @param camera Camera associated with this shadow generator (default: null). If null, takes the scene active camera at the time we need to access it
     * @param useRedTextureType Forces the generator to use a Red instead of a RGBA type for the shadow map texture format (default: false)
     * @param forceGLSL defines a boolean indicating if the shader must be compiled in GLSL even if we are using WebGPU
     */
    constructor(mapSize: number, light: IShadowLight, usefullFloatFirst?: boolean, camera?: Nullable<Camera>, useRedTextureType?: boolean, forceGLSL?: boolean);
    protected _initializeGenerator(): void;
    protected _createTargetRenderTexture(): void;
    protected _initializeShadowMap(): void;
    private _shadersLoaded;
    private _initShaderSourceAsync;
    protected _initializeBlurRTTAndPostProcesses(): void;
    protected _renderForShadowMap(opaqueSubMeshes: SmartArray<SubMesh>, alphaTestSubMeshes: SmartArray<SubMesh>, transparentSubMeshes: SmartArray<SubMesh>, depthOnlySubMeshes: SmartArray<SubMesh>): void;
    protected _bindCustomEffectForRenderSubMeshForShadowMap(subMesh: SubMesh, effect: Effect, mesh: AbstractMesh): void;
    protected _renderSubMeshForShadowMap(subMesh: SubMesh, isTransparent?: boolean): void;
    protected _applyFilterValues(): void;
    /**
     * Forces all the attached effect to compile to enable rendering only once ready vs. lazily compiling effects.
     * @param onCompiled Callback triggered at the and of the effects compilation
     * @param options Sets of optional options forcing the compilation with different modes
     */
    forceCompilation(onCompiled?: (generator: IShadowGenerator) => void, options?: Partial<{
        useInstances: boolean;
    }>): void;
    /**
     * Forces all the attached effect to compile to enable rendering only once ready vs. lazily compiling effects.
     * @param options Sets of optional options forcing the compilation with different modes
     * @returns A promise that resolves when the compilation completes
     */
    forceCompilationAsync(options?: Partial<{
        useInstances: boolean;
    }>): Promise<void>;
    protected _isReadyCustomDefines(defines: any, subMesh: SubMesh, useInstances: boolean): void;
    private _prepareShadowDefines;
    /**
     * Determine whether the shadow generator is ready or not (mainly all effects and related post processes needs to be ready).
     * @param subMesh The submesh we want to render in the shadow map
     * @param useInstances Defines whether will draw in the map using instances
     * @param isTransparent Indicates that isReady is called for a transparent subMesh
     * @returns true if ready otherwise, false
     */
    isReady(subMesh: SubMesh, useInstances: boolean, isTransparent: boolean): boolean;
    /**
     * Prepare all the defines in a material relying on a shadow map at the specified light index.
     * @param defines Defines of the material we want to update
     * @param lightIndex Index of the light in the enabled light list of the material
     */
    prepareDefines(defines: any, lightIndex: number): void;
    /**
     * Binds the shadow related information inside of an effect (information like near, far, darkness...
     * defined in the generator but impacting the effect).
     * @param lightIndex Index of the light in the enabled light list of the material owning the effect
     * @param effect The effect we are binding the information for
     */
    bindShadowLight(lightIndex: string, effect: Effect): void;
    /**
     * Gets the view matrix used to render the shadow map.
     */
    get viewMatrix(): Matrix;
    /**
     * Gets the projection matrix used to render the shadow map.
     */
    get projectionMatrix(): Matrix;
    /**
     * Gets the transformation matrix used to project the meshes into the map from the light point of view.
     * (eq to shadow projection matrix * light transform matrix)
     * @returns The transform matrix used to create the shadow map
     */
    getTransformMatrix(): Matrix;
    /**
     * Recreates the shadow map dependencies like RTT and post processes. This can be used during the switch between
     * Cube and 2D textures for instance.
     */
    recreateShadowMap(): void;
    protected _disposeBlurPostProcesses(): void;
    protected _disposeRTTandPostProcesses(): void;
    protected _disposeSceneUBOs(): void;
    /**
     * Disposes the ShadowGenerator.
     * Returns nothing.
     */
    dispose(): void;
    /**
     * Serializes the shadow generator setup to a json object.
     * @returns The serialized JSON object
     */
    serialize(): any;
    /**
     * Parses a serialized ShadowGenerator and returns a new ShadowGenerator.
     * @param parsedShadowGenerator The JSON object to parse
     * @param scene The scene to create the shadow map for
     * @param constr A function that builds a shadow generator or undefined to create an instance of the default shadow generator
     * @returns The parsed shadow generator
     */
    static Parse(parsedShadowGenerator: any, scene: Scene, constr?: (mapSize: number, light: IShadowLight, camera: Nullable<Camera>) => ShadowGenerator): ShadowGenerator;
}

/**
 * Options to be used when creating a shadow depth material
 */
interface IIOptionShadowDepthMaterial {
    /** Variables in the vertex shader code that need to have their names remapped.
     * The format is: ["var_name", "var_remapped_name", "var_name", "var_remapped_name", ...]
     * "var_name" should be either: worldPos or vNormalW
     * So, if the variable holding the world position in your vertex shader is not named worldPos, you must tell the system
     * the name to use instead by using: ["worldPos", "myWorldPosVar"] assuming the variable is named myWorldPosVar in your code.
     * If the normal must also be remapped: ["worldPos", "myWorldPosVar", "vNormalW", "myWorldNormal"]
     */
    remappedVariables?: string[];
    /** Set standalone to true if the base material wrapped by ShadowDepthMaterial is not used for a regular object but for depth shadow generation only */
    standalone?: boolean;
    /** Set doNotInjectCode if the specific shadow map generation code is already implemented by the material. That will prevent this code to be injected twice by ShadowDepthWrapper */
    doNotInjectCode?: boolean;
}
/**
 * Class that can be used to wrap a base material to generate accurate shadows when using custom vertex/fragment code in the base material
 */
declare class ShadowDepthWrapper {
    private _scene;
    private _options?;
    private _baseMaterial;
    private _onEffectCreatedObserver;
    private _subMeshToEffect;
    private _subMeshToDepthWrapper;
    private _meshes;
    /** Gets the standalone status of the wrapper */
    get standalone(): boolean;
    /** Gets the base material the wrapper is built upon */
    get baseMaterial(): Material;
    /** Gets the doNotInjectCode status of the wrapper */
    get doNotInjectCode(): boolean;
    /**
     * Instantiate a new shadow depth wrapper.
     * It works by injecting some specific code in the vertex/fragment shaders of the base material and is used by a shadow generator to
     * generate the shadow depth map. For more information, please refer to the documentation:
     * https://doc.babylonjs.com/features/featuresDeepDive/lights/shadows
     * @param baseMaterial Material to wrap
     * @param scene Define the scene the material belongs to
     * @param options Options used to create the wrapper
     */
    constructor(baseMaterial: Material, scene?: Scene, options?: IIOptionShadowDepthMaterial);
    private _deleteDepthWrapperEffect;
    /**
     * Gets the effect to use to generate the depth map
     * @param subMesh subMesh to get the effect for
     * @param shadowGenerator shadow generator to get the effect for
     * @param passIdForDrawWrapper Id of the pass for which the effect from the draw wrapper must be retrieved from
     * @returns the effect to use to generate the depth map for the subMesh + shadow generator specified
     */
    getEffect(subMesh: Nullable<SubMesh>, shadowGenerator: ShadowGenerator, passIdForDrawWrapper: number): Nullable<DrawWrapper>;
    /**
     * Specifies that the submesh is ready to be used for depth rendering
     * @param subMesh submesh to check
     * @param defines the list of defines to take into account when checking the effect
     * @param shadowGenerator combined with subMesh, it defines the effect to check
     * @param useInstances specifies that instances should be used
     * @param passIdForDrawWrapper Id of the pass for which the draw wrapper should be created
     * @returns a boolean indicating that the submesh is ready or not
     */
    isReadyForSubMesh(subMesh: SubMesh, defines: string[], shadowGenerator: ShadowGenerator, useInstances: boolean, passIdForDrawWrapper: number): boolean;
    /**
     * Disposes the resources
     */
    dispose(): void;
    private _makeEffect;
}

/**
 * Interface defining the properties of the stencil state.
 */
interface IStencilStateProperties {
    /**
     * Whether the stencil test is enabled or not.
     */
    enabled: boolean;
    /**
     * The stencil mask to use for writing.
     */
    mask: number;
    /**
     * The stencil mask to use for reading.
     */
    funcMask: number;
    /**
     * The reference value to use for the stencil test.
     */
    funcRef: number;
    /**
     * The stencil comparison function to use for front faces.
     */
    func: number;
    /**
     * The operation to perform when both the stencil and depth tests pass for front faces.
     */
    opStencilDepthPass: number;
    /**
     * The operation to perform when the stencil test fails for front faces.
     */
    opStencilFail: number;
    /**
     * The operation to perform when the stencil test passes but the depth test fails for front faces.
     */
    opDepthFail: number;
    /**
     * The stencil comparison function to use for back faces.
     */
    backFunc: number;
    /**
     * The operation to perform when both the stencil and depth tests pass for back faces.
     */
    backOpStencilDepthPass: number;
    /**
     * The operation to perform when the stencil test fails for back faces.
     */
    backOpStencilFail: number;
    /**
     * The operation to perform when the stencil test passes but the depth test fails for back faces.
     */
    backOpDepthFail: number;
}
/**
 * Interface defining the stencil state.
 */
interface IStencilState extends IStencilStateProperties {
    /**
     * Resets the stencil state to default values.
     */
    reset(): void;
}

/**
 * Class that holds the different stencil states of a material
 * Usage example: https://playground.babylonjs.com/#CW5PRI#10
 */
declare class MaterialStencilState implements IStencilState {
    /**
     * Creates a material stencil state instance
     */
    constructor();
    /**
     * Resets all the stencil states to default values
     */
    reset(): void;
    private _func;
    /**
     * Gets or sets the stencil function
     */
    get func(): number;
    set func(value: number);
    private _backFunc;
    /**
     * Gets or sets the stencil back function
     */
    get backFunc(): number;
    set backFunc(value: number);
    private _funcRef;
    /**
     * Gets or sets the stencil function reference
     */
    get funcRef(): number;
    set funcRef(value: number);
    private _funcMask;
    /**
     * Gets or sets the stencil function mask
     */
    get funcMask(): number;
    set funcMask(value: number);
    private _opStencilFail;
    /**
     * Gets or sets the operation when the stencil test fails
     */
    get opStencilFail(): number;
    set opStencilFail(value: number);
    private _opDepthFail;
    /**
     * Gets or sets the operation when the depth test fails
     */
    get opDepthFail(): number;
    set opDepthFail(value: number);
    private _opStencilDepthPass;
    /**
     * Gets or sets the operation when the stencil+depth test succeeds
     */
    get opStencilDepthPass(): number;
    set opStencilDepthPass(value: number);
    private _backOpStencilFail;
    /**
     * Gets or sets the operation when the back stencil test fails
     */
    get backOpStencilFail(): number;
    set backOpStencilFail(value: number);
    private _backOpDepthFail;
    /**
     * Gets or sets the operation when the back depth test fails
     */
    get backOpDepthFail(): number;
    set backOpDepthFail(value: number);
    private _backOpStencilDepthPass;
    /**
     * Gets or sets the operation when the back stencil+depth test succeeds
     */
    get backOpStencilDepthPass(): number;
    set backOpStencilDepthPass(value: number);
    private _mask;
    /**
     * Gets or sets the stencil mask
     */
    get mask(): number;
    set mask(value: number);
    private _enabled;
    /**
     * Enables or disables the stencil test
     */
    get enabled(): boolean;
    set enabled(value: boolean);
    /**
     * Get the current class name, useful for serialization or dynamic coding.
     * @returns "MaterialStencilState"
     */
    getClassName(): string;
    /**
     * Makes a duplicate of the current configuration into another one.
     * @param stencilState defines stencil state where to copy the info
     */
    copyTo(stencilState: MaterialStencilState): void;
    /**
     * Serializes this stencil configuration.
     * @returns - An object with the serialized config.
     */
    serialize(): any;
    /**
     * Parses a stencil state configuration from a serialized object.
     * @param source - Serialized object.
     * @param scene Defines the scene we are parsing for
     * @param rootUrl Defines the rootUrl to load from
     */
    parse(source: any, scene: Scene, rootUrl: string): void;
}

/** @internal */
interface IShaderProcessor {
    shaderLanguage: ShaderLanguage;
    uniformRegexp?: RegExp;
    uniformBufferRegexp?: RegExp;
    textureRegexp?: RegExp;
    noPrecision?: boolean;
    parseGLES3?: boolean;
    attributeKeywordName?: string;
    varyingVertexKeywordName?: string;
    varyingFragmentKeywordName?: string;
    preProcessShaderCode?: (code: string, isFragment: boolean) => string;
    attributeProcessor?: (attribute: string, preProcessors: {
        [key: string]: string;
    }, processingContext: Nullable<_IShaderProcessingContext>) => string;
    varyingCheck?: (varying: string, isFragment: boolean) => boolean;
    varyingProcessor?: (varying: string, isFragment: boolean, preProcessors: {
        [key: string]: string;
    }, processingContext: Nullable<_IShaderProcessingContext>) => string;
    uniformProcessor?: (uniform: string, isFragment: boolean, preProcessors: {
        [key: string]: string;
    }, processingContext: Nullable<_IShaderProcessingContext>) => string;
    uniformBufferProcessor?: (uniformBuffer: string, isFragment: boolean, processingContext: Nullable<_IShaderProcessingContext>) => string;
    textureProcessor?: (texture: string, isFragment: boolean, preProcessors: {
        [key: string]: string;
    }, processingContext: Nullable<_IShaderProcessingContext>) => string;
    endOfUniformBufferProcessor?: (closingBracketLine: string, isFragment: boolean, processingContext: Nullable<_IShaderProcessingContext>) => string;
    lineProcessor?: (line: string, isFragment: boolean, processingContext: Nullable<_IShaderProcessingContext>) => string;
    preProcessor?: (code: string, defines: string[], preProcessors: {
        [key: string]: string;
    }, isFragment: boolean, processingContext: Nullable<_IShaderProcessingContext>) => string;
    postProcessor?: (code: string, defines: string[], isFragment: boolean, processingContext: Nullable<_IShaderProcessingContext>, patameters: {
        [key: string]: number | string | boolean | undefined;
    }, preProcessors: {
        [key: string]: string;
    }, preProcessorsFromCode: {
        [key: string]: string;
    }) => string;
    initializeShaders?: (processingContext: Nullable<_IShaderProcessingContext>) => void;
    finalizeShaders?: (vertexCode: string, fragmentCode: string, processingContext: Nullable<_IShaderProcessingContext>) => {
        vertexCode: string;
        fragmentCode: string;
    };
}

/**
 * Function for custom code generation
 */
type ShaderCustomProcessingFunction = (shaderType: string, code: string, defines?: string[]) => string;
/** @internal */
interface _IShaderProcessingContext {
    vertexBufferKindToNumberOfComponents?: {
        [kind: string]: number;
    };
}
/** @internal */
interface _IProcessingOptions {
    defines: string[];
    indexParameters: any;
    isFragment: boolean;
    shouldUseHighPrecisionShader: boolean;
    supportsUniformBuffers: boolean;
    shadersRepository: string;
    includesShadersStore: {
        [key: string]: string;
    };
    processor: Nullable<IShaderProcessor>;
    version: string;
    platformName: string;
    lookForClosingBracketForUniformBuffer?: boolean;
    processingContext: Nullable<_IShaderProcessingContext>;
    isNDCHalfZRange: boolean;
    useReverseDepthBuffer: boolean;
    processCodeAfterIncludes?: ShaderCustomProcessingFunction;
}

/**
 * Interface used to define common properties for effect fallbacks
 */
interface IEffectFallbacks {
    /**
     * Removes the defines that should be removed when falling back.
     * @param currentDefines defines the current define statements for the shader.
     * @param effect defines the current effect we try to compile
     * @returns The resulting defines with defines of the current rank removed.
     */
    reduce(currentDefines: string, effect: Effect): string;
    /**
     * Removes the fallback from the bound mesh.
     */
    unBindMesh(): void;
    /**
     * Checks to see if more fallbacks are still available.
     */
    hasMoreFallbacks: boolean;
}

/**
 * EffectFallbacks can be used to add fallbacks (properties to disable) to certain properties when desired to improve performance.
 * (Eg. Start at high quality with reflection and fog, if fps is low, remove reflection, if still low remove fog)
 */
declare class EffectFallbacks implements IEffectFallbacks {
    private _defines;
    private _currentRank;
    private _maxRank;
    private _mesh;
    /**
     * Removes the fallback from the bound mesh.
     */
    unBindMesh(): void;
    /**
     * Adds a fallback on the specified property.
     * @param rank The rank of the fallback (Lower ranks will be fallbacked to first)
     * @param define The name of the define in the shader
     */
    addFallback(rank: number, define: string): void;
    /**
     * Sets the mesh to use CPU skinning when needing to fallback.
     * @param rank The rank of the fallback (Lower ranks will be fallbacked to first)
     * @param mesh The mesh to use the fallbacks.
     */
    addCPUSkinningFallback(rank: number, mesh: AbstractMesh): void;
    /**
     * Checks to see if more fallbacks are still available.
     */
    get hasMoreFallbacks(): boolean;
    /**
     * Removes the defines that should be removed when falling back.
     * @param currentDefines defines the current define statements for the shader.
     * @param effect defines the current effect we try to compile
     * @returns The resulting defines with defines of the current rank removed.
     */
    reduce(currentDefines: string, effect: Effect): string;
}

/** @internal */
type MaterialPluginCreated = object;
/** @internal */
type MaterialPluginDisposed = {
    forceDisposeTextures?: boolean;
};
/** @internal */
type MaterialPluginHasTexture = {
    hasTexture: boolean;
    texture: BaseTexture;
};
/** @internal */
type MaterialPluginIsReadyForSubMesh = {
    isReadyForSubMesh: boolean;
    defines: MaterialDefines;
    subMesh: SubMesh;
};
/** @internal */
type MaterialPluginGetDefineNames = {
    defineNames?: {
        [name: string]: {
            type: string;
            default: any;
        };
    };
};
/** @internal */
type MaterialPluginPrepareEffect = {
    defines: MaterialDefines;
    fallbacks: EffectFallbacks;
    fallbackRank: number;
    customCode?: ShaderCustomProcessingFunction;
    attributes: string[];
    uniforms: string[];
    samplers: string[];
    uniformBuffersNames: string[];
    mesh: AbstractMesh;
    indexParameters: any;
};
/** @internal */
type MaterialPluginPrepareDefines = {
    defines: MaterialDefines;
    mesh: AbstractMesh;
};
/** @internal */
type MaterialPluginPrepareUniformBuffer = {
    ubo: UniformBuffer;
};
/** @internal */
type MaterialPluginBindForSubMesh = {
    subMesh: SubMesh;
};
/** @internal */
type MaterialPluginGetAnimatables = {
    animatables: IAnimatable[];
};
/** @internal */
type MaterialPluginGetActiveTextures = {
    activeTextures: BaseTexture[];
};
/** @internal */
type MaterialPluginFillRenderTargetTextures = {
    renderTargets: SmartArray<RenderTargetTexture>;
};
/** @internal */
type MaterialPluginHasRenderTargetTextures = {
    hasRenderTargetTextures: boolean;
};
/** @internal */
type MaterialPluginHardBindForSubMesh = {
    subMesh: SubMesh;
};

/**
 * Represents a 3D path made up of multiple 3D points
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/path3D
 */
declare class Path3D {
    /**
     * an array of Vector3, the curve axis of the Path3D
     */
    path: Vector3[];
    private _curve;
    private _distances;
    private _tangents;
    private _normals;
    private _binormals;
    private _raw;
    private _alignTangentsWithPath;
    private readonly _pointAtData;
    /**
     * new Path3D(path, normal, raw)
     * Creates a Path3D. A Path3D is a logical math object, so not a mesh.
     * please read the description in the tutorial : https://doc.babylonjs.com/features/featuresDeepDive/mesh/path3D
     * @param path an array of Vector3, the curve axis of the Path3D
     * @param firstNormal (options) Vector3, the first wanted normal to the curve. Ex (0, 1, 0) for a vertical normal.
     * @param raw (optional, default false) : boolean, if true the returned Path3D isn't normalized. Useful to depict path acceleration or speed.
     * @param alignTangentsWithPath (optional, default false) : boolean, if true the tangents will be aligned with the path.
     */
    constructor(
    /**
     * an array of Vector3, the curve axis of the Path3D
     */
    path: Vector3[], firstNormal?: Nullable<Vector3>, raw?: boolean, alignTangentsWithPath?: boolean);
    /**
     * Returns the Path3D array of successive Vector3 designing its curve.
     * @returns the Path3D array of successive Vector3 designing its curve.
     */
    getCurve(): Vector3[];
    /**
     * Returns the Path3D array of successive Vector3 designing its curve.
     * @returns the Path3D array of successive Vector3 designing its curve.
     */
    getPoints(): Vector3[];
    /**
     * @returns the computed length (float) of the path.
     */
    length(): number;
    /**
     * Returns an array populated with tangent vectors on each Path3D curve point.
     * @returns an array populated with tangent vectors on each Path3D curve point.
     */
    getTangents(): Vector3[];
    /**
     * Returns an array populated with normal vectors on each Path3D curve point.
     * @returns an array populated with normal vectors on each Path3D curve point.
     */
    getNormals(): Vector3[];
    /**
     * Returns an array populated with binormal vectors on each Path3D curve point.
     * @returns an array populated with binormal vectors on each Path3D curve point.
     */
    getBinormals(): Vector3[];
    /**
     * Returns an array populated with distances (float) of the i-th point from the first curve point.
     * @returns an array populated with distances (float) of the i-th point from the first curve point.
     */
    getDistances(): number[];
    /**
     * Returns an interpolated point along this path
     * @param position the position of the point along this path, from 0.0 to 1.0
     * @returns a new Vector3 as the point
     */
    getPointAt(position: number): Vector3;
    /**
     * Returns the tangent vector of an interpolated Path3D curve point at the specified position along this path.
     * @param position the position of the point along this path, from 0.0 to 1.0
     * @param interpolated (optional, default false) : boolean, if true returns an interpolated tangent instead of the tangent of the previous path point.
     * @returns a tangent vector corresponding to the interpolated Path3D curve point, if not interpolated, the tangent is taken from the precomputed tangents array.
     */
    getTangentAt(position: number, interpolated?: boolean): Vector3;
    /**
     * Returns the tangent vector of an interpolated Path3D curve point at the specified position along this path.
     * @param position the position of the point along this path, from 0.0 to 1.0
     * @param interpolated (optional, default false) : boolean, if true returns an interpolated normal instead of the normal of the previous path point.
     * @returns a normal vector corresponding to the interpolated Path3D curve point, if not interpolated, the normal is taken from the precomputed normals array.
     */
    getNormalAt(position: number, interpolated?: boolean): Vector3;
    /**
     * Returns the binormal vector of an interpolated Path3D curve point at the specified position along this path.
     * @param position the position of the point along this path, from 0.0 to 1.0
     * @param interpolated (optional, default false) : boolean, if true returns an interpolated binormal instead of the binormal of the previous path point.
     * @returns a binormal vector corresponding to the interpolated Path3D curve point, if not interpolated, the binormal is taken from the precomputed binormals array.
     */
    getBinormalAt(position: number, interpolated?: boolean): Vector3;
    /**
     * Returns the distance (float) of an interpolated Path3D curve point at the specified position along this path.
     * @param position the position of the point along this path, from 0.0 to 1.0
     * @returns the distance of the interpolated Path3D curve point at the specified position along this path.
     */
    getDistanceAt(position: number): number;
    /**
     * Returns the array index of the previous point of an interpolated point along this path
     * @param position the position of the point to interpolate along this path, from 0.0 to 1.0
     * @returns the array index
     */
    getPreviousPointIndexAt(position: number): number;
    /**
     * Returns the position of an interpolated point relative to the two path points it lies between, from 0.0 (point A) to 1.0 (point B)
     * @param position the position of the point to interpolate along this path, from 0.0 to 1.0
     * @returns the sub position
     */
    getSubPositionAt(position: number): number;
    /**
     * Returns the position of the closest virtual point on this path to an arbitrary Vector3, from 0.0 to 1.0
     * @param target the vector of which to get the closest position to
     * @returns the position of the closest virtual point on this path to the target vector
     */
    getClosestPositionTo(target: Vector3): number;
    /**
     * Returns a sub path (slice) of this path
     * @param start the position of the fist path point, from 0.0 to 1.0, or a negative value, which will get wrapped around from the end of the path to 0.0 to 1.0 values
     * @param end the position of the last path point, from 0.0 to 1.0, or a negative value, which will get wrapped around from the end of the path to 0.0 to 1.0 values
     * @returns a sub path (slice) of this path
     */
    slice(start?: number, end?: number): Path3D;
    /**
     * Forces the Path3D tangent, normal, binormal and distance recomputation.
     * @param path path which all values are copied into the curves points
     * @param firstNormal which should be projected onto the curve
     * @param alignTangentsWithPath (optional, default false) : boolean, if true the tangents will be aligned with the path
     * @returns the same object updated.
     */
    update(path: Vector3[], firstNormal?: Nullable<Vector3>, alignTangentsWithPath?: boolean): Path3D;
    private _compute;
    private _getFirstNonNullVector;
    private _getLastNonNullVector;
    private _normalVector;
    /**
     * Updates the point at data for an interpolated point along this curve
     * @param position the position of the point along this curve, from 0.0 to 1.0
     * @param interpolateTNB
     * @interpolateTNB whether to compute the interpolated tangent, normal and binormal
     * @returns the (updated) point at data
     */
    private _updatePointAtData;
    /**
     * Updates the point at data from the specified parameters
     * @param position where along the path the interpolated point is, from 0.0 to 1.0
     * @param subPosition
     * @param point the interpolated point
     * @param parentIndex the index of an existing curve point that is on, or else positionally the first behind, the interpolated point
     * @param interpolateTNB whether to compute the interpolated tangent, normal and binormal
     * @returns the (updated) point at data
     */
    private _setPointAtData;
    /**
     * Updates the point at interpolation matrix for the tangents, normals and binormals
     */
    private _updateInterpolationMatrix;
}

/**
 * Interface used to define entities containing multiple clip planes
 */
interface IClipPlanesHolder {
    /**
     * Gets or sets the active clipplane 1
     */
    clipPlane: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 2
     */
    clipPlane2: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 3
     */
    clipPlane3: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 4
     */
    clipPlane4: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 5
     */
    clipPlane5: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 6
     */
    clipPlane6: Nullable<Plane>;
}

/**
 * Interface used to present a loading screen while loading a scene
 * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
 */
interface ILoadingScreen {
    /**
     * Function called to display the loading screen
     */
    displayLoadingUI: () => void;
    /**
     * Function called to hide the loading screen
     */
    hideLoadingUI: () => void;
    /**
     * Gets or sets the color to use for the background
     */
    loadingUIBackgroundColor: string;
    /**
     * Gets or sets the text to display while loading
     */
    loadingUIText: string;
}

/**
 * Class used to store and describe the pipeline context associated with an effect
 */
interface IPipelineContext {
    /**
     * Gets a boolean indicating that this pipeline context is supporting asynchronous creating
     */
    readonly isAsync: boolean;
    /**
     * Gets a boolean indicating that the context is ready to be used (like shaders / pipelines are compiled and ready for instance)
     */
    readonly isReady: boolean;
    /**
     * Property used to handle vertex buffers with int values when the shader code expect float values.
     * @internal
     */
    vertexBufferKindToType?: {
        [kind: string]: number;
    };
    /** @internal */
    _name?: string;
    /** @internal */
    _getVertexShaderCode(): string | null;
    /** @internal */
    _getFragmentShaderCode(): string | null;
    /** @internal */
    _handlesSpectorRebuildCallback?(onCompiled: (compiledObject: any) => void): void;
    /** @internal */
    _fillEffectInformation(effect: Effect, uniformBuffersNames: {
        [key: string]: number;
    }, uniformsNames: string[], uniforms: {
        [key: string]: Nullable<WebGLUniformLocation>;
    }, samplerList: string[], samplers: {
        [key: string]: number;
    }, attributesNames: string[], attributes: number[]): void;
    /** Releases the resources associated with the pipeline. */
    dispose(): void;
    /** set the engine, in case it is not a part of the constructor */
    setEngine<T extends AbstractEngine>(engine: T): void;
    /**
     * Sets an integer value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value Value to be set.
     */
    setInt(uniformName: string, value: number): void;
    /**
     * Sets an int2 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int2.
     * @param y Second int in int2.
     */
    setInt2(uniformName: string, x: number, y: number): void;
    /**
     * Sets an int3 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int3.
     * @param y Second int in int3.
     * @param z Third int in int3.
     */
    setInt3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets an int4 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int4.
     * @param y Second int in int4.
     * @param z Third int in int4.
     * @param w Fourth int in int4.
     */
    setInt4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets an int array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray2(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray3(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray4(uniformName: string, array: Int32Array): void;
    /**
     * Sets an unsigned integer value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value Value to be set.
     */
    setUInt(uniformName: string, value: number): void;
    /**
     * Sets an unsigned int2 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint2.
     * @param y Second unsigned int in uint2.
     */
    setUInt2(uniformName: string, x: number, y: number): void;
    /**
     * Sets an unsigned int3 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint3.
     * @param y Second unsigned int in uint3.
     * @param z Third unsigned int in uint3.
     */
    setUInt3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets an unsigned int4 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint4.
     * @param y Second unsigned int in uint4.
     * @param z Third unsigned int in uint4.
     * @param w Fourth unsigned int in uint4.
     */
    setUInt4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets an unsigned int array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray2(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray3(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray4(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray(uniformName: string, array: FloatArray): void;
    /**
     * Sets an array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray2(uniformName: string, array: FloatArray): void;
    /**
     * Sets an array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray3(uniformName: string, array: FloatArray): void;
    /**
     * Sets an array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray4(uniformName: string, array: FloatArray): void;
    /**
     * Sets matrices on a uniform variable.
     * @param uniformName Name of the variable.
     * @param matrices matrices to be set.
     */
    setMatrices(uniformName: string, matrices: Float32Array): void;
    /**
     * Sets matrix on a uniform variable.
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix(uniformName: string, matrix: IMatrixLike): void;
    /**
     * Sets a 3x3 matrix on a uniform variable. (Specified as [1,2,3,4,5,6,7,8,9] will result in [1,2,3][4,5,6][7,8,9] matrix)
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix3x3(uniformName: string, matrix: Float32Array): void;
    /**
     * Sets a 2x2 matrix on a uniform variable. (Specified as [1,2,3,4] will result in [1,2][3,4] matrix)
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix2x2(uniformName: string, matrix: Float32Array): void;
    /**
     * Sets a float on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value value to be set.
     */
    setFloat(uniformName: string, value: number): void;
    /**
     * Sets a Vector2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector2 vector2 to be set.
     */
    setVector2(uniformName: string, vector2: IVector2Like): void;
    /**
     * Sets a float2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float2.
     * @param y Second float in float2.
     */
    setFloat2(uniformName: string, x: number, y: number): void;
    /**
     * Sets a Vector3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector3 Value to be set.
     */
    setVector3(uniformName: string, vector3: IVector3Like): void;
    /**
     * Sets a float3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float3.
     * @param y Second float in float3.
     * @param z Third float in float3.
     */
    setFloat3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets a Vector4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector4 Value to be set.
     */
    setVector4(uniformName: string, vector4: IVector4Like): void;
    /**
     * Sets a Quaternion on a uniform variable.
     * @param uniformName Name of the variable.
     * @param quaternion Value to be set.
     */
    setQuaternion(uniformName: string, quaternion: IQuaternionLike): void;
    /**
     * Sets a float4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float4.
     * @param y Second float in float4.
     * @param z Third float in float4.
     * @param w Fourth float in float4.
     */
    setFloat4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets a Color3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param color3 Value to be set.
     */
    setColor3(uniformName: string, color3: IColor3Like): void;
    /**
     * Sets a Color4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param color3 Value to be set.
     * @param alpha Alpha value to be set.
     */
    setColor4(uniformName: string, color3: IColor3Like, alpha: number): void;
    /**
     * Sets a Color4 on a uniform variable
     * @param uniformName defines the name of the variable
     * @param color4 defines the value to be set
     */
    setDirectColor4(uniformName: string, color4: IColor4Like): void;
}

/**
 * Interface for attribute information associated with buffer instantiation
 */
interface InstancingAttributeInfo {
    /**
     * Name of the GLSL attribute
     * if attribute index is not specified, this is used to retrieve the index from the effect
     */
    attributeName: string;
    /**
     * Index/offset of the attribute in the vertex shader
     * if not specified, this will be computes from the name.
     */
    index?: number;
    /**
     * size of the attribute, 1, 2, 3 or 4
     */
    attributeSize: number;
    /**
     * Offset of the data in the Vertex Buffer acting as the instancing buffer
     */
    offset: number;
    /**
     * Modifies the rate at which generic vertex attributes advance when rendering multiple instances
     * default to 1
     */
    divisor?: number;
    /**
     * type of the attribute, gl.BYTE, gl.UNSIGNED_BYTE, gl.SHORT, gl.UNSIGNED_SHORT, gl.FIXED, gl.FLOAT.
     * default is FLOAT
     */
    attributeType?: number;
    /**
     * normalization of fixed-point data. behavior unclear, use FALSE, default is FALSE
     */
    normalized?: boolean;
}

/**
 * Performance monitor tracks rolling average frame-time and frame-time variance over a user defined sliding-window
 */
declare class PerformanceMonitor {
    private _enabled;
    private _rollingFrameTime;
    private _lastFrameTimeMs;
    /**
     * constructor
     * @param frameSampleSize The number of samples required to saturate the sliding window
     */
    constructor(frameSampleSize?: number);
    /**
     * Samples current frame
     * @param timeMs A timestamp in milliseconds of the current frame to compare with other frames
     */
    sampleFrame(timeMs?: number): void;
    /**
     * Returns the average frame time in milliseconds over the sliding window (or the subset of frames sampled so far)
     */
    get averageFrameTime(): number;
    /**
     * Returns the variance frame time in milliseconds over the sliding window (or the subset of frames sampled so far)
     */
    get averageFrameTimeVariance(): number;
    /**
     * Returns the frame time of the most recent frame
     */
    get instantaneousFrameTime(): number;
    /**
     * Returns the average framerate in frames per second over the sliding window (or the subset of frames sampled so far)
     */
    get averageFPS(): number;
    /**
     * Returns the average framerate in frames per second using the most recent frame time
     */
    get instantaneousFPS(): number;
    /**
     * Returns true if enough samples have been taken to completely fill the sliding window
     */
    get isSaturated(): boolean;
    /**
     * Enables contributions to the sliding window sample set
     */
    enable(): void;
    /**
     * Disables contributions to the sliding window sample set
     * Samples will not be interpolated over the disabled period
     */
    disable(): void;
    /**
     * Returns true if sampling is enabled
     */
    get isEnabled(): boolean;
    /**
     * Resets performance monitor
     */
    reset(): void;
}

/** @internal */
declare class WebGLHardwareTexture implements IHardwareTextureWrapper {
    private _webGLTexture;
    private _context;
    private _MSAARenderBuffers;
    memoryAllocated?: boolean;
    get underlyingResource(): Nullable<WebGLTexture>;
    constructor(existingTexture: Nullable<WebGLTexture> | undefined, context: WebGLRenderingContext);
    setUsage(): void;
    set(hardwareTexture: WebGLTexture): void;
    reset(): void;
    addMSAARenderBuffer(buffer: WebGLRenderbuffer): void;
    releaseMSAARenderBuffers(): void;
    getMSAARenderBuffer(index?: number): WebGLRenderbuffer | null;
    release(): void;
}

/**
 * @internal
 */
declare function _ConcatenateShader(source: string, defines: Nullable<string>, shaderVersion?: string): string;

/** Interface defining initialization parameters for Engine class */
interface EngineOptions extends AbstractEngineOptions, WebGLContextAttributes {
    /**
     * Defines if webgl2 should be turned off even if supported
     * @see https://doc.babylonjs.com/setup/support/webGL2
     */
    disableWebGL2Support?: boolean;
    /**
     * Defines that engine should compile shaders with high precision floats (if supported). True by default
     */
    useHighPrecisionFloats?: boolean;
    /**
     * Make the canvas XR Compatible for XR sessions
     */
    xrCompatible?: boolean;
    /**
     * Will prevent the system from falling back to software implementation if a hardware device cannot be created
     */
    failIfMajorPerformanceCaveat?: boolean;
    /**
     * If sRGB buffer support is not set during construction, use this value to force a specific state
     * This was originally added to mitigate an issue when processing textures in chrome/edge/firefox.
     * The browser issue has since been fixed. This option remains for backward compatibility.
     * This will not influence NativeEngine and WebGPUEngine which set the behavior to true during construction.
     */
    forceSRGBBufferSupportState?: boolean;
    /**
     * Defines if the gl context should be released.
     * It's false by default for backward compatibility, but you should probably pass true (see https://registry.khronos.org/webgl/extensions/WEBGL_lose_context/)
     */
    loseContextOnDispose?: boolean;
}
/**
 * The base engine class (root of all engines)
 */
declare class ThinEngine extends AbstractEngine {
    private static _TempClearColorUint32;
    private static _TempClearColorInt32;
    /** Use this array to turn off some WebGL2 features on known buggy browsers version */
    static ExceptionList: ({
        key: string;
        capture: string;
        captureConstraint: number;
        targets: string[];
    } | {
        key: string;
        capture: null;
        captureConstraint: null;
        targets: string[];
    })[];
    /** @internal */
    protected _name: string;
    /**
     * Gets or sets the name of the engine
     */
    get name(): string;
    set name(value: string);
    /**
     * Returns the version of the engine
     */
    get version(): number;
    /**
     * Gets or sets the relative url used to load shaders if using the engine in non-minified mode
     */
    static get ShadersRepository(): string;
    static set ShadersRepository(value: string);
    /**
     * Gets or sets a boolean that indicates if textures must be forced to power of 2 size even if not required
     */
    forcePOTTextures: boolean;
    /** Gets or sets a boolean indicating if the engine should validate programs after compilation */
    validateShaderPrograms: boolean;
    /**
     * Gets or sets a boolean indicating that uniform buffers must be disabled even if they are supported
     */
    disableUniformBuffers: boolean;
    /**
     * Gets a boolean indicating that the engine supports uniform buffers
     * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
     */
    get supportsUniformBuffers(): boolean;
    /** @internal */
    _gl: WebGL2RenderingContext;
    /** @internal */
    _webGLVersion: number;
    /** @internal */
    _glSRGBExtensionValues: {
        SRGB: typeof WebGL2RenderingContext.SRGB;
        SRGB8: typeof WebGL2RenderingContext.SRGB8 | EXT_sRGB["SRGB_ALPHA_EXT"];
        SRGB8_ALPHA8: typeof WebGL2RenderingContext.SRGB8_ALPHA8 | EXT_sRGB["SRGB_ALPHA_EXT"];
    };
    /**
     * Gets a boolean indicating that only power of 2 textures are supported
     * Please note that you can still use non power of 2 textures but in this case the engine will forcefully convert them
     */
    get needPOTTextures(): boolean;
    private _glVersion;
    private _glRenderer;
    private _glVendor;
    /** @internal */
    protected _currentProgram: Nullable<WebGLProgram>;
    private _vertexAttribArraysEnabled;
    private _cachedVertexArrayObject;
    private _uintIndicesCurrentlySet;
    protected _currentBoundBuffer: Nullable<DataBuffer>[];
    /** @internal */
    _currentFramebuffer: Nullable<WebGLFramebuffer>;
    /** @internal */
    _dummyFramebuffer: Nullable<WebGLFramebuffer>;
    private _currentBufferPointers;
    private _currentInstanceLocations;
    private _currentInstanceBuffers;
    private _textureUnits;
    /** @internal */
    _workingCanvas: Nullable<ICanvas>;
    /** @internal */
    _workingContext: Nullable<ICanvasRenderingContext>;
    private _vaoRecordInProgress;
    private _mustWipeVertexAttributes;
    private _nextFreeTextureSlots;
    private _maxSimultaneousTextures;
    private _maxMSAASamplesOverride;
    protected get _supportsHardwareTextureRescaling(): boolean;
    protected _framebufferDimensionsObject: Nullable<{
        framebufferWidth: number;
        framebufferHeight: number;
    }>;
    /**
     * sets the object from which width and height will be taken from when getting render width and height
     * Will fallback to the gl object
     * @param dimensions the framebuffer width and height that will be used.
     */
    set framebufferDimensionsObject(dimensions: Nullable<{
        framebufferWidth: number;
        framebufferHeight: number;
    }>);
    /**
     * Creates a new snapshot at the next frame using the current snapshotRenderingMode
     */
    snapshotRenderingReset(): void;
    /**
     * Creates a new engine
     * @param canvasOrContext defines the canvas or WebGL context to use for rendering. If you provide a WebGL context, Babylon.js will not hook events on the canvas (like pointers, keyboards, etc...) so no event observables will be available. This is mostly used when Babylon.js is used as a plugin on a system which already used the WebGL context
     * @param antialias defines whether anti-aliasing should be enabled (default value is "undefined", meaning that the browser may or may not enable it)
     * @param options defines further options to be sent to the getContext() function
     * @param adaptToDeviceRatio defines whether to adapt to the device's viewport characteristics (default: false)
     */
    constructor(canvasOrContext: Nullable<HTMLCanvasElement | OffscreenCanvas | WebGLRenderingContext | WebGL2RenderingContext>, antialias?: boolean, options?: EngineOptions, adaptToDeviceRatio?: boolean);
    protected _clearEmptyResources(): void;
    /**
     * @internal
     */
    _getShaderProcessingContext(shaderLanguage: ShaderLanguage): Nullable<_IShaderProcessingContext>;
    /**
     * Gets a boolean indicating if all created effects are ready
     * @returns true if all effects are ready
     */
    areAllEffectsReady(): boolean;
    protected _initGLContext(): void;
    protected _initFeatures(): void;
    /**
     * Gets version of the current webGL context
     * Keep it for back compat - use version instead
     */
    get webGLVersion(): number;
    /**
     * Gets a string identifying the name of the class
     * @returns "Engine" string
     */
    getClassName(): string;
    /** @internal */
    _prepareWorkingCanvas(): void;
    /**
     * Gets an object containing information about the current engine context
     * @returns an object containing the vendor, the renderer and the version of the current engine context
     */
    getInfo(): {
        vendor: string;
        renderer: string;
        version: string;
    };
    /**
     * Gets an object containing information about the current webGL context
     * @returns an object containing the vendor, the renderer and the version of the current webGL context
     */
    getGlInfo(): {
        vendor: string;
        renderer: string;
        version: string;
    };
    /**Gets driver info if available */
    extractDriverInfo(): string;
    /**
     * Gets the current render width
     * @param useScreen defines if screen size must be used (or the current render target if any)
     * @returns a number defining the current render width
     */
    getRenderWidth(useScreen?: boolean): number;
    /**
     * Gets the current render height
     * @param useScreen defines if screen size must be used (or the current render target if any)
     * @returns a number defining the current render height
     */
    getRenderHeight(useScreen?: boolean): number;
    /**
     * Clear the current render buffer or the current render target (if any is set up)
     * @param color defines the color to use
     * @param backBuffer defines if the back buffer must be cleared
     * @param depth defines if the depth buffer must be cleared
     * @param stencil defines if the stencil buffer must be cleared
     * @param stencilClearValue defines the value to use to clear the stencil buffer (default is 0)
     */
    clear(color: Nullable<IColor4Like>, backBuffer: boolean, depth: boolean, stencil?: boolean, stencilClearValue?: number): void;
    /**
     * @internal
     */
    _viewport(x: number, y: number, width: number, height: number): void;
    /**
     * End the current frame
     */
    endFrame(): void;
    /**
     * Gets the performance monitor attached to this engine
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#engineinstrumentation
     */
    get performanceMonitor(): PerformanceMonitor;
    /**
     * Binds the frame buffer to the specified texture.
     * @param rtWrapper The render target wrapper to render to
     * @param faceIndex The face of the texture to render to in case of cube texture and if the render target wrapper is not a multi render target
     * @param requiredWidth The width of the target to render to
     * @param requiredHeight The height of the target to render to
     * @param forceFullscreenViewport Forces the viewport to be the entire texture/screen if true
     * @param lodLevel Defines the lod level to bind to the frame buffer
     * @param layer Defines the 2d array index to bind to the frame buffer if the render target wrapper is not a multi render target
     */
    bindFramebuffer(rtWrapper: RenderTargetWrapper, faceIndex?: number, requiredWidth?: number, requiredHeight?: number, forceFullscreenViewport?: boolean, lodLevel?: number, layer?: number): void;
    setStateCullFaceType(cullBackFaces?: boolean, force?: boolean): void;
    /**
     * Set various states to the webGL context
     * @param culling defines culling state: true to enable culling, false to disable it
     * @param zOffset defines the value to apply to zOffset (0 by default)
     * @param force defines if states must be applied even if cache is up to date
     * @param reverseSide defines if culling must be reversed (CCW if false, CW if true)
     * @param cullBackFaces true to cull back faces, false to cull front faces (if culling is enabled)
     * @param stencil stencil states to set
     * @param zOffsetUnits defines the value to apply to zOffsetUnits (0 by default)
     */
    setState(culling: boolean, zOffset?: number, force?: boolean, reverseSide?: boolean, cullBackFaces?: boolean, stencil?: IStencilState, zOffsetUnits?: number): void;
    private _resolveAndGenerateMipMapsFramebuffer;
    /**
     * @internal
     */
    _bindUnboundFramebuffer(framebuffer: Nullable<WebGLFramebuffer>): void;
    /** @internal */
    _currentFrameBufferIsDefaultFrameBuffer(): boolean;
    /**
     * Generates the mipmaps for a texture
     * @param texture texture to generate the mipmaps for
     */
    generateMipmaps(texture: InternalTexture): void;
    /**
     * Unbind the current render target texture from the webGL context
     * @param texture defines the render target wrapper to unbind
     * @param disableGenerateMipMaps defines a boolean indicating that mipmaps must not be generated
     * @param onBeforeUnbind defines a function which will be called before the effective unbind
     */
    unBindFramebuffer(texture: RenderTargetWrapper, disableGenerateMipMaps?: boolean, onBeforeUnbind?: () => void): void;
    /**
     * Generates mipmaps for the texture of the (single) render target
     * @param texture The render target containing the texture to generate the mipmaps for
     */
    generateMipMapsFramebuffer(texture: RenderTargetWrapper): void;
    /**
     * Resolves the MSAA texture of the (single) render target into its non-MSAA version.
     * Note that if "texture" is not a MSAA render target, no resolve is performed.
     * @param texture  The render target texture containing the MSAA textures to resolve
     */
    resolveFramebuffer(texture: RenderTargetWrapper): void;
    /**
     * Force a webGL flush (ie. a flush of all waiting webGL commands)
     */
    flushFramebuffer(): void;
    /**
     * Unbind the current render target and bind the default framebuffer
     */
    restoreDefaultFramebuffer(): void;
    /** @internal */
    protected _resetVertexBufferBinding(): void;
    /**
     * Creates a vertex buffer
     * @param data the data or size for the vertex buffer
     * @param _updatable whether the buffer should be created as updatable
     * @param _label defines the label of the buffer (for debug purpose)
     * @returns the new WebGL static buffer
     */
    createVertexBuffer(data: DataArray | number, _updatable?: boolean, _label?: string): DataBuffer;
    private _createVertexBuffer;
    /**
     * Creates a dynamic vertex buffer
     * @param data the data for the dynamic vertex buffer
     * @param _label defines the label of the buffer (for debug purpose)
     * @returns the new WebGL dynamic buffer
     */
    createDynamicVertexBuffer(data: DataArray | number, _label?: string): DataBuffer;
    protected _resetIndexBufferBinding(): void;
    /**
     * Creates a new index buffer
     * @param indices defines the content of the index buffer
     * @param updatable defines if the index buffer must be updatable
     * @param _label defines the label of the buffer (for debug purpose)
     * @returns a new webGL buffer
     */
    createIndexBuffer(indices: IndicesArray, updatable?: boolean, _label?: string): DataBuffer;
    protected _normalizeIndexData(indices: IndicesArray): Uint16Array | Uint32Array;
    /**
     * Bind a webGL buffer to the webGL context
     * @param buffer defines the buffer to bind
     */
    bindArrayBuffer(buffer: Nullable<DataBuffer>): void;
    protected bindIndexBuffer(buffer: Nullable<DataBuffer>): void;
    private _bindBuffer;
    /**
     * update the bound buffer with the given data
     * @param data defines the data to update
     */
    updateArrayBuffer(data: Float32Array): void;
    private _vertexAttribPointer;
    /**
     * @internal
     */
    _bindIndexBufferWithCache(indexBuffer: Nullable<DataBuffer>): void;
    private _bindVertexBuffersAttributes;
    /**
     * Records a vertex array object
     * @see https://doc.babylonjs.com/setup/support/webGL2#vertex-array-objects
     * @param vertexBuffers defines the list of vertex buffers to store
     * @param indexBuffer defines the index buffer to store
     * @param effect defines the effect to store
     * @param overrideVertexBuffers defines optional list of avertex buffers that overrides the entries in vertexBuffers
     * @returns the new vertex array object
     */
    recordVertexArrayObject(vertexBuffers: {
        [key: string]: VertexBuffer;
    }, indexBuffer: Nullable<DataBuffer>, effect: Effect, overrideVertexBuffers?: {
        [kind: string]: Nullable<VertexBuffer>;
    }): WebGLVertexArrayObject;
    /**
     * Bind a specific vertex array object
     * @see https://doc.babylonjs.com/setup/support/webGL2#vertex-array-objects
     * @param vertexArrayObject defines the vertex array object to bind
     * @param indexBuffer defines the index buffer to bind
     */
    bindVertexArrayObject(vertexArrayObject: WebGLVertexArrayObject, indexBuffer: Nullable<DataBuffer>): void;
    /**
     * Bind webGl buffers directly to the webGL context
     * @param vertexBuffer defines the vertex buffer to bind
     * @param indexBuffer defines the index buffer to bind
     * @param vertexDeclaration defines the vertex declaration to use with the vertex buffer
     * @param vertexStrideSize defines the vertex stride of the vertex buffer
     * @param effect defines the effect associated with the vertex buffer
     */
    bindBuffersDirectly(vertexBuffer: DataBuffer, indexBuffer: DataBuffer, vertexDeclaration: number[], vertexStrideSize: number, effect: Effect): void;
    private _unbindVertexArrayObject;
    /**
     * Bind a list of vertex buffers to the webGL context
     * @param vertexBuffers defines the list of vertex buffers to bind
     * @param indexBuffer defines the index buffer to bind
     * @param effect defines the effect associated with the vertex buffers
     * @param overrideVertexBuffers defines optional list of avertex buffers that overrides the entries in vertexBuffers
     */
    bindBuffers(vertexBuffers: {
        [key: string]: Nullable<VertexBuffer>;
    }, indexBuffer: Nullable<DataBuffer>, effect: Effect, overrideVertexBuffers?: {
        [kind: string]: Nullable<VertexBuffer>;
    }): void;
    /**
     * Unbind all instance attributes
     */
    unbindInstanceAttributes(): void;
    /**
     * Release and free the memory of a vertex array object
     * @param vao defines the vertex array object to delete
     */
    releaseVertexArrayObject(vao: WebGLVertexArrayObject): void;
    /**
     * @internal
     */
    _releaseBuffer(buffer: DataBuffer): boolean;
    protected _deleteBuffer(buffer: DataBuffer): void;
    /**
     * Update the content of a webGL buffer used with instantiation and bind it to the webGL context
     * @param instancesBuffer defines the webGL buffer to update and bind
     * @param data defines the data to store in the buffer
     * @param offsetLocations defines the offsets or attributes information used to determine where data must be stored in the buffer
     */
    updateAndBindInstancesBuffer(instancesBuffer: DataBuffer, data: Float32Array, offsetLocations: number[] | InstancingAttributeInfo[]): void;
    /**
     * Bind the content of a webGL buffer used with instantiation
     * @param instancesBuffer defines the webGL buffer to bind
     * @param attributesInfo defines the offsets or attributes information used to determine where data must be stored in the buffer
     * @param computeStride defines Whether to compute the strides from the info or use the default 0
     */
    bindInstancesBuffer(instancesBuffer: DataBuffer, attributesInfo: InstancingAttributeInfo[], computeStride?: boolean): void;
    /**
     * Disable the instance attribute corresponding to the name in parameter
     * @param name defines the name of the attribute to disable
     */
    disableInstanceAttributeByName(name: string): void;
    /**
     * Disable the instance attribute corresponding to the location in parameter
     * @param attributeLocation defines the attribute location of the attribute to disable
     */
    disableInstanceAttribute(attributeLocation: number): void;
    /**
     * Disable the attribute corresponding to the location in parameter
     * @param attributeLocation defines the attribute location of the attribute to disable
     */
    disableAttributeByIndex(attributeLocation: number): void;
    /**
     * Send a draw order
     * @param useTriangles defines if triangles must be used to draw (else wireframe will be used)
     * @param indexStart defines the starting index
     * @param indexCount defines the number of index to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    draw(useTriangles: boolean, indexStart: number, indexCount: number, instancesCount?: number): void;
    /**
     * Draw a list of points
     * @param verticesStart defines the index of first vertex to draw
     * @param verticesCount defines the count of vertices to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    drawPointClouds(verticesStart: number, verticesCount: number, instancesCount?: number): void;
    /**
     * Draw a list of unindexed primitives
     * @param useTriangles defines if triangles must be used to draw (else wireframe will be used)
     * @param verticesStart defines the index of first vertex to draw
     * @param verticesCount defines the count of vertices to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    drawUnIndexed(useTriangles: boolean, verticesStart: number, verticesCount: number, instancesCount?: number): void;
    /**
     * Draw a list of indexed primitives
     * @param fillMode defines the primitive to use
     * @param indexStart defines the starting index
     * @param indexCount defines the number of index to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    drawElementsType(fillMode: number, indexStart: number, indexCount: number, instancesCount?: number): void;
    /**
     * Draw a list of unindexed primitives
     * @param fillMode defines the primitive to use
     * @param verticesStart defines the index of first vertex to draw
     * @param verticesCount defines the count of vertices to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    drawArraysType(fillMode: number, verticesStart: number, verticesCount: number, instancesCount?: number): void;
    private _drawMode;
    /**
     * @internal
     */
    _releaseEffect(effect: Effect): void;
    /**
     * @internal
     */
    _deletePipelineContext(pipelineContext: IPipelineContext): void;
    /**
     * @internal
     */
    _getGlobalDefines(defines?: {
        [key: string]: string;
    }): string | undefined;
    /**
     * Create a new effect (used to store vertex/fragment shaders)
     * @param baseName defines the base name of the effect (The name of file without .fragment.fx or .vertex.fx)
     * @param attributesNamesOrOptions defines either a list of attribute names or an IEffectCreationOptions object
     * @param uniformsNamesOrEngine defines either a list of uniform names or the engine to use
     * @param samplers defines an array of string used to represent textures
     * @param defines defines the string containing the defines to use to compile the shaders
     * @param fallbacks defines the list of potential fallbacks to use if shader compilation fails
     * @param onCompiled defines a function to call when the effect creation is successful
     * @param onError defines a function to call when the effect creation has failed
     * @param indexParameters defines an object containing the index values to use to compile shaders (like the maximum number of simultaneous lights)
     * @param shaderLanguage the language the shader is written in (default: GLSL)
     * @param extraInitializationsAsync additional async code to run before preparing the effect
     * @returns the new Effect
     */
    createEffect(baseName: string | (IShaderPath & {
        vertexToken?: string;
        fragmentToken?: string;
    }), attributesNamesOrOptions: string[] | IEffectCreationOptions, uniformsNamesOrEngine: string[] | ThinEngine, samplers?: string[], defines?: string, fallbacks?: IEffectFallbacks, onCompiled?: Nullable<(effect: Effect) => void>, onError?: Nullable<(effect: Effect, errors: string) => void>, indexParameters?: any, shaderLanguage?: ShaderLanguage, extraInitializationsAsync?: () => Promise<void>): Effect;
    protected static _ConcatenateShader: typeof _ConcatenateShader;
    /**
     * @internal
     */
    _getShaderSource(shader: WebGLShader): Nullable<string>;
    /**
     * Directly creates a webGL program
     * @param pipelineContext  defines the pipeline context to attach to
     * @param vertexCode defines the vertex shader code to use
     * @param fragmentCode defines the fragment shader code to use
     * @param context defines the webGL context to use (if not set, the current one will be used)
     * @param transformFeedbackVaryings defines the list of transform feedback varyings to use
     * @returns the new webGL program
     */
    createRawShaderProgram(pipelineContext: IPipelineContext, vertexCode: string, fragmentCode: string, context?: WebGLRenderingContext, transformFeedbackVaryings?: Nullable<string[]>): WebGLProgram;
    /**
     * Creates a webGL program
     * @param pipelineContext  defines the pipeline context to attach to
     * @param vertexCode  defines the vertex shader code to use
     * @param fragmentCode defines the fragment shader code to use
     * @param defines defines the string containing the defines to use to compile the shaders
     * @param context defines the webGL context to use (if not set, the current one will be used)
     * @param transformFeedbackVaryings defines the list of transform feedback varyings to use
     * @returns the new webGL program
     */
    createShaderProgram(pipelineContext: IPipelineContext, vertexCode: string, fragmentCode: string, defines: Nullable<string>, context?: WebGLRenderingContext, transformFeedbackVaryings?: Nullable<string[]>): WebGLProgram;
    /**
     * Inline functions in shader code that are marked to be inlined
     * @param code code to inline
     * @returns inlined code
     */
    inlineShaderCode(code: string): string;
    /**
     * Creates a new pipeline context
     * @param shaderProcessingContext defines the shader processing context used during the processing if available
     * @returns the new pipeline
     */
    createPipelineContext(shaderProcessingContext: Nullable<_IShaderProcessingContext>): IPipelineContext;
    /**
     * Creates a new material context
     * @returns the new context
     */
    createMaterialContext(): IMaterialContext | undefined;
    /**
     * Creates a new draw context
     * @returns the new context
     */
    createDrawContext(): IDrawContext | undefined;
    protected _finalizePipelineContext(pipelineContext: WebGLPipelineContext): void;
    /**
     * @internal
     */
    _preparePipelineContextAsync(pipelineContext: IPipelineContext, vertexSourceCode: string, fragmentSourceCode: string, createAsRaw: boolean, rawVertexSourceCode: string, rawFragmentSourceCode: string, rebuildRebind: any, defines: Nullable<string>, transformFeedbackVaryings: Nullable<string[]>, key: string, onReady: () => void): void;
    protected _createShaderProgram(pipelineContext: WebGLPipelineContext, vertexShader: WebGLShader, fragmentShader: WebGLShader, context: WebGLRenderingContext, transformFeedbackVaryings?: Nullable<string[]>): WebGLProgram;
    /**
     * @internal
     */
    _isRenderingStateCompiled(pipelineContext: IPipelineContext): boolean;
    /**
     * @internal
     */
    _executeWhenRenderingStateIsCompiled(pipelineContext: IPipelineContext, action: () => void): void;
    /**
     * Gets the list of webGL uniform locations associated with a specific program based on a list of uniform names
     * @param pipelineContext defines the pipeline context to use
     * @param uniformsNames defines the list of uniform names
     * @returns an array of webGL uniform locations
     */
    getUniforms(pipelineContext: IPipelineContext, uniformsNames: string[]): Nullable<WebGLUniformLocation>[];
    /**
     * Gets the list of active attributes for a given webGL program
     * @param pipelineContext defines the pipeline context to use
     * @param attributesNames defines the list of attribute names to get
     * @returns an array of indices indicating the offset of each attribute
     */
    getAttributes(pipelineContext: IPipelineContext, attributesNames: string[]): number[];
    /**
     * Activates an effect, making it the current one (ie. the one used for rendering)
     * @param effect defines the effect to activate
     */
    enableEffect(effect: Nullable<Effect | DrawWrapper>): void;
    /**
     * Set the value of an uniform to a number (int)
     * @param uniform defines the webGL uniform location where to store the value
     * @param value defines the int number to store
     * @returns true if the value was set
     */
    setInt(uniform: Nullable<WebGLUniformLocation>, value: number): boolean;
    /**
     * Set the value of an uniform to a int2
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @returns true if the value was set
     */
    setInt2(uniform: Nullable<WebGLUniformLocation>, x: number, y: number): boolean;
    /**
     * Set the value of an uniform to a int3
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @param z defines the 3rd component of the value
     * @returns true if the value was set
     */
    setInt3(uniform: Nullable<WebGLUniformLocation>, x: number, y: number, z: number): boolean;
    /**
     * Set the value of an uniform to a int4
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @param z defines the 3rd component of the value
     * @param w defines the 4th component of the value
     * @returns true if the value was set
     */
    setInt4(uniform: Nullable<WebGLUniformLocation>, x: number, y: number, z: number, w: number): boolean;
    /**
     * Set the value of an uniform to an array of int32
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of int32 to store
     * @returns true if the value was set
     */
    setIntArray(uniform: Nullable<WebGLUniformLocation>, array: Int32Array): boolean;
    /**
     * Set the value of an uniform to an array of int32 (stored as vec2)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of int32 to store
     * @returns true if the value was set
     */
    setIntArray2(uniform: Nullable<WebGLUniformLocation>, array: Int32Array): boolean;
    /**
     * Set the value of an uniform to an array of int32 (stored as vec3)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of int32 to store
     * @returns true if the value was set
     */
    setIntArray3(uniform: Nullable<WebGLUniformLocation>, array: Int32Array): boolean;
    /**
     * Set the value of an uniform to an array of int32 (stored as vec4)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of int32 to store
     * @returns true if the value was set
     */
    setIntArray4(uniform: Nullable<WebGLUniformLocation>, array: Int32Array): boolean;
    /**
     * Set the value of an uniform to a number (unsigned int)
     * @param uniform defines the webGL uniform location where to store the value
     * @param value defines the unsigned int number to store
     * @returns true if the value was set
     */
    setUInt(uniform: Nullable<WebGLUniformLocation>, value: number): boolean;
    /**
     * Set the value of an uniform to a unsigned int2
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @returns true if the value was set
     */
    setUInt2(uniform: Nullable<WebGLUniformLocation>, x: number, y: number): boolean;
    /**
     * Set the value of an uniform to a unsigned int3
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @param z defines the 3rd component of the value
     * @returns true if the value was set
     */
    setUInt3(uniform: Nullable<WebGLUniformLocation>, x: number, y: number, z: number): boolean;
    /**
     * Set the value of an uniform to a unsigned int4
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @param z defines the 3rd component of the value
     * @param w defines the 4th component of the value
     * @returns true if the value was set
     */
    setUInt4(uniform: Nullable<WebGLUniformLocation>, x: number, y: number, z: number, w: number): boolean;
    /**
     * Set the value of an uniform to an array of unsigned int32
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of unsigned int32 to store
     * @returns true if the value was set
     */
    setUIntArray(uniform: Nullable<WebGLUniformLocation>, array: Uint32Array): boolean;
    /**
     * Set the value of an uniform to an array of unsigned int32 (stored as vec2)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of unsigned int32 to store
     * @returns true if the value was set
     */
    setUIntArray2(uniform: Nullable<WebGLUniformLocation>, array: Uint32Array): boolean;
    /**
     * Set the value of an uniform to an array of unsigned int32 (stored as vec3)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of unsigned int32 to store
     * @returns true if the value was set
     */
    setUIntArray3(uniform: Nullable<WebGLUniformLocation>, array: Uint32Array): boolean;
    /**
     * Set the value of an uniform to an array of unsigned int32 (stored as vec4)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of unsigned int32 to store
     * @returns true if the value was set
     */
    setUIntArray4(uniform: Nullable<WebGLUniformLocation>, array: Uint32Array): boolean;
    /**
     * Set the value of an uniform to an array of number
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of number to store
     * @returns true if the value was set
     */
    setArray(uniform: Nullable<WebGLUniformLocation>, array: FloatArray): boolean;
    /**
     * Set the value of an uniform to an array of number (stored as vec2)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of number to store
     * @returns true if the value was set
     */
    setArray2(uniform: Nullable<WebGLUniformLocation>, array: FloatArray): boolean;
    /**
     * Set the value of an uniform to an array of number (stored as vec3)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of number to store
     * @returns true if the value was set
     */
    setArray3(uniform: Nullable<WebGLUniformLocation>, array: FloatArray): boolean;
    /**
     * Set the value of an uniform to an array of number (stored as vec4)
     * @param uniform defines the webGL uniform location where to store the value
     * @param array defines the array of number to store
     * @returns true if the value was set
     */
    setArray4(uniform: Nullable<WebGLUniformLocation>, array: FloatArray): boolean;
    /**
     * Set the value of an uniform to an array of float32 (stored as matrices)
     * @param uniform defines the webGL uniform location where to store the value
     * @param matrices defines the array of float32 to store
     * @returns true if the value was set
     */
    setMatrices(uniform: Nullable<WebGLUniformLocation>, matrices: DeepImmutable<FloatArray>): boolean;
    /**
     * Set the value of an uniform to a matrix (3x3)
     * @param uniform defines the webGL uniform location where to store the value
     * @param matrix defines the Float32Array representing the 3x3 matrix to store
     * @returns true if the value was set
     */
    setMatrix3x3(uniform: Nullable<WebGLUniformLocation>, matrix: Float32Array): boolean;
    /**
     * Set the value of an uniform to a matrix (2x2)
     * @param uniform defines the webGL uniform location where to store the value
     * @param matrix defines the Float32Array representing the 2x2 matrix to store
     * @returns true if the value was set
     */
    setMatrix2x2(uniform: Nullable<WebGLUniformLocation>, matrix: Float32Array): boolean;
    /**
     * Set the value of an uniform to a number (float)
     * @param uniform defines the webGL uniform location where to store the value
     * @param value defines the float number to store
     * @returns true if the value was transferred
     */
    setFloat(uniform: Nullable<WebGLUniformLocation>, value: number): boolean;
    /**
     * Set the value of an uniform to a vec2
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @returns true if the value was set
     */
    setFloat2(uniform: Nullable<WebGLUniformLocation>, x: number, y: number): boolean;
    /**
     * Set the value of an uniform to a vec3
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @param z defines the 3rd component of the value
     * @returns true if the value was set
     */
    setFloat3(uniform: Nullable<WebGLUniformLocation>, x: number, y: number, z: number): boolean;
    /**
     * Set the value of an uniform to a vec4
     * @param uniform defines the webGL uniform location where to store the value
     * @param x defines the 1st component of the value
     * @param y defines the 2nd component of the value
     * @param z defines the 3rd component of the value
     * @param w defines the 4th component of the value
     * @returns true if the value was set
     */
    setFloat4(uniform: Nullable<WebGLUniformLocation>, x: number, y: number, z: number, w: number): boolean;
    /**
     * Apply all cached states (depth, culling, stencil and alpha)
     */
    applyStates(): void;
    /**
     * Force the entire cache to be cleared
     * You should not have to use this function unless your engine needs to share the webGL context with another engine
     * @param bruteForce defines a boolean to force clearing ALL caches (including stencil, detoh and alpha states)
     */
    wipeCaches(bruteForce?: boolean): void;
    /**
     * @internal
     */
    _getSamplingParameters(samplingMode: number, generateMipMaps: boolean): {
        min: number;
        mag: number;
        hasMipMaps: boolean;
    };
    /** @internal */
    protected _createTexture(): WebGLTexture;
    /** @internal */
    _createHardwareTexture(): IHardwareTextureWrapper;
    /**
     * Creates an internal texture without binding it to a framebuffer
     * @internal
     * @param size defines the size of the texture
     * @param options defines the options used to create the texture
     * @param delayGPUTextureCreation true to delay the texture creation the first time it is really needed. false to create it right away
     * @param source source type of the texture
     * @returns a new internal texture
     */
    _createInternalTexture(size: TextureSize, options: boolean | InternalTextureCreationOptions, delayGPUTextureCreation?: boolean, source?: InternalTextureSource): InternalTexture;
    /**
     * @internal
     */
    _getUseSRGBBuffer(useSRGBBuffer: boolean, noMipmap: boolean): boolean;
    /**
     * Usually called from Texture.ts.
     * Passed information to create a WebGLTexture
     * @param url defines a value which contains one of the following:
     * * A conventional http URL, e.g. 'http://...' or 'file://...'
     * * A base64 string of in-line texture data, e.g. 'data:image/jpg;base64,/...'
     * * An indicator that data being passed using the buffer parameter, e.g. 'data:mytexture.jpg'
     * @param noMipmap defines a boolean indicating that no mipmaps shall be generated.  Ignored for compressed textures.  They must be in the file
     * @param invertY when true, image is flipped when loaded.  You probably want true. Certain compressed textures may invert this if their default is inverted (eg. ktx)
     * @param scene needed for loading to the correct scene
     * @param samplingMode mode with should be used sample / access the texture (Default: Texture.TRILINEAR_SAMPLINGMODE)
     * @param onLoad optional callback to be called upon successful completion
     * @param onError optional callback to be called upon failure
     * @param buffer a source of a file previously fetched as either a base64 string, an ArrayBuffer (compressed or image format), HTMLImageElement (image format), or a Blob
     * @param fallback an internal argument in case the function must be called again, due to etc1 not having alpha capabilities
     * @param format internal format.  Default: RGB when extension is '.jpg' else RGBA.  Ignored for compressed textures
     * @param forcedExtension defines the extension to use to pick the right loader
     * @param mimeType defines an optional mime type
     * @param loaderOptions options to be passed to the loader
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
     * @returns a InternalTexture for assignment back into BABYLON.Texture
     */
    createTexture(url: Nullable<string>, noMipmap: boolean, invertY: boolean, scene: Nullable<ISceneLike>, samplingMode?: number, onLoad?: Nullable<(texture: InternalTexture) => void>, onError?: Nullable<(message: string, exception: any) => void>, buffer?: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>, fallback?: Nullable<InternalTexture>, format?: Nullable<number>, forcedExtension?: Nullable<string>, mimeType?: string, loaderOptions?: any, creationFlags?: number, useSRGBBuffer?: boolean): InternalTexture;
    /**
     * Calls to the GL texImage2D and texImage3D functions require three arguments describing the pixel format of the texture.
     * createTexture derives these from the babylonFormat and useSRGBBuffer arguments and also the file extension of the URL it's working with.
     * This function encapsulates that derivation for easy unit testing.
     * @param babylonFormat Babylon's format enum, as specified in ITextureCreationOptions.
     * @param fileExtension The file extension including the dot, e.g. .jpg.
     * @param useSRGBBuffer Use SRGB not linear.
     * @returns The options to pass to texImage2D or texImage3D calls.
     * @internal
     */
    _getTexImageParametersForCreateTexture(babylonFormat: number, useSRGBBuffer: boolean): TexImageParameters;
    /**
     * @internal
     */
    _rescaleTexture(source: InternalTexture, destination: InternalTexture, scene: Nullable<any>, internalFormat: number, onComplete: () => void): void;
    private _unpackFlipYCached;
    /**
     * In case you are sharing the context with other applications, it might
     * be interested to not cache the unpack flip y state to ensure a consistent
     * value would be set.
     */
    enableUnpackFlipYCached: boolean;
    /**
     * @internal
     */
    _unpackFlipY(value: boolean): void;
    /** @internal */
    _getUnpackAlignement(): number;
    /** @internal */
    _getTextureTarget(texture: InternalTexture): number;
    /**
     * Update the sampling mode of a given texture
     * @param samplingMode defines the required sampling mode
     * @param texture defines the texture to update
     * @param generateMipMaps defines whether to generate mipmaps for the texture
     */
    updateTextureSamplingMode(samplingMode: number, texture: InternalTexture, generateMipMaps?: boolean): void;
    /**
     * Update the dimensions of a texture
     * @param texture texture to update
     * @param width new width of the texture
     * @param height new height of the texture
     * @param depth new depth of the texture
     */
    updateTextureDimensions(texture: InternalTexture, width: number, height: number, depth?: number): void;
    /**
     * Update the sampling mode of a given texture
     * @param texture defines the texture to update
     * @param wrapU defines the texture wrap mode of the u coordinates
     * @param wrapV defines the texture wrap mode of the v coordinates
     * @param wrapR defines the texture wrap mode of the r coordinates
     */
    updateTextureWrappingMode(texture: InternalTexture, wrapU: Nullable<number>, wrapV?: Nullable<number>, wrapR?: Nullable<number>): void;
    /**
     * @internal
     */
    _uploadCompressedDataToTextureDirectly(texture: InternalTexture, internalFormat: number, width: number, height: number, data: ArrayBufferView, faceIndex?: number, lod?: number): void;
    /**
     * @internal
     */
    _uploadDataToTextureDirectly(texture: InternalTexture, imageData: ArrayBufferView, faceIndex?: number, lod?: number, babylonInternalFormat?: number, useTextureWidthAndHeight?: boolean): void;
    /**
     * Update a portion of an internal texture
     * @param texture defines the texture to update
     * @param imageData defines the data to store into the texture
     * @param xOffset defines the x coordinates of the update rectangle
     * @param yOffset defines the y coordinates of the update rectangle
     * @param width defines the width of the update rectangle
     * @param height defines the height of the update rectangle
     * @param faceIndex defines the face index if texture is a cube (0 by default)
     * @param lod defines the lod level to update (0 by default)
     * @param generateMipMaps defines whether to generate mipmaps or not
     */
    updateTextureData(texture: InternalTexture, imageData: ArrayBufferView, xOffset: number, yOffset: number, width: number, height: number, faceIndex?: number, lod?: number, generateMipMaps?: boolean): void;
    /**
     * @internal
     */
    _uploadArrayBufferViewToTexture(texture: InternalTexture, imageData: ArrayBufferView, faceIndex?: number, lod?: number): void;
    protected _prepareWebGLTextureContinuation(texture: InternalTexture, scene: Nullable<ISceneLike>, noMipmap: boolean, isCompressed: boolean, samplingMode: number): void;
    private _prepareWebGLTexture;
    _getInternalFormatFromDepthTextureFormat(textureFormat: number, hasDepth: boolean, hasStencil: boolean): number;
    _getWebGLTextureTypeFromDepthTextureFormat(textureFormat: number): GLenum;
    /**
     * @internal
     */
    _setupFramebufferDepthAttachments(generateStencilBuffer: boolean, generateDepthBuffer: boolean, width: number, height: number, samples?: number, depthTextureFormat?: number, dontBindRenderBufferToFrameBuffer?: boolean): Nullable<WebGLRenderbuffer>;
    /**
     * @internal
     */
    _createRenderBuffer(width: number, height: number, samples: number, internalFormat: number, msInternalFormat: number, attachment: number, unbindBuffer?: boolean): Nullable<WebGLRenderbuffer>;
    _updateRenderBuffer(renderBuffer: Nullable<WebGLRenderbuffer>, width: number, height: number, samples: number, internalFormat: number, msInternalFormat: number, attachment: number, unbindBuffer?: boolean): Nullable<WebGLRenderbuffer>;
    /**
     * @internal
     */
    _releaseTexture(texture: InternalTexture): void;
    protected _deleteTexture(texture: Nullable<WebGLHardwareTexture>): void;
    protected _setProgram(program: Nullable<WebGLProgram>): void;
    /**
     * @internal
     */
    _boundUniforms: {
        [key: number]: WebGLUniformLocation;
    };
    /**
     * Binds an effect to the webGL context
     * @param effect defines the effect to bind
     */
    bindSamplers(effect: Effect): void;
    private _activateCurrentTexture;
    /**
     * @internal
     */
    _bindTextureDirectly(target: number, texture: Nullable<InternalTexture>, forTextureDataUpdate?: boolean, force?: boolean): boolean;
    /**
     * @internal
     */
    _bindTexture(channel: number, texture: Nullable<InternalTexture>, name: string): void;
    /**
     * Unbind all textures from the webGL context
     */
    unbindAllTextures(): void;
    /**
     * Sets a texture to the according uniform.
     * @param channel The texture channel
     * @param uniform The uniform to set
     * @param texture The texture to apply
     * @param name The name of the uniform in the effect
     */
    setTexture(channel: number, uniform: Nullable<WebGLUniformLocation>, texture: Nullable<ThinTexture>, name: string): void;
    private _bindSamplerUniformToChannel;
    private _getTextureWrapMode;
    _setTexture(channel: number, texture: Nullable<ThinTexture>, isPartOfTextureArray?: boolean, depthStencilTexture?: boolean, name?: string): boolean;
    /**
     * Sets an array of texture to the webGL context
     * @param channel defines the channel where the texture array must be set
     * @param uniform defines the associated uniform location
     * @param textures defines the array of textures to bind
     * @param name name of the channel
     */
    setTextureArray(channel: number, uniform: Nullable<WebGLUniformLocation>, textures: ThinTexture[], name: string): void;
    /**
     * @internal
     */
    _setAnisotropicLevel(target: number, internalTexture: InternalTexture, anisotropicFilteringLevel: number): void;
    private _setTextureParameterFloat;
    private _setTextureParameterInteger;
    /**
     * Unbind all vertex attributes from the webGL context
     */
    unbindAllAttributes(): void;
    /**
     * Force the engine to release all cached effects. This means that next effect compilation will have to be done completely even if a similar effect was already compiled
     */
    releaseEffects(): void;
    /**
     * Dispose and release all associated resources
     */
    dispose(): void;
    /**
     * Attach a new callback raised when context lost event is fired
     * @param callback defines the callback to call
     */
    attachContextLostEvent(callback: (event: WebGLContextEvent) => void): void;
    /**
     * Attach a new callback raised when context restored event is fired
     * @param callback defines the callback to call
     */
    attachContextRestoredEvent(callback: (event: WebGLContextEvent) => void): void;
    /**
     * Get the current error code of the webGL context
     * @returns the error code
     * @see https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/getError
     */
    getError(): number;
    private _canRenderToFloatFramebuffer;
    private _canRenderToHalfFloatFramebuffer;
    private _canRenderToFramebuffer;
    /**
     * @internal
     */
    _getWebGLTextureType(type: number): number;
    /**
     * @internal
     */
    _getInternalFormat(format: number, useSRGBBuffer?: boolean): number;
    /**
     * @internal
     */
    _getRGBABufferInternalSizedFormat(type: number, format?: number, useSRGBBuffer?: boolean): number;
    /**
     * Reads pixels from the current frame buffer. Please note that this function can be slow
     * @param x defines the x coordinate of the rectangle where pixels must be read
     * @param y defines the y coordinate of the rectangle where pixels must be read
     * @param width defines the width of the rectangle where pixels must be read
     * @param height defines the height of the rectangle where pixels must be read
     * @param hasAlpha defines whether the output should have alpha or not (defaults to true)
     * @param flushRenderer true to flush the renderer from the pending commands before reading the pixels
     * @param data defines the data to fill with the read pixels (if not provided, a new one will be created)
     * @returns a ArrayBufferView promise (Uint8Array) containing RGBA colors
     */
    readPixels(x: number, y: number, width: number, height: number, hasAlpha?: boolean, flushRenderer?: boolean, data?: Nullable<Uint8Array>): Promise<ArrayBufferView>;
    private static _IsSupported;
    private static _HasMajorPerformanceCaveat;
    /**
     * Gets a Promise<boolean> indicating if the engine can be instantiated (ie. if a webGL context can be found)
     */
    static get IsSupportedAsync(): Promise<boolean>;
    /**
     * Gets a boolean indicating if the engine can be instantiated (ie. if a webGL context can be found)
     */
    static get IsSupported(): boolean;
    /**
     * Gets a boolean indicating if the engine can be instantiated (ie. if a webGL context can be found)
     * @returns true if the engine can be created
     */
    static isSupported(): boolean;
    /**
     * Gets a boolean indicating if the engine can be instantiated on a performant device (ie. if a webGL context can be found and it does not use a slow implementation)
     */
    static get HasMajorPerformanceCaveat(): boolean;
}
interface TexImageParameters {
    internalFormat: number;
    format: number;
    type: number;
}

/** @internal */
declare class WebGLPipelineContext implements IPipelineContext {
    private _valueCache;
    private _uniforms;
    engine: ThinEngine;
    program: Nullable<WebGLProgram>;
    context?: WebGLRenderingContext;
    vertexShader?: WebGLShader;
    fragmentShader?: WebGLShader;
    isParallelCompiled: boolean;
    onCompiled?: () => void;
    transformFeedback?: WebGLTransformFeedback | null;
    vertexCompilationError: Nullable<string>;
    fragmentCompilationError: Nullable<string>;
    programLinkError: Nullable<string>;
    programValidationError: Nullable<string>;
    /** @internal */
    _isDisposed: boolean;
    get isAsync(): boolean;
    get isReady(): boolean;
    _handlesSpectorRebuildCallback(onCompiled: (program: WebGLProgram) => void): void;
    setEngine(engine: AbstractEngine): void;
    _fillEffectInformation(effect: Effect, uniformBuffersNames: {
        [key: string]: number;
    }, uniformsNames: string[], uniforms: {
        [key: string]: Nullable<WebGLUniformLocation>;
    }, samplerList: string[], samplers: {
        [key: string]: number;
    }, attributesNames: string[], attributes: number[]): void;
    /**
     * Release all associated resources.
     **/
    dispose(): void;
    /**
     * @internal
     */
    _cacheMatrix(uniformName: string, matrix: IMatrixLike): boolean;
    /**
     * @internal
     */
    _cacheFloat2(uniformName: string, x: number, y: number): boolean;
    /**
     * @internal
     */
    _cacheFloat3(uniformName: string, x: number, y: number, z: number): boolean;
    /**
     * @internal
     */
    _cacheFloat4(uniformName: string, x: number, y: number, z: number, w: number): boolean;
    /**
     * Sets an integer value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value Value to be set.
     */
    setInt(uniformName: string, value: number): void;
    /**
     * Sets a int2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int2.
     * @param y Second int in int2.
     */
    setInt2(uniformName: string, x: number, y: number): void;
    /**
     * Sets a int3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int3.
     * @param y Second int in int3.
     * @param z Third int in int3.
     */
    setInt3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets a int4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int4.
     * @param y Second int in int4.
     * @param z Third int in int4.
     * @param w Fourth int in int4.
     */
    setInt4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets an int array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray2(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray3(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray4(uniformName: string, array: Int32Array): void;
    /**
     * Sets an unsigned integer value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value Value to be set.
     */
    setUInt(uniformName: string, value: number): void;
    /**
     * Sets an unsigned int2 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint2.
     * @param y Second unsigned int in uint2.
     */
    setUInt2(uniformName: string, x: number, y: number): void;
    /**
     * Sets an unsigned int3 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint3.
     * @param y Second unsigned int in uint3.
     * @param z Third unsigned int in uint3.
     */
    setUInt3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets an unsigned int4 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint4.
     * @param y Second unsigned int in uint4.
     * @param z Third unsigned int in uint4.
     * @param w Fourth unsigned int in uint4.
     */
    setUInt4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets an unsigned int array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray2(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray3(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray4(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray(uniformName: string, array: number[]): void;
    /**
     * Sets an array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray2(uniformName: string, array: number[]): void;
    /**
     * Sets an array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray3(uniformName: string, array: number[]): void;
    /**
     * Sets an array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray4(uniformName: string, array: number[]): void;
    /**
     * Sets matrices on a uniform variable.
     * @param uniformName Name of the variable.
     * @param matrices matrices to be set.
     */
    setMatrices(uniformName: string, matrices: Float32Array): void;
    /**
     * Sets matrix on a uniform variable.
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix(uniformName: string, matrix: IMatrixLike): void;
    /**
     * Sets a 3x3 matrix on a uniform variable. (Specified as [1,2,3,4,5,6,7,8,9] will result in [1,2,3][4,5,6][7,8,9] matrix)
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix3x3(uniformName: string, matrix: Float32Array): void;
    /**
     * Sets a 2x2 matrix on a uniform variable. (Specified as [1,2,3,4] will result in [1,2][3,4] matrix)
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix2x2(uniformName: string, matrix: Float32Array): void;
    /**
     * Sets a float on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value value to be set.
     */
    setFloat(uniformName: string, value: number): void;
    /**
     * Sets a Vector2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector2 vector2 to be set.
     */
    setVector2(uniformName: string, vector2: IVector2Like): void;
    /**
     * Sets a float2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float2.
     * @param y Second float in float2.
     */
    setFloat2(uniformName: string, x: number, y: number): void;
    /**
     * Sets a Vector3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector3 Value to be set.
     */
    setVector3(uniformName: string, vector3: IVector3Like): void;
    /**
     * Sets a float3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float3.
     * @param y Second float in float3.
     * @param z Third float in float3.
     */
    setFloat3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets a Vector4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector4 Value to be set.
     */
    setVector4(uniformName: string, vector4: IVector4Like): void;
    /**
     * Sets a Quaternion on a uniform variable.
     * @param uniformName Name of the variable.
     * @param quaternion Value to be set.
     */
    setQuaternion(uniformName: string, quaternion: IQuaternionLike): void;
    /**
     * Sets a float4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float4.
     * @param y Second float in float4.
     * @param z Third float in float4.
     * @param w Fourth float in float4.
     */
    setFloat4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets a Color3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param color3 Value to be set.
     */
    setColor3(uniformName: string, color3: IColor3Like): void;
    /**
     * Sets a Color4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param color3 Value to be set.
     * @param alpha Alpha value to be set.
     */
    setColor4(uniformName: string, color3: IColor3Like, alpha: number): void;
    /**
     * Sets a Color4 on a uniform variable
     * @param uniformName defines the name of the variable
     * @param color4 defines the value to be set
     */
    setDirectColor4(uniformName: string, color4: IColor4Like): void;
    _getVertexShaderCode(): string | null;
    _getFragmentShaderCode(): string | null;
}

/**
 * Interface for any object that can request an animation frame
 */
interface ICustomAnimationFrameRequester {
    /**
     * This function will be called when the render loop is ready. If this is not populated, the engine's renderloop function will be called
     */
    renderFunction?: Function;
    /**
     * Called to request the next frame to render to
     * @see https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame
     */
    requestAnimationFrame: Function;
    /**
     * You can pass this value to cancelAnimationFrame() to cancel the refresh callback request
     * @see https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame#Return_value
     */
    requestID?: number;
    /**
     * Called to cancel the next frame request
     */
    cancelAnimationFrame?: Function;
}

declare module "../abstractEngine" {
    interface AbstractEngine {
        /**
         * Sets the current alpha mode
         * @param mode defines the mode to use (one of the Engine.ALPHA_XXX)
         * @param noDepthWriteChange defines if depth writing state should remains unchanged (false by default)
         * @param targetIndex defines the index of the target to set the alpha mode for (default is 0)
         * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/advanced/transparent_rendering
         */
        setAlphaMode(mode: number, noDepthWriteChange?: boolean, targetIndex?: number): void;
    }
}

declare module "../abstractEngine" {
    interface AbstractEngine {
        /**
         * Update a raw texture
         * @param texture defines the texture to update
         * @param data defines the data to store in the texture
         * @param format defines the format of the data
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateRawTexture(texture: Nullable<InternalTexture>, data: Nullable<ArrayBufferView>, format: number, invertY: boolean): void;
        /**
         * Update a raw texture
         * @param texture defines the texture to update
         * @param data defines the data to store in the texture
         * @param format defines the format of the data
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the compression used (null by default)
         * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
         * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
         */
        updateRawTexture(texture: Nullable<InternalTexture>, data: Nullable<ArrayBufferView>, format: number, invertY: boolean, compression: Nullable<string>, type: number, useSRGBBuffer: boolean): void;
        /**
         * Update a raw cube texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateRawCubeTexture(texture: InternalTexture, data: ArrayBufferView[], format: number, type: number, invertY: boolean): void;
        /**
         * Update a raw cube texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the compression used (null by default)
         */
        updateRawCubeTexture(texture: InternalTexture, data: ArrayBufferView[], format: number, type: number, invertY: boolean, compression: Nullable<string>): void;
        /**
         * Update a raw cube texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the compression used (null by default)
         * @param level defines which level of the texture to update
         */
        updateRawCubeTexture(texture: InternalTexture, data: ArrayBufferView[], format: number, type: number, invertY: boolean, compression: Nullable<string>, level: number): void;
        /**
         * Creates a new raw cube texture from a specified url
         * @param url defines the url where the data is located
         * @param scene defines the current scene
         * @param size defines the size of the textures
         * @param format defines the format of the data
         * @param type defines the type fo the data (like Engine.TEXTURETYPE_UNSIGNED_BYTE)
         * @param noMipmap defines if the engine should avoid generating the mip levels
         * @param callback defines a callback used to extract texture data from loaded data
         * @param mipmapGenerator defines to provide an optional tool to generate mip levels
         * @param onLoad defines a callback called when texture is loaded
         * @param onError defines a callback called if there is an error
         * @returns the cube texture as an InternalTexture
         */
        createRawCubeTextureFromUrl(url: string, scene: Nullable<Scene>, size: number, format: number, type: number, noMipmap: boolean, callback: (ArrayBuffer: ArrayBuffer) => Nullable<ArrayBufferView[] | Promise<ArrayBufferView[]>>, mipmapGenerator: Nullable<(faces: ArrayBufferView[]) => ArrayBufferView[][]>, onLoad: Nullable<() => void>, onError: Nullable<(message?: string, exception?: any) => void>): InternalTexture;
        /**
         * Creates a new raw cube texture from a specified url
         * @param url defines the url where the data is located
         * @param scene defines the current scene
         * @param size defines the size of the textures
         * @param format defines the format of the data
         * @param type defines the type fo the data (like Engine.TEXTURETYPE_UNSIGNED_BYTE)
         * @param noMipmap defines if the engine should avoid generating the mip levels
         * @param callback defines a callback used to extract texture data from loaded data
         * @param mipmapGenerator defines to provide an optional tool to generate mip levels
         * @param onLoad defines a callback called when texture is loaded
         * @param onError defines a callback called if there is an error
         * @param samplingMode defines the required sampling mode (like Texture.NEAREST_SAMPLINGMODE)
         * @param invertY defines if data must be stored with Y axis inverted
         * @returns the cube texture as an InternalTexture
         */
        createRawCubeTextureFromUrl(url: string, scene: Nullable<Scene>, size: number, format: number, type: number, noMipmap: boolean, callback: (ArrayBuffer: ArrayBuffer) => Nullable<ArrayBufferView[] | Promise<ArrayBufferView[]>>, mipmapGenerator: Nullable<(faces: ArrayBufferView[]) => ArrayBufferView[][]>, onLoad: Nullable<() => void>, onError: Nullable<(message?: string, exception?: any) => void>, samplingMode: number, invertY: boolean): InternalTexture;
        /**
         * Update a raw 3D texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateRawTexture3D(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean): void;
        /**
         * Update a raw 3D texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the used compression (can be null)
         * @param textureType defines the texture Type (Engine.TEXTURETYPE_UNSIGNED_BYTE, Engine.TEXTURETYPE_FLOAT...)
         */
        updateRawTexture3D(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean, compression: Nullable<string>, textureType: number): void;
        /**
         * Update a raw 2D array texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateRawTexture2DArray(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean): void;
        /**
         * Update a raw 2D array texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the used compression (can be null)
         * @param textureType defines the texture Type (Engine.TEXTURETYPE_UNSIGNED_BYTE, Engine.TEXTURETYPE_FLOAT...)
         */
        updateRawTexture2DArray(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean, compression: Nullable<string>, textureType: number): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /** @internal */
        _readTexturePixels(texture: InternalTexture, width: number, height: number, faceIndex?: number, level?: number, buffer?: Nullable<ArrayBufferView>, flushRenderer?: boolean, noDataConversion?: boolean, x?: number, y?: number): Promise<ArrayBufferView>;
        /** @internal */
        _readTexturePixelsSync(texture: InternalTexture, width: number, height: number, faceIndex?: number, level?: number, buffer?: Nullable<ArrayBufferView>, flushRenderer?: boolean, noDataConversion?: boolean, x?: number, y?: number): ArrayBufferView;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Update a dynamic index buffer
         * @param indexBuffer defines the target index buffer
         * @param indices defines the data to update
         * @param offset defines the offset in the target index buffer where update should start
         */
        updateDynamicIndexBuffer(indexBuffer: DataBuffer, indices: IndicesArray, offset?: number): void;
        /**
         * Updates a dynamic vertex buffer.
         * @param vertexBuffer the vertex buffer to update
         * @param data the data used to update the vertex buffer
         * @param byteOffset the byte offset of the data
         * @param byteLength the byte length of the data
         */
        updateDynamicVertexBuffer(vertexBuffer: DataBuffer, data: DataArray, byteOffset?: number, byteLength?: number): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * @internal
         */
        _setCubeMapTextureParams(texture: InternalTexture, loadMipmap: boolean, maxLevel?: number): void;
        /**
         * Creates a depth stencil cube texture.
         * This is only available in WebGL 2.
         * @param size The size of face edge in the cube texture.
         * @param options The options defining the cube texture.
         * @returns The cube texture
         */
        _createDepthStencilCubeTexture(size: number, options: DepthTextureCreationOptions): InternalTexture;
        /**
         * Creates a cube texture
         * @param rootUrl defines the url where the files to load is located
         * @param scene defines the current scene
         * @param files defines the list of files to load (1 per face)
         * @param noMipmap defines a boolean indicating that no mipmaps shall be generated (false by default)
         * @param onLoad defines an optional callback raised when the texture is loaded
         * @param onError defines an optional callback raised if there is an issue to load the texture
         * @param format defines the format of the data
         * @param forcedExtension defines the extension to use to pick the right loader
         * @param createPolynomials if a polynomial sphere should be created for the cube texture
         * @param lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness
         * @param lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness
         * @param fallback defines texture to use while falling back when (compressed) texture file not found.
         * @param loaderOptions options to be passed to the loader
         * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
         * @param buffer defines the data buffer to load instead of loading the rootUrl
         * @returns the cube texture as an InternalTexture
         */
        createCubeTexture(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean | undefined, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any, createPolynomials: boolean, lodScale: number, lodOffset: number, fallback: Nullable<InternalTexture>, loaderOptions: any, useSRGBBuffer: boolean, buffer: Nullable<ArrayBufferView>): InternalTexture;
        /**
         * Creates a cube texture
         * @param rootUrl defines the url where the files to load is located
         * @param scene defines the current scene
         * @param files defines the list of files to load (1 per face)
         * @param noMipmap defines a boolean indicating that no mipmaps shall be generated (false by default)
         * @param onLoad defines an optional callback raised when the texture is loaded
         * @param onError defines an optional callback raised if there is an issue to load the texture
         * @param format defines the format of the data
         * @param forcedExtension defines the extension to use to pick the right loader
         * @returns the cube texture as an InternalTexture
         */
        createCubeTexture(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any): InternalTexture;
        /**
         * Creates a cube texture
         * @param rootUrl defines the url where the files to load is located
         * @param scene defines the current scene
         * @param files defines the list of files to load (1 per face)
         * @param noMipmap defines a boolean indicating that no mipmaps shall be generated (false by default)
         * @param onLoad defines an optional callback raised when the texture is loaded
         * @param onError defines an optional callback raised if there is an issue to load the texture
         * @param format defines the format of the data
         * @param forcedExtension defines the extension to use to pick the right loader
         * @param createPolynomials if a polynomial sphere should be created for the cube texture
         * @param lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness
         * @param lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness
         * @returns the cube texture as an InternalTexture
         */
        createCubeTexture(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any, createPolynomials: boolean, lodScale: number, lodOffset: number): InternalTexture;
        /** @internal */
        createCubeTextureBase(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any, createPolynomials: boolean, lodScale: number, lodOffset: number, fallback: Nullable<InternalTexture>, beforeLoadCubeDataCallback: Nullable<(texture: InternalTexture, data: ArrayBufferView | ArrayBufferView[]) => void>, imageHandler: Nullable<(texture: InternalTexture, imgs: HTMLImageElement[] | ImageBitmap[]) => void>, useSRGBBuffer: boolean, buffer: ArrayBufferView): InternalTexture;
        /**
         * Force the mipmap generation for the given render target texture
         * @param texture defines the render target texture to use
         * @param unbind defines whether or not to unbind the texture after generation. Defaults to true.
         */
        generateMipMapsForCubemap(texture: InternalTexture, unbind?: boolean): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Creates a depth stencil texture.
         * This is only available in WebGL 2 or with the depth texture extension available.
         * @param size The size of face edge in the texture.
         * @param options The options defining the texture.
         * @param rtWrapper The render target wrapper for which the depth/stencil texture must be created
         * @returns The texture
         */
        createDepthStencilTexture(size: TextureSize, options: DepthTextureCreationOptions, rtWrapper: RenderTargetWrapper): InternalTexture;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Creates a new render target texture
         * @param size defines the size of the texture
         * @param options defines the options used to create the texture
         * @returns a new render target wrapper ready to render texture
         */
        createRenderTargetTexture(size: TextureSize, options: boolean | RenderTargetCreationOptions): RenderTargetWrapper;
        /**
         * Updates the sample count of a render target texture
         * @see https://doc.babylonjs.com/setup/support/webGL2#multisample-render-targets
         * @param rtWrapper defines the render target wrapper to update
         * @param samples defines the sample count to set
         * @returns the effective sample count (could be 0 if multisample render targets are not supported)
         */
        updateRenderTargetTextureSampleCount(rtWrapper: Nullable<RenderTargetWrapper>, samples: number): number;
        /** @internal */
        _createDepthStencilTexture(size: TextureSize, options: DepthTextureCreationOptions, rtWrapper: RenderTargetWrapper): InternalTexture;
        /** @internal */
        _createHardwareRenderTargetWrapper(isMulti: boolean, isCube: boolean, size: TextureSize): RenderTargetWrapper;
        /** @internal */
        _setupDepthStencilTexture(internalTexture: InternalTexture, size: TextureSize, bilinearFiltering: boolean, comparisonFunction: number, samples?: number): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Sets a depth stencil texture from a render target to the according uniform.
         * @param channel The texture channel
         * @param uniform The uniform to set
         * @param texture The render target texture containing the depth stencil texture to apply
         * @param name The texture name
         */
        setDepthStencilTexture(channel: number, uniform: Nullable<WebGLUniformLocation>, texture: Nullable<RenderTargetTexture>, name?: string): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Creates a new render target cube wrapper
         * @param size defines the size of the texture
         * @param options defines the options used to create the texture
         * @returns a new render target cube wrapper
         */
        createRenderTargetCubeTexture(size: number, options?: RenderTargetCreationOptions): RenderTargetWrapper;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Create a cube texture from prefiltered data (ie. the mipmaps contain ready to use data for PBR reflection)
         * @param rootUrl defines the url where the file to load is located
         * @param scene defines the current scene
         * @param lodScale defines scale to apply to the mip map selection
         * @param lodOffset defines offset to apply to the mip map selection
         * @param onLoad defines an optional callback raised when the texture is loaded
         * @param onError defines an optional callback raised if there is an issue to load the texture
         * @param format defines the format of the data
         * @param forcedExtension defines the extension to use to pick the right loader
         * @param createPolynomials defines wheter or not to create polynomails harmonics for the texture
         * @returns the cube texture as an InternalTexture
         */
        createPrefilteredCubeTexture(rootUrl: string, scene: Nullable<Scene>, lodScale: number, lodOffset: number, onLoad?: Nullable<(internalTexture: Nullable<InternalTexture>) => void>, onError?: Nullable<(message?: string, exception?: any) => void>, format?: number, forcedExtension?: any, createPolynomials?: boolean): InternalTexture;
    }
}

declare module "../../Engines/thinEngine" {
    interface ThinEngine {
        /**
         * Create an uniform buffer
         * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
         * @param elements defines the content of the uniform buffer
         * @param label defines a name for the buffer (for debugging purpose)
         * @returns the webGL uniform buffer
         */
        createUniformBuffer(elements: FloatArray, label?: string): DataBuffer;
        /**
         * Create a dynamic uniform buffer
         * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
         * @param elements defines the content of the uniform buffer
         * @param label defines a name for the buffer (for debugging purpose)
         * @returns the webGL uniform buffer
         */
        createDynamicUniformBuffer(elements: FloatArray, label?: string): DataBuffer;
        /**
         * Update an existing uniform buffer
         * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
         * @param uniformBuffer defines the target uniform buffer
         * @param elements defines the content to update
         * @param offset defines the offset in the uniform buffer where update should start
         * @param count defines the size of the data to update
         */
        updateUniformBuffer(uniformBuffer: DataBuffer, elements: FloatArray, offset?: number, count?: number): void;
        /**
         * Bind an uniform buffer to the current webGL context
         * @param buffer defines the buffer to bind
         */
        bindUniformBuffer(buffer: Nullable<DataBuffer>): void;
        /**
         * Bind a buffer to the current webGL context at a given location
         * @param buffer defines the buffer to bind
         * @param location defines the index where to bind the buffer
         * @param name Name of the uniform variable to bind
         */
        bindUniformBufferBase(buffer: DataBuffer, location: number, name: string): void;
        /**
         * Bind a specific block at a given index in a specific shader program
         * @param pipelineContext defines the pipeline context to use
         * @param blockName defines the block name
         * @param index defines the index where to bind the block
         */
        bindUniformBlock(pipelineContext: IPipelineContext, blockName: string, index: number): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Display the loading screen
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
         */
        displayLoadingUI(): void;
        /**
         * Hide the loading screen
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
         */
        hideLoadingUI(): void;
        /**
         * Gets or sets the current loading screen object
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
         */
        loadingScreen: ILoadingScreen;
        /**
         * Sets the current loading screen text
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
         */
        loadingUIText: string;
        /**
         * Sets the current loading screen background color
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/customLoadingScreen
         */
        loadingUIBackgroundColor: string;
    }
}

/**
 * Defines the interface used by objects containing a viewport (like a camera)
 */
interface IViewportOwnerLike {
    /**
     * Gets or sets the viewport
     */
    viewport: IViewportLike;
}
declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Gets the HTML element used to attach event listeners
         * @returns a HTML element
         */
        getInputElement(): Nullable<HTMLElement>;
        /**
         * Gets the client rect of the HTML canvas attached with the current webGL context
         * @returns a client rectangle
         */
        getRenderingCanvasClientRect(): Nullable<ClientRect>;
        /**
         * Gets the client rect of the HTML element used for events
         * @returns a client rectangle
         */
        getInputElementClientRect(): Nullable<ClientRect>;
        /**
         * Gets current aspect ratio
         * @param viewportOwner defines the camera to use to get the aspect ratio
         * @param useScreen defines if screen size must be used (or the current render target if any)
         * @returns a number defining the aspect ratio
         */
        getAspectRatio(viewportOwner: IViewportOwnerLike, useScreen?: boolean): number;
        /**
         * Gets current screen aspect ratio
         * @returns a number defining the aspect ratio
         */
        getScreenAspectRatio(): number;
        /**
         * Toggle full screen mode
         * @param requestPointerLock defines if a pointer lock should be requested from the user
         */
        switchFullscreen(requestPointerLock: boolean): void;
        /**
         * Enters full screen mode
         * @param requestPointerLock defines if a pointer lock should be requested from the user
         */
        enterFullscreen(requestPointerLock: boolean): void;
        /**
         * Exits full screen mode
         */
        exitFullscreen(): void;
        /** @internal */
        _onPointerLockChange: () => void;
        /** @internal */
        _verifyPointerLock(): void;
    }
}

declare module "../abstractEngine" {
    interface AbstractEngine {
        /**
         * Sets the current alpha equation
         * @param equation defines the equation to use (one of the Engine.ALPHA_EQUATION_XXX)
         * @param targetIndex defines the index of the target to set the equation for (default is 0)
         */
        setAlphaEquation(equation: number, targetIndex?: number): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Gets the current depth function
         * @returns a number defining the depth function
         */
        getDepthFunction(): Nullable<number>;
        /**
         * Sets the current depth function
         * @param depthFunc defines the function to use
         */
        setDepthFunction(depthFunc: number): void;
        /**
         * Sets the current depth function to GREATER
         */
        setDepthFunctionToGreater(): void;
        /**
         * Sets the current depth function to GEQUAL
         */
        setDepthFunctionToGreaterOrEqual(): void;
        /**
         * Sets the current depth function to LESS
         */
        setDepthFunctionToLess(): void;
        /**
         * Sets the current depth function to LEQUAL
         */
        setDepthFunctionToLessOrEqual(): void;
        /**
         * Gets a boolean indicating if depth writing is enabled
         * @returns the current depth writing state
         */
        getDepthWrite(): boolean;
        /**
         * Enable or disable depth writing
         * @param enable defines the state to set
         */
        setDepthWrite(enable: boolean): void;
        /**
         * Sets alpha constants used by some alpha blending modes
         * @param r defines the red component
         * @param g defines the green component
         * @param b defines the blue component
         * @param a defines the alpha component
         */
        setAlphaConstants(r: number, g: number, b: number, a: number): void;
        /**
         * Gets the current alpha mode
         * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/advanced/transparent_rendering
         * @param targetIndex defines the index of the target to get the alpha mode for (default is 0)
         * @returns the current alpha mode
         */
        getAlphaMode(targetIndex?: number): number;
        /**
         * Gets the current alpha equation.
         * @param targetIndex defines the index of the target to get the alpha equation for (default is 0)
         * @returns the current alpha equation
         */
        getAlphaEquation(targetIndex?: number): number;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /** @internal */
        _cachedStencilBuffer: boolean;
        /** @internal */
        _cachedStencilFunction: number;
        /** @internal */
        _cachedStencilMask: number;
        /** @internal */
        _cachedStencilOperationPass: number;
        /** @internal */
        _cachedStencilOperationFail: number;
        /** @internal */
        _cachedStencilOperationDepthFail: number;
        /** @internal */
        _cachedStencilReference: number;
        /**
         * Gets the current stencil operation when stencil passes
         * @returns a number defining stencil operation to use when stencil passes
         */
        getStencilOperationPass(): number;
        /**
         * Gets the current back stencil operation when stencil passes
         * @returns a number defining back stencil operation to use when stencil passes
         */
        getStencilBackOperationPass(): number;
        /**
         * Gets a boolean indicating if stencil buffer is enabled
         * @returns the current stencil buffer state
         */
        getStencilBuffer(): boolean;
        /**
         * Enable or disable the stencil buffer
         * @param enable defines if the stencil buffer must be enabled or disabled
         */
        setStencilBuffer(enable: boolean): void;
        /**
         * Gets the current stencil mask
         * @returns a number defining the new stencil mask to use
         */
        getStencilMask(): number;
        /**
         * Sets the current stencil mask
         * @param mask defines the new stencil mask to use
         */
        setStencilMask(mask: number): void;
        /**
         * Gets the current stencil function
         * @returns a number defining the stencil function to use
         */
        getStencilFunction(): number;
        /**
         * Gets the current back stencil function
         * @returns a number defining the back stencil function to use
         */
        getStencilBackFunction(): number;
        /**
         * Gets the current stencil reference value
         * @returns a number defining the stencil reference value to use
         */
        getStencilFunctionReference(): number;
        /**
         * Gets the current stencil mask
         * @returns a number defining the stencil mask to use
         */
        getStencilFunctionMask(): number;
        /**
         * Sets the current stencil function
         * @param stencilFunc defines the new stencil function to use
         */
        setStencilFunction(stencilFunc: number): void;
        /**
         * Sets the current back stencil function
         * @param stencilFunc defines the new back stencil function to use
         */
        setStencilBackFunction(stencilFunc: number): void;
        /**
         * Sets the current stencil reference
         * @param reference defines the new stencil reference to use
         */
        setStencilFunctionReference(reference: number): void;
        /**
         * Sets the current stencil mask
         * @param mask defines the new stencil mask to use
         */
        setStencilFunctionMask(mask: number): void;
        /**
         * Gets the current stencil operation when stencil fails
         * @returns a number defining stencil operation to use when stencil fails
         */
        getStencilOperationFail(): number;
        /**
         * Gets the current back stencil operation when stencil fails
         * @returns a number defining back stencil operation to use when stencil fails
         */
        getStencilBackOperationFail(): number;
        /**
         * Gets the current stencil operation when depth fails
         * @returns a number defining stencil operation to use when depth fails
         */
        getStencilOperationDepthFail(): number;
        /**
         * Gets the current back stencil operation when depth fails
         * @returns a number defining back stencil operation to use when depth fails
         */
        getStencilBackOperationDepthFail(): number;
        /**
         * Sets the stencil operation to use when stencil fails
         * @param operation defines the stencil operation to use when stencil fails
         */
        setStencilOperationFail(operation: number): void;
        /**
         * Sets the back stencil operation to use when stencil fails
         * @param operation defines the back stencil operation to use when stencil fails
         */
        setStencilBackOperationFail(operation: number): void;
        /**
         * Sets the stencil operation to use when depth fails
         * @param operation defines the stencil operation to use when depth fails
         */
        setStencilOperationDepthFail(operation: number): void;
        /**
         * Sets the back stencil operation to use when depth fails
         * @param operation defines the back stencil operation to use when depth fails
         */
        setStencilBackOperationDepthFail(operation: number): void;
        /**
         * Sets the stencil operation to use when stencil passes
         * @param operation defines the stencil operation to use when stencil passes
         */
        setStencilOperationPass(operation: number): void;
        /**
         * Sets the back stencil operation to use when stencil passes
         * @param operation defines the back stencil operation to use when stencil passes
         */
        setStencilBackOperationPass(operation: number): void;
        /**
         * Caches the state of the stencil buffer
         */
        cacheStencilState(): void;
        /**
         * Restores the state of the stencil buffer
         */
        restoreStencilState(): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Gets the names of the render passes that are currently created
         * @returns list of the render pass names
         */
        getRenderPassNames(): string[];
        /**
         * Gets the name of the current render pass
         * @returns name of the current render pass
         */
        getCurrentRenderPassName(): string;
        /**
         * Creates a render pass id
         * @param name Name of the render pass (for debug purpose only)
         * @returns the id of the new render pass
         */
        createRenderPassId(name?: string): number;
        /**
         * Releases a render pass id
         * @param id id of the render pass to release
         */
        releaseRenderPassId(id: number): void;
    }
}

declare module "../abstractEngine" {
    interface AbstractEngine {
        /**
         * @internal
         */
        _loadFileAsync(url: string, offlineProvider?: IOfflineProvider, useArrayBuffer?: false): Promise<string>;
        _loadFileAsync(url: string, offlineProvider?: IOfflineProvider, useArrayBuffer?: true): Promise<ArrayBuffer>;
        _loadFileAsync(url: string, offlineProvider?: IOfflineProvider, useArrayBuffer?: boolean): Promise<string | ArrayBuffer>;
    }
}

/**
 * The engine class is responsible for interfacing with all lower-level APIs such as WebGL and Audio
 */
declare class Engine extends ThinEngine {
    /** Defines that alpha blending is disabled */
    static readonly ALPHA_DISABLE = 0;
    /** Defines that alpha blending to SRC ALPHA * SRC + DEST */
    static readonly ALPHA_ADD = 1;
    /** Defines that alpha blending to SRC ALPHA * SRC + (1 - SRC ALPHA) * DEST */
    static readonly ALPHA_COMBINE = 2;
    /** Defines that alpha blending to DEST - SRC * DEST */
    static readonly ALPHA_SUBTRACT = 3;
    /** Defines that alpha blending to SRC * DEST */
    static readonly ALPHA_MULTIPLY = 4;
    /** Defines that alpha blending to SRC ALPHA * SRC + (1 - SRC) * DEST */
    static readonly ALPHA_MAXIMIZED = 5;
    /** Defines that alpha blending to SRC + DEST */
    static readonly ALPHA_ONEONE = 6;
    /** Defines that alpha blending to SRC + (1 - SRC ALPHA) * DEST */
    static readonly ALPHA_PREMULTIPLIED = 7;
    /**
     * Defines that alpha blending to SRC + (1 - SRC ALPHA) * DEST
     * Alpha will be set to (1 - SRC ALPHA) * DEST ALPHA
     */
    static readonly ALPHA_PREMULTIPLIED_PORTERDUFF = 8;
    /** Defines that alpha blending to CST * SRC + (1 - CST) * DEST */
    static readonly ALPHA_INTERPOLATE = 9;
    /**
     * Defines that alpha blending to SRC + (1 - SRC) * DEST
     * Alpha will be set to SRC ALPHA + (1 - SRC ALPHA) * DEST ALPHA
     */
    static readonly ALPHA_SCREENMODE = 10;
    /** Defines that the resource is not delayed*/
    static readonly DELAYLOADSTATE_NONE = 0;
    /** Defines that the resource was successfully delay loaded */
    static readonly DELAYLOADSTATE_LOADED = 1;
    /** Defines that the resource is currently delay loading */
    static readonly DELAYLOADSTATE_LOADING = 2;
    /** Defines that the resource is delayed and has not started loading */
    static readonly DELAYLOADSTATE_NOTLOADED = 4;
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will never pass. i.e. Nothing will be drawn */
    static readonly NEVER = 512;
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will always pass. i.e. Pixels will be drawn in the order they are drawn */
    static readonly ALWAYS = 519;
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is less than the stored value */
    static readonly LESS = 513;
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is equals to the stored value */
    static readonly EQUAL = 514;
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is less than or equal to the stored value */
    static readonly LEQUAL = 515;
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is greater than the stored value */
    static readonly GREATER = 516;
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is greater than or equal to the stored value */
    static readonly GEQUAL = 518;
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is not equal to the stored value */
    static readonly NOTEQUAL = 517;
    /** Passed to stencilOperation to specify that stencil value must be kept */
    static readonly KEEP = 7680;
    /** Passed to stencilOperation to specify that stencil value must be replaced */
    static readonly REPLACE = 7681;
    /** Passed to stencilOperation to specify that stencil value must be incremented */
    static readonly INCR = 7682;
    /** Passed to stencilOperation to specify that stencil value must be decremented */
    static readonly DECR = 7683;
    /** Passed to stencilOperation to specify that stencil value must be inverted */
    static readonly INVERT = 5386;
    /** Passed to stencilOperation to specify that stencil value must be incremented with wrapping */
    static readonly INCR_WRAP = 34055;
    /** Passed to stencilOperation to specify that stencil value must be decremented with wrapping */
    static readonly DECR_WRAP = 34056;
    /** Texture is not repeating outside of 0..1 UVs */
    static readonly TEXTURE_CLAMP_ADDRESSMODE = 0;
    /** Texture is repeating outside of 0..1 UVs */
    static readonly TEXTURE_WRAP_ADDRESSMODE = 1;
    /** Texture is repeating and mirrored */
    static readonly TEXTURE_MIRROR_ADDRESSMODE = 2;
    /** ALPHA */
    static readonly TEXTUREFORMAT_ALPHA = 0;
    /** LUMINANCE */
    static readonly TEXTUREFORMAT_LUMINANCE = 1;
    /** LUMINANCE_ALPHA */
    static readonly TEXTUREFORMAT_LUMINANCE_ALPHA = 2;
    /** RGB */
    static readonly TEXTUREFORMAT_RGB = 4;
    /** RGBA */
    static readonly TEXTUREFORMAT_RGBA = 5;
    /** RED */
    static readonly TEXTUREFORMAT_RED = 6;
    /** RED (2nd reference) */
    static readonly TEXTUREFORMAT_R = 6;
    /** RED unsigned short normed to [0, 1] **/
    static readonly TEXTUREFORMAT_R16_UNORM = 33322;
    /** RG unsigned short normed to [0, 1] **/
    static readonly TEXTUREFORMAT_RG16_UNORM = 33324;
    /** RGB unsigned short normed to [0, 1] **/
    static readonly TEXTUREFORMAT_RGB16_UNORM = 32852;
    /** RGBA unsigned short normed to [0, 1] **/
    static readonly TEXTUREFORMAT_RGBA16_UNORM = 32859;
    /** RED signed short normed to [-1, 1] **/
    static readonly TEXTUREFORMAT_R16_SNORM = 36760;
    /** RG signed short normed to [-1, 1] **/
    static readonly TEXTUREFORMAT_RG16_SNORM = 36761;
    /** RGB signed short normed to [-1, 1] **/
    static readonly TEXTUREFORMAT_RGB16_SNORM = 36762;
    /** RGBA signed short normed to [-1, 1] **/
    static readonly TEXTUREFORMAT_RGBA16_SNORM = 36763;
    /** RG */
    static readonly TEXTUREFORMAT_RG = 7;
    /** RED_INTEGER */
    static readonly TEXTUREFORMAT_RED_INTEGER = 8;
    /** RED_INTEGER (2nd reference) */
    static readonly TEXTUREFORMAT_R_INTEGER = 8;
    /** RG_INTEGER */
    static readonly TEXTUREFORMAT_RG_INTEGER = 9;
    /** RGB_INTEGER */
    static readonly TEXTUREFORMAT_RGB_INTEGER = 10;
    /** RGBA_INTEGER */
    static readonly TEXTUREFORMAT_RGBA_INTEGER = 11;
    /** UNSIGNED_BYTE */
    static readonly TEXTURETYPE_UNSIGNED_BYTE = 0;
    /** @deprecated use more explicit TEXTURETYPE_UNSIGNED_BYTE instead. Use TEXTURETYPE_UNSIGNED_INTEGER for 32bits values.*/
    static readonly TEXTURETYPE_UNSIGNED_INT = 0;
    /** FLOAT */
    static readonly TEXTURETYPE_FLOAT = 1;
    /** HALF_FLOAT */
    static readonly TEXTURETYPE_HALF_FLOAT = 2;
    /** BYTE */
    static readonly TEXTURETYPE_BYTE = 3;
    /** SHORT */
    static readonly TEXTURETYPE_SHORT = 4;
    /** UNSIGNED_SHORT */
    static readonly TEXTURETYPE_UNSIGNED_SHORT = 5;
    /** INT */
    static readonly TEXTURETYPE_INT = 6;
    /** UNSIGNED_INT */
    static readonly TEXTURETYPE_UNSIGNED_INTEGER = 7;
    /** UNSIGNED_SHORT_4_4_4_4 */
    static readonly TEXTURETYPE_UNSIGNED_SHORT_4_4_4_4 = 8;
    /** UNSIGNED_SHORT_5_5_5_1 */
    static readonly TEXTURETYPE_UNSIGNED_SHORT_5_5_5_1 = 9;
    /** UNSIGNED_SHORT_5_6_5 */
    static readonly TEXTURETYPE_UNSIGNED_SHORT_5_6_5 = 10;
    /** UNSIGNED_INT_2_10_10_10_REV */
    static readonly TEXTURETYPE_UNSIGNED_INT_2_10_10_10_REV = 11;
    /** UNSIGNED_INT_24_8 */
    static readonly TEXTURETYPE_UNSIGNED_INT_24_8 = 12;
    /** UNSIGNED_INT_10F_11F_11F_REV */
    static readonly TEXTURETYPE_UNSIGNED_INT_10F_11F_11F_REV = 13;
    /** UNSIGNED_INT_5_9_9_9_REV */
    static readonly TEXTURETYPE_UNSIGNED_INT_5_9_9_9_REV = 14;
    /** FLOAT_32_UNSIGNED_INT_24_8_REV */
    static readonly TEXTURETYPE_FLOAT_32_UNSIGNED_INT_24_8_REV = 15;
    /** nearest is mag = nearest and min = nearest and mip = none */
    static readonly TEXTURE_NEAREST_SAMPLINGMODE = 1;
    /** Bilinear is mag = linear and min = linear and mip = nearest */
    static readonly TEXTURE_BILINEAR_SAMPLINGMODE = 2;
    /** Trilinear is mag = linear and min = linear and mip = linear */
    static readonly TEXTURE_TRILINEAR_SAMPLINGMODE = 3;
    /** nearest is mag = nearest and min = nearest and mip = linear */
    static readonly TEXTURE_NEAREST_NEAREST_MIPLINEAR = 8;
    /** Bilinear is mag = linear and min = linear and mip = nearest */
    static readonly TEXTURE_LINEAR_LINEAR_MIPNEAREST = 11;
    /** Trilinear is mag = linear and min = linear and mip = linear */
    static readonly TEXTURE_LINEAR_LINEAR_MIPLINEAR = 3;
    /** mag = nearest and min = nearest and mip = nearest */
    static readonly TEXTURE_NEAREST_NEAREST_MIPNEAREST = 4;
    /** mag = nearest and min = linear and mip = nearest */
    static readonly TEXTURE_NEAREST_LINEAR_MIPNEAREST = 5;
    /** mag = nearest and min = linear and mip = linear */
    static readonly TEXTURE_NEAREST_LINEAR_MIPLINEAR = 6;
    /** mag = nearest and min = linear and mip = none */
    static readonly TEXTURE_NEAREST_LINEAR = 7;
    /** mag = nearest and min = nearest and mip = none */
    static readonly TEXTURE_NEAREST_NEAREST = 1;
    /** mag = linear and min = nearest and mip = nearest */
    static readonly TEXTURE_LINEAR_NEAREST_MIPNEAREST = 9;
    /** mag = linear and min = nearest and mip = linear */
    static readonly TEXTURE_LINEAR_NEAREST_MIPLINEAR = 10;
    /** mag = linear and min = linear and mip = none */
    static readonly TEXTURE_LINEAR_LINEAR = 2;
    /** mag = linear and min = nearest and mip = none */
    static readonly TEXTURE_LINEAR_NEAREST = 12;
    /** Explicit coordinates mode */
    static readonly TEXTURE_EXPLICIT_MODE = 0;
    /** Spherical coordinates mode */
    static readonly TEXTURE_SPHERICAL_MODE = 1;
    /** Planar coordinates mode */
    static readonly TEXTURE_PLANAR_MODE = 2;
    /** Cubic coordinates mode */
    static readonly TEXTURE_CUBIC_MODE = 3;
    /** Projection coordinates mode */
    static readonly TEXTURE_PROJECTION_MODE = 4;
    /** Skybox coordinates mode */
    static readonly TEXTURE_SKYBOX_MODE = 5;
    /** Inverse Cubic coordinates mode */
    static readonly TEXTURE_INVCUBIC_MODE = 6;
    /** Equirectangular coordinates mode */
    static readonly TEXTURE_EQUIRECTANGULAR_MODE = 7;
    /** Equirectangular Fixed coordinates mode */
    static readonly TEXTURE_FIXED_EQUIRECTANGULAR_MODE = 8;
    /** Equirectangular Fixed Mirrored coordinates mode */
    static readonly TEXTURE_FIXED_EQUIRECTANGULAR_MIRRORED_MODE = 9;
    /** Defines that texture rescaling will use a floor to find the closer power of 2 size */
    static readonly SCALEMODE_FLOOR = 1;
    /** Defines that texture rescaling will look for the nearest power of 2 size */
    static readonly SCALEMODE_NEAREST = 2;
    /** Defines that texture rescaling will use a ceil to find the closer power of 2 size */
    static readonly SCALEMODE_CEILING = 3;
    /**
     * Returns the current npm package of the sdk
     */
    static get NpmPackage(): string;
    /**
     * Returns the current version of the framework
     */
    static get Version(): string;
    /** Gets the list of created engines */
    static get Instances(): AbstractEngine[];
    /**
     * Gets the latest created engine
     */
    static get LastCreatedEngine(): Nullable<AbstractEngine>;
    /**
     * Gets the latest created scene
     */
    static get LastCreatedScene(): Nullable<Scene>;
    /** @internal */
    /**
     * Method called to create the default loading screen.
     * This can be overridden in your own app.
     * @param canvas The rendering canvas element
     * @returns The loading screen
     */
    static DefaultLoadingScreenFactory(canvas: HTMLCanvasElement): ILoadingScreen;
    /**
     * If set, will be used to request the next animation frame for the render loop
     */
    customAnimationFrameRequester: Nullable<ICustomAnimationFrameRequester>;
    private _rescalePostProcess;
    protected get _supportsHardwareTextureRescaling(): boolean;
    private _measureFps;
    private _performanceMonitor;
    /**
     * Gets the performance monitor attached to this engine
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#engineinstrumentation
     */
    get performanceMonitor(): PerformanceMonitor;
    /**
     * Creates a new engine
     * @param canvasOrContext defines the canvas or WebGL context to use for rendering. If you provide a WebGL context, Babylon.js will not hook events on the canvas (like pointers, keyboards, etc...) so no event observables will be available. This is mostly used when Babylon.js is used as a plugin on a system which already used the WebGL context
     * @param antialias defines enable antialiasing (default: false)
     * @param options defines further options to be sent to the getContext() function
     * @param adaptToDeviceRatio defines whether to adapt to the device's viewport characteristics (default: false)
     */
    constructor(canvasOrContext: Nullable<HTMLCanvasElement | OffscreenCanvas | WebGLRenderingContext | WebGL2RenderingContext>, antialias?: boolean, options?: EngineOptions, adaptToDeviceRatio?: boolean);
    protected _initGLContext(): void;
    /**
     * Shared initialization across engines types.
     * @param canvas The canvas associated with this instance of the engine.
     */
    protected _sharedInit(canvas: HTMLCanvasElement): void;
    /**
     * Resize an image and returns the image data as an uint8array
     * @param image image to resize
     * @param bufferWidth destination buffer width
     * @param bufferHeight destination buffer height
     * @returns an uint8array containing RGBA values of bufferWidth * bufferHeight size
     */
    resizeImageBitmap(image: HTMLImageElement | ImageBitmap, bufferWidth: number, bufferHeight: number): Uint8Array;
    /**
     * Engine abstraction for loading and creating an image bitmap from a given source string.
     * @param imageSource source to load the image from.
     * @param options An object that sets options for the image's extraction.
     * @returns ImageBitmap
     */
    _createImageBitmapFromSource(imageSource: string, options?: ImageBitmapOptions): Promise<ImageBitmap>;
    /**
     * Toggle full screen mode
     * @param requestPointerLock defines if a pointer lock should be requested from the user
     */
    switchFullscreen(requestPointerLock: boolean): void;
    /**
     * Enters full screen mode
     * @param requestPointerLock defines if a pointer lock should be requested from the user
     */
    enterFullscreen(requestPointerLock: boolean): void;
    /**
     * Exits full screen mode
     */
    exitFullscreen(): void;
    /** States */
    /**
     * Sets a boolean indicating if the dithering state is enabled or disabled
     * @param value defines the dithering state
     */
    setDitheringState(value: boolean): void;
    /**
     * Sets a boolean indicating if the rasterizer state is enabled or disabled
     * @param value defines the rasterizer state
     */
    setRasterizerState(value: boolean): void;
    /**
     * Directly set the WebGL Viewport
     * @param x defines the x coordinate of the viewport (in screen space)
     * @param y defines the y coordinate of the viewport (in screen space)
     * @param width defines the width of the viewport (in screen space)
     * @param height defines the height of the viewport (in screen space)
     * @returns the current viewport Object (if any) that is being replaced by this call. You can restore this viewport later on to go back to the original state
     */
    setDirectViewport(x: number, y: number, width: number, height: number): Nullable<IViewportLike>;
    /**
     * Executes a scissor clear (ie. a clear on a specific portion of the screen)
     * @param x defines the x-coordinate of the bottom left corner of the clear rectangle
     * @param y defines the y-coordinate of the corner of the clear rectangle
     * @param width defines the width of the clear rectangle
     * @param height defines the height of the clear rectangle
     * @param clearColor defines the clear color
     */
    scissorClear(x: number, y: number, width: number, height: number, clearColor: IColor4Like): void;
    /**
     * Enable scissor test on a specific rectangle (ie. render will only be executed on a specific portion of the screen)
     * @param x defines the x-coordinate of the bottom left corner of the clear rectangle
     * @param y defines the y-coordinate of the corner of the clear rectangle
     * @param width defines the width of the clear rectangle
     * @param height defines the height of the clear rectangle
     */
    enableScissor(x: number, y: number, width: number, height: number): void;
    /**
     * Disable previously set scissor test rectangle
     */
    disableScissor(): void;
    /**
     * Gets the source code of the vertex shader associated with a specific webGL program
     * @param program defines the program to use
     * @returns a string containing the source code of the vertex shader associated with the program
     */
    getVertexShaderSource(program: WebGLProgram): Nullable<string>;
    /**
     * Gets the source code of the fragment shader associated with a specific webGL program
     * @param program defines the program to use
     * @returns a string containing the source code of the fragment shader associated with the program
     */
    getFragmentShaderSource(program: WebGLProgram): Nullable<string>;
    /**
     * sets the object from which width and height will be taken from when getting render width and height
     * Will fallback to the gl object
     * @param dimensions the framebuffer width and height that will be used.
     */
    set framebufferDimensionsObject(dimensions: Nullable<{
        framebufferWidth: number;
        framebufferHeight: number;
    }>);
    protected _rebuildBuffers(): void;
    /**
     * Get Font size information
     * @param font font name
     * @returns an object containing ascent, height and descent
     */
    getFontOffset(font: string): {
        ascent: number;
        height: number;
        descent: number;
    };
    protected _cancelFrame(): void;
    _renderLoop(timestamp?: number): void;
    /**
     * Enters Pointerlock mode
     */
    enterPointerlock(): void;
    /**
     * Exits Pointerlock mode
     */
    exitPointerlock(): void;
    /**
     * Begin a new frame
     */
    beginFrame(): void;
    _deletePipelineContext(pipelineContext: IPipelineContext): void;
    createShaderProgram(pipelineContext: IPipelineContext, vertexCode: string, fragmentCode: string, defines: Nullable<string>, context?: WebGLRenderingContext, transformFeedbackVaryings?: Nullable<string[]>): WebGLProgram;
    protected _createShaderProgram(pipelineContext: WebGLPipelineContext, vertexShader: WebGLShader, fragmentShader: WebGLShader, context: WebGLRenderingContext, transformFeedbackVaryings?: Nullable<string[]>): WebGLProgram;
    /**
     * @internal
     */
    _releaseTexture(texture: InternalTexture): void;
    /**
     * @internal
     */
    _releaseRenderTargetWrapper(rtWrapper: RenderTargetWrapper): void;
    /**
     * @internal
     * Rescales a texture
     * @param source input texture
     * @param destination destination texture
     * @param scene scene to use to render the resize
     * @param internalFormat format to use when resizing
     * @param onComplete callback to be called when resize has completed
     */
    _rescaleTexture(source: InternalTexture, destination: InternalTexture, scene: Nullable<any>, internalFormat: number, onComplete: () => void): void;
    /**
     * Wraps an external web gl texture in a Babylon texture.
     * @param texture defines the external texture
     * @param hasMipMaps defines whether the external texture has mip maps (default: false)
     * @param samplingMode defines the sampling mode for the external texture (default: Constants.TEXTURE_TRILINEAR_SAMPLINGMODE)
     * @param width defines the width for the external texture (default: 0)
     * @param height defines the height for the external texture (default: 0)
     * @returns the babylon internal texture
     */
    wrapWebGLTexture(texture: WebGLTexture, hasMipMaps?: boolean, samplingMode?: number, width?: number, height?: number): InternalTexture;
    /**
     * @internal
     */
    _uploadImageToTexture(texture: InternalTexture, image: HTMLImageElement | ImageBitmap, faceIndex?: number, lod?: number): void;
    /**
     * Updates a depth texture Comparison Mode and Function.
     * If the comparison Function is equal to 0, the mode will be set to none.
     * Otherwise, this only works in webgl 2 and requires a shadow sampler in the shader.
     * @param texture The texture to set the comparison function for
     * @param comparisonFunction The comparison function to set, 0 if no comparison required
     */
    updateTextureComparisonFunction(texture: InternalTexture, comparisonFunction: number): void;
    /**
     * Creates a webGL buffer to use with instantiation
     * @param capacity defines the size of the buffer
     * @returns the webGL buffer
     */
    createInstancesBuffer(capacity: number): DataBuffer;
    /**
     * Delete a webGL buffer used with instantiation
     * @param buffer defines the webGL buffer to delete
     */
    deleteInstancesBuffer(buffer: WebGLBuffer): void;
    private _clientWaitAsync;
    /**
     * This function might return null synchronously, so it is technically not async.
     * @internal
     */
    _readPixelsAsync(x: number, y: number, w: number, h: number, format: number, type: number, outputBuffer: ArrayBufferView): Nullable<Promise<ArrayBufferView>>;
    dispose(): void;
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Unbind a list of render target textures from the webGL context
         * This is used only when drawBuffer extension or webGL2 are active
         * @param rtWrapper defines the render target wrapper to unbind
         * @param disableGenerateMipMaps defines a boolean indicating that mipmaps must not be generated
         * @param onBeforeUnbind defines a function which will be called before the effective unbind
         */
        unBindMultiColorAttachmentFramebuffer(rtWrapper: RenderTargetWrapper, disableGenerateMipMaps: boolean, onBeforeUnbind?: () => void): void;
        /**
         * Create a multi render target texture
         * @see https://doc.babylonjs.com/setup/support/webGL2#multiple-render-target
         * @param size defines the size of the texture
         * @param options defines the creation options
         * @param initializeBuffers if set to true, the engine will make an initializing call of drawBuffers
         * @returns a new render target wrapper ready to render textures
         */
        createMultipleRenderTarget(size: TextureSize, options: IMultiRenderTargetOptions, initializeBuffers?: boolean): RenderTargetWrapper;
        /**
         * Update the sample count for a given multiple render target texture
         * @see https://doc.babylonjs.com/setup/support/webGL2#multisample-render-targets
         * @param rtWrapper defines the render target wrapper to update
         * @param samples defines the sample count to set
         * @param initializeBuffers if set to true, the engine will make an initializing call of drawBuffers
         * @returns the effective sample count (could be 0 if multisample render targets are not supported)
         */
        updateMultipleRenderTargetTextureSampleCount(rtWrapper: Nullable<RenderTargetWrapper>, samples: number, initializeBuffers?: boolean): number;
        /**
         * Generates mipmaps for the texture of the (multi) render target
         * @param texture The render target containing the textures to generate the mipmaps for
         */
        generateMipMapsMultiFramebuffer(texture: RenderTargetWrapper): void;
        /**
         * Resolves the MSAA textures of the (multi) render target into their non-MSAA version.
         * Note that if "texture" is not a MSAA render target, no resolve is performed.
         * @param texture The render target texture containing the MSAA textures to resolve
         */
        resolveMultiFramebuffer(texture: RenderTargetWrapper): void;
        /**
         * Select a subsets of attachments to draw to.
         * @param attachments gl attachments
         */
        bindAttachments(attachments: number[]): void;
        /**
         * Creates a layout object to draw/clear on specific textures in a MRT
         * @param textureStatus textureStatus[i] indicates if the i-th is active
         * @param backBufferLayout if true, the layout will be built to account for the back buffer only, and textureStatus won't be used
         * @returns A layout to be fed to the engine, calling `bindAttachments`.
         */
        buildTextureLayout(textureStatus: boolean[], backBufferLayout?: boolean): number[];
        /**
         * Restores the webgl state to only draw on the main color attachment
         * when the frame buffer associated is the canvas frame buffer
         */
        restoreSingleAttachment(): void;
        /**
         * Restores the webgl state to only draw on the main color attachment
         * when the frame buffer associated is not the canvas frame buffer
         */
        restoreSingleAttachmentForRenderTarget(): void;
    }
}

/**
 * Creation options of the multi render target texture.
 */
interface IMultiRenderTargetOptions {
    /**
     * Specifies if mipmaps must be created. If undefined, the value from generateMipMaps is taken instead
     */
    createMipMaps?: boolean;
    /**
     * Define if the texture needs to create mip maps after render (default: false).
     */
    generateMipMaps?: boolean;
    /**
     * Define the types of all the draw buffers (render textures) we want to create
     */
    types?: number[];
    /**
     * Define the sampling modes of all the draw buffers (render textures) we want to create
     */
    samplingModes?: number[];
    /**
     * Define if sRGB format should be used for each of the draw buffers (render textures) we want to create
     */
    useSRGBBuffers?: boolean[];
    /**
     * Define if a depth buffer is required (default: true)
     */
    generateDepthBuffer?: boolean;
    /**
     * Define if a stencil buffer is required (default: false)
     */
    generateStencilBuffer?: boolean;
    /**
     * Define if a depth texture is required instead of a depth buffer (default: false)
     */
    generateDepthTexture?: boolean;
    /**
     * Define the internal format of the buffer in the RTT (RED, RG, RGB, RGBA (default), ALPHA...) of all the draw buffers (render textures) we want to create
     */
    formats?: number[];
    /**
     * Define depth texture format to use
     */
    depthTextureFormat?: number;
    /**
     * Define the number of desired draw buffers (render textures). You can set it to 0 if you don't need any color attachment. (default: 1)
     */
    textureCount?: number;
    /**
     * Define if aspect ratio should be adapted to the texture or stay the scene one (default: true)
     */
    doNotChangeAspectRatio?: boolean;
    /**
     * Define the default type of the buffers we are creating (default: Constants.TEXTURETYPE_UNSIGNED_BYTE). types[] is prioritized over defaultType if provided.
     */
    defaultType?: number;
    /**
     * Defines sample count (1 by default)
     */
    samples?: number;
    /**
     * Defines if we should draw into all attachments or the first one only by default (default: false)
     */
    drawOnlyOnFirstAttachmentByDefault?: boolean;
    /**
     * Define the type of texture at each attahment index (of Constants.TEXTURE_2D, .TEXTURE_2D_ARRAY, .TEXTURE_CUBE_MAP, .TEXTURE_CUBE_MAP_ARRAY, .TEXTURE_3D).
     * You can also use the -1 value to indicate that no texture should be created but that you will assign a texture to that attachment index later.
     * Can be useful when you want to attach several layers of the same 2DArrayTexture / 3DTexture or several faces of the same CubeMapTexture: Use the setInternalTexture
     * method for that purpose, after the MultiRenderTarget has been created.
     */
    targetTypes?: number[];
    /**
     * Define the face index of each texture in the textures array (if applicable, given the corresponding targetType) at creation time (for Constants.TEXTURE_CUBE_MAP and .TEXTURE_CUBE_MAP_ARRAY).
     * Can be changed at any time by calling setLayerAndFaceIndices or setLayerAndFaceIndex
     */
    faceIndex?: number[];
    /**
     * Define the layer index of each texture in the textures array (if applicable, given the corresponding targetType) at creation time (for Constants.TEXTURE_3D, .TEXTURE_2D_ARRAY, and .TEXTURE_CUBE_MAP_ARRAY).
     * Can be changed at any time by calling setLayerAndFaceIndices or setLayerAndFaceIndex
     */
    layerIndex?: number[];
    /**
     * Define the number of layer of each texture in the textures array (if applicable, given the corresponding targetType) (for Constants.TEXTURE_3D, .TEXTURE_2D_ARRAY, and .TEXTURE_CUBE_MAP_ARRAY)
     */
    layerCounts?: number[];
    /**
     * Define the creation flags of the textures (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     */
    creationFlags?: number[];
    /**
     * Define the names of the textures (used for debugging purpose)
     */
    labels?: string[];
    /**
     * Label of the RenderTargetWrapper (used for debugging only)
     */
    label?: string;
    /**
     * Define if the textures should not be created by the MultiRenderTarget (default: false)
     * If true, you will need to set the textures yourself by calling setTexture on the MultiRenderTarget.
     */
    dontCreateTextures?: boolean;
}
/**
 * A multi render target, like a render target provides the ability to render to a texture.
 * Unlike the render target, it can render to several draw buffers (render textures) in one draw.
 * This is specially interesting in deferred rendering or for any effects requiring more than
 * just one color from a single pass.
 */
declare class MultiRenderTarget extends RenderTargetTexture {
    private _textures;
    private _multiRenderTargetOptions;
    private _count;
    private _drawOnlyOnFirstAttachmentByDefault;
    private _textureNames?;
    /**
     * Get if draw buffers (render textures) are currently supported by the used hardware and browser.
     */
    get isSupported(): boolean;
    /**
     * Get the list of textures generated by the multi render target.
     */
    get textures(): Texture[];
    /**
     * Gets the number of textures in this MRT. This number can be different from `_textures.length` in case a depth texture is generated.
     */
    get count(): number;
    /**
     * Get the depth texture generated by the multi render target if options.generateDepthTexture has been set
     */
    get depthTexture(): Texture;
    /**
     * Set the wrapping mode on U of all the textures we are rendering to.
     * Can be any of the Texture. (CLAMP_ADDRESSMODE, MIRROR_ADDRESSMODE or WRAP_ADDRESSMODE)
     */
    set wrapU(wrap: number);
    /**
     * Set the wrapping mode on V of all the textures we are rendering to.
     * Can be any of the Texture. (CLAMP_ADDRESSMODE, MIRROR_ADDRESSMODE or WRAP_ADDRESSMODE)
     */
    set wrapV(wrap: number);
    /**
     * Instantiate a new multi render target texture.
     * A multi render target, like a render target provides the ability to render to a texture.
     * Unlike the render target, it can render to several draw buffers (render textures) in one draw.
     * This is specially interesting in deferred rendering or for any effects requiring more than
     * just one color from a single pass.
     * @param name Define the name of the texture
     * @param size Define the size of the buffers to render to
     * @param count Define the number of target we are rendering into
     * @param scene Define the scene the texture belongs to
     * @param options Define the options used to create the multi render target
     * @param textureNames Define the names to set to the textures (if count \> 0 - optional)
     */
    constructor(name: string, size: any, count: number, scene?: Scene, options?: IMultiRenderTargetOptions, textureNames?: string[]);
    private _initTypes;
    private _createInternaTextureIndexMapping;
    /**
     * @internal
     */
    _rebuild(fromContextLost?: boolean, forceFullRebuild?: boolean, textureNames?: string[]): void;
    private _createInternalTextures;
    private _releaseTextures;
    private _createTextures;
    /**
     * Replaces an internal texture within the MRT. Useful to share textures between MultiRenderTarget.
     * @param texture The new texture to set in the MRT
     * @param index The index of the texture to replace
     * @param disposePrevious Set to true if the previous internal texture should be disposed
     */
    setInternalTexture(texture: InternalTexture, index: number, disposePrevious?: boolean): void;
    /**
     * Changes an attached texture's face index or layer.
     * @param index The index of the texture to modify the attachment of
     * @param layerIndex The layer index of the texture to be attached to the framebuffer
     * @param faceIndex The face index of the texture to be attached to the framebuffer
     */
    setLayerAndFaceIndex(index: number, layerIndex?: number, faceIndex?: number): void;
    /**
     * Changes every attached texture's face index or layer.
     * @param layerIndices The layer indices of the texture to be attached to the framebuffer
     * @param faceIndices The face indices of the texture to be attached to the framebuffer
     */
    setLayerAndFaceIndices(layerIndices: number[], faceIndices: number[]): void;
    /**
     * Define the number of samples used if MSAA is enabled.
     */
    get samples(): number;
    set samples(value: number);
    /**
     * Resize all the textures in the multi render target.
     * Be careful as it will recreate all the data in the new texture.
     * @param size Define the new size
     */
    resize(size: any): void;
    /**
     * Changes the number of render targets in this MRT
     * Be careful as it will recreate all the data in the new texture.
     * @param count new texture count
     * @param options Specifies texture types and sampling modes for new textures
     * @param textureNames Specifies the names of the textures (optional)
     */
    updateCount(count: number, options?: IMultiRenderTargetOptions, textureNames?: string[]): void;
    protected _unbindFrameBuffer(engine: Engine, faceIndex: number): void;
    /**
     * Dispose the render targets and their associated resources
     * @param doNotDisposeInternalTextures if set to true, internal textures won't be disposed (default: false).
     */
    dispose(doNotDisposeInternalTextures?: boolean): void;
    /**
     * Release all the underlying texture used as draw buffers (render textures).
     */
    releaseInternalTextures(): void;
}

/**
 * The color grading curves provide additional color adjustment that is applied after any color grading transform (3D LUT).
 * They allow basic adjustment of saturation and small exposure adjustments, along with color filter tinting to provide white balance adjustment or more stylistic effects.
 * These are similar to controls found in many professional imaging or colorist software. The global controls are applied to the entire image. For advanced tuning, extra controls are provided to adjust the shadow, midtone and highlight areas of the image;
 * corresponding to low luminance, medium luminance, and high luminance areas respectively.
 */
declare class ColorCurves {
    private _dirty;
    private _tempColor;
    private _globalCurve;
    private _highlightsCurve;
    private _midtonesCurve;
    private _shadowsCurve;
    private _positiveCurve;
    private _negativeCurve;
    private _globalHue;
    private _globalDensity;
    private _globalSaturation;
    private _globalExposure;
    /**
     * Gets the global Hue value.
     * The hue value is a standard HSB hue in the range [0,360] where 0=red, 120=green and 240=blue. The default value is 30 degrees (orange).
     */
    get globalHue(): number;
    /**
     * Sets the global Hue value.
     * The hue value is a standard HSB hue in the range [0,360] where 0=red, 120=green and 240=blue. The default value is 30 degrees (orange).
     */
    set globalHue(value: number);
    /**
     * Gets the global Density value.
     * The density value is in range [-100,+100] where 0 means the color filter has no effect and +100 means the color filter has maximum effect.
     * Values less than zero provide a filter of opposite hue.
     */
    get globalDensity(): number;
    /**
     * Sets the global Density value.
     * The density value is in range [-100,+100] where 0 means the color filter has no effect and +100 means the color filter has maximum effect.
     * Values less than zero provide a filter of opposite hue.
     */
    set globalDensity(value: number);
    /**
     * Gets the global Saturation value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase saturation and negative values decrease saturation.
     */
    get globalSaturation(): number;
    /**
     * Sets the global Saturation value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase saturation and negative values decrease saturation.
     */
    set globalSaturation(value: number);
    /**
     * Gets the global Exposure value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase exposure and negative values decrease exposure.
     */
    get globalExposure(): number;
    /**
     * Sets the global Exposure value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase exposure and negative values decrease exposure.
     */
    set globalExposure(value: number);
    private _highlightsHue;
    private _highlightsDensity;
    private _highlightsSaturation;
    private _highlightsExposure;
    /**
     * Gets the highlights Hue value.
     * The hue value is a standard HSB hue in the range [0,360] where 0=red, 120=green and 240=blue. The default value is 30 degrees (orange).
     */
    get highlightsHue(): number;
    /**
     * Sets the highlights Hue value.
     * The hue value is a standard HSB hue in the range [0,360] where 0=red, 120=green and 240=blue. The default value is 30 degrees (orange).
     */
    set highlightsHue(value: number);
    /**
     * Gets the highlights Density value.
     * The density value is in range [-100,+100] where 0 means the color filter has no effect and +100 means the color filter has maximum effect.
     * Values less than zero provide a filter of opposite hue.
     */
    get highlightsDensity(): number;
    /**
     * Sets the highlights Density value.
     * The density value is in range [-100,+100] where 0 means the color filter has no effect and +100 means the color filter has maximum effect.
     * Values less than zero provide a filter of opposite hue.
     */
    set highlightsDensity(value: number);
    /**
     * Gets the highlights Saturation value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase saturation and negative values decrease saturation.
     */
    get highlightsSaturation(): number;
    /**
     * Sets the highlights Saturation value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase saturation and negative values decrease saturation.
     */
    set highlightsSaturation(value: number);
    /**
     * Gets the highlights Exposure value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase exposure and negative values decrease exposure.
     */
    get highlightsExposure(): number;
    /**
     * Sets the highlights Exposure value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase exposure and negative values decrease exposure.
     */
    set highlightsExposure(value: number);
    private _midtonesHue;
    private _midtonesDensity;
    private _midtonesSaturation;
    private _midtonesExposure;
    /**
     * Gets the midtones Hue value.
     * The hue value is a standard HSB hue in the range [0,360] where 0=red, 120=green and 240=blue. The default value is 30 degrees (orange).
     */
    get midtonesHue(): number;
    /**
     * Sets the midtones Hue value.
     * The hue value is a standard HSB hue in the range [0,360] where 0=red, 120=green and 240=blue. The default value is 30 degrees (orange).
     */
    set midtonesHue(value: number);
    /**
     * Gets the midtones Density value.
     * The density value is in range [-100,+100] where 0 means the color filter has no effect and +100 means the color filter has maximum effect.
     * Values less than zero provide a filter of opposite hue.
     */
    get midtonesDensity(): number;
    /**
     * Sets the midtones Density value.
     * The density value is in range [-100,+100] where 0 means the color filter has no effect and +100 means the color filter has maximum effect.
     * Values less than zero provide a filter of opposite hue.
     */
    set midtonesDensity(value: number);
    /**
     * Gets the midtones Saturation value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase saturation and negative values decrease saturation.
     */
    get midtonesSaturation(): number;
    /**
     * Sets the midtones Saturation value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase saturation and negative values decrease saturation.
     */
    set midtonesSaturation(value: number);
    /**
     * Gets the midtones Exposure value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase exposure and negative values decrease exposure.
     */
    get midtonesExposure(): number;
    /**
     * Sets the midtones Exposure value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase exposure and negative values decrease exposure.
     */
    set midtonesExposure(value: number);
    private _shadowsHue;
    private _shadowsDensity;
    private _shadowsSaturation;
    private _shadowsExposure;
    /**
     * Gets the shadows Hue value.
     * The hue value is a standard HSB hue in the range [0,360] where 0=red, 120=green and 240=blue. The default value is 30 degrees (orange).
     */
    get shadowsHue(): number;
    /**
     * Sets the shadows Hue value.
     * The hue value is a standard HSB hue in the range [0,360] where 0=red, 120=green and 240=blue. The default value is 30 degrees (orange).
     */
    set shadowsHue(value: number);
    /**
     * Gets the shadows Density value.
     * The density value is in range [-100,+100] where 0 means the color filter has no effect and +100 means the color filter has maximum effect.
     * Values less than zero provide a filter of opposite hue.
     */
    get shadowsDensity(): number;
    /**
     * Sets the shadows Density value.
     * The density value is in range [-100,+100] where 0 means the color filter has no effect and +100 means the color filter has maximum effect.
     * Values less than zero provide a filter of opposite hue.
     */
    set shadowsDensity(value: number);
    /**
     * Gets the shadows Saturation value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase saturation and negative values decrease saturation.
     */
    get shadowsSaturation(): number;
    /**
     * Sets the shadows Saturation value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase saturation and negative values decrease saturation.
     */
    set shadowsSaturation(value: number);
    /**
     * Gets the shadows Exposure value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase exposure and negative values decrease exposure.
     */
    get shadowsExposure(): number;
    /**
     * Sets the shadows Exposure value.
     * This is an adjustment value in the range [-100,+100], where the default value of 0.0 makes no adjustment, positive values increase exposure and negative values decrease exposure.
     */
    set shadowsExposure(value: number);
    /**
     * Returns the class name
     * @returns The class name
     */
    getClassName(): string;
    /**
     * Binds the color curves to the shader.
     * @param colorCurves The color curve to bind
     * @param effect The effect to bind to
     * @param positiveUniform The positive uniform shader parameter
     * @param neutralUniform The neutral uniform shader parameter
     * @param negativeUniform The negative uniform shader parameter
     */
    static Bind(colorCurves: ColorCurves, effect: Effect, positiveUniform?: string, neutralUniform?: string, negativeUniform?: string): void;
    /**
     * Prepare the list of uniforms associated with the ColorCurves effects.
     * @param uniformsList The list of uniforms used in the effect
     */
    static PrepareUniforms: (uniformsList: string[]) => void;
    /**
     * Returns color grading data based on a hue, density, saturation and exposure value.
     * @param hue
     * @param density
     * @param saturation The saturation.
     * @param exposure The exposure.
     * @param result The result data container.
     */
    private _getColorGradingDataToRef;
    /**
     * Takes an input slider value and returns an adjusted value that provides extra control near the centre.
     * @param value The input slider value in range [-100,100].
     * @returns Adjusted value.
     */
    private static _ApplyColorGradingSliderNonlinear;
    /**
     * Returns an RGBA Color4 based on Hue, Saturation and Brightness (also referred to as value, HSV).
     * @param hue The hue (H) input.
     * @param saturation The saturation (S) input.
     * @param brightness The brightness (B) input.
     * @param result An RGBA color represented as Vector4.
     */
    private static _FromHSBToRef;
    /**
     * Returns a value clamped between min and max
     * @param value The value to clamp
     * @param min The minimum of value
     * @param max The maximum of value
     * @returns The clamped value.
     */
    private static _Clamp;
    /**
     * Clones the current color curve instance.
     * @returns The cloned curves
     */
    clone(): ColorCurves;
    /**
     * Serializes the current color curve instance to a json representation.
     * @returns a JSON representation
     */
    serialize(): any;
    /**
     * Parses the color curve from a json representation.
     * @param source the JSON source to parse
     * @returns The parsed curves
     */
    static Parse(source: any): ColorCurves;
}

/**
 * Interface to follow in your material defines to integrate easily the
 * Image processing functions.
 * @internal
 */
interface IImageProcessingConfigurationDefines {
    IMAGEPROCESSING: boolean;
    VIGNETTE: boolean;
    VIGNETTEBLENDMODEMULTIPLY: boolean;
    VIGNETTEBLENDMODEOPAQUE: boolean;
    TONEMAPPING: number;
    CONTRAST: boolean;
    EXPOSURE: boolean;
    COLORCURVES: boolean;
    COLORGRADING: boolean;
    COLORGRADING3D: boolean;
    SAMPLER3DGREENDEPTH: boolean;
    SAMPLER3DBGRMAP: boolean;
    DITHER: boolean;
    IMAGEPROCESSINGPOSTPROCESS: boolean;
    SKIPFINALCOLORCLAMP: boolean;
}
/**
 * @internal
 */
declare class ImageProcessingConfigurationDefines extends MaterialDefines implements IImageProcessingConfigurationDefines {
    IMAGEPROCESSING: boolean;
    VIGNETTE: boolean;
    VIGNETTEBLENDMODEMULTIPLY: boolean;
    VIGNETTEBLENDMODEOPAQUE: boolean;
    TONEMAPPING: number;
    CONTRAST: boolean;
    COLORCURVES: boolean;
    COLORGRADING: boolean;
    COLORGRADING3D: boolean;
    SAMPLER3DGREENDEPTH: boolean;
    SAMPLER3DBGRMAP: boolean;
    DITHER: boolean;
    IMAGEPROCESSINGPOSTPROCESS: boolean;
    EXPOSURE: boolean;
    SKIPFINALCOLORCLAMP: boolean;
    constructor();
}

/**
 * This groups together the common properties used for image processing either in direct forward pass
 * or through post processing effect depending on the use of the image processing pipeline in your scene
 * or not.
 */
declare class ImageProcessingConfiguration {
    /**
     * Default tone mapping applied in BabylonJS.
     */
    static readonly TONEMAPPING_STANDARD = 0;
    /**
     * ACES Tone mapping (used by default in unreal and unity). This can help getting closer
     * to other engines rendering to increase portability.
     */
    static readonly TONEMAPPING_ACES = 1;
    /**
     * Neutral Tone mapping developped by the Khronos group in order to constrain
     * values between 0 and 1 without shifting Hue.
     */
    static readonly TONEMAPPING_KHR_PBR_NEUTRAL = 2;
    /**
     * Color curves setup used in the effect if colorCurvesEnabled is set to true
     */
    colorCurves: Nullable<ColorCurves>;
    private _colorCurvesEnabled;
    /**
     * Gets whether the color curves effect is enabled.
     */
    get colorCurvesEnabled(): boolean;
    /**
     * Sets whether the color curves effect is enabled.
     */
    set colorCurvesEnabled(value: boolean);
    private _colorGradingTexture;
    /**
     * Color grading LUT texture used in the effect if colorGradingEnabled is set to true
     */
    get colorGradingTexture(): Nullable<BaseTexture>;
    /**
     * Color grading LUT texture used in the effect if colorGradingEnabled is set to true
     */
    set colorGradingTexture(value: Nullable<BaseTexture>);
    private _colorGradingEnabled;
    /**
     * Gets whether the color grading effect is enabled.
     */
    get colorGradingEnabled(): boolean;
    /**
     * Sets whether the color grading effect is enabled.
     */
    set colorGradingEnabled(value: boolean);
    private _colorGradingWithGreenDepth;
    /**
     * Gets whether the color grading effect is using a green depth for the 3d Texture.
     */
    get colorGradingWithGreenDepth(): boolean;
    /**
     * Sets whether the color grading effect is using a green depth for the 3d Texture.
     */
    set colorGradingWithGreenDepth(value: boolean);
    private _colorGradingBGR;
    /**
     * Gets whether the color grading texture contains BGR values.
     */
    get colorGradingBGR(): boolean;
    /**
     * Sets whether the color grading texture contains BGR values.
     */
    set colorGradingBGR(value: boolean);
    /** @internal */
    _exposure: number;
    /**
     * Gets the Exposure used in the effect.
     */
    get exposure(): number;
    /**
     * Sets the Exposure used in the effect.
     */
    set exposure(value: number);
    private _toneMappingEnabled;
    /**
     * Gets whether the tone mapping effect is enabled.
     */
    get toneMappingEnabled(): boolean;
    /**
     * Sets whether the tone mapping effect is enabled.
     */
    set toneMappingEnabled(value: boolean);
    private _toneMappingType;
    /**
     * Gets the type of tone mapping effect.
     */
    get toneMappingType(): number;
    /**
     * Sets the type of tone mapping effect used in BabylonJS.
     */
    set toneMappingType(value: number);
    protected _contrast: number;
    /**
     * Gets the contrast used in the effect.
     */
    get contrast(): number;
    /**
     * Sets the contrast used in the effect.
     */
    set contrast(value: number);
    /**
     * Vignette stretch size.
     */
    vignetteStretch: number;
    /**
     * Vignette center X Offset.
     */
    vignetteCenterX: number;
    /**
     * Vignette center Y Offset.
     */
    vignetteCenterY: number;
    /**
     * Back Compat: Vignette center Y Offset.
     * @deprecated use vignetteCenterY instead
     */
    get vignetteCentreY(): number;
    set vignetteCentreY(value: number);
    /**
     * Back Compat: Vignette center X Offset.
     * @deprecated use vignetteCenterX instead
     */
    get vignetteCentreX(): number;
    set vignetteCentreX(value: number);
    /**
     * Vignette weight or intensity of the vignette effect.
     */
    vignetteWeight: number;
    /**
     * Color of the vignette applied on the screen through the chosen blend mode (vignetteBlendMode)
     * if vignetteEnabled is set to true.
     */
    vignetteColor: Color4;
    /**
     * Camera field of view used by the Vignette effect.
     */
    vignetteCameraFov: number;
    private _vignetteBlendMode;
    /**
     * Gets the vignette blend mode allowing different kind of effect.
     */
    get vignetteBlendMode(): number;
    /**
     * Sets the vignette blend mode allowing different kind of effect.
     */
    set vignetteBlendMode(value: number);
    private _vignetteEnabled;
    /**
     * Gets whether the vignette effect is enabled.
     */
    get vignetteEnabled(): boolean;
    /**
     * Sets whether the vignette effect is enabled.
     */
    set vignetteEnabled(value: boolean);
    private _ditheringEnabled;
    /**
     * Gets whether the dithering effect is enabled.
     * The dithering effect can be used to reduce banding.
     */
    get ditheringEnabled(): boolean;
    /**
     * Sets whether the dithering effect is enabled.
     * The dithering effect can be used to reduce banding.
     */
    set ditheringEnabled(value: boolean);
    private _ditheringIntensity;
    /**
     * Gets the dithering intensity. 0 is no dithering. Default is 1.0 / 255.0.
     */
    get ditheringIntensity(): number;
    /**
     * Sets the dithering intensity. 0 is no dithering. Default is 1.0 / 255.0.
     */
    set ditheringIntensity(value: number);
    /** @internal */
    _skipFinalColorClamp: boolean;
    /**
     * If apply by post process is set to true, setting this to true will skip the final color clamp step in the fragment shader
     * Applies to PBR materials.
     */
    get skipFinalColorClamp(): boolean;
    /**
     * If apply by post process is set to true, setting this to true will skip the final color clamp step in the fragment shader
     * Applies to PBR materials.
     */
    set skipFinalColorClamp(value: boolean);
    /** @internal */
    _applyByPostProcess: boolean;
    /**
     * Gets whether the image processing is applied through a post process or not.
     */
    get applyByPostProcess(): boolean;
    /**
     * Sets whether the image processing is applied through a post process or not.
     */
    set applyByPostProcess(value: boolean);
    private _isEnabled;
    /**
     * Gets whether the image processing is enabled or not.
     */
    get isEnabled(): boolean;
    /**
     * Sets whether the image processing is enabled or not.
     */
    set isEnabled(value: boolean);
    /**
     * Width of the output texture used in the post process. If not provided, uses the width of the screen.
     */
    outputTextureWidth: number;
    /**
     * Height of the output texture used in the post process. If not provided, uses the height of the screen.
     */
    outputTextureHeight: number;
    /**
     * An event triggered when the configuration changes and requires Shader to Update some parameters.
     */
    onUpdateParameters: Observable<ImageProcessingConfiguration>;
    /**
     * Method called each time the image processing information changes requires to recompile the effect.
     */
    protected _updateParameters(): void;
    /**
     * Gets the current class name.
     * @returns "ImageProcessingConfiguration"
     */
    getClassName(): string;
    /**
     * Prepare the list of uniforms associated with the Image Processing effects.
     * @param uniforms The list of uniforms used in the effect
     * @param defines the list of defines currently in use
     */
    static PrepareUniforms: (uniforms: string[], defines: IImageProcessingConfigurationDefines) => void;
    /**
     * Prepare the list of samplers associated with the Image Processing effects.
     * @param samplersList The list of uniforms used in the effect
     * @param defines the list of defines currently in use
     */
    static PrepareSamplers: (samplersList: string[], defines: IImageProcessingConfigurationDefines) => void;
    /**
     * Prepare the list of defines associated to the shader.
     * @param defines the list of defines to complete
     * @param forPostProcess Define if we are currently in post process mode or not
     */
    prepareDefines(defines: IImageProcessingConfigurationDefines, forPostProcess?: boolean): void;
    /**
     * Returns true if all the image processing information are ready.
     * @returns True if ready, otherwise, false
     */
    isReady(): boolean;
    /**
     * Binds the image processing to the shader.
     * @param effect The effect to bind to
     * @param overrideAspectRatio Override the aspect ratio of the effect
     */
    bind(effect: Effect, overrideAspectRatio?: number): void;
    /**
     * Clones the current image processing instance.
     * @returns The cloned image processing
     */
    clone(): ImageProcessingConfiguration;
    /**
     * Serializes the current image processing instance to a json representation.
     * @returns a JSON representation
     */
    serialize(): any;
    /**
     * Parses the image processing from a json representation.
     * @param source the JSON source to parse
     * @returns The parsed image processing
     */
    static Parse(source: any): ImageProcessingConfiguration;
    private static _VIGNETTEMODE_MULTIPLY;
    private static _VIGNETTEMODE_OPAQUE;
    /**
     * Used to apply the vignette as a mix with the pixel color.
     */
    static get VIGNETTEMODE_MULTIPLY(): number;
    /**
     * Used to apply the vignette as a replacement of the pixel color.
     */
    static get VIGNETTEMODE_OPAQUE(): number;
}

/**
 * Effect Render Options
 */
interface IEffectRendererOptions {
    /**
     * Defines the vertices positions.
     */
    positions?: number[];
    /**
     * Defines the indices.
     */
    indices?: number[];
}
/**
 * Helper class to render one or more effects.
 * You can access the previous rendering in your shader by declaring a sampler named textureSampler
 */
declare class EffectRenderer {
    /**
     * The engine the effect renderer has been created for.
     */
    readonly engine: AbstractEngine;
    private _vertexBuffers;
    private _indexBuffer;
    private _indexBufferLength;
    private _fullscreenViewport;
    private _onContextRestoredObserver;
    private _savedStateDepthTest;
    private _savedStateStencilTest;
    /**
     * Creates an effect renderer
     * @param engine the engine to use for rendering
     * @param options defines the options of the effect renderer
     */
    constructor(engine: AbstractEngine, options?: IEffectRendererOptions);
    /**
     * Sets the current viewport in normalized coordinates 0-1
     * @param viewport Defines the viewport to set (defaults to 0 0 1 1)
     */
    setViewport(viewport?: Viewport): void;
    /**
     * Binds the embedded attributes buffer to the effect.
     * @param effect Defines the effect to bind the attributes for
     */
    bindBuffers(effect: Effect): void;
    /**
     * Sets the current effect wrapper to use during draw.
     * The effect needs to be ready before calling this api.
     * This also sets the default full screen position attribute.
     * @param effectWrapper Defines the effect to draw with
     * @param depthTest Whether to enable depth testing (default: false)
     * @param stencilTest Whether to enable stencil testing (default: false)
     */
    applyEffectWrapper(effectWrapper: EffectWrapper, depthTest?: boolean, stencilTest?: boolean): void;
    /**
     * Saves engine states
     */
    saveStates(): void;
    /**
     * Restores engine states
     */
    restoreStates(): void;
    /**
     * Draws a full screen quad.
     */
    draw(): void;
    private _isRenderTargetTexture;
    /**
     * renders one or more effects to a specified texture
     * @param effectWrapper the effect to renderer
     * @param outputTexture texture to draw to, if null it will render to the currently bound frame buffer
     */
    render(effectWrapper: EffectWrapper, outputTexture?: Nullable<RenderTargetWrapper | IRenderTargetTexture>): void;
    /**
     * Disposes of the effect renderer
     */
    dispose(): void;
}
/**
 * Allows for custom processing of the shader code used by an effect wrapper
 */
type EffectWrapperCustomShaderCodeProcessing = {
    /**
     * If provided, will be called two times with the vertex and fragment code so that this code can be updated after the #include have been processed
     */
    processCodeAfterIncludes?: (postProcessName: string, shaderType: string, code: string) => string;
    /**
     * If provided, will be called two times with the vertex and fragment code so that this code can be updated before it is compiled by the GPU
     */
    processFinalCode?: (postProcessName: string, shaderType: string, code: string) => string;
    /**
     * If provided, will be called before creating the effect to collect additional custom bindings (defines, uniforms, samplers)
     */
    defineCustomBindings?: (postProcessName: string, defines: Nullable<string>, uniforms: string[], samplers: string[]) => Nullable<string>;
    /**
     * If provided, will be called when binding inputs to the shader code to allow the user to add custom bindings
     */
    bindCustomBindings?: (postProcessName: string, effect: Effect) => void;
};
/**
 * Options to create an EffectWrapper
 */
interface EffectWrapperCreationOptions {
    /**
     * Engine to use to create the effect
     */
    engine?: AbstractEngine;
    /**
     * Fragment shader for the effect
     */
    fragmentShader?: string;
    /**
     * Use the shader store instead of direct source code
     */
    useShaderStore?: boolean;
    /**
     * Vertex shader for the effect (default: "postprocess")
     */
    vertexShader?: string;
    /**
     * Alias for vertexShader
     */
    vertexUrl?: string;
    /**
     * Attributes to use in the shader (default: ["position"])
     */
    attributeNames?: Array<string>;
    /**
     * Uniforms to use in the shader
     */
    uniformNames?: Array<string>;
    /**
     * Alias for uniformNames. Note that if it is provided, it takes precedence over uniformNames.
     */
    uniforms?: Nullable<string[]>;
    /**
     * Texture sampler names to use in the shader
     */
    samplerNames?: Array<string>;
    /**
     * Alias for samplerNames. Note that if it is provided, it takes precedence over samplerNames.
     */
    samplers?: Nullable<string[]>;
    /**
     * The list of uniform buffers used in the shader (if any)
     */
    uniformBuffers?: Nullable<string[]>;
    /**
     * Defines to use in the shader
     */
    defines?: Nullable<string | Array<string>>;
    /**
     * The index parameters to be used for babylons include syntax "#include<kernelBlurVaryingDeclaration>[0..varyingCount]". (default: undefined)
     * See usage in babylon.blurPostProcess.ts and kernelBlur.vertex.fx
     */
    indexParameters?: any;
    /**
     * If the shader should not be compiled immediately. (default: false)
     */
    blockCompilation?: boolean;
    /**
     * Callback when effect is compiled
     */
    onCompiled?: Nullable<(effect: Effect) => void>;
    /**
     * The friendly name of the effect (default: "effectWrapper")
     */
    name?: string;
    /**
     * The language the shader is written in (default: GLSL)
     */
    shaderLanguage?: ShaderLanguage;
    /**
     * Defines additional code to call to prepare the shader code
     */
    extraInitializations?: (useWebGPU: boolean, list: Promise<any>[]) => void;
    /**
     * Additional async code to run before preparing the effect
     */
    extraInitializationsAsync?: () => Promise<void>;
    /**
     * If the effect should be used as a post process (default: false). If true, the effect will be created with a "scale" uniform and a "textureSampler" sampler
     */
    useAsPostProcess?: boolean;
    /**
     * Sets this property to true if the fragment shader doesn't use a textureSampler texture (default: false).
     */
    allowEmptySourceTexture?: boolean;
}
/**
 * Wraps an effect to be used for rendering
 */
declare class EffectWrapper {
    /**
     * Force code to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    private static _CustomShaderCodeProcessing;
    /**
     * Registers a shader code processing with an effect wrapper name.
     * @param effectWrapperName name of the effect wrapper. Use null for the fallback shader code processing. This is the shader code processing that will be used in case no specific shader code processing has been associated to an effect wrapper name
     * @param customShaderCodeProcessing shader code processing to associate to the effect wrapper name
     */
    static RegisterShaderCodeProcessing(effectWrapperName: Nullable<string>, customShaderCodeProcessing?: EffectWrapperCustomShaderCodeProcessing): void;
    private static _GetShaderCodeProcessing;
    /**
     * Gets or sets the name of the effect wrapper
     */
    get name(): string;
    set name(value: string);
    /**
     * Type of alpha mode to use when applying the effect (default: Engine.ALPHA_DISABLE). Used only if useAsPostProcess is true.
     */
    alphaMode: number;
    /**
     * Executed when the effect is created
     * @returns effect that was created for this effect wrapper
     */
    onEffectCreatedObservable: Observable<Effect>;
    /**
     * Options used to create the effect wrapper
     */
    readonly options: Required<NonNullableFields<EffectWrapperCreationOptions>>;
    /**
     * Get a value indicating if the effect is ready to be used
     * @returns true if the post-process is ready (shader is compiled)
     */
    isReady(): boolean;
    /**
     * Get the draw wrapper associated with the effect wrapper
     * @returns the draw wrapper associated with the effect wrapper
     */
    get drawWrapper(): DrawWrapper;
    /**
     * Event that is fired (only when the EffectWrapper is used with an EffectRenderer) right before the effect is drawn (should be used to update uniforms)
     */
    onApplyObservable: Observable<{}>;
    /**
     * The underlying effect
     */
    get effect(): Effect;
    set effect(effect: Effect);
    protected readonly _drawWrapper: DrawWrapper;
    protected _shadersLoaded: boolean;
    protected readonly _shaderPath: IShaderPath;
    /** @internal */
    _webGPUReady: boolean;
    private _onContextRestoredObserver;
    /**
     * Creates an effect to be rendered
     * @param creationOptions options to create the effect
     */
    constructor(creationOptions: EffectWrapperCreationOptions);
    protected _gatherImports(_useWebGPU: boolean | undefined, _list: Promise<any>[]): void;
    private _importPromises;
    /** @internal */
    _postConstructor(blockCompilation: boolean, defines?: Nullable<string>, extraInitializations?: (useWebGPU: boolean, list: Promise<any>[]) => void, importPromises?: Array<Promise<any>>): void;
    /**
     * Updates the effect with the current effect wrapper compile time values and recompiles the shader.
     * @param defines Define statements that should be added at the beginning of the shader. (default: null)
     * @param uniforms Set of uniform variables that will be passed to the shader. (default: null)
     * @param samplers Set of Texture2D variables that will be passed to the shader. (default: null)
     * @param indexParameters The index parameters to be used for babylons include syntax "#include<kernelBlurVaryingDeclaration>[0..varyingCount]". (default: undefined) See usage in babylon.blurPostProcess.ts and kernelBlur.vertex.fx
     * @param onCompiled Called when the shader has been compiled.
     * @param onError Called if there is an error when compiling a shader.
     * @param vertexUrl The url of the vertex shader to be used (default: the one given at construction time)
     * @param fragmentUrl The url of the fragment shader to be used (default: the one given at construction time)
     */
    updateEffect(defines?: Nullable<string>, uniforms?: Nullable<string[]>, samplers?: Nullable<string[]>, indexParameters?: any, onCompiled?: (effect: Effect) => void, onError?: (effect: Effect, errors: string) => void, vertexUrl?: string, fragmentUrl?: string): void;
    /**
     * Binds the data to the effect.
     * @param noDefaultBindings if true, the default bindings (scale and alpha mode) will not be set.
     */
    bind(noDefaultBindings?: boolean): void;
    /**
     * Disposes of the effect wrapper
     * @param _ignored kept for backward compatibility
     */
    dispose(_ignored?: boolean): void;
}

/**
 * Options used to create a ThinImageProcessingPostProcessOptions.
 */
interface ThinImageProcessingPostProcessOptions extends EffectWrapperCreationOptions {
    /**
     * An existing image processing configuration to use. If not provided, the scene one will be used.
     */
    imageProcessingConfiguration?: ImageProcessingConfiguration;
    /**
     * The scene to retrieve the image processing configuration from if not provided in the options.
     * If not provided, the last created scene will be used.
     */
    scene?: Nullable<Scene>;
}
/**
 * Post process used to apply image processing to a scene
 */
declare class ThinImageProcessingPostProcess extends EffectWrapper {
    /**
     * The fragment shader url
     */
    static readonly FragmentUrl = "imageProcessing";
    protected _gatherImports(useWebGPU: boolean, list: Promise<any>[]): void;
    /**
     * Default configuration related to image processing available in the PBR Material.
     */
    protected _imageProcessingConfiguration: ImageProcessingConfiguration;
    /**
     * Gets the image processing configuration used either in this material.
     */
    get imageProcessingConfiguration(): ImageProcessingConfiguration;
    /**
     * Sets the Default image processing configuration used either in the this material.
     *
     * If sets to null, the scene one is in use.
     */
    set imageProcessingConfiguration(value: ImageProcessingConfiguration);
    /**
     * Keep track of the image processing observer to allow dispose and replace.
     */
    private _imageProcessingObserver;
    /**
     * Attaches a new image processing configuration to the PBR Material.
     * @param configuration
     * @param doNotBuild
     */
    protected _attachImageProcessingConfiguration(configuration: Nullable<ImageProcessingConfiguration>, doNotBuild?: boolean): void;
    /**
     * Gets Color curves setup used in the effect if colorCurvesEnabled is set to true .
     */
    get colorCurves(): Nullable<ColorCurves>;
    /**
     * Sets Color curves setup used in the effect if colorCurvesEnabled is set to true .
     */
    set colorCurves(value: Nullable<ColorCurves>);
    /**
     * Gets whether the color curves effect is enabled.
     */
    get colorCurvesEnabled(): boolean;
    /**
     * Sets whether the color curves effect is enabled.
     */
    set colorCurvesEnabled(value: boolean);
    /**
     * Gets Color grading LUT texture used in the effect if colorGradingEnabled is set to true.
     */
    get colorGradingTexture(): Nullable<BaseTexture>;
    /**
     * Sets Color grading LUT texture used in the effect if colorGradingEnabled is set to true.
     */
    set colorGradingTexture(value: Nullable<BaseTexture>);
    /**
     * Gets whether the color grading effect is enabled.
     */
    get colorGradingEnabled(): boolean;
    /**
     * Gets whether the color grading effect is enabled.
     */
    set colorGradingEnabled(value: boolean);
    /**
     * Gets exposure used in the effect.
     */
    get exposure(): number;
    /**
     * Sets exposure used in the effect.
     */
    set exposure(value: number);
    /**
     * Gets whether tonemapping is enabled or not.
     */
    get toneMappingEnabled(): boolean;
    /**
     * Sets whether tonemapping is enabled or not
     */
    set toneMappingEnabled(value: boolean);
    /**
     * Gets the type of tone mapping effect.
     */
    get toneMappingType(): number;
    /**
     * Sets the type of tone mapping effect.
     */
    set toneMappingType(value: number);
    /**
     * Gets contrast used in the effect.
     */
    get contrast(): number;
    /**
     * Sets contrast used in the effect.
     */
    set contrast(value: number);
    /**
     * Gets Vignette stretch size.
     */
    get vignetteStretch(): number;
    /**
     * Sets Vignette stretch size.
     */
    set vignetteStretch(value: number);
    /**
     * Gets Vignette center X Offset.
     * @deprecated use vignetteCenterX instead
     */
    get vignetteCentreX(): number;
    /**
     * Sets Vignette center X Offset.
     * @deprecated use vignetteCenterX instead
     */
    set vignetteCentreX(value: number);
    /**
     * Gets Vignette center Y Offset.
     * @deprecated use vignetteCenterY instead
     */
    get vignetteCentreY(): number;
    /**
     * Sets Vignette center Y Offset.
     * @deprecated use vignetteCenterY instead
     */
    set vignetteCentreY(value: number);
    /**
     * Vignette center Y Offset.
     */
    get vignetteCenterY(): number;
    set vignetteCenterY(value: number);
    /**
     * Vignette center X Offset.
     */
    get vignetteCenterX(): number;
    set vignetteCenterX(value: number);
    /**
     * Gets Vignette weight or intensity of the vignette effect.
     */
    get vignetteWeight(): number;
    /**
     * Sets Vignette weight or intensity of the vignette effect.
     */
    set vignetteWeight(value: number);
    /**
     * Gets Color of the vignette applied on the screen through the chosen blend mode (vignetteBlendMode)
     * if vignetteEnabled is set to true.
     */
    get vignetteColor(): Color4;
    /**
     * Sets Color of the vignette applied on the screen through the chosen blend mode (vignetteBlendMode)
     * if vignetteEnabled is set to true.
     */
    set vignetteColor(value: Color4);
    /**
     * Gets Camera field of view used by the Vignette effect.
     */
    get vignetteCameraFov(): number;
    /**
     * Sets Camera field of view used by the Vignette effect.
     */
    set vignetteCameraFov(value: number);
    /**
     * Gets the vignette blend mode allowing different kind of effect.
     */
    get vignetteBlendMode(): number;
    /**
     * Sets the vignette blend mode allowing different kind of effect.
     */
    set vignetteBlendMode(value: number);
    /**
     * Gets whether the vignette effect is enabled.
     */
    get vignetteEnabled(): boolean;
    /**
     * Sets whether the vignette effect is enabled.
     */
    set vignetteEnabled(value: boolean);
    /**
     * Gets intensity of the dithering effect.
     */
    get ditheringIntensity(): number;
    /**
     * Sets intensity of the dithering effect.
     */
    set ditheringIntensity(value: number);
    /**
     * Gets whether the dithering effect is enabled.
     */
    get ditheringEnabled(): boolean;
    /**
     * Sets whether the dithering effect is enabled.
     */
    set ditheringEnabled(value: boolean);
    private _fromLinearSpace;
    /**
     * Gets whether the input of the processing is in Gamma or Linear Space.
     */
    get fromLinearSpace(): boolean;
    /**
     * Sets whether the input of the processing is in Gamma or Linear Space.
     */
    set fromLinearSpace(value: boolean);
    /**
     * * Gets the width of the output texture used to store the result of the post process.
     */
    get outputTextureWidth(): number;
    /**
     * * Sets the width of the output texture used to store the result of the post process.
     */
    set outputTextureWidth(value: number);
    /**
     * * Gets the height of the output texture used to store the result of the post process.
     */
    get outputTextureHeight(): number;
    /**
     * * Sets the height of the output texture used to store the result of the post process.
     */
    set outputTextureHeight(value: number);
    /**
     * Gets/sets the aspect ratio used to override the default one.
     */
    overrideAspectRatio?: number;
    /**
     * Defines cache preventing GC.
     */
    private _defines;
    readonly options: Required<NonNullableFields<ThinImageProcessingPostProcessOptions>>;
    /**
     * Constructs a new image processing post process
     * @param name Name of the effect
     * @param engine Engine to use to render the effect. If not provided, the last created engine will be used
     * @param options Options to configure the effect
     */
    constructor(name: string, engine?: Nullable<AbstractEngine>, options?: ThinImageProcessingPostProcessOptions);
    /**
     * @internal
     */
    _updateParameters(): void;
    bind(noDefaultBindings?: boolean): void;
    dispose(): void;
}

/**
 * ImageProcessingPostProcess
 * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/usePostProcesses#imageprocessing
 */
declare class ImageProcessingPostProcess extends PostProcess {
    protected get _imageProcessingConfiguration(): ImageProcessingConfiguration;
    /**
     * Gets the image processing configuration used either in this material.
     */
    get imageProcessingConfiguration(): ImageProcessingConfiguration;
    /**
     * Sets the Default image processing configuration used either in the this material.
     *
     * If sets to null, the scene one is in use.
     */
    set imageProcessingConfiguration(value: ImageProcessingConfiguration);
    /**
     * If the post process is supported.
     */
    get isSupported(): boolean;
    /**
     * Gets Color curves setup used in the effect if colorCurvesEnabled is set to true .
     */
    get colorCurves(): Nullable<ColorCurves>;
    /**
     * Sets Color curves setup used in the effect if colorCurvesEnabled is set to true .
     */
    set colorCurves(value: Nullable<ColorCurves>);
    /**
     * Gets whether the color curves effect is enabled.
     */
    get colorCurvesEnabled(): boolean;
    /**
     * Sets whether the color curves effect is enabled.
     */
    set colorCurvesEnabled(value: boolean);
    /**
     * Gets Color grading LUT texture used in the effect if colorGradingEnabled is set to true.
     */
    get colorGradingTexture(): Nullable<BaseTexture>;
    /**
     * Sets Color grading LUT texture used in the effect if colorGradingEnabled is set to true.
     */
    set colorGradingTexture(value: Nullable<BaseTexture>);
    /**
     * Gets whether the color grading effect is enabled.
     */
    get colorGradingEnabled(): boolean;
    /**
     * Gets whether the color grading effect is enabled.
     */
    set colorGradingEnabled(value: boolean);
    /**
     * Gets exposure used in the effect.
     */
    get exposure(): number;
    /**
     * Sets exposure used in the effect.
     */
    set exposure(value: number);
    /**
     * Gets whether tonemapping is enabled or not.
     */
    get toneMappingEnabled(): boolean;
    /**
     * Sets whether tonemapping is enabled or not
     */
    set toneMappingEnabled(value: boolean);
    /**
     * Gets the type of tone mapping effect.
     */
    get toneMappingType(): number;
    /**
     * Sets the type of tone mapping effect.
     */
    set toneMappingType(value: number);
    /**
     * Gets contrast used in the effect.
     */
    get contrast(): number;
    /**
     * Sets contrast used in the effect.
     */
    set contrast(value: number);
    /**
     * Gets Vignette stretch size.
     */
    get vignetteStretch(): number;
    /**
     * Sets Vignette stretch size.
     */
    set vignetteStretch(value: number);
    /**
     * Gets Vignette center X Offset.
     * @deprecated use vignetteCenterX instead
     */
    get vignetteCentreX(): number;
    /**
     * Sets Vignette center X Offset.
     * @deprecated use vignetteCenterX instead
     */
    set vignetteCentreX(value: number);
    /**
     * Gets Vignette center Y Offset.
     * @deprecated use vignetteCenterY instead
     */
    get vignetteCentreY(): number;
    /**
     * Sets Vignette center Y Offset.
     * @deprecated use vignetteCenterY instead
     */
    set vignetteCentreY(value: number);
    /**
     * Vignette center Y Offset.
     */
    get vignetteCenterY(): number;
    set vignetteCenterY(value: number);
    /**
     * Vignette center X Offset.
     */
    get vignetteCenterX(): number;
    set vignetteCenterX(value: number);
    /**
     * Gets Vignette weight or intensity of the vignette effect.
     */
    get vignetteWeight(): number;
    /**
     * Sets Vignette weight or intensity of the vignette effect.
     */
    set vignetteWeight(value: number);
    /**
     * Gets Color of the vignette applied on the screen through the chosen blend mode (vignetteBlendMode)
     * if vignetteEnabled is set to true.
     */
    get vignetteColor(): Color4;
    /**
     * Sets Color of the vignette applied on the screen through the chosen blend mode (vignetteBlendMode)
     * if vignetteEnabled is set to true.
     */
    set vignetteColor(value: Color4);
    /**
     * Gets Camera field of view used by the Vignette effect.
     */
    get vignetteCameraFov(): number;
    /**
     * Sets Camera field of view used by the Vignette effect.
     */
    set vignetteCameraFov(value: number);
    /**
     * Gets the vignette blend mode allowing different kind of effect.
     */
    get vignetteBlendMode(): number;
    /**
     * Sets the vignette blend mode allowing different kind of effect.
     */
    set vignetteBlendMode(value: number);
    /**
     * Gets whether the vignette effect is enabled.
     */
    get vignetteEnabled(): boolean;
    /**
     * Sets whether the vignette effect is enabled.
     */
    set vignetteEnabled(value: boolean);
    /**
     * Gets intensity of the dithering effect.
     */
    get ditheringIntensity(): number;
    /**
     * Sets intensity of the dithering effect.
     */
    set ditheringIntensity(value: number);
    /**
     * Gets whether the dithering effect is enabled.
     */
    get ditheringEnabled(): boolean;
    /**
     * Sets whether the dithering effect is enabled.
     */
    set ditheringEnabled(value: boolean);
    /**
     * Gets whether the input of the processing is in Gamma or Linear Space.
     */
    get fromLinearSpace(): boolean;
    /**
     * Sets whether the input of the processing is in Gamma or Linear Space.
     */
    set fromLinearSpace(value: boolean);
    protected _effectWrapper: ThinImageProcessingPostProcess;
    constructor(name: string, options: number | PostProcessOptions, camera?: Nullable<Camera>, samplingMode?: number, engine?: AbstractEngine, reusable?: boolean, textureType?: number, imageProcessingConfiguration?: ImageProcessingConfiguration);
    /**
     *  "ImageProcessingPostProcess"
     * @returns "ImageProcessingPostProcess"
     */
    getClassName(): string;
    /**
     * @internal
     */
    _updateParameters(): void;
    dispose(camera?: Camera): void;
}

/**
 * A multi render target designed to render the prepass.
 * Prepass is a scene component used to render information in multiple textures
 * alongside with the scene materials rendering.
 * Note : This is an internal class, and you should NOT need to instanciate this.
 * Only the `PrePassRenderer` should instanciate this class.
 * It is more likely that you need a regular `MultiRenderTarget`
 * @internal
 */
declare class PrePassRenderTarget extends MultiRenderTarget {
    /**
     * @internal
     */
    _beforeCompositionPostProcesses: PostProcess[];
    /**
     * Image processing post process for composition
     */
    imageProcessingPostProcess: ImageProcessingPostProcess;
    /**
     * @internal
     */
    _engine: Engine;
    /**
     * @internal
     */
    _scene: Scene;
    /**
     * @internal
     */
    _outputPostProcess: Nullable<PostProcess>;
    /**
     * @internal
     */
    _internalTextureDirty: boolean;
    /**
     * Is this render target enabled for prepass rendering
     */
    enabled: boolean;
    /**
     * Render target associated with this prePassRenderTarget
     * If this is `null`, it means this prePassRenderTarget is associated with the scene
     */
    renderTargetTexture: Nullable<RenderTargetTexture>;
    constructor(name: string, renderTargetTexture: Nullable<RenderTargetTexture>, size: any, count: number, scene?: Scene, options?: IMultiRenderTargetOptions);
    /**
     * Creates a composition effect for this RT
     * @internal
     */
    _createCompositionEffect(): void;
    /**
     * Checks that the size of this RT is still adapted to the desired render size.
     * @internal
     */
    _checkSize(): void;
    /**
     * Changes the number of render targets in this MRT
     * Be careful as it will recreate all the data in the new texture.
     * @param count new texture count
     * @param options Specifies texture types and sampling modes for new textures
     * @param textureNames Specifies the names of the textures (optional)
     */
    updateCount(count: number, options?: IMultiRenderTargetOptions, textureNames?: string[]): void;
    /**
     * Resets the post processes chains applied to this RT.
     * @internal
     */
    _resetPostProcessChain(): void;
    /**
     * Diposes this render target
     */
    dispose(): void;
}

/**
 * Interface for defining prepass effects in the prepass post-process pipeline
 */
interface PrePassEffectConfiguration {
    /**
     * Name of the effect
     */
    name: string;
    /**
     * Post process to attach for this effect
     */
    postProcess?: PostProcess;
    /**
     * Textures required in the MRT
     */
    texturesRequired: number[];
    /**
     * Is the effect enabled
     */
    enabled: boolean;
    /**
     * Does the output of this prepass need to go through imageprocessing
     */
    needsImageProcessing?: boolean;
    /**
     * The clear color of the render targets. If not provided, defaults to (0, 0, 0, 0)
     */
    clearColor?: Color4;
    /**
     * Disposes the effect configuration
     */
    dispose?: () => void;
    /**
     * Creates the associated post process
     */
    createPostProcess?: () => PostProcess;
}

/**
 * Renders a pre pass of the scene
 * This means every mesh in the scene will be rendered to a render target texture
 * And then this texture will be composited to the rendering canvas with post processes
 * It is necessary for effects like subsurface scattering or deferred shading
 */
declare class PrePassRenderer {
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    /**
     * To save performance, we can excluded skinned meshes from the prepass
     */
    excludedSkinnedMesh: AbstractMesh[];
    /**
     * Force material to be excluded from the prepass
     * Can be useful when `useGeometryBufferFallback` is set to `true`
     * and you don't want a material to show in the effect.
     */
    excludedMaterials: Material[];
    private _scene;
    private _engine;
    /**
     * Number of textures in the multi render target texture where the scene is directly rendered
     */
    mrtCount: number;
    private _mrtTypes;
    private _mrtFormats;
    private _mrtLayout;
    private _mrtNames;
    private _textureIndices;
    private _multiRenderAttachments;
    private _defaultAttachments;
    private _clearAttachments;
    private _clearDepthAttachments;
    private _generateNormalsInWorldSpace;
    /**
     * Indicates if the prepass renderer is generating normals in world space or camera space (default: camera space)
     */
    get generateNormalsInWorldSpace(): boolean;
    set generateNormalsInWorldSpace(value: boolean);
    /**
     * Returns the index of a texture in the multi render target texture array.
     * @param type Texture type
     * @returns The index
     */
    getIndex(type: number): number;
    /**
     * How many samples are used for MSAA of the scene render target
     */
    get samples(): number;
    set samples(n: number);
    private _useSpecificClearForDepthTexture;
    /**
     * If set to true (default: false), the depth texture will be cleared with the depth value corresponding to the far plane (1 in normal mode, 0 in reverse depth buffer mode)
     * If set to false, the depth texture is always cleared with 0.
     */
    get useSpecificClearForDepthTexture(): boolean;
    set useSpecificClearForDepthTexture(value: boolean);
    /**
     * Describes the types and formats of the textures used by the pre-pass renderer
     */
    static TextureFormats: {
        purpose: number;
        type: number;
        format: number;
        name: string;
    }[];
    private _isDirty;
    /**
     * The render target where the scene is directly rendered
     */
    defaultRT: PrePassRenderTarget;
    /**
     * Configuration for prepass effects
     */
    private _effectConfigurations;
    /**
     * @returns the prepass render target for the rendering pass.
     * If we are currently rendering a render target, it returns the PrePassRenderTarget
     * associated with that render target. Otherwise, it returns the scene default PrePassRenderTarget
     */
    getRenderTarget(): PrePassRenderTarget;
    /**
     * @internal
     * Managed by the scene component
     * @param prePassRenderTarget
     */
    _setRenderTarget(prePassRenderTarget: Nullable<PrePassRenderTarget>): void;
    /**
     * Returns true if the currently rendered prePassRenderTarget is the one
     * associated with the scene.
     */
    get currentRTisSceneRT(): boolean;
    private _geometryBuffer;
    /**
     * Prevents the PrePassRenderer from using the GeometryBufferRenderer as a fallback
     */
    doNotUseGeometryRendererFallback: boolean;
    private _refreshGeometryBufferRendererLink;
    private _currentTarget;
    /**
     * All the render targets generated by prepass
     */
    renderTargets: PrePassRenderTarget[];
    private readonly _clearColor;
    private readonly _clearDepthColor;
    private _enabled;
    private _needsCompositionForThisPass;
    private _postProcessesSourceForThisPass;
    /**
     * Indicates if the prepass is enabled
     */
    get enabled(): boolean;
    /**
     * Set to true to disable gamma transform in PrePass.
     * Can be useful in case you already proceed to gamma transform on a material level
     * and your post processes don't need to be in linear color space.
     */
    disableGammaTransform: boolean;
    /**
     * Instantiates a prepass renderer
     * @param scene The scene
     */
    constructor(scene: Scene);
    /**
     * Creates a new PrePassRenderTarget
     * This should be the only way to instantiate a `PrePassRenderTarget`
     * @param name Name of the `PrePassRenderTarget`
     * @param renderTargetTexture RenderTarget the `PrePassRenderTarget` will be attached to.
     * Can be `null` if the created `PrePassRenderTarget` is attached to the scene (default framebuffer).
     * @internal
     */
    _createRenderTarget(name: string, renderTargetTexture: Nullable<RenderTargetTexture>): PrePassRenderTarget;
    /**
     * Indicates if rendering a prepass is supported
     */
    get isSupported(): boolean;
    /**
     * Sets the proper output textures to draw in the engine.
     * @param effect The effect that is drawn. It can be or not be compatible with drawing to several output textures.
     * @param subMesh Submesh on which the effect is applied
     */
    bindAttachmentsForEffect(effect: Effect, subMesh: SubMesh): void;
    private _reinitializeAttachments;
    private _resetLayout;
    private _updateGeometryBufferLayout;
    /**
     * Restores attachments for single texture draw.
     */
    restoreAttachments(): void;
    /**
     * @internal
     */
    _beforeDraw(camera?: Camera, faceIndex?: number, layer?: number): void;
    private _prepareFrame;
    /**
     * Sets an intermediary texture between prepass and postprocesses. This texture
     * will be used as input for post processes
     * @param rt The render target texture to use
     * @returns true if there are postprocesses that will use this texture,
     * false if there is no postprocesses - and the function has no effect
     */
    setCustomOutput(rt: RenderTargetTexture): boolean;
    private _renderPostProcesses;
    /**
     * @internal
     */
    _afterDraw(faceIndex?: number, layer?: number): void;
    /**
     * Clears the current prepass render target (in the sense of settings pixels to the scene clear color value)
     * @internal
     */
    _clear(): void;
    private _bindFrameBuffer;
    private _setEnabled;
    private _setRenderTargetEnabled;
    /**
     * Adds an effect configuration to the prepass render target.
     * If an effect has already been added, it won't add it twice and will return the configuration
     * already present.
     * @param cfg the effect configuration
     * @returns the effect configuration now used by the prepass
     */
    addEffectConfiguration(cfg: PrePassEffectConfiguration): PrePassEffectConfiguration;
    /**
     * Retrieves an effect configuration by name
     * @param name the name of the effect configuration
     * @returns the effect configuration, or null if not present
     */
    getEffectConfiguration(name: string): Nullable<PrePassEffectConfiguration>;
    private _enable;
    private _disable;
    private _getPostProcessesSource;
    private _setupOutputForThisPass;
    private _linkInternalTexture;
    /**
     * @internal
     */
    _unlinkInternalTexture(prePassRenderTarget: PrePassRenderTarget): void;
    private _needsImageProcessing;
    private _hasImageProcessing;
    /**
     * Internal, gets the first post proces.
     * @param postProcesses
     * @returns the first post process to be run on this camera.
     */
    private _getFirstPostProcess;
    /**
     * Marks the prepass renderer as dirty, triggering a check if the prepass is necessary for the next rendering.
     */
    markAsDirty(): void;
    /**
     * Enables a texture on the MultiRenderTarget for prepass
     * @param types
     */
    private _enableTextures;
    /**
     * Makes sure that the prepass renderer is up to date if it has been dirtified.
     */
    update(): void;
    private _update;
    private _markAllMaterialsAsPrePassDirty;
    /**
     * Disposes the prepass renderer.
     */
    dispose(): void;
}

/**
 * Options for compiling materials.
 */
interface IMaterialCompilationOptions {
    /**
     * Defines whether clip planes are enabled.
     */
    clipPlane: boolean;
    /**
     * Defines whether instances are enabled.
     */
    useInstances: boolean;
}
/**
 * Options passed when calling customShaderNameResolve
 */
interface ICustomShaderNameResolveOptions {
    /**
     * If provided, will be called two times with the vertex and fragment code so that this code can be updated before it is compiled by the GPU
     */
    processFinalCode?: Nullable<ShaderCustomProcessingFunction>;
}
/**
 * Base class for the main features of a material in Babylon.js
 */
declare class Material implements IAnimatable, IClipPlanesHolder {
    /**
     * Returns the triangle fill mode
     */
    static readonly TriangleFillMode = 0;
    /**
     * Returns the wireframe mode
     */
    static readonly WireFrameFillMode = 1;
    /**
     * Returns the point fill mode
     */
    static readonly PointFillMode = 2;
    /**
     * Returns the point list draw mode
     */
    static readonly PointListDrawMode = 3;
    /**
     * Returns the line list draw mode
     */
    static readonly LineListDrawMode = 4;
    /**
     * Returns the line loop draw mode
     */
    static readonly LineLoopDrawMode = 5;
    /**
     * Returns the line strip draw mode
     */
    static readonly LineStripDrawMode = 6;
    /**
     * Returns the triangle strip draw mode
     */
    static readonly TriangleStripDrawMode = 7;
    /**
     * Returns the triangle fan draw mode
     */
    static readonly TriangleFanDrawMode = 8;
    /**
     * Stores the clock-wise side orientation
     */
    static readonly ClockWiseSideOrientation = 0;
    /**
     * Stores the counter clock-wise side orientation
     */
    static readonly CounterClockWiseSideOrientation = 1;
    /**
     * The dirty image processing flag value
     */
    static readonly ImageProcessingDirtyFlag = 64;
    /**
     * The dirty texture flag value
     */
    static readonly TextureDirtyFlag = 1;
    /**
     * The dirty light flag value
     */
    static readonly LightDirtyFlag = 2;
    /**
     * The dirty fresnel flag value
     */
    static readonly FresnelDirtyFlag = 4;
    /**
     * The dirty attribute flag value
     */
    static readonly AttributesDirtyFlag = 8;
    /**
     * The dirty misc flag value
     */
    static readonly MiscDirtyFlag = 16;
    /**
     * The dirty prepass flag value
     */
    static readonly PrePassDirtyFlag = 32;
    /**
     * The all dirty flag value
     */
    static readonly AllDirtyFlag = 127;
    /**
     * MaterialTransparencyMode: No transparency mode, Alpha channel is not use.
     */
    static readonly MATERIAL_OPAQUE = 0;
    /**
     * MaterialTransparencyMode: Alpha Test mode, pixel are discarded below a certain threshold defined by the alpha cutoff value.
     */
    static readonly MATERIAL_ALPHATEST = 1;
    /**
     * MaterialTransparencyMode: Pixels are blended (according to the alpha mode) with the already drawn pixels in the current frame buffer.
     */
    static readonly MATERIAL_ALPHABLEND = 2;
    /**
     * MaterialTransparencyMode: Pixels are blended (according to the alpha mode) with the already drawn pixels in the current frame buffer.
     * They are also discarded below the alpha cutoff threshold to improve performances.
     */
    static readonly MATERIAL_ALPHATESTANDBLEND = 3;
    /**
     * The Whiteout method is used to blend normals.
     * Details of the algorithm can be found here: https://blog.selfshadow.com/publications/blending-in-detail/
     */
    static readonly MATERIAL_NORMALBLENDMETHOD_WHITEOUT = 0;
    /**
     * The Reoriented Normal Mapping method is used to blend normals.
     * Details of the algorithm can be found here: https://blog.selfshadow.com/publications/blending-in-detail/
     */
    static readonly MATERIAL_NORMALBLENDMETHOD_RNM = 1;
    /**
     * PBRMaterialLightFalloff Physical: light is falling off following the inverse squared distance law.
     */
    static readonly LIGHTFALLOFF_PHYSICAL = 0;
    /**
     * PBRMaterialLightFalloff gltf: light is falling off as described in the gltf moving to PBR document
     * to enhance interoperability with other engines.
     */
    static readonly LIGHTFALLOFF_GLTF = 1;
    /**
     * PBRMaterialLightFalloff Standard: light is falling off like in the standard material
     * to enhance interoperability with other materials.
     */
    static readonly LIGHTFALLOFF_STANDARD = 2;
    /**
     * Event observable which raises global events common to all materials (like MaterialPluginEvent.Created)
     */
    static OnEventObservable: Observable<Material>;
    /**
     * If true, all materials will have their vertex output set to invariant (see the vertexOutputInvariant property).
     */
    static ForceVertexOutputInvariant: boolean;
    /**
     * Custom callback helping to override the default shader used in the material.
     */
    customShaderNameResolve: (shaderName: string, uniforms: string[], uniformBuffers: string[], samplers: string[], defines: MaterialDefines | string[], attributes?: string[], options?: ICustomShaderNameResolveOptions) => string;
    /**
     * Custom shadow depth material to use for shadow rendering instead of the in-built one
     */
    shadowDepthWrapper: Nullable<ShadowDepthWrapper>;
    /**
     * Gets or sets a boolean indicating that the material is allowed (if supported) to do shader hot swapping.
     * This means that the material can keep using a previous shader while a new one is being compiled.
     * This is mostly used when shader parallel compilation is supported (true by default)
     */
    allowShaderHotSwapping: boolean;
    /** Shader language used by the material */
    protected _shaderLanguage: ShaderLanguage;
    protected _forceGLSL: boolean;
    protected _useVertexPulling: boolean;
    /**
     * Tells the engine to draw geometry using vertex pulling instead of index drawing. This will automatically
     * set the vertex buffers as storage buffers and make them accessible to the vertex shader (WebGPU only).
     */
    get useVertexPulling(): boolean;
    set useVertexPulling(value: boolean);
    /** @internal */
    get _supportGlowLayer(): boolean;
    /** @internal */
    set _glowModeEnabled(value: boolean);
    /**
     * Gets the shader language used in this material.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * The ID of the material
     */
    id: string;
    /**
     * Gets or sets the unique id of the material
     */
    uniqueId: number;
    /** @internal */
    _loadedUniqueId: string;
    /**
     * The name of the material
     */
    name: string;
    /**
     * Gets or sets user defined metadata
     */
    metadata: any;
    /** @internal */
    _internalMetadata: any;
    /**
     * For internal use only. Please do not use.
     */
    reservedDataStore: any;
    /**
     * Specifies if the ready state should be checked on each call
     */
    checkReadyOnEveryCall: boolean;
    /**
     * Specifies if the ready state should be checked once
     */
    checkReadyOnlyOnce: boolean;
    /**
     * The state of the material
     */
    state: string;
    /**
     * If the material can be rendered to several textures with MRT extension
     */
    get canRenderToMRT(): boolean;
    /**
     * The alpha value of the material
     */
    protected _alpha: number;
    /**
     * List of inspectable custom properties (used by the Inspector)
     * @see https://doc.babylonjs.com/toolsAndResources/inspector#extensibility
     */
    inspectableCustomProperties: IInspectable[];
    /**
     * Sets the alpha value of the material
     */
    set alpha(value: number);
    /**
     * Gets the alpha value of the material
     */
    get alpha(): number;
    /**
     * Specifies if back face culling is enabled
     */
    protected _backFaceCulling: boolean;
    /**
     * Sets the culling state (true to enable culling, false to disable)
     */
    set backFaceCulling(value: boolean);
    /**
     * Gets the culling state
     */
    get backFaceCulling(): boolean;
    /**
     * Specifies if back or front faces should be culled (when culling is enabled)
     */
    protected _cullBackFaces: boolean;
    /**
     * Sets the type of faces that should be culled (true for back faces, false for front faces)
     */
    set cullBackFaces(value: boolean);
    /**
     * Gets the type of faces that should be culled
     */
    get cullBackFaces(): boolean;
    private _blockDirtyMechanism;
    /**
     * Block the dirty-mechanism for this specific material
     * When set to false after being true the material will be marked as dirty.
     */
    get blockDirtyMechanism(): boolean;
    set blockDirtyMechanism(value: boolean);
    /**
     * This allows you to modify the material without marking it as dirty after every change.
     * This function should be used if you need to make more than one dirty-enabling change to the material - adding a texture, setting a new fill mode and so on.
     * The callback will pass the material as an argument, so you can make your changes to it.
     * @param callback the callback to be executed that will update the material
     */
    atomicMaterialsUpdate(callback: (material: this) => void): void;
    /**
     * Stores the value for side orientation
     */
    sideOrientation: Nullable<number>;
    /**
     * Callback triggered when the material is compiled
     */
    onCompiled: Nullable<(effect: Effect) => void>;
    /**
     * Callback triggered when an error occurs
     */
    onError: Nullable<(effect: Effect, errors: string) => void>;
    /**
     * Callback triggered to get the render target textures
     */
    getRenderTargetTextures: Nullable<() => SmartArray<RenderTargetTexture>>;
    /**
     * Gets a boolean indicating that current material needs to register RTT
     */
    get hasRenderTargetTextures(): boolean;
    /**
     * Specifies if the material should be serialized
     */
    doNotSerialize: boolean;
    /**
     * @internal
     */
    _storeEffectOnSubMeshes: boolean;
    /**
     * Stores the animations for the material
     */
    animations: Nullable<Array<Animation>>;
    /**
     * An event triggered when the material is disposed
     */
    onDisposeObservable: Observable<Material>;
    /**
     * An observer which watches for dispose events
     */
    private _onDisposeObserver;
    private _onUnBindObservable;
    /**
     * Called during a dispose event
     */
    set onDispose(callback: () => void);
    private _onBindObservable;
    /**
     * An event triggered when the material is bound
     */
    get onBindObservable(): Observable<AbstractMesh>;
    /**
     * An observer which watches for bind events
     */
    private _onBindObserver;
    /**
     * Called during a bind event
     */
    set onBind(callback: (Mesh: AbstractMesh) => void);
    /**
     * An event triggered when the material is unbound
     */
    get onUnBindObservable(): Observable<Material>;
    protected _onEffectCreatedObservable: Nullable<Observable<{
        effect: Effect;
        subMesh: Nullable<SubMesh>;
    }>>;
    /**
     * An event triggered when the effect is (re)created
     */
    get onEffectCreatedObservable(): Observable<{
        effect: Effect;
        subMesh: Nullable<SubMesh>;
    }>;
    /**
     * Stores the value of the alpha mode
     */
    private _alphaMode;
    /**
     * Sets the value of the alpha mode.
     *
     * | Value | Type | Description |
     * | --- | --- | --- |
     * | 0 | ALPHA_DISABLE |  |
     * | 1 | ALPHA_ADD | Defines that alpha blending is COLOR=SRC_ALPHA * SRC + DEST, ALPHA=DEST_ALPHA |
     * | 2 | ALPHA_COMBINE | Defines that alpha blending is COLOR=SRC_ALPHA * SRC + (1 - SRC_ALPHA) * DEST, ALPHA=SRC_ALPHA + DEST_ALPHA |
     * | 3 | ALPHA_SUBTRACT | Defines that alpha blending is COLOR=(1 - SRC) * DEST, ALPHA=SRC_ALPHA + DEST_ALPHA |
     * | 4 | ALPHA_MULTIPLY | Defines that alpha blending is COLOR=DEST * SRC, ALPHA=SRC_ALPHA + DEST_ALPHA |
     * | 5 | ALPHA_MAXIMIZED | Defines that alpha blending is COLOR=SRC_ALPHA * SRC + (1 - SRC) * DEST, ALPHA=SRC_ALPHA + DEST_ALPHA |
     * | 6 | ALPHA_ONEONE | Defines that alpha blending is COLOR=SRC + DEST, ALPHA=DEST_ALPHA |
     * | 7 | ALPHA_PREMULTIPLIED | Defines that alpha blending is COLOR=SRC + (1 - SRC_ALPHA) * DEST, ALPHA=SRC_ALPHA + DEST_ALPHA |
     * | 8 | ALPHA_PREMULTIPLIED_PORTERDUFF | Defines that alpha blending is COLOR=SRC + (1 - SRC_ALPHA) * DEST, ALPHA=SRC_ALPHA + (1 - SRC_ALPHA) * DEST_ALPHA |
     * | 9 | ALPHA_INTERPOLATE | Defines that alpha blending is COLOR=CST * SRC + (1 - CST) * DEST, ALPHA=CST_ALPHA * SRC + (1 - CST_ALPHA) * DEST_ALPHA |
     * | 10 | ALPHA_SCREENMODE | Defines that alpha blending is COLOR=SRC + (1 - SRC) * DEST, ALPHA=SRC_ALPHA + (1 - SRC_ALPHA) * DEST_ALPHA |
     * | 11 | ALPHA_ONEONE_ONEONE | Defines that alpha blending is COLOR=SRC + DST, ALPHA=SRC_ALPHA + DEST_ALPHA |
     * | 12 | ALPHA_ALPHATOCOLOR | Defines that alpha blending is COLOR=DEST_ALPHA * SRC + DST, ALPHA=0 |
     * | 13 | ALPHA_REVERSEONEMINUS | Defines that alpha blending is COLOR=(1 - DEST) * SRC + (1 - SRC) * DEST, ALPHA=(1 - DEST_ALPHA) * SRC_ALPHA + (1 - SRC_ALPHA) * DEST_ALPHA |
     * | 14 | ALPHA_SRC_DSTONEMINUSSRCALPHA | Defines that alpha blending is ALPHA=SRC + (1 - SRC ALPHA) * DEST, ALPHA=SRC_ALPHA + (1 - SRC ALPHA) * DEST_ALPHA |
     * | 15 | ALPHA_ONEONE_ONEZERO | Defines that alpha blending is COLOR=SRC + DST, ALPHA=SRC_ALPHA |
     * | 16 | ALPHA_EXCLUSION | Defines that alpha blending is COLOR=(1 - DEST) * SRC + (1 - SRC) * DEST, ALPHA=DEST_ALPHA |
     * | 17 | ALPHA_LAYER_ACCUMULATE | Defines that alpha blending is COLOR=SRC_ALPHA * SRC + (1 - SRC ALPHA) * DEST, ALPHA=SRC_ALPHA + (1 - SRC_ALPHA) * DEST_ALPHA |
     * | 18 | ALPHA_MIN | Defines that alpha blending is COLOR=MIN(SRC, DEST), ALPHA=MIN(SRC_ALPHA, DEST_ALPHA) |
     * | 19 | ALPHA_MAX | Defines that alpha blending is COLOR=MAX(SRC, DEST), ALPHA=MAX(SRC_ALPHA, DEST_ALPHA) |
     * | 20 | ALPHA_DUAL_SRC0_ADD_SRC1xDST | Defines that alpha blending uses dual source blending and is COLOR=SRC + SRC1 * DEST, ALPHA=DST_ALPHA |
     *
     */
    set alphaMode(value: number);
    /**
     * Gets the value of the alpha mode
     */
    get alphaMode(): number;
    /**
     * Gets the list of alpha modes (length greater than 1 for multi-targets)
     */
    get alphaModes(): Immutable<number[]>;
    /**
     * Sets the value of the alpha mode for a specific target index.
     * @param value The alpha mode value to set.
     * @param targetIndex The index of the target to set the alpha mode for. Defaults to 0.
     */
    setAlphaMode(value: number, targetIndex?: number): void;
    /**
     * Stores the state of the need depth pre-pass value
     */
    private _needDepthPrePass;
    /**
     * Sets the need depth pre-pass value
     */
    set needDepthPrePass(value: boolean);
    /**
     * Gets the depth pre-pass value
     */
    get needDepthPrePass(): boolean;
    /**
     * Can this material render to prepass
     */
    get isPrePassCapable(): boolean;
    /**
     * Specifies if depth writing should be disabled
     */
    disableDepthWrite: boolean;
    /**
     * Specifies if color writing should be disabled
     */
    disableColorWrite: boolean;
    /**
     * Specifies if depth writing should be forced
     */
    forceDepthWrite: boolean;
    /**
     * Specifies the depth function that should be used. 0 means the default engine function
     */
    depthFunction: number;
    /**
     * Specifies if there should be a separate pass for culling
     */
    separateCullingPass: boolean;
    /**
     * Stores the state specifying if fog should be enabled
     */
    private _fogEnabled;
    /**
     * Sets the state for enabling fog
     */
    set fogEnabled(value: boolean);
    /**
     * Gets the value of the fog enabled state
     */
    get fogEnabled(): boolean;
    /**
     * Stores the size of points
     */
    pointSize: number;
    /**
     * Stores the z offset Factor value
     */
    zOffset: number;
    /**
     * Stores the z offset Units value
     */
    zOffsetUnits: number;
    get wireframe(): boolean;
    /**
     * Sets the state of wireframe mode
     */
    set wireframe(value: boolean);
    /**
     * Gets the value specifying if point clouds are enabled
     */
    get pointsCloud(): boolean;
    /**
     * Sets the state of point cloud mode
     */
    set pointsCloud(value: boolean);
    /**
     * Gets the material fill mode
     */
    get fillMode(): number;
    /**
     * Sets the material fill mode
     */
    set fillMode(value: number);
    /**
     * Gets or sets the active clipplane 1
     */
    clipPlane: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 2
     */
    clipPlane2: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 3
     */
    clipPlane3: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 4
     */
    clipPlane4: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 5
     */
    clipPlane5: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 6
     */
    clipPlane6: Nullable<Plane>;
    /**
     * Gives access to the stencil properties of the material
     */
    readonly stencil: MaterialStencilState;
    protected _useLogarithmicDepth: boolean;
    /**
     * In case the depth buffer does not allow enough depth precision for your scene (might be the case in large scenes)
     * You can try switching to logarithmic depth.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/advanced/logarithmicDepthBuffer
     */
    get useLogarithmicDepth(): boolean;
    set useLogarithmicDepth(value: boolean);
    protected _isVertexOutputInvariant: boolean;
    /**
     * Gets or sets the vertex output invariant state
     * Setting this property to true will force the shader compiler to disable some optimization to make sure the vertex output is always calculated
     * the same way across different compilation units.
     * You may need to enable this option if you are seeing some depth artifacts when using a depth pre-pass, for e.g.
     * Note that this may have an impact on performance, so leave this option disabled if not needed.
     */
    get isVertexOutputInvariant(): boolean;
    set isVertexOutputInvariant(value: boolean);
    /**
     * @internal
     * Stores the effects for the material
     */
    _materialContext: IMaterialContext | undefined;
    protected _drawWrapper: DrawWrapper;
    /** @internal */
    _getDrawWrapper(): DrawWrapper;
    /**
     * @internal
     */
    _setDrawWrapper(drawWrapper: DrawWrapper): void;
    /**
     * Specifies if uniform buffers should be used
     */
    private _useUBO;
    /**
     * Stores a reference to the scene
     */
    private _scene;
    protected _needToBindSceneUbo: boolean;
    /**
     * Stores the fill mode state
     */
    private _fillMode;
    /**
     * Specifies if the depth write state should be cached
     */
    private _cachedDepthWriteState;
    /**
     * Specifies if the color write state should be cached
     */
    private _cachedColorWriteState;
    /**
     * Specifies if the depth function state should be cached
     */
    private _cachedDepthFunctionState;
    /**
     * Stores the uniform buffer
     * @internal
     */
    _uniformBuffer: UniformBuffer;
    /** @internal */
    _indexInSceneMaterialArray: number;
    /** @internal */
    meshMap: Nullable<{
        [id: string]: AbstractMesh | undefined;
    }>;
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /** @internal */
    _dirtyCallbacks: {
        [code: number]: () => void;
    };
    /** @internal */
    _uniformBufferLayoutBuilt: boolean;
    protected _eventInfo: MaterialPluginCreated & MaterialPluginDisposed & MaterialPluginHasTexture & MaterialPluginIsReadyForSubMesh & MaterialPluginGetDefineNames & MaterialPluginPrepareEffect & MaterialPluginPrepareDefines & MaterialPluginPrepareUniformBuffer & MaterialPluginBindForSubMesh & MaterialPluginGetAnimatables & MaterialPluginGetActiveTextures & MaterialPluginFillRenderTargetTextures & MaterialPluginHasRenderTargetTextures & MaterialPluginHardBindForSubMesh;
    /** @internal */
    _callbackPluginEventGeneric: (id: number, info: MaterialPluginGetActiveTextures | MaterialPluginGetAnimatables | MaterialPluginHasTexture | MaterialPluginDisposed | MaterialPluginGetDefineNames | MaterialPluginPrepareEffect | MaterialPluginPrepareUniformBuffer) => void;
    /** @internal */
    _callbackPluginEventIsReadyForSubMesh: (eventData: MaterialPluginIsReadyForSubMesh) => void;
    /** @internal */
    _callbackPluginEventPrepareDefines: (eventData: MaterialPluginPrepareDefines) => void;
    /** @internal */
    _callbackPluginEventPrepareDefinesBeforeAttributes: (eventData: MaterialPluginPrepareDefines) => void;
    /** @internal */
    _callbackPluginEventHardBindForSubMesh: (eventData: MaterialPluginHardBindForSubMesh) => void;
    /** @internal */
    _callbackPluginEventBindForSubMesh: (eventData: MaterialPluginBindForSubMesh) => void;
    /** @internal */
    _callbackPluginEventHasRenderTargetTextures: (eventData: MaterialPluginHasRenderTargetTextures) => void;
    /** @internal */
    _callbackPluginEventFillRenderTargetTextures: (eventData: MaterialPluginFillRenderTargetTextures) => void;
    /**
     * Creates a material instance
     * @param name defines the name of the material
     * @param scene defines the scene to reference
     * @param doNotAdd specifies if the material should be added to the scene
     * @param forceGLSL Use the GLSL code generation for the shader (even on WebGPU). Default is false
     */
    constructor(name: string, scene?: Nullable<Scene>, doNotAdd?: boolean, forceGLSL?: boolean);
    /** @internal */
    _createUniformBuffer(): void;
    /**
     * Returns a string representation of the current material
     * @param fullDetails defines a boolean indicating which levels of logging is desired
     * @returns a string with material information
     */
    toString(fullDetails?: boolean): string;
    /**
     * Gets the class name of the material
     * @returns a string with the class name of the material
     */
    getClassName(): string;
    /** @internal */
    get _isMaterial(): boolean;
    /**
     * Specifies if updates for the material been locked
     */
    get isFrozen(): boolean;
    /**
     * Locks updates for the material
     */
    freeze(): void;
    /**
     * Unlocks updates for the material
     */
    unfreeze(): void;
    /**
     * Specifies if the material is ready to be used
     * @param mesh defines the mesh to check
     * @param useInstances specifies if instances should be used
     * @returns a boolean indicating if the material is ready to be used
     */
    isReady(mesh?: AbstractMesh, useInstances?: boolean): boolean;
    /**
     * Specifies that the submesh is ready to be used
     * @param mesh defines the mesh to check
     * @param subMesh defines which submesh to check
     * @param useInstances specifies that instances should be used
     * @returns a boolean indicating that the submesh is ready or not
     */
    isReadyForSubMesh(mesh: AbstractMesh, subMesh: SubMesh, useInstances?: boolean): boolean;
    /**
     * Returns the material effect
     * @returns the effect associated with the material
     */
    getEffect(): Nullable<Effect>;
    /**
     * Returns the current scene
     * @returns a Scene
     */
    getScene(): Scene;
    /** @internal */
    _getEffectiveOrientation(mesh: Mesh): number;
    /**
     * The transparency mode of the material.
     */
    protected _transparencyMode: Nullable<number>;
    /**
     * Gets the current transparency mode.
     */
    get transparencyMode(): Nullable<number>;
    /**
     * Sets the transparency mode of the material.
     *
     * | Value | Type                                | Description |
     * | ----- | ----------------------------------- | ----------- |
     * | 0     | OPAQUE                              |             |
     * | 1     | ALPHATEST                           |             |
     * | 2     | ALPHABLEND                          |             |
     * | 3     | ALPHATESTANDBLEND                   |             |
     *
     */
    set transparencyMode(value: Nullable<number>);
    protected get _hasTransparencyMode(): boolean;
    protected get _transparencyModeIsBlend(): boolean;
    protected get _transparencyModeIsTest(): boolean;
    /**
     * Returns true if alpha blending should be disabled.
     */
    protected get _disableAlphaBlending(): boolean;
    /**
     * Specifies whether or not this material should be rendered in alpha blend mode.
     * @returns a boolean specifying if alpha blending is needed
     * @deprecated Please use needAlphaBlendingForMesh instead
     */
    needAlphaBlending(): boolean;
    /**
     * Specifies if the mesh will require alpha blending
     * @param mesh defines the mesh to check
     * @returns a boolean specifying if alpha blending is needed for the mesh
     */
    needAlphaBlendingForMesh(mesh: AbstractMesh): boolean;
    /**
     * Specifies whether or not this material should be rendered in alpha test mode.
     * @returns a boolean specifying if an alpha test is needed.
     * @deprecated Please use needAlphaTestingForMesh instead
     */
    needAlphaTesting(): boolean;
    /**
     * Specifies if material alpha testing should be turned on for the mesh
     * @param mesh defines the mesh to check
     * @returns a boolean specifying if alpha testing should be turned on for the mesh
     */
    needAlphaTestingForMesh(mesh: AbstractMesh): boolean;
    /**
     * Gets the texture used for the alpha test
     * @returns the texture to use for alpha testing
     */
    getAlphaTestTexture(): Nullable<BaseTexture>;
    /**
     * Marks the material to indicate that it needs to be re-calculated
     * @param forceMaterialDirty - Forces the material to be marked as dirty for all components (same as this.markAsDirty(Material.AllDirtyFlag)). You should use this flag if the material is frozen and you want to force a recompilation.
     */
    markDirty(forceMaterialDirty?: boolean): void;
    /**
     * @internal
     */
    _preBind(effect?: Effect | DrawWrapper, overrideOrientation?: Nullable<number>): boolean;
    /**
     * Binds the material to the mesh
     * @param world defines the world transformation matrix
     * @param mesh defines the mesh to bind the material to
     */
    bind(world: Matrix, mesh?: Mesh): void;
    /**
     * Initializes the uniform buffer layout for the shader.
     */
    buildUniformLayout(): void;
    /**
     * Binds the submesh to the material
     * @param world defines the world transformation matrix
     * @param mesh defines the mesh containing the submesh
     * @param subMesh defines the submesh to bind the material to
     */
    bindForSubMesh(world: Matrix, mesh: Mesh, subMesh: SubMesh): void;
    /**
     * Binds the world matrix to the material
     * @param world defines the world transformation matrix
     */
    bindOnlyWorldMatrix(world: Matrix): void;
    /**
     * Binds the view matrix to the effect
     * @param effect defines the effect to bind the view matrix to
     */
    bindView(effect: Effect): void;
    /**
     * Binds the view projection and projection matrices to the effect
     * @param effect defines the effect to bind the view projection and projection matrices to
     */
    bindViewProjection(effect: Effect): void;
    /**
     * Binds the view matrix to the effect
     * @param effect defines the effect to bind the view matrix to
     * @param variableName name of the shader variable that will hold the eye position
     */
    bindEyePosition(effect: Effect, variableName?: string): void;
    /**
     * Processes to execute after binding the material to a mesh
     * @param mesh defines the rendered mesh
     * @param effect defines the effect used to bind the material
     * @param _subMesh defines the subMesh that the material has been bound for
     */
    protected _afterBind(mesh?: AbstractMesh, effect?: Nullable<Effect>, _subMesh?: SubMesh): void;
    /**
     * Unbinds the material from the mesh
     */
    unbind(): void;
    /**
     * Returns the animatable textures.
     * @returns - Array of animatable textures.
     */
    getAnimatables(): IAnimatable[];
    /**
     * Gets the active textures from the material
     * @returns an array of textures
     */
    getActiveTextures(): BaseTexture[];
    /**
     * Specifies if the material uses a texture
     * @param texture defines the texture to check against the material
     * @returns a boolean specifying if the material uses the texture
     */
    hasTexture(texture: BaseTexture): boolean;
    /**
     * Makes a duplicate of the material, and gives it a new name
     * @param name defines the new name for the duplicated material
     * @returns the cloned material
     */
    clone(name: string): Nullable<Material>;
    protected _clonePlugins(targetMaterial: Material, rootUrl: string): void;
    /**
     * Gets the meshes bound to the material
     * @returns an array of meshes bound to the material
     */
    getBindedMeshes(): AbstractMesh[];
    /**
     * Force shader compilation
     * @param mesh defines the mesh associated with this material
     * @param onCompiled defines a function to execute once the material is compiled
     * @param options defines the options to configure the compilation
     * @param onError defines a function to execute if the material fails compiling
     */
    forceCompilation(mesh: AbstractMesh, onCompiled?: (material: Material) => void, options?: Partial<IMaterialCompilationOptions>, onError?: (reason: string) => void): void;
    /**
     * Force shader compilation
     * @param mesh defines the mesh that will use this material
     * @param options defines additional options for compiling the shaders
     * @returns a promise that resolves when the compilation completes
     */
    forceCompilationAsync(mesh: AbstractMesh, options?: Partial<IMaterialCompilationOptions>): Promise<void>;
    private static readonly _AllDirtyCallBack;
    private static readonly _ImageProcessingDirtyCallBack;
    private static readonly _TextureDirtyCallBack;
    private static readonly _FresnelDirtyCallBack;
    private static readonly _MiscDirtyCallBack;
    private static readonly _PrePassDirtyCallBack;
    private static readonly _LightsDirtyCallBack;
    private static readonly _AttributeDirtyCallBack;
    private static _FresnelAndMiscDirtyCallBack;
    private static _TextureAndMiscDirtyCallBack;
    private static readonly _DirtyCallbackArray;
    private static readonly _RunDirtyCallBacks;
    /**
     * Marks a define in the material to indicate that it needs to be re-computed
     * @param flag defines a flag used to determine which parts of the material have to be marked as dirty
     */
    markAsDirty(flag: number): void;
    /**
     * Resets the draw wrappers cache for all submeshes that are using this material
     */
    resetDrawCache(): void;
    /**
     * Marks all submeshes of a material to indicate that their material defines need to be re-calculated
     * @param func defines a function which checks material defines against the submeshes
     */
    protected _markAllSubMeshesAsDirty(func: (defines: MaterialDefines) => void): void;
    /**
     * Indicates that the scene should check if the rendering now needs a prepass
     */
    protected _markScenePrePassDirty(): void;
    /**
     * Indicates that we need to re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsAllDirty(): void;
    /**
     * Indicates that image processing needs to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsImageProcessingDirty(): void;
    /**
     * Indicates that textures need to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsTexturesDirty(): void;
    /**
     * Indicates that fresnel needs to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsFresnelDirty(): void;
    /**
     * Indicates that fresnel and misc need to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsFresnelAndMiscDirty(): void;
    /**
     * Indicates that lights need to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsLightsDirty(): void;
    /**
     * Indicates that attributes need to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsAttributesDirty(): void;
    /**
     * Indicates that misc needs to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsMiscDirty(): void;
    /**
     * Indicates that prepass needs to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsPrePassDirty(): void;
    /**
     * Indicates that textures and misc need to be re-calculated for all submeshes
     */
    protected _markAllSubMeshesAsTexturesAndMiscDirty(): void;
    protected _checkScenePerformancePriority(): void;
    /**
     * Sets the required values to the prepass renderer.
     * @param prePassRenderer defines the prepass renderer to setup.
     * @returns true if the pre pass is needed.
     */
    setPrePassRenderer(prePassRenderer: PrePassRenderer): boolean;
    /**
     * Disposes the material
     * @param _forceDisposeEffect kept for backward compat. We reference count the effect now.
     * @param forceDisposeTextures specifies if textures should be forcefully disposed
     * @param notBoundToMesh specifies if the material that is being disposed is known to be not bound to any mesh
     */
    dispose(_forceDisposeEffect?: boolean, forceDisposeTextures?: boolean, notBoundToMesh?: boolean): void;
    private _disposeMeshResources;
    /**
     * Serializes this material
     * @returns the serialized material object
     */
    serialize(): any;
    protected _serializePlugins(serializationObject: any): void;
    /**
     * Parses the alpha mode from the material data to parse
     * @param parsedMaterial defines the material data to parse
     * @param material defines the material to update
     */
    static ParseAlphaMode(parsedMaterial: any, material: Material): void;
    /**
     * Creates a material from parsed material data
     * @param parsedMaterial defines parsed material data
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures
     * @returns a new material
     */
    static Parse(parsedMaterial: any, scene: Scene, rootUrl: string): Nullable<Material>;
    protected static _ParsePlugins(serializationObject: any, material: Material, scene: Scene, rootUrl: string): void;
}

/**
 * Interface used to define Action
 */
interface IAction {
    /**
     * Trigger for the action
     */
    trigger: number;
    /** Options of the trigger */
    triggerOptions: any;
    /**
     * Gets the trigger parameters
     * @returns the trigger parameters
     */
    getTriggerParameter(): any;
    /**
     * Internal only - executes current action event
     * @internal
     */
    _executeCurrent(evt?: ActionEvent): void;
    /**
     * Serialize placeholder for child classes
     * @param parent of child
     * @returns the serialized object
     */
    serialize(parent: any): any;
    /**
     * Internal only
     * @internal
     */
    _prepare(): void;
    /**
     * Internal only - manager for action
     * @internal
     */
    _actionManager: Nullable<AbstractActionManager>;
    /**
     * Adds action to chain of actions, may be a DoNothingAction
     * @param action defines the next action to execute
     * @returns The action passed in
     * @see https://www.babylonjs-playground.com/#1T30HR#0
     */
    then(action: IAction): IAction;
    /**
     * Internal only - Returns if the current condition allows to run the action
     * @internal
     */
    _evaluateConditionForCurrentFrame(): boolean;
}

/**
 * Action Manager manages all events to be triggered on a given mesh or the global scene.
 * A single scene can have many Action Managers to handle predefined actions on specific meshes.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions
 */
declare class ActionManager extends AbstractActionManager {
    /**
     * Nothing
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly NothingTrigger = 0;
    /**
     * On pick
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnPickTrigger = 1;
    /**
     * On left pick
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnLeftPickTrigger = 2;
    /**
     * On right pick
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnRightPickTrigger = 3;
    /**
     * On center pick
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnCenterPickTrigger = 4;
    /**
     * On pick down
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnPickDownTrigger = 5;
    /**
     * On double pick
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnDoublePickTrigger = 6;
    /**
     * On pick up
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnPickUpTrigger = 7;
    /**
     * On pick out.
     * This trigger will only be raised if you also declared a OnPickDown
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnPickOutTrigger = 16;
    /**
     * On long press
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnLongPressTrigger = 8;
    /**
     * On pointer over
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnPointerOverTrigger = 9;
    /**
     * On pointer out
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnPointerOutTrigger = 10;
    /**
     * On every frame
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnEveryFrameTrigger = 11;
    /**
     * On intersection enter
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnIntersectionEnterTrigger = 12;
    /**
     * On intersection exit
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnIntersectionExitTrigger = 13;
    /**
     * On key down
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnKeyDownTrigger = 14;
    /**
     * On key up
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions#triggers
     */
    static readonly OnKeyUpTrigger = 15;
    private _scene;
    /**
     * Creates a new action manager
     * @param scene defines the hosting scene
     */
    constructor(scene?: Nullable<Scene>);
    /**
     * Releases all associated resources
     */
    dispose(): void;
    /**
     * Gets hosting scene
     * @returns the hosting scene
     */
    getScene(): Scene;
    /**
     * Does this action manager handles actions of any of the given triggers
     * @param triggers defines the triggers to be tested
     * @returns a boolean indicating whether one (or more) of the triggers is handled
     */
    hasSpecificTriggers(triggers: number[]): boolean;
    /**
     * Does this action manager handles actions of any of the given triggers. This function takes two arguments for
     * speed.
     * @param triggerA defines the trigger to be tested
     * @param triggerB defines the trigger to be tested
     * @returns a boolean indicating whether one (or more) of the triggers is handled
     */
    hasSpecificTriggers2(triggerA: number, triggerB: number): boolean;
    /**
     * Does this action manager handles actions of a given trigger
     * @param trigger defines the trigger to be tested
     * @param parameterPredicate defines an optional predicate to filter triggers by parameter
     * @returns whether the trigger is handled
     */
    hasSpecificTrigger(trigger: number, parameterPredicate?: (parameter: any) => boolean): boolean;
    /**
     * Does this action manager has pointer triggers
     */
    get hasPointerTriggers(): boolean;
    /**
     * Does this action manager has pick triggers
     */
    get hasPickTriggers(): boolean;
    /**
     * Registers an action to this action manager
     * @param action defines the action to be registered
     * @returns the action amended (prepared) after registration
     */
    registerAction(action: IAction): Nullable<IAction>;
    /**
     * Unregisters an action to this action manager
     * @param action defines the action to be unregistered
     * @returns a boolean indicating whether the action has been unregistered
     */
    unregisterAction(action: IAction): boolean;
    /**
     * Process a specific trigger
     * @param trigger defines the trigger to process
     * @param evt defines the event details to be processed
     */
    processTrigger(trigger: number, evt?: IActionEvent): void;
    /**
     * @internal
     */
    _getEffectiveTarget(target: any, propertyPath: string): any;
    /**
     * @internal
     */
    _getProperty(propertyPath: string): string;
    /**
     * Serialize this manager to a JSON object
     * @param name defines the property name to store this manager
     * @returns a JSON representation of this manager
     */
    serialize(name: string): any;
    /**
     * Creates a new ActionManager from a JSON data
     * @param parsedActions defines the JSON data to read from
     * @param object defines the hosting mesh
     * @param scene defines the hosting scene
     */
    static Parse(parsedActions: any, object: Nullable<AbstractMesh>, scene: Scene): void;
    /**
     * Get a trigger name by index
     * @param trigger defines the trigger index
     * @returns a trigger name
     */
    static GetTriggerName(trigger: number): string;
}

/**
 * Enum for Device Types
 */
declare enum DeviceType {
    /** Generic */
    Generic = 0,
    /** Keyboard */
    Keyboard = 1,
    /** Mouse */
    Mouse = 2,
    /** Touch Pointers */
    Touch = 3,
    /** PS4 Dual Shock */
    DualShock = 4,
    /** Xbox */
    Xbox = 5,
    /** Switch Controller */
    Switch = 6,
    /** PS5 DualSense */
    DualSense = 7
}
/**
 * Enum for All Pointers (Touch/Mouse)
 */
declare enum PointerInput {
    /** Horizontal Axis (Not used in events/observables; only in polling) */
    Horizontal = 0,
    /** Vertical Axis (Not used in events/observables; only in polling) */
    Vertical = 1,
    /** Left Click or Touch */
    LeftClick = 2,
    /** Middle Click */
    MiddleClick = 3,
    /** Right Click */
    RightClick = 4,
    /** Browser Back */
    BrowserBack = 5,
    /** Browser Forward */
    BrowserForward = 6,
    /** Mouse Wheel X */
    MouseWheelX = 7,
    /** Mouse Wheel Y */
    MouseWheelY = 8,
    /** Mouse Wheel Z */
    MouseWheelZ = 9,
    /** Used in events/observables to identify if x/y changes occurred */
    Move = 12
}
/**
 * Enum for Dual Shock Gamepad
 */
declare const enum DualShockInput {
    /** Cross */
    Cross = 0,
    /** Circle */
    Circle = 1,
    /** Square */
    Square = 2,
    /** Triangle */
    Triangle = 3,
    /** L1 */
    L1 = 4,
    /** R1 */
    R1 = 5,
    /** L2 */
    L2 = 6,
    /** R2 */
    R2 = 7,
    /** Share */
    Share = 8,
    /** Options */
    Options = 9,
    /** L3 */
    L3 = 10,
    /** R3 */
    R3 = 11,
    /** DPadUp */
    DPadUp = 12,
    /** DPadDown */
    DPadDown = 13,
    /** DPadLeft */
    DPadLeft = 14,
    /** DRight */
    DPadRight = 15,
    /** Home */
    Home = 16,
    /** TouchPad */
    TouchPad = 17,
    /** LStickXAxis */
    LStickXAxis = 18,
    /** LStickYAxis */
    LStickYAxis = 19,
    /** RStickXAxis */
    RStickXAxis = 20,
    /** RStickYAxis */
    RStickYAxis = 21
}
/**
 * Enum for Dual Sense Gamepad
 */
declare const enum DualSenseInput {
    /** Cross */
    Cross = 0,
    /** Circle */
    Circle = 1,
    /** Square */
    Square = 2,
    /** Triangle */
    Triangle = 3,
    /** L1 */
    L1 = 4,
    /** R1 */
    R1 = 5,
    /** L2 */
    L2 = 6,
    /** R2 */
    R2 = 7,
    /** Create */
    Create = 8,
    /** Options */
    Options = 9,
    /** L3 */
    L3 = 10,
    /** R3 */
    R3 = 11,
    /** DPadUp */
    DPadUp = 12,
    /** DPadDown */
    DPadDown = 13,
    /** DPadLeft */
    DPadLeft = 14,
    /** DRight */
    DPadRight = 15,
    /** Home */
    Home = 16,
    /** TouchPad */
    TouchPad = 17,
    /** LStickXAxis */
    LStickXAxis = 18,
    /** LStickYAxis */
    LStickYAxis = 19,
    /** RStickXAxis */
    RStickXAxis = 20,
    /** RStickYAxis */
    RStickYAxis = 21
}
/**
 * Enum for Xbox Gamepad
 */
declare const enum XboxInput {
    /** A */
    A = 0,
    /** B */
    B = 1,
    /** X */
    X = 2,
    /** Y */
    Y = 3,
    /** LB */
    LB = 4,
    /** RB */
    RB = 5,
    /** LT */
    LT = 6,
    /** RT */
    RT = 7,
    /** Back */
    Back = 8,
    /** Start */
    Start = 9,
    /** LS */
    LS = 10,
    /** RS */
    RS = 11,
    /** DPadUp */
    DPadUp = 12,
    /** DPadDown */
    DPadDown = 13,
    /** DPadLeft */
    DPadLeft = 14,
    /** DRight */
    DPadRight = 15,
    /** Home */
    Home = 16,
    /** LStickXAxis */
    LStickXAxis = 17,
    /** LStickYAxis */
    LStickYAxis = 18,
    /** RStickXAxis */
    RStickXAxis = 19,
    /** RStickYAxis */
    RStickYAxis = 20
}
/**
 * Enum for Switch (Pro/JoyCon L+R) Gamepad
 */
declare const enum SwitchInput {
    /** B */
    B = 0,
    /** A */
    A = 1,
    /** Y */
    Y = 2,
    /** X */
    X = 3,
    /** L */
    L = 4,
    /** R */
    R = 5,
    /** ZL */
    ZL = 6,
    /** ZR */
    ZR = 7,
    /** Minus */
    Minus = 8,
    /** Plus */
    Plus = 9,
    /** LS */
    LS = 10,
    /** RS */
    RS = 11,
    /** DPadUp */
    DPadUp = 12,
    /** DPadDown */
    DPadDown = 13,
    /** DPadLeft */
    DPadLeft = 14,
    /** DRight */
    DPadRight = 15,
    /** Home */
    Home = 16,
    /** Capture */
    Capture = 17,
    /** LStickXAxis */
    LStickXAxis = 18,
    /** LStickYAxis */
    LStickYAxis = 19,
    /** RStickXAxis */
    RStickXAxis = 20,
    /** RStickYAxis */
    RStickYAxis = 21
}

/**
 * Native friendly interface for Event Object
 */
interface IUIEvent {
    /**
     * Input array index
     */
    inputIndex: number;
    /**
     * Current target for an event
     */
    currentTarget?: any;
    /**
     * Alias for target
     * @deprecated Use target instead
     */
    srcElement?: any;
    /**
     * Type of event
     */
    type: string;
    /**
     * Reference to object where object was dispatched
     */
    target: any;
    /**
     * Tells user agent what to do when not explicitly handled
     */
    preventDefault: () => void;
}
/**
 * Native friendly interface for KeyboardEvent Object
 */
interface IKeyboardEvent extends IUIEvent {
    /**
     * Status of Alt key being pressed
     */
    altKey: boolean;
    /**
     * Unicode value of character pressed
     * @deprecated Required for event, use keyCode instead.
     */
    charCode?: number;
    /**
     * Code for key based on layout
     */
    code: string;
    /**
     * Status of Ctrl key being pressed
     */
    ctrlKey: boolean;
    /**
     * String representation of key
     */
    key: string;
    /**
     * ASCII value of key
     * @deprecated Used with DeviceSourceManager
     */
    keyCode: number;
    /**
     * Status of Meta key (eg. Windows key) being pressed
     */
    metaKey: boolean;
    /**
     * Status of Shift key being pressed
     */
    shiftKey: boolean;
}
/**
 * Native friendly interface for MouseEvent Object
 */
interface IMouseEvent extends IUIEvent {
    /**
     * Subset of possible PointerInput values for events, excluding ones that CANNOT be in events organically
     */
    inputIndex: Exclude<PointerInput, PointerInput.Horizontal | PointerInput.Vertical>;
    /**
     * Status of Alt key being pressed
     */
    altKey: boolean;
    /**
     * Value of single mouse button pressed
     */
    button: number;
    /**
     * Value of all mouse buttons pressed
     */
    buttons: number;
    /**
     * Current X coordinate
     */
    clientX: number;
    /**
     * Current Y coordinate
     */
    clientY: number;
    /**
     * Status of Ctrl key being pressed
     */
    ctrlKey: boolean;
    /**
     * Provides current click count
     */
    detail?: number;
    /**
     * Status of Meta key (eg. Windows key) being pressed
     */
    metaKey: boolean;
    /**
     * Delta of movement on X axis
     */
    movementX: number;
    /**
     * Delta of movement on Y axis
     */
    movementY: number;
    /**
     * Delta of movement on X axis
     * @deprecated Use 'movementX' instead
     */
    mozMovementX?: number;
    /**
     * Delta of movement on Y axis
     * @deprecated Use 'movementY' instead
     */
    mozMovementY?: number;
    /**
     * Delta of movement on X axis
     * @deprecated Use 'movementX' instead
     */
    msMovementX?: number;
    /**
     * Delta of movement on Y axis
     * @deprecated Use 'movementY' instead
     */
    msMovementY?: number;
    /**
     * Current coordinate of X within container
     */
    offsetX: number;
    /**
     * Current coordinate of Y within container
     */
    offsetY: number;
    /**
     * Horizontal coordinate of event
     */
    pageX: number;
    /**
     * Vertical coordinate of event
     */
    pageY: number;
    /**
     * Status of Shift key being pressed
     */
    shiftKey: boolean;
    /**
     * Delta of movement on X axis
     * @deprecated Use 'movementX' instead
     */
    webkitMovementX?: number;
    /**
     * Delta of movement on Y axis
     * @deprecated Use 'movementY' instead
     */
    webkitMovementY?: number;
    /**
     * Alias of clientX
     */
    x: number;
    /**
     * Alias of clientY
     */
    y: number;
}
/**
 * Native friendly interface for PointerEvent Object
 */
interface IPointerEvent extends IMouseEvent {
    /**
     * Subset of possible PointerInput values for events, excluding ones that CANNOT be in events organically and mouse wheel values
     */
    inputIndex: Exclude<PointerInput, PointerInput.Horizontal | PointerInput.Vertical | PointerInput.MouseWheelX | PointerInput.MouseWheelY | PointerInput.MouseWheelZ>;
    /**
     * Pointer Event ID
     */
    pointerId: number;
    /**
     * Type of pointer
     */
    pointerType: string;
}
/**
 * Native friendly interface for WheelEvent Object
 */
interface IWheelEvent extends IMouseEvent {
    /**
     * Subset of possible PointerInput values for events that can only be used with mouse wheel
     */
    inputIndex: PointerInput.MouseWheelX | PointerInput.MouseWheelY | PointerInput.MouseWheelZ;
    /**
     * Units for delta value
     */
    deltaMode: number;
    /**
     * Horizontal scroll delta
     */
    deltaX: number;
    /**
     * Vertical scroll delta
     */
    deltaY: number;
    /**
     * Z-Axis scroll delta
     */
    deltaZ: number;
    /**
     * WheelDelta (From MouseWheel Event)
     * @deprecated
     */
    wheelDelta?: number;
}

/**
 * This represents a scene component.
 *
 * This is used to decouple the dependency the scene is having on the different workloads like
 * layers, post processes...
 */
interface ISceneComponent {
    /**
     * The name of the component. Each component must have a unique name.
     */
    name: string;
    /**
     * The scene the component belongs to.
     */
    scene: Scene;
    /**
     * Register the component to one instance of a scene.
     */
    register(): void;
    /**
     * Rebuilds the elements related to this component in case of
     * context lost for instance.
     */
    rebuild(): void;
    /**
     * Disposes the component and the associated resources.
     */
    dispose(): void;
}
/**
 * This represents a SERIALIZABLE scene component.
 *
 * This extends Scene Component to add Serialization methods on top.
 */
interface ISceneSerializableComponent extends ISceneComponent {
    /**
     * Adds all the elements from the container to the scene
     * @param container the container holding the elements
     */
    addFromContainer(container: IAssetContainer): void;
    /**
     * Removes all the elements in the container from the scene
     * @param container contains the elements to remove
     * @param dispose if the removed element should be disposed (default: false)
     */
    removeFromContainer(container: IAssetContainer, dispose?: boolean): void;
    /**
     * Serializes the component data to the specified json object
     * @param serializationObject The object to serialize to
     */
    serialize(serializationObject: any): void;
}
/**
 * Strong typing of a Mesh related stage step action
 */
type MeshStageAction = (mesh: AbstractMesh, hardwareInstancedRendering: boolean) => boolean;
/**
 * Strong typing of a Evaluate Sub Mesh related stage step action
 */
type EvaluateSubMeshStageAction = (mesh: AbstractMesh, subMesh: SubMesh) => void;
/**
 * Strong typing of a pre active Mesh related stage step action
 */
type PreActiveMeshStageAction = (mesh: AbstractMesh) => void;
/**
 * Strong typing of a Camera related stage step action
 */
type CameraStageAction = (camera: Camera) => void;
/**
 * Strong typing of a Camera Frame buffer related stage step action
 */
type CameraStageFrameBufferAction = (camera: Camera) => boolean;
/**
 * Strong typing of a Render Target related stage step action
 */
type RenderTargetStageAction = (renderTarget: RenderTargetTexture, faceIndex?: number, layer?: number) => void;
/**
 * Strong typing of a RenderingGroup related stage step action
 */
type RenderingGroupStageAction = (renderingGroupId: number) => void;
/**
 * Strong typing of a Mesh Render related stage step action
 */
type RenderingMeshStageAction = (mesh: Mesh, subMesh: SubMesh, batch: any, effect: Nullable<Effect>) => void;
/**
 * Strong typing of a simple stage step action
 */
type SimpleStageAction = () => void;
/**
 * Strong typing of a render target action.
 */
type RenderTargetsStageAction = (renderTargets: SmartArrayNoDuplicate<RenderTargetTexture>) => void;
/**
 * Strong typing of a pointer move action.
 */
type PointerMoveStageAction = (unTranslatedPointerX: number, unTranslatedPointerY: number, pickResult: Nullable<PickingInfo>, isMeshPicked: boolean, element: Nullable<HTMLElement>) => Nullable<PickingInfo>;
/**
 * Strong typing of a pointer up/down action.
 */
type PointerUpDownStageAction = (unTranslatedPointerX: number, unTranslatedPointerY: number, pickResult: Nullable<PickingInfo>, evt: IPointerEvent, doubleClick: boolean) => Nullable<PickingInfo>;
/**
 * Representation of a stage in the scene (Basically a list of ordered steps)
 * @internal
 */
declare class Stage<T extends Function> extends Array<{
    index: number;
    component: ISceneComponent;
    action: T;
}> {
    /**
     * Hide ctor from the rest of the world.
     * @param items The items to add.
     */
    private constructor();
    /**
     * Creates a new Stage.
     * @returns A new instance of a Stage
     */
    static Create<T extends Function>(): Stage<T>;
    /**
     * Registers a step in an ordered way in the targeted stage.
     * @param index Defines the position to register the step in
     * @param component Defines the component attached to the step
     * @param action Defines the action to launch during the step
     */
    registerStep(index: number, component: ISceneComponent, action: T): void;
    /**
     * Clears all the steps from the stage.
     */
    clear(): void;
}

declare module "../scene" {
    interface Scene {
        /** @internal */
        _pointerOverSprite: Nullable<Sprite>;
        /** @internal */
        _pickedDownSprite: Nullable<Sprite>;
        /** @internal */
        _tempSpritePickingRay: Nullable<Ray>;
        /**
         * All of the sprite managers added to this scene
         * @see https://doc.babylonjs.com/features/featuresDeepDive/sprites
         */
        spriteManagers?: Array<ISpriteManager>;
        /**
         * An event triggered when a sprite manager is added to the scene
         */
        readonly onNewSpriteManagerAddedObservable: IReadonlyObservable<ISpriteManager>;
        /**
         * An event triggered when a sprite manager is removed from the scene
         */
        readonly onSpriteManagerRemovedObservable: IReadonlyObservable<ISpriteManager>;
        /**
         * An event triggered when sprites rendering is about to start
         * Note: This event can be trigger more than once per frame (because sprites can be rendered by render target textures as well)
         */
        onBeforeSpritesRenderingObservable: Observable<Scene>;
        /**
         * An event triggered when sprites rendering is done
         * Note: This event can be trigger more than once per frame (because sprites can be rendered by render target textures as well)
         */
        onAfterSpritesRenderingObservable: Observable<Scene>;
        /** @internal */
        _internalPickSprites(ray: Ray, predicate?: (sprite: Sprite) => boolean, fastCheck?: boolean, camera?: Camera): Nullable<PickingInfo>;
        /** Launch a ray to try to pick a sprite in the scene
         * @param x position on screen
         * @param y position on screen
         * @param predicate Predicate function used to determine eligible sprites. Can be set to null. In this case, a sprite must have isPickable set to true
         * @param fastCheck defines if the first intersection will be used (and not the closest)
         * @param camera camera to use for computing the picking ray. Can be set to null. In this case, the scene.activeCamera will be used
         * @returns a PickingInfo
         */
        pickSprite(x: number, y: number, predicate?: (sprite: Sprite) => boolean, fastCheck?: boolean, camera?: Camera): Nullable<PickingInfo>;
        /** Use the given ray to pick a sprite in the scene
         * @param ray The ray (in world space) to use to pick meshes
         * @param predicate Predicate function used to determine eligible sprites. Can be set to null. In this case, a sprite must have isPickable set to true
         * @param fastCheck defines if the first intersection will be used (and not the closest)
         * @param camera camera to use. Can be set to null. In this case, the scene.activeCamera will be used
         * @returns a PickingInfo
         */
        pickSpriteWithRay(ray: Ray, predicate?: (sprite: Sprite) => boolean, fastCheck?: boolean, camera?: Camera): Nullable<PickingInfo>;
        /** @internal */
        _internalMultiPickSprites(ray: Ray, predicate?: (sprite: Sprite) => boolean, camera?: Camera): Nullable<PickingInfo[]>;
        /** Launch a ray to try to pick sprites in the scene
         * @param x position on screen
         * @param y position on screen
         * @param predicate Predicate function used to determine eligible sprites. Can be set to null. In this case, a sprite must have isPickable set to true
         * @param camera camera to use for computing the picking ray. Can be set to null. In this case, the scene.activeCamera will be used
         * @returns a PickingInfo array
         */
        multiPickSprite(x: number, y: number, predicate?: (sprite: Sprite) => boolean, camera?: Camera): Nullable<PickingInfo[]>;
        /** Use the given ray to pick sprites in the scene
         * @param ray The ray (in world space) to use to pick meshes
         * @param predicate Predicate function used to determine eligible sprites. Can be set to null. In this case, a sprite must have isPickable set to true
         * @param camera camera to use. Can be set to null. In this case, the scene.activeCamera will be used
         * @returns a PickingInfo array
         */
        multiPickSpriteWithRay(ray: Ray, predicate?: (sprite: Sprite) => boolean, camera?: Camera): Nullable<PickingInfo[]>;
        /**
         * Force the sprite under the pointer
         * @param sprite defines the sprite to use
         */
        setPointerOverSprite(sprite: Nullable<Sprite>): void;
        /**
         * Gets the sprite under the pointer
         * @returns a Sprite or null if no sprite is under the pointer
         */
        getPointerOverSprite(): Nullable<Sprite>;
    }
}
/** @internal */
type InternalSpriteAugmentedScene = Scene & {
    _onNewSpriteManagerAddedObservable?: Observable<ISpriteManager>;
    _onSpriteManagerRemovedObservable?: Observable<ISpriteManager>;
};

/**
 * ThinSprite Class used to represent a thin sprite
 * This is the base class for sprites but can also directly be used with ThinEngine
 * @see https://doc.babylonjs.com/features/featuresDeepDive/sprites
 */
declare class ThinSprite {
    /** Gets or sets the cell index in the sprite sheet */
    cellIndex: number;
    /** Gets or sets the cell reference in the sprite sheet, uses sprite's filename when added to sprite sheet */
    cellRef: string;
    /** Gets or sets the current world position */
    position: IVector3Like;
    /** Gets or sets the main color */
    color: IColor4Like;
    /** Gets or sets the width */
    width: number;
    /** Gets or sets the height */
    height: number;
    /** Gets or sets rotation angle */
    angle: number;
    /** Gets or sets a boolean indicating if UV coordinates should be inverted in U axis */
    invertU: boolean;
    /** Gets or sets a boolean indicating if UV coordinates should be inverted in B axis */
    invertV: boolean;
    /** Gets or sets a boolean indicating if the sprite is visible (renderable). Default is true */
    isVisible: boolean;
    /**
     * Returns a boolean indicating if the animation is started
     */
    get animationStarted(): boolean;
    /** Gets the initial key for the animation (setting it will restart the animation)  */
    get fromIndex(): number;
    /** Gets or sets the end key for the animation (setting it will restart the animation)  */
    get toIndex(): number;
    /** Gets or sets a boolean indicating if the animation is looping (setting it will restart the animation)  */
    get loopAnimation(): boolean;
    /** Gets or sets the delay between cell changes (setting it will restart the animation)  */
    get delay(): number;
    /** @internal */
    _xOffset: number;
    /** @internal */
    _yOffset: number;
    /** @internal */
    _xSize: number;
    /** @internal */
    _ySize: number;
    private _animationStarted;
    protected _loopAnimation: boolean;
    protected _fromIndex: number;
    protected _toIndex: number;
    protected _delay: number;
    private _direction;
    private _time;
    private _onBaseAnimationEnd;
    /**
     * Creates a new Thin Sprite
     */
    constructor();
    /**
     * Starts an animation
     * @param from defines the initial key
     * @param to defines the end key
     * @param loop defines if the animation must loop
     * @param delay defines the start delay (in ms)
     * @param onAnimationEnd defines a callback for when the animation ends
     */
    playAnimation(from: number, to: number, loop: boolean, delay: number, onAnimationEnd: Nullable<() => void>): void;
    /** Stops current animation (if any) */
    stopAnimation(): void;
    /**
     * @internal
     */
    _animate(deltaTime: number): void;
}

/**
 * Options for the SpriteRenderer
 */
interface SpriteRendererOptions {
    /**
     * Sets a boolean indicating if the renderer must render sprites with pixel perfect rendering.
     * In this mode, sprites are rendered as "pixel art", which means that they appear as pixelated but remain stable when moving or when rotated or scaled.
     * Note that for this mode to work as expected, the sprite texture must use the BILINEAR sampling mode, not NEAREST!
     * Default is false.
     */
    pixelPerfect?: boolean;
}
/**
 * Class used to render sprites.
 *
 * It can be used either to render Sprites or ThinSprites with ThinEngine only.
 */
declare class SpriteRenderer {
    /**
     * Force all the sprites to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * Defines the texture of the spritesheet
     */
    texture: Nullable<ThinTexture>;
    /**
     * Defines the default width of a cell in the spritesheet
     */
    cellWidth: number;
    /**
     * Defines the default height of a cell in the spritesheet
     */
    cellHeight: number;
    /**
     * Blend mode use to render the particle, it can be any of
     * the static Constants.ALPHA_x properties provided in this class.
     * Default value is Constants.ALPHA_COMBINE
     */
    blendMode: number;
    /**
     * Gets or sets a boolean indicating if alpha mode is automatically
     * reset.
     */
    autoResetAlpha: boolean;
    /**
     * Disables writing to the depth buffer when rendering the sprites.
     * It can be handy to disable depth writing when using textures without alpha channel
     * and setting some specific blend modes.
     */
    disableDepthWrite: boolean;
    private _fogEnabled;
    /**
     * Gets or sets a boolean indicating if the manager must consider scene fog when rendering
     */
    get fogEnabled(): boolean;
    set fogEnabled(value: boolean);
    protected _useLogarithmicDepth: boolean;
    /**
     * In case the depth buffer does not allow enough depth precision for your scene (might be the case in large scenes)
     * You can try switching to logarithmic depth.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/advanced/logarithmicDepthBuffer
     */
    get useLogarithmicDepth(): boolean;
    set useLogarithmicDepth(value: boolean);
    /**
     * Gets the capacity of the manager
     */
    get capacity(): number;
    private _pixelPerfect;
    /**
     * Gets or sets a boolean indicating if the renderer must render sprites with pixel perfect rendering
     * Note that pixel perfect mode is not supported in WebGL 1
     */
    get pixelPerfect(): boolean;
    set pixelPerfect(value: boolean);
    /** Shader language used by the material */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this renderer.
     */
    get shaderLanguage(): ShaderLanguage;
    private readonly _engine;
    private readonly _useVAO;
    private readonly _useInstancing;
    private readonly _scene;
    private readonly _capacity;
    private readonly _epsilon;
    private _vertexBufferSize;
    private _vertexData;
    private _buffer;
    private _vertexBuffers;
    private _spriteBuffer;
    private _indexBuffer;
    /** @internal */
    _drawWrapperBase: DrawWrapper;
    /** @internal */
    _drawWrapperDepth: DrawWrapper;
    private _vertexArrayObject;
    private _isDisposed;
    /**
     * Creates a new sprite renderer
     * @param engine defines the engine the renderer works with
     * @param capacity defines the maximum allowed number of sprites
     * @param epsilon defines the epsilon value to align texture (0.01 by default)
     * @param scene defines the hosting scene
     * @param rendererOptions options for the sprite renderer
     */
    constructor(engine: AbstractEngine, capacity: number, epsilon?: number, scene?: Nullable<Scene>, rendererOptions?: SpriteRendererOptions);
    private _shadersLoaded;
    private _initShaderSourceAsync;
    private _createEffects;
    /**
     * Render all child sprites
     * @param sprites defines the list of sprites to render
     * @param deltaTime defines the time since last frame
     * @param viewMatrix defines the viewMatrix to use to render the sprites
     * @param projectionMatrix defines the projectionMatrix to use to render the sprites
     * @param customSpriteUpdate defines a custom function to update the sprites data before they render
     */
    render(sprites: ThinSprite[], deltaTime: number, viewMatrix: IMatrixLike, projectionMatrix: IMatrixLike, customSpriteUpdate?: Nullable<(sprite: ThinSprite, baseSize: ISize) => void>): void;
    private _appendSpriteVertex;
    private _buildIndexBuffer;
    /**
     * Rebuilds the renderer (after a context lost, for eg)
     */
    rebuild(): void;
    /**
     * Release associated resources
     */
    dispose(): void;
}

/**
 * Defines the minimum interface to fulfill in order to be a sprite manager.
 */
interface ISpriteManager extends IDisposable {
    /**
     * Gets or sets the unique id of the sprite manager
     */
    uniqueId: number;
    /**
     * Gets manager's name
     */
    name: string;
    /**
     * Restricts the camera to viewing objects with the same layerMask.
     * A camera with a layerMask of 1 will render spriteManager.layerMask & camera.layerMask!== 0
     */
    layerMask: number;
    /**
     * Gets or sets a boolean indicating if the mesh can be picked (by scene.pick for instance or through actions). Default is true
     */
    isPickable: boolean;
    /**
     * Gets the hosting scene
     */
    scene: Scene;
    /**
     * Specifies the rendering group id for this mesh (0 by default)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/advanced/transparent_rendering#rendering-groups
     */
    renderingGroupId: number;
    /**
     * Defines the list of sprites managed by the manager.
     */
    sprites: Array<Sprite>;
    /**
     * Gets or sets the spritesheet texture
     */
    texture: Texture;
    /** Defines the default width of a cell in the spritesheet */
    cellWidth: number;
    /** Defines the default height of a cell in the spritesheet */
    cellHeight: number;
    /** @internal */
    _wasDispatched: boolean;
    /**
     * Specifies if the sprite manager should be serialized
     */
    doNotSerialize?: boolean;
    /**
     * Tests the intersection of a sprite with a specific ray.
     * @param ray The ray we are sending to test the collision
     * @param camera The camera space we are sending rays in
     * @param predicate A predicate allowing excluding sprites from the list of object to test
     * @param fastCheck defines if the first intersection will be used (and not the closest)
     * @returns picking info or null.
     */
    intersects(ray: Ray, camera: Camera, predicate?: (sprite: Sprite) => boolean, fastCheck?: boolean): Nullable<PickingInfo>;
    /**
     * Intersects the sprites with a ray
     * @param ray defines the ray to intersect with
     * @param camera defines the current active camera
     * @param predicate defines a predicate used to select candidate sprites
     * @returns null if no hit or a PickingInfo array
     */
    multiIntersects(ray: Ray, camera: Camera, predicate?: (sprite: Sprite) => boolean): Nullable<PickingInfo[]>;
    /**
     * Renders the list of sprites on screen.
     */
    render(): void;
    /**
     * Rebuilds the manager (after a context lost, for eg)
     */
    rebuild(): void;
    /**
     * Serializes the sprite manager to a JSON object
     */
    serialize(serializeTexture?: boolean): any;
}
/**
 * Options for the SpriteManager
 */
interface SpriteManagerOptions {
    /** Options for the sprite renderer */
    spriteRendererOptions: SpriteRendererOptions;
}
/**
 * Class used to manage multiple sprites on the same spritesheet
 * @see https://doc.babylonjs.com/features/featuresDeepDive/sprites
 */
declare class SpriteManager implements ISpriteManager {
    /** defines the manager's name */
    name: string;
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /** Define the Url to load snippets */
    static SnippetUrl: string;
    /** Snippet ID if the manager was created from the snippet server */
    snippetId: string;
    /** Gets the list of sprites */
    sprites: Sprite[];
    /** Gets or sets the rendering group id (0 by default) */
    renderingGroupId: number;
    /** Gets or sets camera layer mask */
    layerMask: number;
    /** Gets or sets a boolean indicating if the sprites are pickable */
    isPickable: boolean;
    /**
     * Gets or sets an object used to store user defined information for the sprite manager
     */
    metadata: any;
    /** @internal */
    _wasDispatched: boolean;
    /**
     * An event triggered when the manager is disposed.
     */
    onDisposeObservable: Observable<SpriteManager>;
    /**
     * Callback called when the manager is disposed
     */
    set onDispose(callback: () => void);
    /**
     * Gets or sets the unique id of the sprite
     */
    uniqueId: number;
    /**
     * Specifies if the sprite manager should be serialized
     */
    doNotSerialize: boolean;
    /**
     * Gets the array of sprites
     */
    get children(): Sprite[];
    /**
     * Gets the hosting scene
     */
    get scene(): InternalSpriteAugmentedScene;
    /**
     * Gets the capacity of the manager
     */
    get capacity(): number;
    /**
     * Gets or sets the spritesheet texture
     */
    get texture(): Texture;
    set texture(value: Texture);
    /** Defines the default width of a cell in the spritesheet */
    get cellWidth(): number;
    set cellWidth(value: number);
    /** Defines the default height of a cell in the spritesheet */
    get cellHeight(): number;
    set cellHeight(value: number);
    /** Gets or sets a boolean indicating if the manager must consider scene fog when rendering */
    get fogEnabled(): boolean;
    set fogEnabled(value: boolean);
    /** Gets or sets a boolean indicating if the manager must use logarithmic depth when rendering */
    get useLogarithmicDepth(): boolean;
    set useLogarithmicDepth(value: boolean);
    /**
     * Blend mode use to render the particle, it can be any of
     * the static Constants.ALPHA_x properties provided in this class.
     * Default value is Constants.ALPHA_COMBINE
     */
    get blendMode(): number;
    set blendMode(blendMode: number);
    private _disableDepthWrite;
    /** Disables writing to the depth buffer when rendering the sprites.
     *  It can be handy to disable depth writing when using textures without alpha channel
     *  and setting some specific blend modes.
     */
    get disableDepthWrite(): boolean;
    set disableDepthWrite(value: boolean);
    /**
     * Gets or sets a boolean indicating if the renderer must render sprites with pixel perfect rendering
     * In this mode, sprites are rendered as "pixel art", which means that they appear as pixelated but remain stable when moving or when rotated or scaled.
     * Note that for this mode to work as expected, the sprite texture must use the BILINEAR sampling mode, not NEAREST!
     */
    get pixelPerfect(): boolean;
    set pixelPerfect(value: boolean);
    /**
     * Gets the sprite renderer associated with this manager
     */
    get spriteRenderer(): SpriteRenderer;
    private _spriteRenderer;
    /** Associative array from JSON sprite data file */
    private _cellData;
    /** Array of sprite names from JSON sprite data file */
    private _spriteMap;
    /** True when packed cell data from JSON file is ready*/
    private _packedAndReady;
    private _textureContent;
    private _onDisposeObserver;
    private _fromPacked;
    private _scene;
    /**
     * Creates a new sprite manager
     * @param name defines the manager's name
     * @param imgUrl defines the sprite sheet url
     * @param capacity defines the maximum allowed number of sprites
     * @param cellSize defines the size of a sprite cell
     * @param scene defines the hosting scene
     * @param epsilon defines the epsilon value to align texture (0.01 by default)
     * @param samplingMode defines the sampling mode to use with spritesheet
     * @param fromPacked set to false; do not alter
     * @param spriteJSON null otherwise a JSON object defining sprite sheet data; do not alter
     * @param options options used to create the SpriteManager instance
     */
    constructor(
    /** defines the manager's name */
    name: string, imgUrl: string, capacity: number, cellSize: any, scene: Scene, epsilon?: number, samplingMode?: number, fromPacked?: boolean, spriteJSON?: null | string, options?: SpriteManagerOptions);
    /**
     * Returns the string "SpriteManager"
     * @returns "SpriteManager"
     */
    getClassName(): string;
    private _makePacked;
    private _checkTextureAlpha;
    /**
     * Intersects the sprites with a ray
     * @param ray defines the ray to intersect with
     * @param camera defines the current active camera
     * @param predicate defines a predicate used to select candidate sprites
     * @param fastCheck defines if a fast check only must be done (the first potential sprite is will be used and not the closer)
     * @returns null if no hit or a PickingInfo
     */
    intersects(ray: Ray, camera: Camera, predicate?: (sprite: Sprite) => boolean, fastCheck?: boolean): Nullable<PickingInfo>;
    /**
     * Intersects the sprites with a ray
     * @param ray defines the ray to intersect with
     * @param camera defines the current active camera
     * @param predicate defines a predicate used to select candidate sprites
     * @returns null if no hit or a PickingInfo array
     */
    multiIntersects(ray: Ray, camera: Camera, predicate?: (sprite: Sprite) => boolean): Nullable<PickingInfo[]>;
    /**
     * Render all child sprites
     */
    render(): void;
    private _customUpdate;
    /**
     * Rebuilds the manager (after a context lost, for eg)
     */
    rebuild(): void;
    /**
     * Release associated resources
     */
    dispose(): void;
    /**
     * Serializes the sprite manager to a JSON object
     * @param serializeTexture defines if the texture must be serialized as well
     * @returns the JSON object
     */
    serialize(serializeTexture?: boolean): any;
    /**
     * Parses a JSON object to create a new sprite manager.
     * @param parsedManager The JSON object to parse
     * @param scene The scene to create the sprite manager
     * @param rootUrl The root url to use to load external dependencies like texture
     * @returns the new sprite manager
     */
    static Parse(parsedManager: any, scene: Scene, rootUrl: string): SpriteManager;
    /**
     * Creates a sprite manager from a snippet saved in a remote file
     * @param name defines the name of the sprite manager to create (can be null or empty to use the one from the json data)
     * @param url defines the url to load from
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a promise that will resolve to the new sprite manager
     */
    static ParseFromFileAsync(name: Nullable<string>, url: string, scene: Scene, rootUrl?: string): Promise<SpriteManager>;
    /**
     * Creates a sprite manager from a snippet saved by the sprite editor
     * @param snippetId defines the snippet to load (can be set to _BLANK to create a default one)
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a promise that will resolve to the new sprite manager
     */
    static ParseFromSnippetAsync(snippetId: string, scene: Scene, rootUrl?: string): Promise<SpriteManager>;
    /**
     * Creates a sprite manager from a snippet saved by the sprite editor
     * @deprecated Please use ParseFromSnippetAsync instead
     * @param snippetId defines the snippet to load (can be set to _BLANK to create a default one)
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a promise that will resolve to the new sprite manager
     */
    static CreateFromSnippetAsync: typeof SpriteManager.ParseFromSnippetAsync;
}

/**
 * Class used to represent a sprite
 * @see https://doc.babylonjs.com/features/featuresDeepDive/sprites
 */
declare class Sprite extends ThinSprite implements IAnimatable {
    /** defines the name */
    name: string;
    /** Gets or sets the current world position */
    position: Vector3;
    /** Gets or sets the main color */
    color: Color4;
    /** Gets or sets a boolean indicating that this sprite should be disposed after animation ends */
    disposeWhenFinishedAnimating: boolean;
    /** Gets the list of attached animations */
    animations: Nullable<Array<Animation>>;
    /** Gets or sets a boolean indicating if the sprite can be picked */
    isPickable: boolean;
    /** Gets or sets a boolean indicating that sprite texture alpha will be used for precise picking (false by default) */
    useAlphaForPicking: boolean;
    /**
     * Gets or sets the associated action manager
     */
    actionManager: Nullable<ActionManager>;
    /**
     * An event triggered when the control has been disposed
     */
    onDisposeObservable: Observable<Sprite>;
    private _manager;
    private _onAnimationEnd;
    /**
     * Gets or sets the sprite size
     */
    get size(): number;
    set size(value: number);
    /**
     * Gets or sets the unique id of the sprite
     */
    uniqueId: number;
    /**
     * Gets the manager of this sprite
     */
    get manager(): ISpriteManager;
    /**
     * Creates a new Sprite
     * @param name defines the name
     * @param manager defines the manager
     */
    constructor(
    /** defines the name */
    name: string, manager: ISpriteManager);
    /**
     * Returns the string "Sprite"
     * @returns "Sprite"
     */
    getClassName(): string;
    /** Gets or sets the initial key for the animation (setting it will restart the animation)  */
    get fromIndex(): number;
    set fromIndex(value: number);
    /** Gets or sets the end key for the animation (setting it will restart the animation)  */
    get toIndex(): number;
    set toIndex(value: number);
    /** Gets or sets a boolean indicating if the animation is looping (setting it will restart the animation)  */
    get loopAnimation(): boolean;
    set loopAnimation(value: boolean);
    /** Gets or sets the delay between cell changes (setting it will restart the animation)  */
    get delay(): number;
    set delay(value: number);
    /**
     * Starts an animation
     * @param from defines the initial key
     * @param to defines the end key
     * @param loop defines if the animation must loop
     * @param delay defines the start delay (in ms)
     * @param onAnimationEnd defines a callback to call when animation ends
     */
    playAnimation(from: number, to: number, loop: boolean, delay: number, onAnimationEnd?: Nullable<() => void>): void;
    private _endAnimation;
    /** Release associated resources */
    dispose(): void;
    /**
     * Serializes the sprite to a JSON object
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parses a JSON object to create a new sprite
     * @param parsedSprite The JSON object to parse
     * @param manager defines the hosting manager
     * @returns the new sprite
     */
    static Parse(parsedSprite: any, manager: SpriteManager): Sprite;
}

/**
 * Information about the result of picking within a scene
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/interactions/picking_collisions
 */
declare class PickingInfo {
    /**
     * If the pick collided with an object
     */
    hit: boolean;
    /**
     * Distance away where the pick collided
     */
    distance: number;
    /**
     * The location of pick collision
     */
    pickedPoint: Nullable<Vector3>;
    /**
     * The mesh corresponding the pick collision
     */
    pickedMesh: Nullable<AbstractMesh>;
    /** (See getTextureCoordinates) The barycentric U coordinate that is used when calculating the texture coordinates of the collision.*/
    bu: number;
    /** (See getTextureCoordinates) The barycentric V coordinate that is used when calculating the texture coordinates of the collision.*/
    bv: number;
    /** The index of the face on the mesh that was picked, or the index of the Line if the picked Mesh is a LinesMesh */
    faceId: number;
    /** The index of the face on the subMesh that was picked, or the index of the Line if the picked Mesh is a LinesMesh */
    subMeshFaceId: number;
    /** Id of the submesh that was picked */
    subMeshId: number;
    /** If a sprite was picked, this will be the sprite the pick collided with */
    pickedSprite: Nullable<Sprite>;
    /** If we are picking a mesh with thin instance, this will give you the picked thin instance */
    thinInstanceIndex: number;
    /**
     * The ray that was used to perform the picking.
     */
    ray: Nullable<Ray>;
    /**
     * If a mesh was used to do the picking (eg. 6dof controller) as a "near interaction", this will be populated.
     */
    originMesh: Nullable<AbstractMesh>;
    /**
     * The aim-space transform of the input used for picking, if it is an XR input source.
     */
    aimTransform: Nullable<TransformNode>;
    /**
     * The grip-space transform of the input used for picking, if it is an XR input source.
     * Some XR sources, such as input coming from head mounted displays, do not have this.
     */
    gripTransform: Nullable<TransformNode>;
    /**
     * Gets the normal corresponding to the face the pick collided with
     * @param useWorldCoordinates If the resulting normal should be relative to the world (default: false)
     * @param useVerticesNormals If the vertices normals should be used to calculate the normal instead of the normal map (default: true)
     * @returns The normal corresponding to the face the pick collided with
     * @remarks Note that the returned normal will always point towards the picking ray.
     */
    getNormal(useWorldCoordinates?: boolean, useVerticesNormals?: boolean): Nullable<Vector3>;
    /**
     * Gets the texture coordinates of where the pick occurred
     * @param uvSet The UV set to use to calculate the texture coordinates (default: VertexBuffer.UVKind)
     * @returns The vector containing the coordinates of the texture
     */
    getTextureCoordinates(uvSet?: string): Nullable<Vector2>;
}

/**
 * Type used to define predicate for selecting meshes and instances (if exist)
 */
type MeshPredicate = (mesh: AbstractMesh, thinInstanceIndex: number) => boolean;
/**
 * Type used to define predicate used to select faces when a mesh intersection is detected
 */
type TrianglePickingPredicate = (p0: Vector3, p1: Vector3, p2: Vector3, ray: Ray, i0: number, i1: number, i2: number) => boolean;
/**
 * Class representing a ray with position and direction
 */
declare class Ray {
    /** origin point */
    origin: Vector3;
    /** direction */
    direction: Vector3;
    /** [Number.MAX_VALUE] length of the ray */
    length: number;
    /** [Epsilon] The epsilon value to use when calculating the ray/triangle intersection (default: Epsilon from math constants) */
    epsilon: number;
    private static readonly _TmpVector3;
    private static _RayDistant;
    private _tmpRay;
    /**
     * Creates a new ray
     * @param origin origin point
     * @param direction direction
     * @param length length of the ray
     * @param epsilon The epsilon value to use when calculating the ray/triangle intersection (default: Epsilon from math constants)
     */
    constructor(
    /** origin point */
    origin: Vector3, 
    /** direction */
    direction: Vector3, 
    /** [Number.MAX_VALUE] length of the ray */
    length?: number, 
    /** [Epsilon] The epsilon value to use when calculating the ray/triangle intersection (default: Epsilon from math constants) */
    epsilon?: number);
    /**
     * Clone the current ray
     * @returns a new ray
     */
    clone(): Ray;
    /**
     * Checks if the ray intersects a box
     * This does not account for the ray length by design to improve perfs.
     * @param minimum bound of the box
     * @param maximum bound of the box
     * @param intersectionTreshold extra extend to be added to the box in all direction
     * @returns if the box was hit
     */
    intersectsBoxMinMax(minimum: DeepImmutable<Vector3>, maximum: DeepImmutable<Vector3>, intersectionTreshold?: number): boolean;
    /**
     * Checks if the ray intersects a box
     * This does not account for the ray length by design to improve perfs.
     * @param box the bounding box to check
     * @param intersectionTreshold extra extend to be added to the BoundingBox in all direction
     * @returns if the box was hit
     */
    intersectsBox(box: DeepImmutable<BoundingBox>, intersectionTreshold?: number): boolean;
    /**
     * If the ray hits a sphere
     * @param sphere the bounding sphere to check
     * @param intersectionTreshold extra extend to be added to the BoundingSphere in all direction
     * @returns true if it hits the sphere
     */
    intersectsSphere(sphere: DeepImmutable<BoundingSphere>, intersectionTreshold?: number): boolean;
    /**
     * If the ray hits a triange
     * @param vertex0 triangle vertex
     * @param vertex1 triangle vertex
     * @param vertex2 triangle vertex
     * @returns intersection information if hit
     */
    intersectsTriangle(vertex0: DeepImmutable<Vector3>, vertex1: DeepImmutable<Vector3>, vertex2: DeepImmutable<Vector3>): Nullable<IntersectionInfo>;
    /**
     * Checks if ray intersects a plane
     * @param plane the plane to check
     * @returns the distance away it was hit
     */
    intersectsPlane(plane: DeepImmutable<Plane>): Nullable<number>;
    /**
     * Calculate the intercept of a ray on a given axis
     * @param axis to check 'x' | 'y' | 'z'
     * @param offset from axis interception (i.e. an offset of 1y is intercepted above ground)
     * @returns a vector containing the coordinates where 'axis' is equal to zero (else offset), or null if there is no intercept.
     */
    intersectsAxis(axis: string, offset?: number): Nullable<Vector3>;
    /**
     * Checks if ray intersects a mesh. The ray is defined in WORLD space. A mesh triangle can be picked both from its front and back sides,
     * irrespective of orientation.
     * @param mesh the mesh to check
     * @param fastCheck defines if the first intersection will be used (and not the closest)
     * @param trianglePredicate defines an optional predicate used to select faces when a mesh intersection is detected
     * @param onlyBoundingInfo defines a boolean indicating if picking should only happen using bounding info (false by default)
     * @param worldToUse defines the world matrix to use to get the world coordinate of the intersection point
     * @param skipBoundingInfo a boolean indicating if we should skip the bounding info check
     * @returns picking info of the intersection
     */
    intersectsMesh(mesh: DeepImmutable<AbstractMesh>, fastCheck?: boolean, trianglePredicate?: TrianglePickingPredicate, onlyBoundingInfo?: boolean, worldToUse?: Matrix, skipBoundingInfo?: boolean): PickingInfo;
    /**
     * Checks if ray intersects a mesh
     * @param meshes the meshes to check
     * @param fastCheck defines if the first intersection will be used (and not the closest)
     * @param results array to store result in
     * @returns Array of picking infos
     */
    intersectsMeshes(meshes: Array<DeepImmutable<AbstractMesh>>, fastCheck?: boolean, results?: Array<PickingInfo>): Array<PickingInfo>;
    private _comparePickingInfo;
    private static _Smallnum;
    private static _Rayl;
    /**
     * Intersection test between the ray and a given segment within a given tolerance (threshold)
     * @param sega the first point of the segment to test the intersection against
     * @param segb the second point of the segment to test the intersection against
     * @param threshold the tolerance margin, if the ray doesn't intersect the segment but is close to the given threshold, the intersection is successful
     * @returns the distance from the ray origin to the intersection point if there's intersection, or -1 if there's no intersection
     */
    intersectionSegment(sega: DeepImmutable<Vector3>, segb: DeepImmutable<Vector3>, threshold: number): number;
    /**
     * Update the ray from viewport position
     * @param x position
     * @param y y position
     * @param viewportWidth viewport width
     * @param viewportHeight viewport height
     * @param world world matrix
     * @param view view matrix
     * @param projection projection matrix
     * @param enableDistantPicking defines if picking should handle large values for mesh position/scaling (false by default)
     * @returns this ray updated
     */
    update(x: number, y: number, viewportWidth: number, viewportHeight: number, world: DeepImmutable<Matrix>, view: DeepImmutable<Matrix>, projection: DeepImmutable<Matrix>, enableDistantPicking?: boolean): Ray;
    /**
     * Creates a ray with origin and direction of 0,0,0
     * @returns the new ray
     */
    static Zero(): Ray;
    /**
     * Creates a new ray from screen space and viewport
     * @param x position
     * @param y y position
     * @param viewportWidth viewport width
     * @param viewportHeight viewport height
     * @param world world matrix
     * @param view view matrix
     * @param projection projection matrix
     * @returns new ray
     */
    static CreateNew(x: number, y: number, viewportWidth: number, viewportHeight: number, world: DeepImmutable<Matrix>, view: DeepImmutable<Matrix>, projection: DeepImmutable<Matrix>): Ray;
    /**
     * Function will create a new transformed ray starting from origin and ending at the end point. Ray's length will be set, and ray will be
     * transformed to the given world matrix.
     * @param origin The origin point
     * @param end The end point
     * @param world a matrix to transform the ray to. Default is the identity matrix.
     * @returns the new ray
     */
    static CreateNewFromTo(origin: Vector3, end: Vector3, world?: DeepImmutable<Matrix>): Ray;
    /**
     * Function will update a transformed ray starting from origin and ending at the end point. Ray's length will be set, and ray will be
     * transformed to the given world matrix.
     * @param origin The origin point
     * @param end The end point
     * @param result the object to store the result
     * @param world a matrix to transform the ray to. Default is the identity matrix.
     * @returns the ref ray
     */
    static CreateFromToToRef(origin: Vector3, end: Vector3, result: Ray, world?: DeepImmutable<Matrix>): Ray;
    /**
     * Transforms a ray by a matrix
     * @param ray ray to transform
     * @param matrix matrix to apply
     * @returns the resulting new ray
     */
    static Transform(ray: DeepImmutable<Ray>, matrix: DeepImmutable<Matrix>): Ray;
    /**
     * Transforms a ray by a matrix
     * @param ray ray to transform
     * @param matrix matrix to apply
     * @param result ray to store result in
     * @returns the updated result ray
     */
    static TransformToRef(ray: DeepImmutable<Ray>, matrix: DeepImmutable<Matrix>, result: Ray): Ray;
    /**
     * Unproject a ray from screen space to object space
     * @param sourceX defines the screen space x coordinate to use
     * @param sourceY defines the screen space y coordinate to use
     * @param viewportWidth defines the current width of the viewport
     * @param viewportHeight defines the current height of the viewport
     * @param world defines the world matrix to use (can be set to Identity to go to world space)
     * @param view defines the view matrix to use
     * @param projection defines the projection matrix to use
     */
    unprojectRayToRef(sourceX: float, sourceY: float, viewportWidth: number, viewportHeight: number, world: DeepImmutable<Matrix>, view: DeepImmutable<Matrix>, projection: DeepImmutable<Matrix>): void;
}

/**
 * Defines a subdivision inside a mesh
 */
declare class SubMesh implements ICullable {
    /** the material index to use */
    materialIndex: number;
    /** vertex index start */
    verticesStart: number;
    /** vertices count */
    verticesCount: number;
    /** index start */
    indexStart: number;
    /** indices count */
    indexCount: number;
    private _engine;
    /** @internal */
    _drawWrappers: Array<DrawWrapper>;
    private _mainDrawWrapperOverride;
    /**
     * Gets material defines used by the effect associated to the sub mesh
     */
    get materialDefines(): Nullable<MaterialDefines>;
    /**
     * Sets material defines used by the effect associated to the sub mesh
     */
    set materialDefines(defines: Nullable<MaterialDefines>);
    /**
     * @internal
     */
    _getDrawWrapper(passId?: number, createIfNotExisting?: boolean): DrawWrapper | undefined;
    /**
     * @internal
     */
    _removeDrawWrapper(passId: number, disposeWrapper?: boolean, immediate?: boolean): void;
    /**
     * Gets associated (main) effect (possibly the effect override if defined)
     */
    get effect(): Nullable<Effect>;
    /** @internal */
    get _drawWrapper(): DrawWrapper;
    /** @internal */
    get _drawWrapperOverride(): Nullable<DrawWrapper>;
    /**
     * @internal
     */
    _setMainDrawWrapperOverride(wrapper: Nullable<DrawWrapper>): void;
    /**
     * Sets associated effect (effect used to render this submesh)
     * @param effect defines the effect to associate with
     * @param defines defines the set of defines used to compile this effect
     * @param materialContext material context associated to the effect
     * @param resetContext true to reset the draw context
     */
    setEffect(effect: Nullable<Effect>, defines?: Nullable<string | MaterialDefines>, materialContext?: IMaterialContext, resetContext?: boolean): void;
    /**
     * Resets the draw wrappers cache
     * @param passId If provided, releases only the draw wrapper corresponding to this render pass id
     * @param immediate If true, the draw wrapper will dispose the effect immediately (false by default)
     */
    resetDrawCache(passId?: number, immediate?: boolean): void;
    /** @internal */
    _linesIndexCount: number;
    private _mesh;
    private _renderingMesh;
    private _boundingInfo;
    private _linesIndexBuffer;
    /** @internal */
    _lastColliderWorldVertices: Nullable<Vector3[]>;
    /** @internal */
    _trianglePlanes: Plane[];
    /** @internal */
    _lastColliderTransformMatrix: Nullable<Matrix>;
    /** @internal */
    _wasDispatched: boolean;
    /** @internal */
    _renderId: number;
    /** @internal */
    _alphaIndex: number;
    /** @internal */
    _distanceToCamera: number;
    /** @internal */
    _id: number;
    private _currentMaterial;
    /**
     * Add a new submesh to a mesh
     * @param materialIndex defines the material index to use
     * @param verticesStart defines vertex index start
     * @param verticesCount defines vertices count
     * @param indexStart defines index start
     * @param indexCount defines indices count
     * @param mesh defines the parent mesh
     * @param renderingMesh defines an optional rendering mesh
     * @param createBoundingBox defines if bounding box should be created for this submesh
     * @returns the new submesh
     */
    static AddToMesh(materialIndex: number, verticesStart: number, verticesCount: number, indexStart: number, indexCount: number, mesh: AbstractMesh, renderingMesh?: Mesh, createBoundingBox?: boolean): SubMesh;
    /**
     * Creates a new submesh
     * @param materialIndex defines the material index to use
     * @param verticesStart defines vertex index start
     * @param verticesCount defines vertices count
     * @param indexStart defines index start
     * @param indexCount defines indices count
     * @param mesh defines the parent mesh
     * @param renderingMesh defines an optional rendering mesh
     * @param createBoundingBox defines if bounding box should be created for this submesh
     * @param addToMesh defines a boolean indicating that the submesh must be added to the mesh.subMeshes array (true by default)
     */
    constructor(
    /** the material index to use */
    materialIndex: number, 
    /** vertex index start */
    verticesStart: number, 
    /** vertices count */
    verticesCount: number, 
    /** index start */
    indexStart: number, 
    /** indices count */
    indexCount: number, mesh: AbstractMesh, renderingMesh?: Mesh, createBoundingBox?: boolean, addToMesh?: boolean);
    /**
     * Returns true if this submesh covers the entire parent mesh
     * @ignorenaming
     */
    get IsGlobal(): boolean;
    /**
     * Returns the submesh BoundingInfo object
     * @returns current bounding info (or mesh's one if the submesh is global)
     */
    getBoundingInfo(): BoundingInfo;
    /**
     * Sets the submesh BoundingInfo
     * @param boundingInfo defines the new bounding info to use
     * @returns the SubMesh
     */
    setBoundingInfo(boundingInfo: BoundingInfo): SubMesh;
    /**
     * Returns the mesh of the current submesh
     * @returns the parent mesh
     */
    getMesh(): AbstractMesh;
    /**
     * Returns the rendering mesh of the submesh
     * @returns the rendering mesh (could be different from parent mesh)
     */
    getRenderingMesh(): Mesh;
    /**
     * Returns the replacement mesh of the submesh
     * @returns the replacement mesh (could be different from parent mesh)
     */
    getReplacementMesh(): Nullable<AbstractMesh>;
    /**
     * Returns the effective mesh of the submesh
     * @returns the effective mesh (could be different from parent mesh)
     */
    getEffectiveMesh(): AbstractMesh;
    /**
     * Returns the submesh material
     * @param getDefaultMaterial Defines whether or not to get the default material if nothing has been defined.
     * @returns null or the current material
     */
    getMaterial(getDefaultMaterial?: boolean): Nullable<Material>;
    private _isMultiMaterial;
    /**
     * Sets a new updated BoundingInfo object to the submesh
     * @param data defines an optional position array to use to determine the bounding info
     * @returns the SubMesh
     */
    refreshBoundingInfo(data?: Nullable<FloatArray>): SubMesh;
    /**
     * @internal
     */
    _checkCollision(collider: Collider): boolean;
    /**
     * Updates the submesh BoundingInfo
     * @param world defines the world matrix to use to update the bounding info
     * @returns the submesh
     */
    updateBoundingInfo(world: DeepImmutable<Matrix>): SubMesh;
    /**
     * True is the submesh bounding box intersects the frustum defined by the passed array of planes.
     * @param frustumPlanes defines the frustum planes
     * @returns true if the submesh is intersecting with the frustum
     */
    isInFrustum(frustumPlanes: Plane[]): boolean;
    /**
     * True is the submesh bounding box is completely inside the frustum defined by the passed array of planes
     * @param frustumPlanes defines the frustum planes
     * @returns true if the submesh is inside the frustum
     */
    isCompletelyInFrustum(frustumPlanes: Plane[]): boolean;
    /**
     * Renders the submesh
     * @param enableAlphaMode defines if alpha needs to be used
     * @returns the submesh
     */
    render(enableAlphaMode: boolean): SubMesh;
    /**
     * @internal
     */
    _getLinesIndexBuffer(indices: IndicesArray, engine: AbstractEngine): DataBuffer;
    /**
     * Checks if the submesh intersects with a ray
     * @param ray defines the ray to test
     * @returns true is the passed ray intersects the submesh bounding box
     */
    canIntersects(ray: Ray): boolean;
    /**
     * Intersects current submesh with a ray
     * @param ray defines the ray to test
     * @param positions defines mesh's positions array
     * @param indices defines mesh's indices array
     * @param fastCheck defines if the first intersection will be used (and not the closest)
     * @param trianglePredicate defines an optional predicate used to select faces when a mesh intersection is detected
     * @returns intersection info or null if no intersection
     */
    intersects(ray: Ray, positions: Vector3[], indices: IndicesArray, fastCheck?: boolean, trianglePredicate?: TrianglePickingPredicate): Nullable<IntersectionInfo>;
    /**
     * @internal
     */
    private _intersectLines;
    /**
     * @internal
     */
    private _intersectUnIndexedLines;
    /**
     * @internal
     */
    private _intersectTriangles;
    /**
     * @internal
     */
    private _intersectUnIndexedTriangles;
    /** @internal */
    _rebuild(): void;
    /**
     * Creates a new submesh from the passed mesh
     * @param newMesh defines the new hosting mesh
     * @param newRenderingMesh defines an optional rendering mesh
     * @returns the new submesh
     */
    clone(newMesh: AbstractMesh, newRenderingMesh?: Mesh): SubMesh;
    /**
     * Release associated resources
     * @param immediate If true, the effect will be disposed immediately (false by default)
     */
    dispose(immediate?: boolean): void;
    /**
     * Gets the class name
     * @returns the string "SubMesh".
     */
    getClassName(): string;
    /**
     * Creates a new submesh from indices data
     * @param materialIndex the index of the main mesh material
     * @param startIndex the index where to start the copy in the mesh indices array
     * @param indexCount the number of indices to copy then from the startIndex
     * @param mesh the main mesh to create the submesh from
     * @param renderingMesh the optional rendering mesh
     * @param createBoundingBox defines if bounding box should be created for this submesh
     * @returns a new submesh
     */
    static CreateFromIndices(materialIndex: number, startIndex: number, indexCount: number, mesh: AbstractMesh, renderingMesh?: Mesh, createBoundingBox?: boolean): SubMesh;
}

/**
 * Options to create a procedural texture
 */
interface IProceduralTextureCreationOptions extends RenderTargetTextureOptions {
    /**
     * Defines a fallback texture in case there were issues to create the custom texture
     */
    fallbackTexture?: Nullable<Texture>;
    /**
     * The shader language of the shader. (default: GLSL)
     */
    shaderLanguage?: ShaderLanguage;
    /**
     * Additional async code to run before preparing the effect
     */
    extraInitializationsAsync?: () => Promise<void>;
}
/**
 * Procedural texturing is a way to programmatically create a texture. There are 2 types of procedural textures: code-only, and code that references some classic 2D images, sometimes calmpler' images.
 * This is the base class of any Procedural texture and contains most of the shareable code.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/proceduralTextures
 */
declare class ProceduralTexture extends Texture {
    /**
     * Define if the texture is enabled or not (disabled texture will not render)
     */
    isEnabled: boolean;
    /**
     * Define if the texture must be cleared before rendering (default is true)
     */
    autoClear: boolean;
    /**
     * Callback called when the texture is generated
     */
    onGenerated: () => void;
    /**
     * Event raised when the texture is generated
     */
    onGeneratedObservable: Observable<ProceduralTexture>;
    /**
     * Event raised before the texture is generated
     */
    onBeforeGenerationObservable: Observable<ProceduralTexture>;
    /**
     * Gets or sets the node material used to create this texture (null if the texture was manually created)
     */
    nodeMaterialSource: Nullable<NodeMaterial>;
    /**
     * Define the list of custom preprocessor defines used in the shader
     */
    defines: string;
    /** @internal */
    _generateMipMaps: boolean;
    private _drawWrapper;
    /** @internal */
    _textures: {
        [key: string]: ThinTexture;
    };
    /** @internal */
    protected _fallbackTexture: Nullable<Texture>;
    /** @internal */
    private _shaderLanguage;
    /**
     * Gets the shader language type used to generate vertex and fragment source code.
     */
    get shaderLanguage(): ShaderLanguage;
    private _size;
    private _textureType;
    private _currentRefreshId;
    private _frameId;
    private _refreshRate;
    private _vertexBuffers;
    private _indexBuffer;
    private _uniforms;
    private _samplers;
    private _fragment;
    private _floats;
    private _ints;
    private _floatsArrays;
    private _colors3;
    private _colors4;
    private _vectors2;
    private _vectors3;
    private _vectors4;
    private _matrices;
    private _fallbackTextureUsed;
    private _fullEngine;
    private _cachedDefines;
    private _contentUpdateId;
    private _contentData;
    private _rtWrapper;
    private _options;
    /**
     * Instantiates a new procedural texture.
     * Procedural texturing is a way to programmatically create a texture. There are 2 types of procedural textures: code-only, and code that references some classic 2D images, sometimes called 'refMaps' or 'sampler' images.
     * This is the base class of any Procedural texture and contains most of the shareable code.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/proceduralTextures
     * @param name  Define the name of the texture
     * @param size Define the size of the texture to create
     * @param fragment Define the fragment shader to use to generate the texture or null if it is defined later:
     *  * object: \{ fragmentElement: "fragmentShaderCode" \}, used with shader code in script tags
     *  * object: \{ fragmentSource: "fragment shader code string" \}, the string contains the shader code
     *  * string: the string contains a name "XXX" to lookup in Effect.ShadersStore["XXXFragmentShader"]
     * @param scene Define the scene the texture belongs to
     * @param fallbackTexture Define a fallback texture in case there were issues to create the custom texture
     * @param generateMipMaps Define if the texture should creates mip maps or not
     * @param isCube Define if the texture is a cube texture or not (this will render each faces of the cube)
     * @param textureType The FBO internal texture type
     */
    constructor(name: string, size: TextureSize, fragment: any, scene: Nullable<Scene>, fallbackTexture?: Nullable<Texture> | IProceduralTextureCreationOptions, generateMipMaps?: boolean, isCube?: boolean, textureType?: number);
    private _createRtWrapper;
    /**
     * The effect that is created when initializing the post process.
     * @returns The created effect corresponding the postprocess.
     */
    getEffect(): Effect;
    /**
     * @internal
     */
    _setEffect(effect: Effect): void;
    /**
     * Gets texture content (Use this function wisely as reading from a texture can be slow)
     * @returns an ArrayBufferView promise (Uint8Array or Float32Array)
     */
    getContent(): Nullable<Promise<ArrayBufferView>>;
    private _createIndexBuffer;
    /** @internal */
    _rebuild(): void;
    /**
     * Resets the texture in order to recreate its associated resources.
     * This can be called in case of context loss or if you change the shader code and need to regenerate the texture with the new code
     */
    reset(): void;
    protected _getDefines(): string;
    /**
     * Executes a function when the texture will be ready to be drawn.
     * @param func The callback to be used.
     */
    executeWhenReady(func: (texture: ProceduralTexture) => void): void;
    /**
     * Is the texture ready to be used ? (rendered at least once)
     * @returns true if ready, otherwise, false.
     */
    isReady(): boolean;
    /**
     * Resets the refresh counter of the texture and start bak from scratch.
     * Could be useful to regenerate the texture if it is setup to render only once.
     */
    resetRefreshCounter(): void;
    /**
     * Set the fragment shader to use in order to render the texture.
     * @param fragment This can be set to a path (into the shader store) or to a json object containing a fragmentElement property.
     */
    setFragment(fragment: any): void;
    /**
     * Define the refresh rate of the texture or the rendering frequency.
     * Use 0 to render just once, 1 to render on every frame, 2 to render every two frames and so on...
     */
    get refreshRate(): number;
    set refreshRate(value: number);
    /** @internal */
    _shouldRender(): boolean;
    /**
     * Get the size the texture is rendering at.
     * @returns the size (on cube texture it is always squared)
     */
    getRenderSize(): TextureSize;
    /**
     * Resize the texture to new value.
     * @param size Define the new size the texture should have
     * @param generateMipMaps Define whether the new texture should create mip maps
     */
    resize(size: TextureSize, generateMipMaps: boolean): void;
    private _checkUniform;
    /**
     * Set a texture in the shader program used to render.
     * @param name Define the name of the uniform samplers as defined in the shader
     * @param texture Define the texture to bind to this sampler
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setTexture(name: string, texture: ThinTexture): ProceduralTexture;
    /**
     * Set a float in the shader.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setFloat(name: string, value: number): ProceduralTexture;
    /**
     * Set a int in the shader.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setInt(name: string, value: number): ProceduralTexture;
    /**
     * Set an array of floats in the shader.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setFloats(name: string, value: number[]): ProceduralTexture;
    /**
     * Set a vec3 in the shader from a Color3.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setColor3(name: string, value: Color3): ProceduralTexture;
    /**
     * Set a vec4 in the shader from a Color4.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setColor4(name: string, value: Color4): ProceduralTexture;
    /**
     * Set a vec2 in the shader from a Vector2.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setVector2(name: string, value: Vector2): ProceduralTexture;
    /**
     * Set a vec3 in the shader from a Vector3.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setVector3(name: string, value: Vector3): ProceduralTexture;
    /**
     * Set a vec4 in the shader from a Vector4.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setVector4(name: string, value: Vector4): ProceduralTexture;
    /**
     * Set a mat4 in the shader from a MAtrix.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the texture itself allowing "fluent" like uniform updates
     */
    setMatrix(name: string, value: Matrix): ProceduralTexture;
    /**
     * Render the texture to its associated render target.
     * @param useCameraPostProcess Define if camera post process should be applied to the texture
     */
    render(useCameraPostProcess?: boolean): void;
    /**
     * Clone the texture.
     * @returns the cloned texture
     */
    clone(): ProceduralTexture;
    /**
     * Dispose the texture and release its associated resources.
     */
    dispose(): void;
}

/** @internal */
declare class UniformBufferEffectCommonAccessor {
    setMatrix3x3: (name: string, matrix: Float32Array) => void;
    setMatrix2x2: (name: string, matrix: Float32Array) => void;
    setFloat: (name: string, x: number) => void;
    setFloat2: (name: string, x: number, y: number, suffix?: string) => void;
    setFloat3: (name: string, x: number, y: number, z: number, suffix?: string) => void;
    setFloat4: (name: string, x: number, y: number, z: number, w: number, suffix?: string) => void;
    setFloatArray: (name: string, array: Float32Array) => void;
    setArray: (name: string, array: number[]) => void;
    setIntArray: (name: string, array: Int32Array) => void;
    setMatrix: (name: string, mat: IMatrixLike) => void;
    setMatrices: (name: string, mat: Float32Array) => void;
    setVector3: (name: string, vector: IVector3Like) => void;
    setVector4: (name: string, vector: IVector4Like) => void;
    setColor3: (name: string, color: IColor3Like, suffix?: string) => void;
    setColor4: (name: string, color: IColor3Like, alpha: number, suffix?: string) => void;
    setDirectColor4: (name: string, color: IColor4Like) => void;
    setInt: (name: string, x: number, suffix?: string) => void;
    setInt2: (name: string, x: number, y: number, suffix?: string) => void;
    setInt3: (name: string, x: number, y: number, z: number, suffix?: string) => void;
    setInt4: (name: string, x: number, y: number, z: number, w: number, suffix?: string) => void;
    private _isUbo;
    constructor(uboOrEffect: UniformBuffer | Effect);
}

/**
 * Particle emitter represents a volume emitting particles.
 * This is the responsibility of the implementation to define the volume shape like cone/sphere/box.
 */
interface IParticleEmitterType {
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the direction for
     * @param isLocal defines if the direction should be set in local space
     * @param inverseWorldMatrix defines the inverted world matrix to use if isLocal is false
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean, inverseWorldMatrix: Matrix): void;
    /**
     * Called by the particle System when the position is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param positionToUpdate is the position vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the position should be set in local space
     */
    startPositionFunction(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): IParticleEmitterType;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns the effect defines string
     */
    getEffectDefines(): string;
    /**
     * Returns a string representing the class name
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     * @param scene defines the hosting scene
     */
    parse(serializationObject: any, scene: Nullable<Scene>): void;
}

/**
 * Particle emitter emitting particles from a point.
 * It emits the particles randomly between 2 given directions.
 */
declare class PointParticleEmitter implements IParticleEmitterType {
    /**
     * Random direction of each particle after it has been emitted, between direction1 and direction2 vectors.
     */
    direction1: Vector3;
    /**
     * Random direction of each particle after it has been emitted, between direction1 and direction2 vectors.
     */
    direction2: Vector3;
    /**
     * Creates a new instance PointParticleEmitter
     */
    constructor();
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the direction for
     * @param isLocal defines if the direction should be set in local space
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Called by the particle System when the position is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param positionToUpdate is the position vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the position should be set in local space
     */
    startPositionFunction(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): PointParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "PointParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}

/**
 * Particle emitter emitting particles from the inside of a hemisphere.
 * It emits the particles alongside the hemisphere radius. The emission direction might be randomized.
 */
declare class HemisphericParticleEmitter implements IParticleEmitterType {
    /**
     * [1] The radius of the emission hemisphere.
     */
    radius: number;
    /**
     * [1] The range of emission [0-1] 0 Surface only, 1 Entire Radius.
     */
    radiusRange: number;
    /**
     * [0] How much to randomize the particle direction [0-1].
     */
    directionRandomizer: number;
    /**
     * Creates a new instance HemisphericParticleEmitter
     * @param radius the radius of the emission hemisphere (1 by default)
     * @param radiusRange the range of the emission hemisphere [0-1] 0 Surface only, 1 Entire Radius (1 by default)
     * @param directionRandomizer defines how much to randomize the particle direction [0-1]
     */
    constructor(
    /**
     * [1] The radius of the emission hemisphere.
     */
    radius?: number, 
    /**
     * [1] The range of emission [0-1] 0 Surface only, 1 Entire Radius.
     */
    radiusRange?: number, 
    /**
     * [0] How much to randomize the particle direction [0-1].
     */
    directionRandomizer?: number);
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the direction for
     * @param isLocal defines if the direction should be set in local space
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Called by the particle System when the position is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param positionToUpdate is the position vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the position should be set in local space
     */
    startPositionFunction(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): HemisphericParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "HemisphericParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}

/**
 * Particle emitter emitting particles from the inside of a sphere.
 * It emits the particles alongside the sphere radius. The emission direction might be randomized.
 */
declare class SphereParticleEmitter implements IParticleEmitterType {
    /**
     * [1] The radius of the emission sphere.
     */
    radius: number;
    /**
     * [1] The range of emission [0-1] 0 Surface only, 1 Entire Radius.
     */
    radiusRange: number;
    /**
     * [0] How much to randomize the particle direction [0-1].
     */
    directionRandomizer: number;
    /**
     * Creates a new instance SphereParticleEmitter
     * @param radius the radius of the emission sphere (1 by default)
     * @param radiusRange the range of the emission sphere [0-1] 0 Surface only, 1 Entire Radius (1 by default)
     * @param directionRandomizer defines how much to randomize the particle direction [0-1]
     */
    constructor(
    /**
     * [1] The radius of the emission sphere.
     */
    radius?: number, 
    /**
     * [1] The range of emission [0-1] 0 Surface only, 1 Entire Radius.
     */
    radiusRange?: number, 
    /**
     * [0] How much to randomize the particle direction [0-1].
     */
    directionRandomizer?: number);
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the direction for
     * @param isLocal defines if the direction should be set in local space
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Called by the particle System when the position is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param positionToUpdate is the position vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the position should be set in local space
     */
    startPositionFunction(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): SphereParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "SphereParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}
/**
 * Particle emitter emitting particles from the inside of a sphere.
 * It emits the particles randomly between two vectors.
 */
declare class SphereDirectedParticleEmitter extends SphereParticleEmitter {
    /**
     * [Up vector] The min limit of the emission direction.
     */
    direction1: Vector3;
    /**
     * [Up vector] The max limit of the emission direction.
     */
    direction2: Vector3;
    /**
     * Creates a new instance SphereDirectedParticleEmitter
     * @param radius the radius of the emission sphere (1 by default)
     * @param direction1 the min limit of the emission direction (up vector by default)
     * @param direction2 the max limit of the emission direction (up vector by default)
     */
    constructor(radius?: number, 
    /**
     * [Up vector] The min limit of the emission direction.
     */
    direction1?: Vector3, 
    /**
     * [Up vector] The max limit of the emission direction.
     */
    direction2?: Vector3);
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the direction should be set in local space
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): SphereDirectedParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "SphereDirectedParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}

/**
 * Particle emitter emitting particles from the inside of a cylinder.
 * It emits the particles alongside the cylinder radius. The emission direction might be randomized.
 */
declare class CylinderParticleEmitter implements IParticleEmitterType {
    /**
     * [1] The radius of the emission cylinder.
     */
    radius: number;
    /**
     * [1] The height of the emission cylinder.
     */
    height: number;
    /**
     * [1] The range of emission [0-1] 0 Surface only, 1 Entire Radius.
     */
    radiusRange: number;
    /**
     * [0] How much to randomize the particle direction [0-1].
     */
    directionRandomizer: number;
    private _tempVector;
    /**
     * Creates a new instance CylinderParticleEmitter
     * @param radius the radius of the emission cylinder (1 by default)
     * @param height the height of the emission cylinder (1 by default)
     * @param radiusRange the range of the emission cylinder [0-1] 0 Surface only, 1 Entire Radius (1 by default)
     * @param directionRandomizer defines how much to randomize the particle direction [0-1]
     */
    constructor(
    /**
     * [1] The radius of the emission cylinder.
     */
    radius?: number, 
    /**
     * [1] The height of the emission cylinder.
     */
    height?: number, 
    /**
     * [1] The range of emission [0-1] 0 Surface only, 1 Entire Radius.
     */
    radiusRange?: number, 
    /**
     * [0] How much to randomize the particle direction [0-1].
     */
    directionRandomizer?: number);
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the direction for
     * @param isLocal defines if the direction should be set in local space
     * @param inverseWorldMatrix defines the inverted world matrix to use if isLocal is false
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean, inverseWorldMatrix: Matrix): void;
    /**
     * Called by the particle System when the position is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param positionToUpdate is the position vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the position should be set in local space
     */
    startPositionFunction(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): CylinderParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "CylinderParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}
/**
 * Particle emitter emitting particles from the inside of a cylinder.
 * It emits the particles randomly between two vectors.
 */
declare class CylinderDirectedParticleEmitter extends CylinderParticleEmitter {
    /**
     * [Up vector] The min limit of the emission direction.
     */
    direction1: Vector3;
    /**
     * [Up vector] The max limit of the emission direction.
     */
    direction2: Vector3;
    /**
     * Creates a new instance CylinderDirectedParticleEmitter
     * @param radius the radius of the emission cylinder (1 by default)
     * @param height the height of the emission cylinder (1 by default)
     * @param radiusRange the range of the emission cylinder [0-1] 0 Surface only, 1 Entire Radius (1 by default)
     * @param direction1 the min limit of the emission direction (up vector by default)
     * @param direction2 the max limit of the emission direction (up vector by default)
     */
    constructor(radius?: number, height?: number, radiusRange?: number, 
    /**
     * [Up vector] The min limit of the emission direction.
     */
    direction1?: Vector3, 
    /**
     * [Up vector] The max limit of the emission direction.
     */
    direction2?: Vector3);
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param _particle is the particle we are computed the direction for
     * @param isLocal defines if the direction should be set in local space
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, _particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): CylinderDirectedParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "CylinderDirectedParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}

/**
 * Particle emitter emitting particles from the inside of a cone.
 * It emits the particles alongside the cone volume from the base to the particle.
 * The emission direction might be randomized.
 */
declare class ConeParticleEmitter implements IParticleEmitterType {
    /** [0] defines how much to randomize the particle direction [0-1] (default is 0) */
    directionRandomizer: number;
    private _radius;
    private _angle;
    private _height;
    /**
     * Gets or sets a value indicating where on the radius the start position should be picked (1 = everywhere, 0 = only surface)
     */
    radiusRange: number;
    /**
     * Gets or sets a value indicating where on the height the start position should be picked (1 = everywhere, 0 = only surface)
     */
    heightRange: number;
    /**
     * Gets or sets a value indicating if all the particles should be emitted from the spawn point only (the base of the cone)
     */
    emitFromSpawnPointOnly: boolean;
    /**
     * Gets or sets the radius of the emission cone
     */
    get radius(): number;
    set radius(value: number);
    /**
     * Gets or sets the angle of the emission cone
     */
    get angle(): number;
    set angle(value: number);
    private _buildHeight;
    /**
     * Creates a new instance ConeParticleEmitter
     * @param radius the radius of the emission cone (1 by default)
     * @param angle the cone base angle (PI by default)
     * @param directionRandomizer defines how much to randomize the particle direction [0-1] (default is 0)
     */
    constructor(radius?: number, angle?: number, 
    /** [0] defines how much to randomize the particle direction [0-1] (default is 0) */
    directionRandomizer?: number);
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the direction for
     * @param isLocal defines if the direction should be set in local space
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Called by the particle System when the position is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param positionToUpdate is the position vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the position should be set in local space
     */
    startPositionFunction(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): ConeParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "ConeParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}
declare class ConeDirectedParticleEmitter extends ConeParticleEmitter {
    /**
     * [Up vector] The min limit of the emission direction.
     */
    direction1: Vector3;
    /**
     * [Up vector] The max limit of the emission direction.
     */
    direction2: Vector3;
    constructor(radius?: number, angle?: number, 
    /**
     * [Up vector] The min limit of the emission direction.
     */
    direction1?: Vector3, 
    /**
     * [Up vector] The max limit of the emission direction.
     */
    direction2?: Vector3);
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the direction should be set in local space
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): ConeDirectedParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "ConeDirectedParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}

/**
 * This represents the base class for particle system in Babylon.
 * Particles are often small sprites used to simulate hard-to-reproduce phenomena like fire, smoke, water, or abstract visual effects like magic glitter and faery dust.
 * Particles can take different shapes while emitted like box, sphere, cone or you can write your custom function.
 * @example https://doc.babylonjs.com/features/featuresDeepDive/particles/particle_system/particle_system_intro
 */
declare class BaseParticleSystem implements IClipPlanesHolder {
    /**
     * Source color is added to the destination color without alpha affecting the result. Great for additive glow effects (fire, magic, lasers)
     */
    static BLENDMODE_ONEONE: number;
    /**
     * Blend current color and particle color using particles alpha. Same as Constants.ALPHA_COMBINE, the go-to for transparency. 100% alpha means source, 0% alpha means background. Glass, UI fade, smoke
     */
    static BLENDMODE_STANDARD: number;
    /**
     * Add current color and particle color multiplied by particles alpha
     */
    static BLENDMODE_ADD: number;
    /**
     * Multiply current color with particle color
     */
    static BLENDMODE_MULTIPLY: number;
    /**
     * Multiply current color with particle color then add current color and particle color multiplied by particles alpha
     */
    static BLENDMODE_MULTIPLYADD: number;
    /**
     * Subtracts source (particle) from destination (current color), leading to darker results
     * - NOTE: Init as -1 so we can properly map all modes to Engine Const's (otherwise ALPHA_SUBTRACT will conflict with BLENDMODE_MULTIPLY since both use 3)
     */
    static BLENDMODE_SUBTRACT: number;
    /**
     * List of animations used by the particle system.
     */
    animations: Animation[];
    /**
     * Gets or sets the unique id of the particle system
     */
    uniqueId: number;
    /**
     * The id of the Particle system.
     */
    id: string;
    /**
     * The friendly name of the Particle system.
     */
    name: string;
    /**
     * Snippet ID if the particle system was created from the snippet server
     */
    snippetId: string;
    /**
     * The rendering group used by the Particle system to chose when to render.
     */
    renderingGroupId: number;
    /**
     * The emitter represents the Mesh or position we are attaching the particle system to.
     */
    emitter: Nullable<AbstractMesh | Vector3>;
    /**
     * The maximum number of particles to emit per frame
     */
    emitRate: number;
    /**
     * If you want to launch only a few particles at once, that can be done, as well.
     */
    manualEmitCount: number;
    /**
     * The overall motion speed (0.01 is default update speed, faster updates = faster animation)
     */
    updateSpeed: number;
    /** @internal */
    _targetStopDuration: number;
    /**
     * The amount of time the particle system is running (depends of the overall update speed).
     */
    get targetStopDuration(): number;
    set targetStopDuration(value: number);
    /**
     * Specifies whether the particle system will be disposed once it reaches the end of the animation.
     */
    disposeOnStop: boolean;
    /**
     * Minimum power of emitting particles.
     */
    minEmitPower: number;
    /**
     * Maximum power of emitting particles.
     */
    maxEmitPower: number;
    /**
     * Minimum life time of emitting particles.
     */
    minLifeTime: number;
    /**
     * Maximum life time of emitting particles.
     */
    maxLifeTime: number;
    /**
     * Minimum Size of emitting particles.
     */
    minSize: number;
    /**
     * Maximum Size of emitting particles.
     */
    maxSize: number;
    /**
     * Minimum scale of emitting particles on X axis.
     */
    minScaleX: number;
    /**
     * Maximum scale of emitting particles on X axis.
     */
    maxScaleX: number;
    /**
     * Minimum scale of emitting particles on Y axis.
     */
    minScaleY: number;
    /**
     * Maximum scale of emitting particles on Y axis.
     */
    maxScaleY: number;
    /**
     * Gets or sets the minimal initial rotation in radians.
     */
    minInitialRotation: number;
    /**
     * Gets or sets the maximal initial rotation in radians.
     */
    maxInitialRotation: number;
    /**
     * Minimum angular speed of emitting particles (Z-axis rotation for each particle).
     */
    minAngularSpeed: number;
    /**
     * Maximum angular speed of emitting particles (Z-axis rotation for each particle).
     */
    maxAngularSpeed: number;
    /**
     * The texture used to render each particle. (this can be a spritesheet)
     */
    particleTexture: Nullable<BaseTexture>;
    /**
     * The layer mask we are rendering the particles through.
     */
    layerMask: number;
    /**
     * This can help using your own shader to render the particle system.
     * The according effect will be created
     */
    customShader: any;
    /**
     * By default particle system starts as soon as they are created. This prevents the
     * automatic start to happen and let you decide when to start emitting particles.
     */
    preventAutoStart: boolean;
    /**
     * Gets or sets a boolean indicating that this particle system will allow fog to be rendered on it (false by default)
     */
    applyFog: boolean;
    /** @internal */
    _wasDispatched: boolean;
    protected _rootUrl: string;
    protected _noiseTexture: Nullable<ProceduralTexture>;
    /**
     * Returns true if the particle system was generated by a node particle system set
     */
    get isNodeGenerated(): boolean;
    /**
     * Gets or sets a texture used to add random noise to particle positions
     */
    get noiseTexture(): Nullable<ProceduralTexture>;
    set noiseTexture(value: Nullable<ProceduralTexture>);
    /** Gets or sets the strength to apply to the noise value (default is (10, 10, 10)) */
    noiseStrength: Vector3;
    /**
     * Callback triggered when the particle animation is ending.
     */
    onAnimationEnd: Nullable<() => void>;
    /**
     * Blend mode use to render the particle
     * For original blend modes which are exposed from ParticleSystem (OneOne, Standard, Add, Multiply, MultiplyAdd, and Subtract), use ParticleSystem.BLENDMODE_FOO
     * For all other blend modes, use Engine Constants.ALPHA_FOO blend modes
     */
    blendMode: number;
    /**
     * Forces the particle to write their depth information to the depth buffer. This can help preventing other draw calls
     * to override the particles.
     */
    forceDepthWrite: boolean;
    /** Gets or sets a value indicating how many cycles (or frames) must be executed before first rendering (this value has to be set before starting the system). Default is 0 */
    preWarmCycles: number;
    /** Gets or sets a value indicating the time step multiplier to use in pre-warm mode (default is 1) */
    preWarmStepOffset: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled) defines the speed of the sprite loop (default is 1 meaning the animation will play once during the entire particle lifetime)
     */
    spriteCellChangeSpeed: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled) defines the first sprite cell to display
     */
    startSpriteCellID: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled) defines the last sprite cell to display
     */
    endSpriteCellID: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled), defines the sprite cell width to use
     */
    spriteCellWidth: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled), defines the sprite cell height to use
     */
    spriteCellHeight: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled), defines wether the sprite animation is looping
     */
    spriteCellLoop: boolean;
    /**
     * This allows the system to random pick the start cell ID between startSpriteCellID and endSpriteCellID
     */
    spriteRandomStartCell: boolean;
    /** Gets or sets a Vector2 used to move the pivot (by default (0,0)) */
    translationPivot: Vector2;
    protected _animationSheetEnabled: boolean;
    /** @internal */
    get _isAnimationSheetEnabled(): boolean;
    set _isAnimationSheetEnabled(value: boolean);
    /**
     * Gets or sets a boolean indicating that hosted animations (in the system.animations array) must be started when system.start() is called
     */
    beginAnimationOnStart: boolean;
    /**
     * Gets or sets the frame to start the animation from when beginAnimationOnStart is true
     */
    beginAnimationFrom: number;
    /**
     * Gets or sets the frame to end the animation on when beginAnimationOnStart is true
     */
    beginAnimationTo: number;
    /**
     * Gets or sets a boolean indicating if animations must loop when beginAnimationOnStart is true
     */
    beginAnimationLoop: boolean;
    /**
     * Gets or sets a world offset applied to all particles
     */
    worldOffset: Vector3;
    /**
     * Gets or sets the active clipplane 1
     */
    clipPlane: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 2
     */
    clipPlane2: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 3
     */
    clipPlane3: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 4
     */
    clipPlane4: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 5
     */
    clipPlane5: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 6
     */
    clipPlane6: Nullable<Plane>;
    /**
     * Gets or sets whether an animation sprite sheet is enabled or not on the particle system
     */
    get isAnimationSheetEnabled(): boolean;
    set isAnimationSheetEnabled(value: boolean);
    private _useLogarithmicDepth;
    /**
     * Gets or sets a boolean enabling the use of logarithmic depth buffers, which is good for wide depth buffers.
     */
    get useLogarithmicDepth(): boolean;
    set useLogarithmicDepth(value: boolean);
    /**
     * Get hosting scene
     * @returns the scene
     */
    getScene(): Nullable<Scene>;
    /**
     * You can use gravity if you want to give an orientation to your particles.
     */
    gravity: Vector3;
    /** @internal */
    _colorGradients: Nullable<Array<ColorGradient>>;
    /** @internal */
    _sizeGradients: Nullable<Array<FactorGradient>>;
    /** @internal */
    _lifeTimeGradients: Nullable<Array<FactorGradient>>;
    /** @internal */
    _angularSpeedGradients: Nullable<Array<FactorGradient>>;
    /** @internal */
    _velocityGradients: Nullable<Array<FactorGradient>>;
    /** @internal */
    _limitVelocityGradients: Nullable<Array<FactorGradient>>;
    /** @internal */
    _dragGradients: Nullable<Array<FactorGradient>>;
    protected _emitRateGradients: Nullable<Array<FactorGradient>>;
    /** @internal */
    _startSizeGradients: Nullable<Array<FactorGradient>>;
    protected _rampGradients: Nullable<Array<Color3Gradient>>;
    /** @internal */
    _colorRemapGradients: Nullable<Array<FactorGradient>>;
    /** @internal */
    _alphaRemapGradients: Nullable<Array<FactorGradient>>;
    protected _hasTargetStopDurationDependantGradient(): boolean | null;
    protected _setEngineBasedOnBlendMode(blendMode: number): void;
    /**
     * Defines the delay in milliseconds before starting the system (0 by default)
     */
    startDelay: number;
    /**
     * Gets the current list of drag gradients.
     * You must use addDragGradient and removeDragGradient to update this list
     * @returns the list of drag gradients
     */
    getDragGradients(): Nullable<Array<FactorGradient>>;
    /** Gets or sets a value indicating the damping to apply if the limit velocity factor is reached */
    limitVelocityDamping: number;
    /**
     * Gets the current list of limit velocity gradients.
     * You must use addLimitVelocityGradient and removeLimitVelocityGradient to update this list
     * @returns the list of limit velocity gradients
     */
    getLimitVelocityGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of color gradients.
     * You must use addColorGradient and removeColorGradient to update this list
     * @returns the list of color gradients
     */
    getColorGradients(): Nullable<Array<ColorGradient>>;
    /**
     * Gets the current list of size gradients.
     * You must use addSizeGradient and removeSizeGradient to update this list
     * @returns the list of size gradients
     */
    getSizeGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of color remap gradients.
     * You must use addColorRemapGradient and removeColorRemapGradient to update this list
     * @returns the list of color remap gradients
     */
    getColorRemapGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of alpha remap gradients.
     * You must use addAlphaRemapGradient and removeAlphaRemapGradient to update this list
     * @returns the list of alpha remap gradients
     */
    getAlphaRemapGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of life time gradients.
     * You must use addLifeTimeGradient and removeLifeTimeGradient to update this list
     * @returns the list of life time gradients
     */
    getLifeTimeGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of angular speed gradients.
     * You must use addAngularSpeedGradient and removeAngularSpeedGradient to update this list
     * @returns the list of angular speed gradients
     */
    getAngularSpeedGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of velocity gradients.
     * You must use addVelocityGradient and removeVelocityGradient to update this list
     * @returns the list of velocity gradients
     */
    getVelocityGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of start size gradients.
     * You must use addStartSizeGradient and removeStartSizeGradient to update this list
     * @returns the list of start size gradients
     */
    getStartSizeGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of emit rate gradients.
     * You must use addEmitRateGradient and removeEmitRateGradient to update this list
     * @returns the list of emit rate gradients
     */
    getEmitRateGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Random direction of each particle after it has been emitted, between direction1 and direction2 vectors.
     * This only works when particleEmitterTyps is a BoxParticleEmitter
     */
    get direction1(): Vector3;
    set direction1(value: Vector3);
    /**
     * Random direction of each particle after it has been emitted, between direction1 and direction2 vectors.
     * This only works when particleEmitterTyps is a BoxParticleEmitter
     */
    get direction2(): Vector3;
    set direction2(value: Vector3);
    /**
     * Minimum box point around our emitter. Our emitter is the center of particles source, but if you want your particles to emit from more than one point, then you can tell it to do so.
     * This only works when particleEmitterTyps is a BoxParticleEmitter
     */
    get minEmitBox(): Vector3;
    set minEmitBox(value: Vector3);
    /**
     * Maximum box point around our emitter. Our emitter is the center of particles source, but if you want your particles to emit from more than one point, then you can tell it to do so.
     * This only works when particleEmitterTyps is a BoxParticleEmitter
     */
    get maxEmitBox(): Vector3;
    set maxEmitBox(value: Vector3);
    /**
     * Random color of each particle after it has been emitted, between color1 and color2 vectors
     */
    color1: Color4;
    /**
     * Random color of each particle after it has been emitted, between color1 and color2 vectors
     */
    color2: Color4;
    /**
     * Color the particle will have at the end of its lifetime
     */
    colorDead: Color4;
    /**
     * An optional mask to filter some colors out of the texture, or filter a part of the alpha channel
     */
    textureMask: Color4;
    /**
     * The particle emitter type defines the emitter used by the particle system.
     * It can be for example box, sphere, or cone...
     */
    particleEmitterType: IParticleEmitterType;
    /** @internal */
    _isSubEmitter: boolean;
    /** @internal */
    _billboardMode: number;
    /**
     * Gets or sets the billboard mode to use when isBillboardBased = true.
     * Value can be: ParticleSystem.BILLBOARDMODE_ALL, ParticleSystem.BILLBOARDMODE_Y, ParticleSystem.BILLBOARDMODE_STRETCHED, ParticleSystem.PARTICLES_BILLBOARDMODE_STRETCHED_LOCAL
     */
    get billboardMode(): number;
    set billboardMode(value: number);
    /** @internal */
    _isBillboardBased: boolean;
    /**
     * Gets or sets a boolean indicating if the particles must be rendered as billboard or aligned with the direction
     */
    get isBillboardBased(): boolean;
    set isBillboardBased(value: boolean);
    /**
     * The scene the particle system belongs to.
     */
    protected _scene: Nullable<Scene>;
    /**
     * The engine the particle system belongs to.
     */
    protected _engine: AbstractEngine;
    /**
     * Local cache of defines for image processing.
     */
    protected _imageProcessingConfigurationDefines: ImageProcessingConfigurationDefines;
    /**
     * Default configuration related to image processing available in the standard Material.
     */
    protected _imageProcessingConfiguration: Nullable<ImageProcessingConfiguration>;
    /**
     * Gets the image processing configuration used either in this material.
     */
    get imageProcessingConfiguration(): Nullable<ImageProcessingConfiguration>;
    /**
     * Sets the Default image processing configuration used either in the this material.
     *
     * If sets to null, the scene one is in use.
     */
    set imageProcessingConfiguration(value: Nullable<ImageProcessingConfiguration>);
    /**
     * Attaches a new image processing configuration to the Standard Material.
     * @param configuration
     */
    protected _attachImageProcessingConfiguration(configuration: Nullable<ImageProcessingConfiguration>): void;
    /** @internal */
    protected _reset(): void;
    /**
     * @internal
     */
    protected _removeGradientAndTexture(gradient: number, gradients: Nullable<IValueGradient[]>, texture: Nullable<RawTexture>): BaseParticleSystem;
    /**
     * Instantiates a particle system.
     * Particles are often small sprites used to simulate hard-to-reproduce phenomena like fire, smoke, water, or abstract visual effects like magic glitter and faery dust.
     * @param name The name of the particle system
     */
    constructor(name: string);
    /**
     * Creates a Point Emitter for the particle system (emits directly from the emitter position)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the box
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the box
     */
    createPointEmitter(direction1: Vector3, direction2: Vector3): PointParticleEmitter;
    /**
     * Creates a Hemisphere Emitter for the particle system (emits along the hemisphere radius)
     * @param radius The radius of the hemisphere to emit from
     * @param radiusRange The range of the hemisphere to emit from [0-1] 0 Surface Only, 1 Entire Radius
     */
    createHemisphericEmitter(radius?: number, radiusRange?: number): HemisphericParticleEmitter;
    /**
     * Creates a Sphere Emitter for the particle system (emits along the sphere radius)
     * @param radius The radius of the sphere to emit from
     * @param radiusRange The range of the sphere to emit from [0-1] 0 Surface Only, 1 Entire Radius
     */
    createSphereEmitter(radius?: number, radiusRange?: number): SphereParticleEmitter;
    /**
     * Creates a Directed Sphere Emitter for the particle system (emits between direction1 and direction2)
     * @param radius The radius of the sphere to emit from
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the sphere
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the sphere
     */
    createDirectedSphereEmitter(radius?: number, direction1?: Vector3, direction2?: Vector3): SphereDirectedParticleEmitter;
    /**
     * Creates a Cylinder Emitter for the particle system (emits from the cylinder to the particle position)
     * @param radius The radius of the emission cylinder
     * @param height The height of the emission cylinder
     * @param radiusRange The range of emission [0-1] 0 Surface only, 1 Entire Radius
     * @param directionRandomizer How much to randomize the particle direction [0-1]
     */
    createCylinderEmitter(radius?: number, height?: number, radiusRange?: number, directionRandomizer?: number): CylinderParticleEmitter;
    /**
     * Creates a Directed Cylinder Emitter for the particle system (emits between direction1 and direction2)
     * @param radius The radius of the cylinder to emit from
     * @param height The height of the emission cylinder
     * @param radiusRange the range of the emission cylinder [0-1] 0 Surface only, 1 Entire Radius (1 by default)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the cylinder
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the cylinder
     */
    createDirectedCylinderEmitter(radius?: number, height?: number, radiusRange?: number, direction1?: Vector3, direction2?: Vector3): CylinderDirectedParticleEmitter;
    /**
     * Creates a Cone Emitter for the particle system (emits from the cone to the particle position)
     * @param radius The radius of the cone to emit from
     * @param angle The base angle of the cone
     */
    createConeEmitter(radius?: number, angle?: number): ConeParticleEmitter;
    /**
     * Creates a Cone Emitter for the particle system (emits from the cone to the particle position)
     * @param radius The radius of the cone to emit from
     * @param angle The base angle of the cone
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the cone
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the cone
     */
    createDirectedConeEmitter(radius?: number, angle?: number, direction1?: Vector3, direction2?: Vector3): ConeDirectedParticleEmitter;
    /**
     * Creates a Box Emitter for the particle system. (emits between direction1 and direction2 from withing the box defined by minEmitBox and maxEmitBox)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the box
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the box
     * @param minEmitBox Particles are emitted from the box between minEmitBox and maxEmitBox
     * @param maxEmitBox  Particles are emitted from the box between minEmitBox and maxEmitBox
     */
    createBoxEmitter(direction1: Vector3, direction2: Vector3, minEmitBox: Vector3, maxEmitBox: Vector3): BoxParticleEmitter;
}

/** @internal */
interface _IExecutionQueueItem {
    /** @internal */
    process: (particle: Particle, system: ThinParticleSystem) => void;
    /** @internal */
    previousItem: Nullable<_IExecutionQueueItem>;
    /** @internal */
    nextItem: Nullable<_IExecutionQueueItem>;
}

/**
 * This represents a thin particle system in Babylon.
 * Particles are often small sprites used to simulate hard-to-reproduce phenomena like fire, smoke, water, or abstract visual effects like magic glitter and faery dust.
 * Particles can take different shapes while emitted like box, sphere, cone or you can write your custom function.
 * This thin version contains a limited subset of the total features in order to provide users with a way to get particles but with a smaller footprint
 * @example https://doc.babylonjs.com/features/featuresDeepDive/particles/particle_system/particle_system_intro
 */
declare class ThinParticleSystem extends BaseParticleSystem implements IDisposable, IAnimatable, IParticleSystem {
    /**
     * Force all the particle systems to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * This function can be defined to provide custom update for active particles.
     * This function will be called instead of regular update (age, position, color, etc.).
     * Do not forget that this function will be called on every frame so try to keep it simple and fast :)
     */
    updateFunction: (particles: Particle[]) => void;
    /** @internal */
    _emitterWorldMatrix: Matrix;
    /** @internal */
    _emitterInverseWorldMatrix: Matrix;
    private _startDirectionFunction;
    /**
     * This function can be defined to specify initial direction for every new particle.
     * It by default use the emitterType defined function
     */
    get startDirectionFunction(): Nullable<(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean) => void>;
    set startDirectionFunction(value: Nullable<(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean) => void>);
    private _startPositionFunction;
    /**
     * This function can be defined to specify initial position for every new particle.
     * It by default use the emitterType defined function
     */
    get startPositionFunction(): Nullable<(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean) => void>;
    set startPositionFunction(value: Nullable<(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean) => void>);
    /**
     * @internal
     */
    _inheritedVelocityOffset: Vector3;
    /**
     * An event triggered when the system is disposed
     */
    onDisposeObservable: Observable<IParticleSystem>;
    /**
     * An event triggered when the system is stopped
     */
    onStoppedObservable: Observable<IParticleSystem>;
    /**
     * An event triggered when the system is started
     */
    onStartedObservable: Observable<IParticleSystem>;
    private _onDisposeObserver;
    /**
     * Sets a callback that will be triggered when the system is disposed
     */
    set onDispose(callback: () => void);
    /** @internal */
    _noiseTextureSize: Nullable<ISize>;
    /** @internal */
    _noiseTextureData: Nullable<Uint8Array>;
    private _particles;
    private _epsilon;
    private _capacity;
    private _stockParticles;
    private _newPartsExcess;
    private _vertexData;
    private _vertexBuffer;
    private _vertexBuffers;
    private _spriteBuffer;
    private _indexBuffer;
    private _linesIndexBuffer;
    private _linesIndexBufferUseInstancing;
    private _drawWrappers;
    /** @internal */
    _customWrappers: {
        [blendMode: number]: Nullable<DrawWrapper>;
    };
    /** @internal */
    _scaledColorStep: Color4;
    /** @internal */
    _colorDiff: Color4;
    /** @internal */
    _scaledGravity: Vector3;
    private _currentRenderId;
    private _alive;
    private _useInstancing;
    private _vertexArrayObject;
    private _isDisposed;
    /**
     * Gets a boolean indicating that the particle system was disposed
     */
    get isDisposed(): boolean;
    private _started;
    private _stopped;
    /** @internal */
    _actualFrame: number;
    /** @internal */
    _scaledUpdateSpeed: number;
    private _vertexBufferSize;
    /** @internal */
    _currentEmitRateGradient: Nullable<FactorGradient>;
    /** @internal */
    _currentEmitRate1: number;
    /** @internal */
    _currentEmitRate2: number;
    /** @internal */
    _currentStartSizeGradient: Nullable<FactorGradient>;
    /** @internal */
    _currentStartSize1: number;
    /** @internal */
    _currentStartSize2: number;
    /** Indicates that the update of particles is done in the animate function */
    readonly updateInAnimate = true;
    private readonly _rawTextureWidth;
    private _rampGradientsTexture;
    private _useRampGradients;
    /** @internal */
    _updateQueueStart: Nullable<_IExecutionQueueItem>;
    protected _colorProcessing: _IExecutionQueueItem;
    protected _angularSpeedGradientProcessing: _IExecutionQueueItem;
    protected _angularSpeedProcessing: _IExecutionQueueItem;
    protected _velocityGradientProcessing: _IExecutionQueueItem;
    protected _directionProcessing: _IExecutionQueueItem;
    protected _limitVelocityGradientProcessing: _IExecutionQueueItem;
    protected _positionProcessing: _IExecutionQueueItem;
    protected _dragGradientProcessing: _IExecutionQueueItem;
    protected _noiseProcessing: _IExecutionQueueItem;
    protected _gravityProcessing: _IExecutionQueueItem;
    protected _sizeGradientProcessing: _IExecutionQueueItem;
    protected _remapGradientProcessing: _IExecutionQueueItem;
    /** @internal */
    _lifeTimeCreation: _IExecutionQueueItem;
    /** @internal */
    _positionCreation: _IExecutionQueueItem;
    private _isLocalCreation;
    /** @internal */
    _directionCreation: _IExecutionQueueItem;
    private _emitPowerCreation;
    /** @internal */
    _sizeCreation: _IExecutionQueueItem;
    private _startSizeCreation;
    /** @internal */
    _angleCreation: _IExecutionQueueItem;
    private _velocityCreation;
    private _limitVelocityCreation;
    private _dragCreation;
    /** @internal */
    _colorCreation: _IExecutionQueueItem;
    /** @internal */
    _colorDeadCreation: _IExecutionQueueItem;
    private _sheetCreation;
    private _rampCreation;
    private _noiseCreation;
    private _createQueueStart;
    /** @internal */
    _tempScaledUpdateSpeed: number;
    /** @internal */
    _ratio: number;
    /** @internal */
    _emitPower: number;
    /** Gets or sets a matrix to use to compute projection */
    defaultProjectionMatrix: Matrix;
    /** Gets or sets a matrix to use to compute view */
    defaultViewMatrix: Matrix;
    /** Gets or sets a boolean indicating that ramp gradients must be used
     * @see https://doc.babylonjs.com/features/featuresDeepDive/particles/particle_system/particle_system_intro#ramp-gradients
     */
    get useRampGradients(): boolean;
    set useRampGradients(value: boolean);
    private _isLocal;
    /**
     * Specifies if the particles are updated in emitter local space or world space
     */
    get isLocal(): boolean;
    set isLocal(value: boolean);
    /** Indicates that the particle system is CPU based */
    readonly isGPU = false;
    /**
     * Gets the current list of active particles
     */
    get particles(): Particle[];
    /** Shader language used by the material */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this material.
     */
    get shaderLanguage(): ShaderLanguage;
    /** @internal */
    get _isAnimationSheetEnabled(): boolean;
    set _isAnimationSheetEnabled(value: boolean);
    /**
     * Gets the number of particles active at the same time.
     * @returns The number of active particles.
     */
    getActiveCount(): number;
    /**
     * Returns the string "ParticleSystem"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Gets a boolean indicating that the system is stopping
     * @returns true if the system is currently stopping
     */
    isStopping(): boolean;
    /**
     * Gets the custom effect used to render the particles
     * @param blendMode Blend mode for which the effect should be retrieved
     * @returns The effect
     */
    getCustomEffect(blendMode?: number): Nullable<Effect>;
    private _getCustomDrawWrapper;
    /**
     * Sets the custom effect used to render the particles
     * @param effect The effect to set
     * @param blendMode Blend mode for which the effect should be set
     */
    setCustomEffect(effect: Nullable<Effect>, blendMode?: number): void;
    /** @internal */
    private _onBeforeDrawParticlesObservable;
    /**
     * Observable that will be called just before the particles are drawn
     */
    get onBeforeDrawParticlesObservable(): Observable<Nullable<Effect>>;
    /**
     * Gets the name of the particle vertex shader
     */
    get vertexShaderName(): string;
    /**
     * Gets the vertex buffers used by the particle system
     */
    get vertexBuffers(): Immutable<{
        [key: string]: VertexBuffer;
    }>;
    /**
     * Gets the index buffer used by the particle system (or null if no index buffer is used (if _useInstancing=true))
     */
    get indexBuffer(): Nullable<DataBuffer>;
    /**
     * Gets or sets a texture used to add random noise to particle positions
     */
    get noiseTexture(): Nullable<ProceduralTexture>;
    set noiseTexture(value: Nullable<ProceduralTexture>);
    /**
     * Instantiates a particle system.
     * Particles are often small sprites used to simulate hard-to-reproduce phenomena like fire, smoke, water, or abstract visual effects like magic glitter and faery dust.
     * @param name The name of the particle system
     * @param capacity The max number of particles alive at the same time
     * @param sceneOrEngine The scene the particle system belongs to or the engine to use if no scene
     * @param customEffect a custom effect used to change the way particles are rendered by default
     * @param isAnimationSheetEnabled Must be true if using a spritesheet to animate the particles texture
     * @param epsilon Offset used to render the particles
     * @param noUpdateQueue If true, the particle system will start with an empty update queue
     */
    constructor(name: string, capacity: number, sceneOrEngine: Scene | AbstractEngine, customEffect?: Nullable<Effect>, isAnimationSheetEnabled?: boolean, epsilon?: number, noUpdateQueue?: boolean);
    /** @internal */
    _emitFromParticle: (particle: Particle) => void;
    /**
     * Serializes the particle system to a JSON object.
     * @param _serializeTexture Whether to serialize the texture information
     */
    serialize(_serializeTexture: boolean): void;
    /**
     * Clones the particle system.
     * @param name The name of the cloned object
     * @param newEmitter The new emitter to use
     * @param _cloneTexture Also clone the textures if true
     */
    clone(name: string, newEmitter: any, _cloneTexture?: boolean): ThinParticleSystem;
    private _addFactorGradient;
    private _removeFactorGradient;
    private _syncLifeTimeCreation;
    private _syncStartSizeCreation;
    /**
     * The amount of time the particle system is running (depends of the overall update speed).
     */
    get targetStopDuration(): number;
    set targetStopDuration(value: number);
    /**
     * Adds a new life time gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the life time factor to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addLifeTimeGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific life time gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeLifeTimeGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new size gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the size factor to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addSizeGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific size gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeSizeGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new color remap gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param min defines the color remap minimal range
     * @param max defines the color remap maximal range
     * @returns the current particle system
     */
    addColorRemapGradient(gradient: number, min: number, max: number): IParticleSystem;
    /**
     * Remove a specific color remap gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeColorRemapGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new alpha remap gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param min defines the alpha remap minimal range
     * @param max defines the alpha remap maximal range
     * @returns the current particle system
     */
    addAlphaRemapGradient(gradient: number, min: number, max: number): IParticleSystem;
    /**
     * Remove a specific alpha remap gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeAlphaRemapGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new angular speed gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the angular speed  to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addAngularSpeedGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific angular speed gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeAngularSpeedGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new velocity gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the velocity to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addVelocityGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific velocity gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeVelocityGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new limit velocity gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the limit velocity value to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addLimitVelocityGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific limit velocity gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeLimitVelocityGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new drag gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the drag value to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addDragGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific drag gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeDragGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new emit rate gradient (please note that this will only work if you set the targetStopDuration property)
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the emit rate value to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addEmitRateGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific emit rate gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeEmitRateGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new start size gradient (please note that this will only work if you set the targetStopDuration property)
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the start size value to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addStartSizeGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific start size gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeStartSizeGradient(gradient: number): IParticleSystem;
    private _createRampGradientTexture;
    /**
     * Gets the current list of ramp gradients.
     * You must use addRampGradient and removeRampGradient to update this list
     * @returns the list of ramp gradients
     */
    getRampGradients(): Nullable<Array<Color3Gradient>>;
    /** Force the system to rebuild all gradients that need to be resync */
    forceRefreshGradients(): void;
    private _syncRampGradientTexture;
    /**
     * Adds a new ramp gradient used to remap particle colors
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param color defines the color to affect to the specified gradient
     * @returns the current particle system
     */
    addRampGradient(gradient: number, color: Color3): ThinParticleSystem;
    /**
     * Remove a specific ramp gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeRampGradient(gradient: number): ThinParticleSystem;
    /**
     * Adds a new color gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param color1 defines the color to affect to the specified gradient
     * @param color2 defines an additional color used to define a range ([color, color2]) with main color to pick the final color from
     * @returns this particle system
     */
    addColorGradient(gradient: number, color1: Color4, color2?: Color4): IParticleSystem;
    /**
     * Remove a specific color gradient
     * @param gradient defines the gradient to remove
     * @returns this particle system
     */
    removeColorGradient(gradient: number): IParticleSystem;
    /**
     * Resets the draw wrappers cache
     */
    resetDrawCache(): void;
    /** @internal */
    _fetchR(u: number, v: number, width: number, height: number, pixels: Uint8Array | Uint8ClampedArray): number;
    protected _reset(): void;
    private _resetEffect;
    private _createVertexBuffers;
    private _createIndexBuffer;
    /**
     * Gets the maximum number of particles active at the same time.
     * @returns The max number of active particles.
     */
    getCapacity(): number;
    /**
     * Gets whether there are still active particles in the system.
     * @returns True if it is alive, otherwise false.
     */
    isAlive(): boolean;
    /**
     * Gets if the system has been started. (Note: this will still be true after stop is called)
     * @returns True if it has been started, otherwise false.
     */
    isStarted(): boolean;
    /** @internal */
    _preStart(): void;
    /**
     * Starts the particle system and begins to emit
     * @param delay defines the delay in milliseconds before starting the system (this.startDelay by default)
     */
    start(delay?: number): void;
    /**
     * Stops the particle system.
     * @param stopSubEmitters if true it will stop the current system and all created sub-Systems if false it will stop the current root system only, this param is used by the root particle system only. The default value is true.
     */
    stop(stopSubEmitters?: boolean): void;
    /** @internal */
    _postStop(_stopSubEmitters: boolean): void;
    /**
     * Remove all active particles
     */
    reset(): void;
    /**
     * @internal (for internal use only)
     */
    _appendParticleVertex(index: number, particle: Particle, offsetX: number, offsetY: number): void;
    /**
     * "Recycles" one of the particle by copying it back to the "stock" of particles and removing it from the active list.
     * Its lifetime will start back at 0.
     * @param particle
     */
    recycleParticle: (particle: Particle) => void;
    private _createParticle;
    /** @internal */
    _prepareParticle(_particle: Particle): void;
    private _createNewOnes;
    private _update;
    /**
     * @internal
     */
    static _GetAttributeNamesOrOptions(isAnimationSheetEnabled?: boolean, isBillboardBased?: boolean, useRampGradients?: boolean): string[];
    /**
     * @internal
     */
    static _GetEffectCreationOptions(isAnimationSheetEnabled?: boolean, useLogarithmicDepth?: boolean, applyFog?: boolean): string[];
    /**
     * Fill the defines array according to the current settings of the particle system
     * @param defines Array to be updated
     * @param blendMode blend mode to take into account when updating the array
     * @param fillImageProcessing fills the image processing defines
     */
    fillDefines(defines: Array<string>, blendMode: number, fillImageProcessing?: boolean): void;
    /**
     * Fill the uniforms, attributes and samplers arrays according to the current settings of the particle system
     * @param uniforms Uniforms array to fill
     * @param attributes Attributes array to fill
     * @param samplers Samplers array to fill
     */
    fillUniformsAttributesAndSamplerNames(uniforms: Array<string>, attributes: Array<string>, samplers: Array<string>): void;
    /**
     * @internal
     */
    private _getWrapper;
    /**
     * Gets or sets a boolean indicating that the particle system is paused (no animation will be done).
     */
    paused: boolean;
    /**
     * Animates the particle system for the current frame by emitting new particles and or animating the living ones.
     * @param preWarmOnly will prevent the system from updating the vertex buffer (default is false)
     */
    animate(preWarmOnly?: boolean): void;
    /**
     * Internal only. Calculates the current emit rate based on the gradients if any.
     * @returns The emit rate
     * @internal
     */
    _calculateEmitRate(): number;
    private _appendParticleVertices;
    /**
     * Rebuilds the particle system.
     */
    rebuild(): void;
    private _shadersLoaded;
    private _initShaderSourceAsync;
    /**
     * Is this system ready to be used/rendered
     * @returns true if the system is ready
     */
    isReady(): boolean;
    private _render;
    /**
     * Renders the particle system in its current state.
     * @returns the current number of particles
     */
    render(): number;
    /** @internal */
    _onDispose(_disposeAttachedSubEmitters?: boolean, _disposeEndSubEmitters?: boolean): void;
    /**
     * Disposes the particle system and free the associated resources
     * @param disposeTexture defines if the particle texture must be disposed as well (true by default)
     * @param disposeAttachedSubEmitters defines if the attached sub-emitters must be disposed as well (false by default)
     * @param disposeEndSubEmitters defines if the end type sub-emitters must be disposed as well (false by default)
     */
    dispose(disposeTexture?: boolean, disposeAttachedSubEmitters?: boolean, disposeEndSubEmitters?: boolean): void;
}

/**
 * Class representing an attractor in a particle system.
 * #DEZ79M#40
 */
declare class Attractor {
    /**
     * Gets or sets the strength of the attractor.
     * A positive value attracts particles, while a negative value repels them.
     */
    strength: number;
    /**
     * Gets or sets the position of the attractor in 3D space.
     */
    position: Vector3;
    /** @internal */
    _processParticle(particle: Particle, system: ThinParticleSystem): void;
    /**
     * Serializes the attractor to a JSON object.
     * @returns The serialized JSON object.
     */
    serialize(): any;
}

/**
 * Represents an object that can move or be influenced by FlowMap
 */
interface IFlowable {
    /**
     * The direction vector indicating the flow or movement direction of the object.
     */
    direction: Vector3;
    /**
     * The current position of the object in 3D space.
     */
    position: Vector3;
}
/**
 * Class used to represent a particle flow map.
 * #5DM02T#7
 * GPUParts: #5DM02T#12 (webgl2)
 * GPUParts: #5DM02T#13 (webgpu)
 */
declare class FlowMap {
    readonly width: number;
    readonly height: number;
    readonly data: Uint8ClampedArray;
    /**
     * Create a new flow map.
     * @param width defines the width of the flow map
     * @param height defines the height of the flow map
     * @param data defines the data of the flow map
     */
    constructor(width: number, height: number, data: Uint8ClampedArray);
    processFlowable(flowable: IFlowable, strength?: number, flowMapSamplePosOrTransformationMatrix?: IVector3Like | Matrix): void;
    /** @internal */
    _processParticle(particle: Particle, strength?: number, matrix?: Matrix): void;
    /**
     * Creates a FlowMap from a url.
     * @param url The url of the image to load
     * @returns a promise that resolves to a FlowMap object
     */
    static FromUrlAsync(url: string): Promise<FlowMap>;
    /**
     * Load from a texture
     * @param texture defines the source texture
     * @returns a promise fulfilled when image data is loaded
     */
    static ExtractFromTextureAsync(texture: Texture): Promise<FlowMap>;
}

/**
 * Represents a set of particle systems working together to create a specific effect
 */
declare class ParticleSystemSet implements IDisposable {
    /**
     * Gets or sets base Assets URL
     * Only used when parsing particle systems from JSON, not part of the core assets
     */
    static BaseAssetsUrl: string;
    private _emitterCreationOptions;
    private _emitterNode;
    private _emitterNodeIsOwned;
    /**
     * Gets the particle system list
     */
    systems: IParticleSystem[];
    /**
     * Gets or sets the emitter node used with this set
     */
    get emitterNode(): Nullable<AbstractMesh | Vector3>;
    set emitterNode(value: Nullable<AbstractMesh | Vector3>);
    /**
     * Creates a new emitter mesh as a sphere
     * @param options defines the options used to create the sphere
     * @param options.diameter
     * @param options.segments
     * @param options.color
     * @param renderingGroupId defines the renderingGroupId to use for the sphere
     * @param scene defines the hosting scene
     */
    setEmitterAsSphere(options: {
        diameter: number;
        segments: number;
        color: Color3;
    }, renderingGroupId: number, scene: Scene): void;
    /**
     * Starts all particle systems of the set
     * @param emitter defines an optional mesh to use as emitter for the particle systems
     */
    start(emitter?: AbstractMesh): void;
    /**
     * Release all associated resources
     */
    dispose(): void;
    /**
     * Serialize the set into a JSON compatible object
     * @param serializeTexture defines if the texture must be serialized as well
     * @returns a JSON compatible representation of the set
     */
    serialize(serializeTexture?: boolean): any;
    /**
     * Parse a new ParticleSystemSet from a serialized source
     * @param data defines a JSON compatible representation of the set
     * @param scene defines the hosting scene
     * @param gpu defines if we want GPU particles or CPU particles
     * @param capacity defines the system capacity (if null or undefined the sotred capacity will be used)
     * @returns a new ParticleSystemSet
     */
    static Parse(data: any, scene: Scene, gpu?: boolean, capacity?: number): ParticleSystemSet;
}

/**
 * Defines the kind of connection point for node geometry
 */
declare enum NodeParticleBlockConnectionPointTypes {
    /** Int */
    Int = 1,
    /** Float */
    Float = 2,
    /** Vector2 */
    Vector2 = 4,
    /** Vector3 */
    Vector3 = 8,
    /** Matrix */
    Matrix = 16,
    /** Particle */
    Particle = 32,
    /** Texture */
    Texture = 64,
    /** Color4 */
    Color4 = 128,
    /** FloatGradient */
    FloatGradient = 256,
    /** Vector2Gradient */
    Vector2Gradient = 512,
    /** Vector3Gradient */
    Vector3Gradient = 1024,
    /** Color4Gradient */
    Color4Gradient = 2048,
    /** System */
    System = 4096,
    /** Detect type based on connection */
    AutoDetect = 8192,
    /** Output type that will be defined by input type */
    BasedOnInput = 16384,
    /** Undefined */
    Undefined = 32768,
    /** Bitmask of all types */
    All = 65535
}

/**
 * Defines the kind of contextual sources for node particles
 */
declare enum NodeParticleContextualSources {
    /** None */
    None = 0,
    /** Position */
    Position = 1,
    /** Direction */
    Direction = 2,
    /** Age */
    Age = 3,
    /** Lifetime */
    Lifetime = 4,
    /** Color */
    Color = 5,
    /** ScaledDirection */
    ScaledDirection = 6,
    /** Scale */
    Scale = 7,
    /** AgeGradient */
    AgeGradient = 8,
    /** Angle */
    Angle = 9,
    /** SpriteCellIndex */
    SpriteCellIndex = 16,
    /** SpriteCellStart */
    SpriteCellStart = 17,
    /** SpriteCellEnd */
    SpriteCellEnd = 18,
    /** Initial Color */
    InitialColor = 19,
    /** Color Dead*/
    ColorDead = 20,
    /** Initial Direction */
    InitialDirection = 21,
    /** Color Step */
    ColorStep = 22,
    /** Scaled Color Step */
    ScaledColorStep = 23,
    /** Local Position Updated */
    LocalPositionUpdated = 24,
    /** Size */
    Size = 25,
    /** Direction Scale */
    DirectionScale = 32
}

/**
 * Enum used to define system values e.g. values automatically provided by the system
 */
declare enum NodeParticleSystemSources {
    /** None */
    None = 0,
    /** Time */
    Time = 1,
    /** Delta time */
    Delta = 2,
    /** Emitter */
    Emitter = 3,
    /** Camera position */
    CameraPosition = 4
}

/**
 * Class used to store node based geometry build state
 */
declare class NodeParticleBuildState {
    /**
     * Gets the capactity of the particle system to build
     */
    capacity: number;
    /**
     * Gets the scene where the particle system is built
     */
    scene: Scene;
    /** Gets or sets the build identifier */
    buildId: number;
    /** Gets or sets the list of non connected mandatory inputs */
    notConnectedNonOptionalInputs: NodeParticleConnectionPoint[];
    /** Gets or sets a boolean indicating that verbose mode is on */
    verbose: boolean;
    /**
     * Gets or sets the particle context for contextual data
     */
    particleContext: Nullable<Particle>;
    /**
     * Gets or sets the system context for contextual data
     */
    systemContext: Nullable<ThinParticleSystem>;
    /**
     * Gets or sets the index of the gradient to use
     */
    gradientIndex: number;
    /**
     * Gets or sets next gradient in line
     */
    nextGradientIndex: number;
    /**
     * Gets or sets the next gradient value
     */
    nextGradientValue: any;
    /**
     * Emits errors if any
     */
    emitErrors(): void;
    /**
     * Adapt a value to a target type
     * @param source defines the value to adapt
     * @param targetType defines the target type
     * @returns the adapted value
     */
    adapt(source: NodeParticleConnectionPoint, targetType: NodeParticleBlockConnectionPointTypes): any;
    /**
     * Gets the value associated with a contextual source
     * @param source Source of the contextual value
     * @returns the value associated with the source
     */
    getContextualValue(source: NodeParticleContextualSources): number | Color4 | Nullable<Vector3> | Vector2;
    /**
     * Gets the emitter world matrix
     */
    get emitterWorldMatrix(): Matrix | null;
    /**
     * Gets the emitter inverse world matrix
     */
    get emitterInverseWorldMatrix(): Matrix | null;
    /**
     * Gets the emitter position
     */
    get emitterPosition(): Nullable<Vector3>;
    /**
     * Gets the value associated with a system source
     * @param source Source of the system value
     * @returns the value associated with the source
     */
    getSystemValue(source: NodeParticleSystemSources): number | Nullable<Vector3>;
}

/**
 * Defines a block that can be used inside a node based particle system
 */
declare class NodeParticleBlock {
    private _name;
    protected _buildId: number;
    protected _isInput: boolean;
    protected _isSystem: boolean;
    protected _isDebug: boolean;
    protected _isTeleportOut: boolean;
    protected _isTeleportIn: boolean;
    /**
     * Gets or sets the unique id of the node
     */
    uniqueId: number;
    /** @internal */
    _inputs: NodeParticleConnectionPoint[];
    /** @internal */
    _outputs: NodeParticleConnectionPoint[];
    /**
     * Gets an observable raised when the block is built
     */
    onBuildObservable: Observable<NodeParticleBlock>;
    /**
     * Gets an observable raised when the block is disposed
     */
    onDisposeObservable: Observable<NodeParticleBlock>;
    /**
     * Gets an observable raised when the inputs of the block change
     */
    onInputChangedObservable: Observable<NodeParticleConnectionPoint>;
    /**
     * Gets a boolean indicating if this block is a teleport out
     */
    get isTeleportOut(): boolean;
    /**
     * Gets a boolean indicating if this block is a teleport in
     */
    get isTeleportIn(): boolean;
    /**
     * Gets a boolean indicating that this block is a system block
     */
    get isSystem(): boolean;
    /**
     * Gets a boolean indicating that this block is an input block
     */
    get isInput(): boolean;
    /**
     * Gets a boolean indicating if this block is a debug block
     */
    get isDebug(): boolean;
    /**
     * A free comment about the block
     */
    comments: string;
    /** Gets or sets a boolean indicating that this input can be edited from a collapsed frame */
    visibleOnFrame: boolean;
    /**
     * Gets or set the name of the block
     */
    get name(): string;
    set name(value: string);
    /**
     * Gets the current class name e.g. "NodeParticleBlock"
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the list of input points
     */
    get inputs(): NodeParticleConnectionPoint[];
    /** Gets the list of output points */
    get outputs(): NodeParticleConnectionPoint[];
    /**
     * Creates a new NodeParticleBlock
     * @param name defines the block name
     */
    constructor(name: string);
    protected _inputRename(name: string): string;
    protected _outputRename(name: string): string;
    /**
     * Checks if the current block is an ancestor of a given block
     * @param block defines the potential descendant block to check
     * @returns true if block is a descendant
     */
    isAnAncestorOf(block: NodeParticleBlock): boolean;
    /**
     * Checks if the current block is an ancestor of a given type
     * @param type defines the potential type to check
     * @returns true if block is a descendant
     */
    isAnAncestorOfType(type: string): boolean;
    /**
     * Find an input by its name
     * @param name defines the name of the input to look for
     * @returns the input or null if not found
     */
    getInputByName(name: string): NodeParticleConnectionPoint | null;
    protected _linkConnectionTypes(inputIndex0: number, inputIndex1: number, looseCoupling?: boolean): void;
    /**
     * Register a new input. Must be called inside a block constructor
     * @param name defines the connection point name
     * @param type defines the connection point type
     * @param isOptional defines a boolean indicating that this input can be omitted
     * @param value value to return if there is no connection
     * @param valueMin min value accepted for value
     * @param valueMax max value accepted for value
     * @returns the current block
     */
    registerInput(name: string, type: NodeParticleBlockConnectionPointTypes, isOptional?: boolean, value?: any, valueMin?: any, valueMax?: any): this;
    /**
     * Register a new output. Must be called inside a block constructor
     * @param name defines the connection point name
     * @param type defines the connection point type
     * @param point an already created connection point. If not provided, create a new one
     * @returns the current block
     */
    registerOutput(name: string, type: NodeParticleBlockConnectionPointTypes, point?: NodeParticleConnectionPoint): this;
    /**
     * Builds the block. Must be implemented by derived classes.
     * @param _state defines the current build state
     */
    _build(_state: NodeParticleBuildState): void;
    protected _customBuildStep(_state: NodeParticleBuildState): void;
    /**
     * Builds the block
     * @param state defines the current build state
     * @returns the built block
     */
    build(state: NodeParticleBuildState): boolean;
    /**
     * Serializes this block in a JSON representation
     * @returns the serialized block object
     */
    serialize(): any;
    /**
     * @internal
     */
    _deserialize(serializationObject: any): void;
    private _deserializePortDisplayNamesAndExposedOnFrame;
    /**
     * Clone the current block to a new identical block
     * @returns a copy of the current block
     */
    clone(): NodeParticleBlock | null;
    /**
     * Release resources
     */
    dispose(): void;
}

/**
 * Enum used to define the compatibility state between two connection points
 */
declare const enum NodeParticleConnectionPointCompatibilityStates {
    /** Points are compatibles */
    Compatible = 0,
    /** Points are incompatible because of their types */
    TypeIncompatible = 1,
    /** Points are incompatible because they are in the same hierarchy **/
    HierarchyIssue = 2
}
/**
 * Defines the direction of a connection point
 */
declare const enum NodeParticleConnectionPointDirection {
    /** Input */
    Input = 0,
    /** Output */
    Output = 1
}
/**
 * Defines a connection point for a block
 */
declare class NodeParticleConnectionPoint {
    /** @internal */
    _ownerBlock: NodeParticleBlock;
    /** @internal */
    _connectedPoint: Nullable<NodeParticleConnectionPoint>;
    /** @internal */
    _storedValue: any;
    /** @internal */
    _storedFunction: Nullable<(state: NodeParticleBuildState) => any>;
    /** @internal */
    _acceptedConnectionPointType: Nullable<NodeParticleConnectionPoint>;
    private _endpoints;
    private _direction;
    private _type;
    /** @internal */
    _linkedConnectionSource: Nullable<NodeParticleConnectionPoint>;
    /** @internal */
    _typeConnectionSource: Nullable<NodeParticleConnectionPoint>;
    /** @internal */
    _typeConnectionSourceTranslation: Nullable<(source: NodeParticleBlockConnectionPointTypes) => NodeParticleBlockConnectionPointTypes>;
    /** @internal */
    _defaultConnectionPointType: Nullable<NodeParticleBlockConnectionPointTypes>;
    /** @internal */
    _isMainLinkSource: boolean;
    /** Gets the direction of the point */
    get direction(): NodeParticleConnectionPointDirection;
    /**
     * Gets or sets the additional types supported by this connection point
     */
    acceptedConnectionPointTypes: NodeParticleBlockConnectionPointTypes[];
    /**
     * Gets or sets the additional types excluded by this connection point
     */
    excludedConnectionPointTypes: NodeParticleBlockConnectionPointTypes[];
    /**
     * Observable triggered when this point is connected
     */
    onConnectionObservable: Observable<NodeParticleConnectionPoint>;
    /**
     * Observable triggered when this point is disconnected
     */
    onDisconnectionObservable: Observable<NodeParticleConnectionPoint>;
    /**
     * Gets or sets a boolean indicating that this connection point is exposed on a frame
     */
    isExposedOnFrame: boolean;
    /**
     * Gets or sets number indicating the position that the port is exposed to on a frame
     */
    exposedPortPosition: number;
    /**
     * Gets the default value used for this point at creation time
     */
    defaultValue: Nullable<any>;
    /**
     * Gets or sets the default value used for this point if nothing is connected
     */
    value: Nullable<any>;
    /**
     * Gets or sets the min value accepted for this point if nothing is connected
     */
    valueMin: Nullable<any>;
    /**
     * Gets or sets the max value accepted for this point if nothing is connected
     */
    valueMax: Nullable<any>;
    /**
     * Gets or sets the connection point type (default is float)
     */
    get type(): NodeParticleBlockConnectionPointTypes;
    set type(value: NodeParticleBlockConnectionPointTypes);
    /**
     * Gets or sets the connection point name
     */
    name: string;
    /**
     * Gets or sets the connection point display name
     */
    displayName: string;
    /**
     * Gets or sets a boolean indicating that this connection point can be omitted
     */
    isOptional: boolean;
    /**
     * Gets a boolean indicating that the current point is connected to another NodeMaterialBlock
     */
    get isConnected(): boolean;
    /** Get the other side of the connection (if any) */
    get connectedPoint(): Nullable<NodeParticleConnectionPoint>;
    /** Get the block that owns this connection point */
    get ownerBlock(): NodeParticleBlock;
    /** Get the block connected on the other side of this connection (if any) */
    get sourceBlock(): Nullable<NodeParticleBlock>;
    /** Get the block connected on the endpoints of this connection (if any) */
    get connectedBlocks(): Array<NodeParticleBlock>;
    /** Gets the list of connected endpoints */
    get endpoints(): NodeParticleConnectionPoint[];
    /** Gets a boolean indicating if that output point is connected to at least one input */
    get hasEndpoints(): boolean;
    /** Get the inner type (ie AutoDetect for instance instead of the inferred one) */
    get innerType(): NodeParticleBlockConnectionPointTypes;
    /**
     * Creates a new connection point
     * @param name defines the connection point name
     * @param ownerBlock defines the block hosting this connection point
     * @param direction defines the direction of the connection point
     */
    constructor(name: string, ownerBlock: NodeParticleBlock, direction: NodeParticleConnectionPointDirection);
    /**
     * Gets the current class name e.g. "NodeMaterialConnectionPoint"
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the value represented by this connection point
     * @param state current evaluation state
     * @returns the connected value or the value if nothing is connected
     */
    getConnectedValue(state: NodeParticleBuildState): any;
    /**
     * Gets a boolean indicating if the current point can be connected to another point
     * @param connectionPoint defines the other connection point
     * @returns a boolean
     */
    canConnectTo(connectionPoint: NodeParticleConnectionPoint): boolean;
    /**
     * Gets a number indicating if the current point can be connected to another point
     * @param connectionPoint defines the other connection point
     * @returns a number defining the compatibility state
     */
    checkCompatibilityState(connectionPoint: NodeParticleConnectionPoint): NodeParticleConnectionPointCompatibilityStates;
    /**
     * Connect this point to another connection point
     * @param connectionPoint defines the other connection point
     * @param ignoreConstraints defines if the system will ignore connection type constraints (default is false)
     * @returns the current connection point
     */
    connectTo(connectionPoint: NodeParticleConnectionPoint, ignoreConstraints?: boolean): NodeParticleConnectionPoint;
    /**
     * Disconnect this point from one of his endpoint
     * @param endpoint defines the other connection point
     * @returns the current connection point
     */
    disconnectFrom(endpoint: NodeParticleConnectionPoint): NodeParticleConnectionPoint;
    /**
     * Fill the list of excluded connection point types with all types other than those passed in the parameter
     * @param mask Types (ORed values of NodeMaterialBlockConnectionPointTypes) that are allowed, and thus will not be pushed to the excluded list
     */
    addExcludedConnectionPointFromAllowedTypes(mask: number): void;
    /**
     * Serializes this point in a JSON representation
     * @param isInput defines if the connection point is an input (default is true)
     * @returns the serialized point object
     */
    serialize(isInput?: boolean): any;
    /**
     * Release resources
     */
    dispose(): void;
}

/**
 * Block used to get a system of particles
 */
declare class SystemBlock extends NodeParticleBlock {
    private static _IdCounter;
    /**
     * Gets or sets the blend mode for the particle system
     */
    blendMode: number;
    /**
     * Gets or sets the epsilon value used for comparison
     */
    capacity: number;
    /**
     * Gets or sets the manual emit count
     */
    manualEmitCount: number;
    /**
     * Gets or sets the target stop duration for the particle system
     */
    startDelay: number;
    /**
     * Gets or sets the target stop duration for the particle system
     */
    updateSpeed: number;
    /**
     * Gets or sets the number of pre-warm cycles before rendering the particle system
     */
    preWarmCycles: number;
    /**
     * Gets or sets the time step multiplier used for pre-warm
     */
    preWarmStepOffset: number;
    /**
     * Gets or sets a boolean indicating if the system is billboard based
     */
    isBillboardBased: boolean;
    /**
     * Gets or sets the billboard mode for the particle system
     */
    billBoardMode: number;
    /**
     * Gets or sets a boolean indicating if the system coordinate space is local or global
     */
    isLocal: boolean;
    /**
     * Gets or sets a boolean indicating if the system should be disposed when stopped
     */
    disposeOnStop: boolean;
    /**
     * Gets or sets a boolean indicating if the system should not start automatically
     */
    doNoStart: boolean;
    /** @internal */
    _internalId: number;
    /**
     * Create a new SystemBlock
     * @param name defines the block name
     */
    constructor(name: string);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the particle input component
     */
    get particle(): NodeParticleConnectionPoint;
    /**
     * Gets the emitRate input component
     */
    get emitRate(): NodeParticleConnectionPoint;
    /**
     * Gets the texture input component
     */
    get texture(): NodeParticleConnectionPoint;
    /**
     * Gets the translationPivot input component
     */
    get translationPivot(): NodeParticleConnectionPoint;
    /**
     * Gets the textureMask input component
     */
    get textureMask(): NodeParticleConnectionPoint;
    /**
     * Gets the targetStopDuration input component
     */
    get targetStopDuration(): NodeParticleConnectionPoint;
    /**
     * Gets the onStart input component
     */
    get onStart(): NodeParticleConnectionPoint;
    /**
     * Gets the onEnd input component
     */
    get onEnd(): NodeParticleConnectionPoint;
    /**
     * Gets the rampGradient input component
     */
    get rampGradient(): NodeParticleConnectionPoint;
    /**
     * Gets the emitterPosition input component
     */
    get emitterPosition(): NodeParticleConnectionPoint;
    /**
     * Gets the system output component
     */
    get system(): NodeParticleConnectionPoint;
    /**
     * Builds the block and return a functional particle system
     * @param state defines the building state
     * @returns the built particle system
     */
    createSystem(state: NodeParticleBuildState): ParticleSystem;
    /**
     * Serializes the system block
     * @returns The serialized object
     */
    serialize(): any;
    /**
     * Deserializes the system block
     * @param serializationObject The serialized system
     */
    _deserialize(serializationObject: any): void;
}

/**
 * Block used to expose an input value
 */
declare class ParticleInputBlock extends NodeParticleBlock {
    private _storedValue;
    private _valueCallback;
    private _type;
    /** Gets or set a value used to limit the range of float values */
    min: number;
    /** Gets or set a value used to limit the range of float values */
    max: number;
    /** Gets or sets the group to use to display this block in the Inspector */
    groupInInspector: string;
    /**
     * Gets or sets a boolean indicating that this input is displayed in the Inspector
     */
    displayInInspector: boolean;
    /** Gets an observable raised when the value is changed */
    onValueChangedObservable: Observable<ParticleInputBlock>;
    /**
     * Gets or sets the connection point type (default is float)
     */
    get type(): NodeParticleBlockConnectionPointTypes;
    /** @internal */
    private _systemSource;
    /**
     * Gets a boolean indicating that the current connection point is a system source
     */
    get isSystemSource(): boolean;
    /**
     * Gets or sets the system source used by this input block
     */
    get systemSource(): NodeParticleSystemSources;
    set systemSource(value: NodeParticleSystemSources);
    private _contextualSource;
    /**
     * Gets a boolean indicating that the current connection point is a contextual value
     */
    get isContextual(): boolean;
    /**
     * Gets or sets the current contextual value
     */
    get contextualValue(): NodeParticleContextualSources;
    set contextualValue(value: NodeParticleContextualSources);
    /**
     * Creates a new InputBlock
     * @param name defines the block name
     * @param type defines the type of the input (can be set to NodeParticleBlockConnectionPointTypes.AutoDetect)
     */
    constructor(name: string, type?: NodeParticleBlockConnectionPointTypes);
    /**
     * Gets or sets the value of that point.
     * Please note that this value will be ignored if valueCallback is defined
     */
    get value(): any;
    set value(value: any);
    /**
     * Gets or sets a callback used to get the value of that point.
     * Please note that setting this value will force the connection point to ignore the value property
     */
    get valueCallback(): () => any;
    set valueCallback(value: () => any);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the output component
     */
    get output(): NodeParticleConnectionPoint;
    /**
     * Set the input block to its default value (based on its type)
     */
    setDefaultValue(): void;
    _build(state: NodeParticleBuildState): void;
    dispose(): void;
    serialize(): any;
    _deserialize(serializationObject: any): void;
}

/**
 * Interface used to configure the node particle editor
 */
interface INodeParticleEditorOptions {
    /** Define the URL to load node editor script from */
    editorURL?: string;
    /** Additional configuration for the NPE */
    nodeEditorConfig?: {
        backgroundColor?: Color4;
        /** If true, the node particle system set will be disposed when the editor is closed (default: true) */
        disposeOnClose?: boolean;
    };
}
/**
 * Defines a set of particle systems defined as a node graph.
 * NPE: #K6F1ZB#1
 * PG: #ZT509U#1
 */
declare class NodeParticleSystemSet {
    private _systemBlocks;
    private _buildId;
    /** Define the Url to load node editor script */
    static EditorURL: string;
    /** Define the Url to load snippets */
    static SnippetUrl: string;
    /**
     * Snippet ID if the material was created from the snippet server
     */
    snippetId: string;
    /**
     * Gets an array of blocks that needs to be serialized even if they are not yet connected
     */
    attachedBlocks: NodeParticleBlock[];
    /**
     * Gets or sets data used by visual editor
     * @see https://npe.babylonjs.com
     */
    editorData: any;
    /**
     * Observable raised when the particle set is built
     */
    onBuildObservable: Observable<NodeParticleSystemSet>;
    /**
     * The name of the set
     */
    name: string;
    /**
     * A free comment about the set
     */
    comment: string;
    /**
     * Gets the system blocks
     */
    get systemBlocks(): SystemBlock[];
    /**
     * Gets the list of input blocks attached to this material
     * @returns an array of InputBlocks
     */
    get inputBlocks(): ParticleInputBlock[];
    /**
     * Get a block by its name
     * @param name defines the name of the block to retrieve
     * @returns the required block or null if not found
     */
    getBlockByName(name: string): NodeParticleBlock | null;
    /**
     * Get a block using a predicate
     * @param predicate defines the predicate used to find the good candidate
     * @returns the required block or null if not found
     */
    getBlockByPredicate(predicate: (block: NodeParticleBlock) => boolean): NodeParticleBlock | null;
    /**
     * Get an input block using a predicate
     * @param predicate defines the predicate used to find the good candidate
     * @returns the required input block or null if not found
     */
    getInputBlockByPredicate(predicate: (block: ParticleInputBlock) => boolean): Nullable<ParticleInputBlock>;
    /**
     * Creates a new set
     * @param name defines the name of the set
     */
    constructor(name: string);
    /**
     * Gets the current class name of the node particle set e.g. "NodeParticleSystemSet"
     * @returns the class name
     */
    getClassName(): string;
    private _initializeBlock;
    private BJSNODEPARTICLEEDITOR;
    /** Get the editor from bundle or global
     * @returns the global NPE
     */
    private _getGlobalNodeParticleEditor;
    /** Creates the node editor window.
     * @param additionalConfig Define the configuration of the editor
     */
    private _createNodeParticleEditor;
    /**
     * Launch the node particle editor
     * @param config Define the configuration of the editor
     * @returns a promise fulfilled when the node editor is visible
     */
    editAsync(config?: INodeParticleEditorOptions): Promise<void>;
    /**
     * Builds the particle system set from the defined blocks.
     * @param scene defines the hosting scene
     * @param verbose defines whether to log detailed information during the build process (false by default)
     * @returns a promise that resolves to the built particle system set
     */
    buildAsync(scene: Scene, verbose?: boolean): Promise<ParticleSystemSet>;
    /**
     * Clear the current node particle set
     */
    clear(): void;
    /**
     * Clear the current set and restore it to a default state
     */
    setToDefault(): void;
    /**
     * Remove a block from the current system set
     * @param block defines the block to remove
     */
    removeBlock(block: NodeParticleBlock): void;
    /**
     * Clear the current graph and load a new one from a serialization object
     * @param source defines the JSON representation of the particle set
     * @param merge defines whether or not the source must be merged or replace the current content
     */
    parseSerializedObject(source: any, merge?: boolean): void;
    private _restoreConnections;
    /**
     * Serializes this node particle set in a JSON representation
     * @param selectedBlocks defines the list of blocks to save (if null the whole node particle set will be saved)
     * @returns the serialized particle system set object
     */
    serialize(selectedBlocks?: NodeParticleBlock[]): any;
    /**
     * Makes a duplicate of the current particle system set.
     * @param name defines the name to use for the new particle system set
     * @returns the cloned particle system set
     */
    clone(name: string): NodeParticleSystemSet;
    /**
     * Disposes the resources
     */
    dispose(): void;
    /**
     * Creates a new node particle set set to default basic configuration
     * @param name defines the name of the particle set
     * @returns a new NodeParticleSystemSet
     */
    static CreateDefault(name: string): NodeParticleSystemSet;
    /**
     * Creates a node particle set from parsed data
     * @param source defines the JSON representation of the particle set
     * @returns a new node particle set
     */
    static Parse(source: any): NodeParticleSystemSet;
    /**
     * Creates a node particle set from a snippet saved in a remote file
     * @param name defines the name of the node particle set to create
     * @param url defines the url to load from
     * @param nodeParticleSet defines a node particle set to update (instead of creating a new one)
     * @returns a promise that will resolve to the new node particle set
     */
    static ParseFromFileAsync(name: string, url: string, nodeParticleSet?: NodeParticleSystemSet): Promise<NodeParticleSystemSet>;
    /**
     * Creates a node particle set from a snippet saved by the node particle editor
     * @param snippetId defines the snippet to load
     * @param nodeParticleSet defines a node particle set to update (instead of creating a new one)
     * @returns a promise that will resolve to the new node particle set
     */
    static ParseFromSnippetAsync(snippetId: string, nodeParticleSet?: NodeParticleSystemSet): Promise<NodeParticleSystemSet>;
}

/**
 * This represents a particle system in Babylon.
 * Particles are often small sprites used to simulate hard-to-reproduce phenomena like fire, smoke, water, or abstract visual effects like magic glitter and faery dust.
 * Particles can take different shapes while emitted like box, sphere, cone or you can write your custom function.
 * @example https://doc.babylonjs.com/features/featuresDeepDive/particles/particle_system/particle_system_intro
 */
declare class ParticleSystem extends ThinParticleSystem {
    /**
     * Billboard mode will only apply to Y axis
     */
    static readonly BILLBOARDMODE_Y = 2;
    /**
     * Billboard mode will apply to all axes
     */
    static readonly BILLBOARDMODE_ALL = 7;
    /**
     * Special billboard mode where the particle will be biilboard to the camera but rotated to align with direction
     */
    static readonly BILLBOARDMODE_STRETCHED = 8;
    /**
     * Special billboard mode where the particle will be billboard to the camera but only around the axis of the direction of particle emission
     */
    static readonly BILLBOARDMODE_STRETCHED_LOCAL = 9;
    private _rootParticleSystem;
    /**
     * The Sub-emitters templates that will be used to generate the sub particle system to be associated with the system, this property is used by the root particle system only.
     * When a particle is spawned, an array will be chosen at random and all the emitters in that array will be attached to the particle.  (Default: [])
     */
    subEmitters: Array<ParticleSystem | SubEmitter | Array<SubEmitter>>;
    private _subEmitters;
    /**
     * @internal
     * If the particle systems emitter should be disposed when the particle system is disposed
     */
    _disposeEmitterOnDispose: boolean;
    /**
     * The current active Sub-systems, this property is used by the root particle system only.
     */
    activeSubSystems: Array<ParticleSystem>;
    /**
     * Specifies if the particle system should be serialized
     */
    doNotSerialize: boolean;
    /**
     * Creates a Point Emitter for the particle system (emits directly from the emitter position)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the box
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the box
     * @returns the emitter
     */
    createPointEmitter(direction1: Vector3, direction2: Vector3): PointParticleEmitter;
    /**
     * Gets or sets a function indicating if the particle system can start.
     * @returns true if the particle system can start, false otherwise.
     */
    canStart: () => boolean;
    /** Flow map */
    private _flowMap;
    private _flowMapUpdate;
    /** @internal */
    _source: Nullable<NodeParticleSystemSet>;
    /** @internal */
    _blockReference: number;
    /**
     * Gets the NodeParticleSystemSet that this particle system belongs to.
     */
    get source(): Nullable<NodeParticleSystemSet>;
    /**
     * Returns true if the particle system was generated by a node particle system set
     */
    get isNodeGenerated(): boolean;
    /**
     * The strength of the flow map
     */
    flowMapStrength: number;
    /** Gets or sets the current flow map */
    get flowMap(): Nullable<FlowMap>;
    set flowMap(value: Nullable<FlowMap>);
    /** Attractors */
    private _attractors;
    private _attractorUpdate;
    /**
     * The list of attractors used to change the direction of the particles in the system.
     * Please note that this is a copy of the internal array. If you want to modify it, please use the addAttractor and removeAttractor methods.
     */
    get attractors(): Attractor[];
    /**
     * Gets or sets an object used to store user defined information for the particle system
     */
    metadata: any;
    /**
     * Add an attractor to the particle system. Attractors are used to change the direction of the particles in the system.
     * @param attractor The attractor to add to the particle system
     */
    addAttractor(attractor: Attractor): void;
    /**
     * Removes an attractor from the particle system. Attractors are used to change the direction of the particles in the system.
     * @param attractor The attractor to remove from the particle system
     */
    removeAttractor(attractor: Attractor): void;
    /**
     * Starts the particle system and begins to emit
     * @param delay defines the delay in milliseconds before starting the system (this.startDelay by default)
     */
    start(delay?: number): void;
    /**
     * Creates a Hemisphere Emitter for the particle system (emits along the hemisphere radius)
     * @param radius The radius of the hemisphere to emit from
     * @param radiusRange The range of the hemisphere to emit from [0-1] 0 Surface Only, 1 Entire Radius
     * @returns the emitter
     */
    createHemisphericEmitter(radius?: number, radiusRange?: number): HemisphericParticleEmitter;
    /**
     * Creates a Sphere Emitter for the particle system (emits along the sphere radius)
     * @param radius The radius of the sphere to emit from
     * @param radiusRange The range of the sphere to emit from [0-1] 0 Surface Only, 1 Entire Radius
     * @returns the emitter
     */
    createSphereEmitter(radius?: number, radiusRange?: number): SphereParticleEmitter;
    /**
     * Creates a Directed Sphere Emitter for the particle system (emits between direction1 and direction2)
     * @param radius The radius of the sphere to emit from
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the sphere
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the sphere
     * @returns the emitter
     */
    createDirectedSphereEmitter(radius?: number, direction1?: Vector3, direction2?: Vector3): SphereDirectedParticleEmitter;
    /**
     * Creates a Cylinder Emitter for the particle system (emits from the cylinder to the particle position)
     * @param radius The radius of the emission cylinder
     * @param height The height of the emission cylinder
     * @param radiusRange The range of emission [0-1] 0 Surface only, 1 Entire Radius
     * @param directionRandomizer How much to randomize the particle direction [0-1]
     * @returns the emitter
     */
    createCylinderEmitter(radius?: number, height?: number, radiusRange?: number, directionRandomizer?: number): CylinderParticleEmitter;
    /**
     * Creates a Directed Cylinder Emitter for the particle system (emits between direction1 and direction2)
     * @param radius The radius of the cylinder to emit from
     * @param height The height of the emission cylinder
     * @param radiusRange the range of the emission cylinder [0-1] 0 Surface only, 1 Entire Radius (1 by default)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the cylinder
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the cylinder
     * @returns the emitter
     */
    createDirectedCylinderEmitter(radius?: number, height?: number, radiusRange?: number, direction1?: Vector3, direction2?: Vector3): CylinderDirectedParticleEmitter;
    /**
     * Creates a Cone Emitter for the particle system (emits from the cone to the particle position)
     * @param radius The radius of the cone to emit from
     * @param angle The base angle of the cone
     * @returns the emitter
     */
    createConeEmitter(radius?: number, angle?: number): ConeParticleEmitter;
    /**
     * Creates a Cone Emitter for the particle system (emits from the cone to the particle position)
     * @param radius The radius of the cone to emit from
     * @param angle The base angle of the cone
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the cone
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the cone
     * @returns the emitter
     */
    createDirectedConeEmitter(radius?: number, angle?: number, direction1?: Vector3, direction2?: Vector3): ConeDirectedParticleEmitter;
    /**
     * Creates a Box Emitter for the particle system. (emits between direction1 and direction2 from withing the box defined by minEmitBox and maxEmitBox)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the box
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the box
     * @param minEmitBox Particles are emitted from the box between minEmitBox and maxEmitBox
     * @param maxEmitBox  Particles are emitted from the box between minEmitBox and maxEmitBox
     * @returns the emitter
     */
    createBoxEmitter(direction1: Vector3, direction2: Vector3, minEmitBox: Vector3, maxEmitBox: Vector3): BoxParticleEmitter;
    private _prepareSubEmitterInternalArray;
    private _stopSubEmitters;
    private _removeFromRoot;
    /** @internal */
    _emitFromParticle: (particle: Particle) => void;
    /** @internal */
    _preStart(): void;
    /** @internal */
    _postStop(stopSubEmitters: boolean): void;
    /** @internal */
    _prepareParticle(particle: Particle): void;
    /** @internal */
    _onDispose(disposeAttachedSubEmitters?: boolean, disposeEndSubEmitters?: boolean): void;
    /**
     * @internal
     */
    static _Parse(parsedParticleSystem: any, particleSystem: IParticleSystem, sceneOrEngine: Scene | AbstractEngine, rootUrl: string): void;
    /**
     * Parses a JSON object to create a particle system.
     * @param parsedParticleSystem The JSON object to parse
     * @param sceneOrEngine The scene or the engine to create the particle system in
     * @param rootUrl The root url to use to load external dependencies like texture
     * @param doNotStart Ignore the preventAutoStart attribute and does not start
     * @param capacity defines the system capacity (if null or undefined the sotred capacity will be used)
     * @returns the Parsed particle system
     */
    static Parse(parsedParticleSystem: any, sceneOrEngine: Scene | AbstractEngine, rootUrl: string, doNotStart?: boolean, capacity?: number): ParticleSystem;
    /**
     * Serializes the particle system to a JSON object
     * @param serializeTexture defines if the texture must be serialized as well
     * @returns the JSON object
     */
    serialize(serializeTexture?: boolean): any;
    /**
     * @internal
     */
    static _Serialize(serializationObject: any, particleSystem: IParticleSystem, serializeTexture: boolean): void;
    /**
     * Clones the particle system.
     * @param name The name of the cloned object
     * @param newEmitter The new emitter to use
     * @param cloneTexture Also clone the textures if true
     * @returns the cloned particle system
     */
    clone(name: string, newEmitter: any, cloneTexture?: boolean): ParticleSystem;
}

/**
 * Type of sub emitter
 */
declare const enum SubEmitterType {
    /**
     * Attached to the particle over it's lifetime
     */
    ATTACHED = 0,
    /**
     * Created when the particle dies
     */
    END = 1
}
/**
 * Sub emitter class used to emit particles from an existing particle
 */
declare class SubEmitter {
    /**
     * the particle system to be used by the sub emitter
     */
    particleSystem: ParticleSystem;
    /**
     * Type of the submitter (Default: END)
     */
    type: SubEmitterType;
    /**
     * If the particle should inherit the direction from the particle it's attached to. (+Y will face the direction the particle is moving) (Default: false)
     * Note: This only is supported when using an emitter of type Mesh
     */
    inheritDirection: boolean;
    /**
     * How much of the attached particles speed should be added to the sub emitted particle (default: 0)
     */
    inheritedVelocityAmount: number;
    /**
     * Creates a sub emitter
     * @param particleSystem the particle system to be used by the sub emitter
     */
    constructor(
    /**
     * the particle system to be used by the sub emitter
     */
    particleSystem: ParticleSystem);
    /**
     * Clones the sub emitter
     * @returns the cloned sub emitter
     */
    clone(): SubEmitter;
    /**
     * Serialize current object to a JSON object
     * @param serializeTexture defines if the texture must be serialized as well
     * @returns the serialized object
     */
    serialize(serializeTexture?: boolean): any;
    /**
     * @internal
     */
    static _ParseParticleSystem(system: any, sceneOrEngine: Scene | AbstractEngine, rootUrl: string, doNotStart?: boolean): ParticleSystem;
    /**
     * Creates a new SubEmitter from a serialized JSON version
     * @param serializationObject defines the JSON object to read from
     * @param sceneOrEngine defines the hosting scene or the hosting engine
     * @param rootUrl defines the rootUrl for data loading
     * @returns a new SubEmitter
     */
    static Parse(serializationObject: any, sceneOrEngine: Scene | AbstractEngine, rootUrl: string): SubEmitter;
    /** Release associated resources */
    dispose(): void;
}

/**
 * A particle represents one of the element emitted by a particle system.
 * This is mainly define by its coordinates, direction, velocity and age.
 */
declare class Particle {
    /**
     * The particle system the particle belongs to.
     */
    particleSystem: ThinParticleSystem;
    private static _Count;
    /**
     * Unique ID of the particle
     */
    id: number;
    /**
     * The world position of the particle in the scene.
     */
    position: Vector3;
    /**
     * The world direction of the particle in the scene.
     */
    direction: Vector3;
    /**
     * The color of the particle.
     */
    color: Color4;
    /**
     * The color change of the particle per step.
     */
    colorStep: Color4;
    /**
     * The creation color of the particle.
     */
    initialColor: Color4;
    /**
     * The color used when the end of life of the particle.
     */
    colorDead: Color4;
    /**
     * Defines how long will the life of the particle be.
     */
    lifeTime: number;
    /**
     * The current age of the particle.
     */
    age: number;
    /**
     * The current size of the particle.
     */
    size: number;
    /**
     * The current scale of the particle.
     */
    scale: Vector2;
    /**
     * The current angle of the particle.
     */
    angle: number;
    /**
     * Defines how fast is the angle changing.
     */
    angularSpeed: number;
    /**
     * Defines the cell index used by the particle to be rendered from a sprite.
     */
    cellIndex: number;
    /**
     * The information required to support color remapping
     */
    remapData: Vector4;
    /** @internal */
    _randomCellOffset?: number;
    /** @internal */
    _initialDirection: Nullable<Vector3>;
    /** @internal */
    _attachedSubEmitters: Nullable<Array<SubEmitter>>;
    /** @internal */
    _initialStartSpriteCellId: number;
    /** @internal */
    _initialEndSpriteCellId: number;
    /** @internal */
    _initialSpriteCellLoop: boolean;
    /** @internal */
    _currentColorGradient: Nullable<ColorGradient>;
    /** @internal */
    _currentColor1: Color4;
    /** @internal */
    _currentColor2: Color4;
    /** @internal */
    _currentSizeGradient: Nullable<FactorGradient>;
    /** @internal */
    _currentSize1: number;
    /** @internal */
    _currentSize2: number;
    /** @internal */
    _currentAngularSpeedGradient: Nullable<FactorGradient>;
    /** @internal */
    _currentAngularSpeed1: number;
    /** @internal */
    _currentAngularSpeed2: number;
    /** @internal */
    _currentVelocityGradient: Nullable<FactorGradient>;
    /** @internal */
    _currentVelocity1: number;
    /** @internal */
    _currentVelocity2: number;
    /** @internal */
    _directionScale: number;
    /** @internal */
    _scaledDirection: Vector3;
    /** @internal */
    _currentLimitVelocityGradient: Nullable<FactorGradient>;
    /** @internal */
    _currentLimitVelocity1: number;
    /** @internal */
    _currentLimitVelocity2: number;
    /** @internal */
    _currentDragGradient: Nullable<FactorGradient>;
    /** @internal */
    _currentDrag1: number;
    /** @internal */
    _currentDrag2: number;
    /** @internal */
    _randomNoiseCoordinates1: Nullable<Vector3>;
    /** @internal */
    _randomNoiseCoordinates2: Nullable<Vector3>;
    /** @internal */
    _localPosition?: Vector3;
    /**
     * Callback triggered when the particle is reset
     */
    onReset: Nullable<() => void>;
    /**
     * Creates a new instance Particle
     * @param particleSystem the particle system the particle belongs to
     */
    constructor(
    /**
     * The particle system the particle belongs to.
     */
    particleSystem: ThinParticleSystem);
    private _updateCellInfoFromSystem;
    /**
     * Defines how the sprite cell index is updated for the particle
     */
    updateCellIndex(): void;
    /**
     * @internal
     */
    _inheritParticleInfoToSubEmitter(subEmitter: SubEmitter): void;
    /** @internal */
    _inheritParticleInfoToSubEmitters(): void;
    /** @internal */
    _reset(): void;
    /**
     * Copy the properties of particle to another one.
     * @param other the particle to copy the information to.
     */
    copyTo(other: Particle): void;
}

/**
 * Particle emitter emitting particles from the inside of a box.
 * It emits the particles randomly between 2 given directions.
 */
declare class BoxParticleEmitter implements IParticleEmitterType {
    /**
     * Random direction of each particle after it has been emitted, between direction1 and direction2 vectors.
     */
    direction1: Vector3;
    /**
     * Random direction of each particle after it has been emitted, between direction1 and direction2 vectors.
     */
    direction2: Vector3;
    /**
     * Minimum box point around our emitter. Our emitter is the center of particles source, but if you want your particles to emit from more than one point, then you can tell it to do so.
     */
    minEmitBox: Vector3;
    /**
     * Maximum box point around our emitter. Our emitter is the center of particles source, but if you want your particles to emit from more than one point, then you can tell it to do so.
     */
    maxEmitBox: Vector3;
    /**
     * Creates a new instance BoxParticleEmitter
     */
    constructor();
    /**
     * Called by the particle System when the direction is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param directionToUpdate is the direction vector to update with the result
     * @param particle is the particle we are computed the direction for
     * @param isLocal defines if the direction should be set in local space
     */
    startDirectionFunction(worldMatrix: Matrix, directionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Called by the particle System when the position is computed for the created particle.
     * @param worldMatrix is the world matrix of the particle system
     * @param positionToUpdate is the position vector to update with the result
     * @param particle is the particle we are computed the position for
     * @param isLocal defines if the position should be set in local space
     */
    startPositionFunction(worldMatrix: Matrix, positionToUpdate: Vector3, particle: Particle, isLocal: boolean): void;
    /**
     * Clones the current emitter and returns a copy of it
     * @returns the new emitter
     */
    clone(): BoxParticleEmitter;
    /**
     * Called by the GPUParticleSystem to setup the update shader
     * @param uboOrEffect defines the update shader
     */
    applyToShader(uboOrEffect: UniformBufferEffectCommonAccessor): void;
    /**
     * Creates the structure of the ubo for this particle emitter
     * @param ubo ubo to create the structure for
     */
    buildUniformLayout(ubo: UniformBuffer): void;
    /**
     * Returns a string to use to update the GPU particles update shader
     * @returns a string containing the defines string
     */
    getEffectDefines(): string;
    /**
     * Returns the string "BoxParticleEmitter"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Serializes the particle system to a JSON object.
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Parse properties from a JSON object
     * @param serializationObject defines the JSON object
     */
    parse(serializationObject: any): void;
}

/**
 * Interface representing a particle system in Babylon.js.
 * This groups the common functionalities that needs to be implemented in order to create a particle system.
 * A particle system represents a way to manage particles from their emission to their animation and rendering.
 */
interface IParticleSystem {
    /**
     * Gets or sets the unique id of the particle system.
     */
    uniqueId: number;
    /**
     * List of animations used by the particle system.
     */
    animations: Animation[];
    /**
     * The id of the Particle system.
     */
    id: string;
    /**
     * The name of the Particle system.
     */
    name: string;
    /**
     * The emitter represents the Mesh or position we are attaching the particle system to.
     */
    emitter: Nullable<AbstractMesh | Vector3>;
    /**
     * Gets or sets a boolean indicating if the particles must be rendered as billboard or aligned with the direction
     */
    isBillboardBased: boolean;
    /**
     * The rendering group used by the Particle system to chose when to render.
     */
    renderingGroupId: number;
    /**
     * The layer mask we are rendering the particles through.
     */
    layerMask: number;
    /**
     * The overall motion speed (0.01 is default update speed, faster updates = faster animation)
     */
    updateSpeed: number;
    /**
     * The amount of time the particle system is running (depends of the overall update speed).
     */
    targetStopDuration: number;
    /**
     * The texture used to render each particle. (this can be a spritesheet)
     */
    particleTexture: Nullable<BaseTexture>;
    /**
     * Blend mode use to render the particle. It can be any of the ParticleSystem.BLENDMODE_* constants
     */
    blendMode: number;
    /**
     * Minimum life time of emitting particles.
     */
    minLifeTime: number;
    /**
     * Maximum life time of emitting particles.
     */
    maxLifeTime: number;
    /**
     * Minimum Size of emitting particles.
     */
    minSize: number;
    /**
     * Maximum Size of emitting particles.
     */
    maxSize: number;
    /**
     * Minimum scale of emitting particles on X axis.
     */
    minScaleX: number;
    /**
     * Maximum scale of emitting particles on X axis.
     */
    maxScaleX: number;
    /**
     * Minimum scale of emitting particles on Y axis.
     */
    minScaleY: number;
    /**
     * Maximum scale of emitting particles on Y axis.
     */
    maxScaleY: number;
    /**
     * Random color of each particle after it has been emitted, between color1 and color2 vectors.
     */
    color1: Color4;
    /**
     * Random color of each particle after it has been emitted, between color1 and color2 vectors.
     */
    color2: Color4;
    /**
     * Color the particle will have at the end of its lifetime.
     */
    colorDead: Color4;
    /**
     * The maximum number of particles to emit per frame until we reach the activeParticleCount value
     */
    emitRate: number;
    /**
     * You can use gravity if you want to give an orientation to your particles.
     */
    gravity: Vector3;
    /**
     * Minimum power of emitting particles.
     */
    minEmitPower: number;
    /**
     * Maximum power of emitting particles.
     */
    maxEmitPower: number;
    /**
     * Minimum angular speed of emitting particles (Z-axis rotation for each particle).
     */
    minAngularSpeed: number;
    /**
     * Maximum angular speed of emitting particles (Z-axis rotation for each particle).
     */
    maxAngularSpeed: number;
    /**
     * Gets or sets the minimal initial rotation in radians.
     */
    minInitialRotation: number;
    /**
     * Gets or sets the maximal initial rotation in radians.
     */
    maxInitialRotation: number;
    /**
     * The particle emitter type defines the emitter used by the particle system.
     * It can be for example box, sphere, or cone...
     */
    particleEmitterType: Nullable<IParticleEmitterType>;
    /**
     * Defines the delay in milliseconds before starting the system (0 by default)
     */
    startDelay: number;
    /**
     * Gets or sets a value indicating how many cycles (or frames) must be executed before first rendering (this value has to be set before starting the system). Default is 0
     */
    preWarmCycles: number;
    /**
     * Gets or sets a value indicating the time step multiplier to use in pre-warm mode (default is 1)
     */
    preWarmStepOffset: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled) defines the speed of the sprite loop (default is 1 meaning the animation will play once during the entire particle lifetime)
     */
    spriteCellChangeSpeed: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled) defines the first sprite cell to display
     */
    startSpriteCellID: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled) defines the last sprite cell to display
     */
    endSpriteCellID: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled), defines whether the sprite animation is looping
     */
    spriteCellLoop: boolean;
    /**
     * If using a spritesheet (isAnimationSheetEnabled), defines the sprite cell width to use
     */
    spriteCellWidth: number;
    /**
     * If using a spritesheet (isAnimationSheetEnabled), defines the sprite cell height to use
     */
    spriteCellHeight: number;
    /**
     * This allows the system to random pick the start cell ID between startSpriteCellID and endSpriteCellID
     */
    spriteRandomStartCell: boolean;
    /**
     * Gets or sets a boolean indicating if a spritesheet is used to animate the particles texture
     */
    isAnimationSheetEnabled: boolean;
    /** Gets or sets a Vector2 used to move the pivot (by default (0,0)) */
    translationPivot: Vector2;
    /**
     * Gets or sets a texture used to add random noise to particle positions
     */
    noiseTexture: Nullable<BaseTexture>;
    /** Gets or sets the strength to apply to the noise value (default is (10, 10, 10)) */
    noiseStrength: Vector3;
    /**
     * Gets or sets the billboard mode to use when isBillboardBased = true.
     * Value can be: ParticleSystem.BILLBOARDMODE_ALL, ParticleSystem.BILLBOARDMODE_Y, ParticleSystem.BILLBOARDMODE_STRETCHED
     */
    billboardMode: number;
    /**
     * Gets or sets a boolean enabling the use of logarithmic depth buffers, which is good for wide depth buffers.
     */
    useLogarithmicDepth: boolean;
    /** Gets or sets a value indicating the damping to apply if the limit velocity factor is reached */
    limitVelocityDamping: number;
    /**
     * Gets or sets a boolean indicating that hosted animations (in the system.animations array) must be started when system.start() is called
     */
    beginAnimationOnStart: boolean;
    /**
     * Gets or sets the frame to start the animation from when beginAnimationOnStart is true
     */
    beginAnimationFrom: number;
    /**
     * Gets or sets the frame to end the animation on when beginAnimationOnStart is true
     */
    beginAnimationTo: number;
    /**
     * Gets or sets a boolean indicating if animations must loop when beginAnimationOnStart is true
     */
    beginAnimationLoop: boolean;
    /**
     * Specifies whether the particle system will be disposed once it reaches the end of the animation.
     */
    disposeOnStop: boolean;
    /**
     * If you want to launch only a few particles at once, that can be done, as well.
     */
    manualEmitCount: number;
    /**
     * Specifies if the particles are updated in emitter local space or world space
     */
    isLocal: boolean;
    /** Snippet ID if the particle system was created from the snippet server */
    snippetId: string;
    /** Gets or sets a matrix to use to compute projection */
    defaultProjectionMatrix: Matrix;
    /** Indicates that the update of particles is done in the animate function (and not in render) */
    updateInAnimate: boolean;
    /** @internal */
    _wasDispatched: boolean;
    /**
     * Returns true if the particle system was generated by a node particle system set
     */
    isNodeGenerated: boolean;
    /**
     * Specifies if the particle system should be serialized
     */
    doNotSerialize?: boolean;
    /**
     * Gets the maximum number of particles active at the same time.
     * @returns The max number of active particles.
     */
    getCapacity(): number;
    /**
     * Gets the number of particles active at the same time.
     * @returns The number of active particles.
     */
    getActiveCount(): number;
    /**
     * Gets if the system has been started. (Note: this will still be true after stop is called)
     * @returns True if it has been started, otherwise false.
     */
    isStarted(): boolean;
    /**
     * Animates the particle system for this frame.
     */
    animate(): void;
    /**
     * Renders the particle system in its current state.
     * @returns the current number of particles
     */
    render(): number;
    /**
     * Dispose the particle system and frees its associated resources.
     * @param disposeTexture defines if the particle texture must be disposed as well (true by default)
     * @param disposeAttachedSubEmitters defines if the attached sub-emitters must be disposed as well (false by default)
     * @param disposeEndSubEmitters defines if the end type sub-emitters must be disposed as well (false by default)
     */
    dispose(disposeTexture?: boolean, disposeAttachedSubEmitters?: boolean, disposeEndSubEmitters?: boolean): void;
    /**
     * An event triggered when the system is disposed
     */
    onDisposeObservable: Observable<IParticleSystem>;
    /**
     * An event triggered when the system is stopped
     */
    onStoppedObservable: Observable<IParticleSystem>;
    /**
     * An event triggered when the system is started
     */
    onStartedObservable: Observable<IParticleSystem>;
    /**
     * Clones the particle system.
     * @param name The name of the cloned object
     * @param newEmitter The new emitter to use
     * @returns the cloned particle system
     */
    clone(name: string, newEmitter: any): Nullable<IParticleSystem>;
    /**
     * Serializes the particle system to a JSON object
     * @param serializeTexture defines if the texture must be serialized as well
     * @returns the JSON object
     */
    serialize(serializeTexture: boolean): any;
    /**
     * Rebuild the particle system
     */
    rebuild(): void;
    /** Force the system to rebuild all gradients that need to be resync */
    forceRefreshGradients(): void;
    /**
     * Starts the particle system and begins to emit
     * @param delay defines the delay in milliseconds before starting the system (0 by default)
     */
    start(delay?: number): void;
    /**
     * Stops the particle system.
     */
    stop(): void;
    /**
     * Remove all active particles
     */
    reset(): void;
    /**
     * Gets a boolean indicating that the system is stopping
     * @returns true if the system is currently stopping
     */
    isStopping(): boolean;
    /**
     * Is this system ready to be used/rendered
     * @returns true if the system is ready
     */
    isReady(): boolean;
    /**
     * Returns the string "ParticleSystem"
     * @returns a string containing the class name
     */
    getClassName(): string;
    /**
     * Gets the custom effect used to render the particles
     * @param blendMode Blend mode for which the effect should be retrieved
     * @returns The effect
     */
    getCustomEffect(blendMode: number): Nullable<Effect>;
    /**
     * Sets the custom effect used to render the particles
     * @param effect The effect to set
     * @param blendMode Blend mode for which the effect should be set
     */
    setCustomEffect(effect: Nullable<Effect>, blendMode: number): void;
    /**
     * Fill the defines array according to the current settings of the particle system
     * @param defines Array to be updated
     * @param blendMode blend mode to take into account when updating the array
     * @param fillImageProcessing fills the image processing defines
     */
    fillDefines(defines: Array<string>, blendMode: number, fillImageProcessing?: boolean): void;
    /**
     * Fill the uniforms, attributes and samplers arrays according to the current settings of the particle system
     * @param uniforms Uniforms array to fill
     * @param attributes Attributes array to fill
     * @param samplers Samplers array to fill
     */
    fillUniformsAttributesAndSamplerNames(uniforms: Array<string>, attributes: Array<string>, samplers: Array<string>): void;
    /**
     * Observable that will be called just before the particles are drawn
     */
    onBeforeDrawParticlesObservable: Observable<Nullable<Effect>>;
    /**
     * Gets the name of the particle vertex shader
     */
    vertexShaderName: string;
    /**
     * Gets the vertex buffers used by the particle system
     */
    vertexBuffers: Immutable<{
        [key: string]: VertexBuffer;
    }>;
    /**
     * Gets the index buffer used by the particle system (or null if no index buffer is used)
     */
    indexBuffer: Nullable<DataBuffer>;
    /**
     * Adds a new color gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param color1 defines the color to affect to the specified gradient
     * @param color2 defines an additional color used to define a range ([color, color2]) with main color to pick the final color from
     * @returns the current particle system
     */
    addColorGradient(gradient: number, color1: Color4, color2?: Color4): IParticleSystem;
    /**
     * Remove a specific color gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeColorGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new size gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the size factor to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addSizeGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific size gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeSizeGradient(gradient: number): IParticleSystem;
    /**
     * Gets the current list of color gradients.
     * You must use addColorGradient and removeColorGradient to update this list
     * @returns the list of color gradients
     */
    getColorGradients(): Nullable<Array<ColorGradient>>;
    /**
     * Gets the current list of size gradients.
     * You must use addSizeGradient and removeSizeGradient to update this list
     * @returns the list of size gradients
     */
    getSizeGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of angular speed gradients.
     * You must use addAngularSpeedGradient and removeAngularSpeedGradient to update this list
     * @returns the list of angular speed gradients
     */
    getAngularSpeedGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Adds a new angular speed gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the angular speed to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addAngularSpeedGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific angular speed gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeAngularSpeedGradient(gradient: number): IParticleSystem;
    /**
     * Gets the current list of velocity gradients.
     * You must use addVelocityGradient and removeVelocityGradient to update this list
     * @returns the list of velocity gradients
     */
    getVelocityGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Adds a new velocity gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the velocity to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addVelocityGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific velocity gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeVelocityGradient(gradient: number): IParticleSystem;
    /**
     * Gets the current list of limit velocity gradients.
     * You must use addLimitVelocityGradient and removeLimitVelocityGradient to update this list
     * @returns the list of limit velocity gradients
     */
    getLimitVelocityGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Adds a new limit velocity gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the limit velocity to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addLimitVelocityGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific limit velocity gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeLimitVelocityGradient(gradient: number): IParticleSystem;
    /**
     * Adds a new drag gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the drag to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addDragGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific drag gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeDragGradient(gradient: number): IParticleSystem;
    /**
     * Gets the current list of drag gradients.
     * You must use addDragGradient and removeDragGradient to update this list
     * @returns the list of drag gradients
     */
    getDragGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Adds a new emit rate gradient (please note that this will only work if you set the targetStopDuration property)
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the emit rate to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addEmitRateGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific emit rate gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeEmitRateGradient(gradient: number): IParticleSystem;
    /**
     * Gets the current list of emit rate gradients.
     * You must use addEmitRateGradient and removeEmitRateGradient to update this list
     * @returns the list of emit rate gradients
     */
    getEmitRateGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Adds a new start size gradient (please note that this will only work if you set the targetStopDuration property)
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the start size to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addStartSizeGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific start size gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeStartSizeGradient(gradient: number): IParticleSystem;
    /**
     * Gets the current list of start size gradients.
     * You must use addStartSizeGradient and removeStartSizeGradient to update this list
     * @returns the list of start size gradients
     */
    getStartSizeGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Adds a new life time gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param factor defines the life time factor to affect to the specified gradient
     * @param factor2 defines an additional factor used to define a range ([factor, factor2]) with main value to pick the final value from
     * @returns the current particle system
     */
    addLifeTimeGradient(gradient: number, factor: number, factor2?: number): IParticleSystem;
    /**
     * Remove a specific life time gradient
     * @param gradient defines the gradient to remove
     * @returns the current particle system
     */
    removeLifeTimeGradient(gradient: number): IParticleSystem;
    /**
     * Gets the current list of life time gradients.
     * You must use addLifeTimeGradient and removeLifeTimeGradient to update this list
     * @returns the list of life time gradients
     */
    getLifeTimeGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Gets the current list of color gradients.
     * You must use addColorGradient and removeColorGradient to update this list
     * @returns the list of color gradients
     */
    getColorGradients(): Nullable<Array<ColorGradient>>;
    /**
     * Adds a new ramp gradient used to remap particle colors
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param color defines the color to affect to the specified gradient
     * @returns the current particle system
     */
    addRampGradient(gradient: number, color: Color3): IParticleSystem;
    /**
     * Gets the current list of ramp gradients.
     * You must use addRampGradient and removeRampGradient to update this list
     * @returns the list of ramp gradients
     */
    getRampGradients(): Nullable<Array<Color3Gradient>>;
    /** Gets or sets a boolean indicating that ramp gradients must be used
     * @see https://doc.babylonjs.com/features/featuresDeepDive/particles/particle_system/ramps_and_blends
     */
    useRampGradients: boolean;
    /**
     * Adds a new color remap gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param min defines the color remap minimal range
     * @param max defines the color remap maximal range
     * @returns the current particle system
     */
    addColorRemapGradient(gradient: number, min: number, max: number): IParticleSystem;
    /**
     * Gets the current list of color remap gradients.
     * You must use addColorRemapGradient and removeColorRemapGradient to update this list
     * @returns the list of color remap gradients
     */
    getColorRemapGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Adds a new alpha remap gradient
     * @param gradient defines the gradient to use (between 0 and 1)
     * @param min defines the alpha remap minimal range
     * @param max defines the alpha remap maximal range
     * @returns the current particle system
     */
    addAlphaRemapGradient(gradient: number, min: number, max: number): IParticleSystem;
    /**
     * Gets the current list of alpha remap gradients.
     * You must use addAlphaRemapGradient and removeAlphaRemapGradient to update this list
     * @returns the list of alpha remap gradients
     */
    getAlphaRemapGradients(): Nullable<Array<FactorGradient>>;
    /**
     * Creates a Point Emitter for the particle system (emits directly from the emitter position)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the box
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the box
     * @returns the emitter
     */
    createPointEmitter(direction1: Vector3, direction2: Vector3): PointParticleEmitter;
    /**
     * Creates a Hemisphere Emitter for the particle system (emits along the hemisphere radius)
     * @param radius The radius of the hemisphere to emit from
     * @param radiusRange The range of the hemisphere to emit from [0-1] 0 Surface Only, 1 Entire Radius
     * @returns the emitter
     */
    createHemisphericEmitter(radius: number, radiusRange: number): HemisphericParticleEmitter;
    /**
     * Creates a Sphere Emitter for the particle system (emits along the sphere radius)
     * @param radius The radius of the sphere to emit from
     * @param radiusRange The range of the sphere to emit from [0-1] 0 Surface Only, 1 Entire Radius
     * @returns the emitter
     */
    createSphereEmitter(radius: number, radiusRange: number): SphereParticleEmitter;
    /**
     * Creates a Directed Sphere Emitter for the particle system (emits between direction1 and direction2)
     * @param radius The radius of the sphere to emit from
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the sphere
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the sphere
     * @returns the emitter
     */
    createDirectedSphereEmitter(radius: number, direction1: Vector3, direction2: Vector3): SphereDirectedParticleEmitter;
    /**
     * Creates a Cylinder Emitter for the particle system (emits from the cylinder to the particle position)
     * @param radius The radius of the emission cylinder
     * @param height The height of the emission cylinder
     * @param radiusRange The range of emission [0-1] 0 Surface only, 1 Entire Radius
     * @param directionRandomizer How much to randomize the particle direction [0-1]
     * @returns the emitter
     */
    createCylinderEmitter(radius: number, height: number, radiusRange: number, directionRandomizer: number): CylinderParticleEmitter;
    /**
     * Creates a Directed Cylinder Emitter for the particle system (emits between direction1 and direction2)
     * @param radius The radius of the cylinder to emit from
     * @param height The height of the emission cylinder
     * @param radiusRange the range of the emission cylinder [0-1] 0 Surface only, 1 Entire Radius (1 by default)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the cylinder
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the cylinder
     * @returns the emitter
     */
    createDirectedCylinderEmitter(radius: number, height: number, radiusRange: number, direction1: Vector3, direction2: Vector3): CylinderDirectedParticleEmitter;
    /**
     * Creates a Cone Emitter for the particle system (emits from the cone to the particle position)
     * @param radius The radius of the cone to emit from
     * @param angle The base angle of the cone
     * @returns the emitter
     */
    createConeEmitter(radius: number, angle: number): ConeParticleEmitter;
    createDirectedConeEmitter(radius: number, angle: number, direction1: Vector3, direction2: Vector3): ConeDirectedParticleEmitter;
    /**
     * Creates a Box Emitter for the particle system. (emits between direction1 and direction2 from withing the box defined by minEmitBox and maxEmitBox)
     * @param direction1 Particles are emitted between the direction1 and direction2 from within the box
     * @param direction2 Particles are emitted between the direction1 and direction2 from within the box
     * @param minEmitBox Particles are emitted from the box between minEmitBox and maxEmitBox
     * @param maxEmitBox  Particles are emitted from the box between minEmitBox and maxEmitBox
     * @returns the emitter
     */
    createBoxEmitter(direction1: Vector3, direction2: Vector3, minEmitBox: Vector3, maxEmitBox: Vector3): BoxParticleEmitter;
    /**
     * Get hosting scene
     * @returns the scene
     */
    getScene(): Nullable<Scene>;
}

/** @internal */
declare abstract class WebGPUCacheRenderPipeline {
    static LogErrorIfNoVertexBuffer: boolean;
    static NumCacheHitWithoutHash: number;
    static NumCacheHitWithHash: number;
    static NumCacheMiss: number;
    static NumPipelineCreationLastFrame: number;
    disabled: boolean;
    private static _NumPipelineCreationCurrentFrame;
    protected _states: number[];
    protected _statesLength: number;
    protected _stateDirtyLowestIndex: number;
    lastStateDirtyLowestIndex: number;
    private _device;
    private _isDirty;
    private _emptyVertexBuffer;
    private _parameter;
    private _kMaxVertexBufferStride;
    private _shaderId;
    private _alphaToCoverageEnabled;
    private _frontFace;
    private _cullEnabled;
    private _cullFace;
    private _clampDepth;
    private _rasterizationState;
    private _depthBias;
    private _depthBiasClamp;
    private _depthBiasSlopeScale;
    private _colorFormat;
    private _webgpuColorFormat;
    private _mrtAttachments;
    private _mrtFormats;
    private _mrtEnabledMask;
    private _alphaBlendEnabled;
    private _numAlphaBlendTargetsEnabled;
    private _alphaBlendFuncParams;
    private _alphaBlendEqParams;
    private _writeMask;
    private _depthStencilFormat;
    private _webgpuDepthStencilFormat;
    private _depthTestEnabled;
    private _depthWriteEnabled;
    private _depthCompare;
    private _stencilEnabled;
    private _stencilFrontCompare;
    private _stencilFrontDepthFailOp;
    private _stencilFrontPassOp;
    private _stencilFrontFailOp;
    private _stencilBackCompare;
    private _stencilBackDepthFailOp;
    private _stencilBackPassOp;
    private _stencilBackFailOp;
    private _stencilReadMask;
    private _stencilWriteMask;
    private _depthStencilState;
    private _vertexBuffers;
    private _overrideVertexBuffers;
    private _textureState;
    private _useTextureStage;
    constructor(device: GPUDevice, emptyVertexBuffer: VertexBuffer);
    reset(): void;
    protected abstract _getRenderPipeline(param: {
        token: any;
        pipeline: Nullable<GPURenderPipeline>;
    }): void;
    protected abstract _setRenderPipeline(param: {
        token: any;
        pipeline: Nullable<GPURenderPipeline>;
    }): void;
    readonly vertexBuffers: VertexBuffer[];
    readonly indexBuffer: Nullable<DataBuffer>;
    get colorFormats(): (GPUTextureFormat | null)[];
    readonly mrtAttachments: number[];
    readonly mrtTextureArray: InternalTexture[];
    readonly mrtTextureCount: number;
    getRenderPipeline(fillMode: number, effect: Effect, sampleCount: number, textureState?: number): GPURenderPipeline;
    endFrame(): void;
    setAlphaToCoverage(enabled: boolean): void;
    setFrontFace(frontFace: number): void;
    setCullEnabled(enabled: boolean): void;
    setCullFace(cullFace: number): void;
    setClampDepth(clampDepth: boolean): void;
    resetDepthCullingState(): void;
    setDepthCullingState(cullEnabled: boolean, frontFace: number, cullFace: number, zOffset: number, zOffsetUnits: number, depthTestEnabled: boolean, depthWriteEnabled: boolean, depthCompare: Nullable<number>): void;
    setDepthBias(depthBias: number): void;
    setDepthBiasSlopeScale(depthBiasSlopeScale: number): void;
    setColorFormat(format: GPUTextureFormat | null): void;
    setMRTAttachments(attachments: number[]): void;
    setMRT(textureArray: InternalTexture[], textureCount?: number): void;
    setAlphaBlendEnabled(enabled: boolean[], numAlphaBlendTargetsEnabled: number): void;
    setAlphaBlendFactors(factors: Array<Nullable<number>>, operations: Array<Nullable<number>>): void;
    setWriteMask(mask: number): void;
    setDepthStencilFormat(format: GPUTextureFormat | undefined): void;
    setDepthTestEnabled(enabled: boolean): void;
    setDepthWriteEnabled(enabled: boolean): void;
    setDepthCompare(func: Nullable<number>): void;
    setStencilEnabled(enabled: boolean): void;
    setStencilCompare(func: Nullable<number>): void;
    setStencilDepthFailOp(op: Nullable<number>): void;
    setStencilPassOp(op: Nullable<number>): void;
    setStencilFailOp(op: Nullable<number>): void;
    setStencilBackCompare(func: Nullable<number>): void;
    setStencilBackDepthFailOp(op: Nullable<number>): void;
    setStencilBackPassOp(op: Nullable<number>): void;
    setStencilBackFailOp(op: Nullable<number>): void;
    setStencilReadMask(mask: number): void;
    setStencilWriteMask(mask: number): void;
    resetStencilState(): void;
    setStencilState(stencilEnabled: boolean, compare: Nullable<number>, depthFailOp: Nullable<number>, passOp: Nullable<number>, failOp: Nullable<number>, readMask: number, writeMask: number, backCompare?: Nullable<number>, backDepthFailOp?: Nullable<number>, backPassOp?: Nullable<number>, backFailOp?: Nullable<number>): void;
    setBuffers(vertexBuffers: Nullable<{
        [key: string]: Nullable<VertexBuffer>;
    }>, indexBuffer: Nullable<DataBuffer>, overrideVertexBuffers: Nullable<{
        [key: string]: Nullable<VertexBuffer>;
    }>): void;
    private static _GetTopology;
    private static _GetAphaBlendOperation;
    private static _GetAphaBlendFactor;
    private static _GetCompareFunction;
    private static _GetStencilOpFunction;
    private static _GetVertexInputDescriptorFormat;
    private _getAphaBlendState;
    private _getColorBlendState;
    private _setShaderStage;
    private _setRasterizationState;
    private _setColorStates;
    private _setDepthStencilState;
    private _setVertexState;
    private _setTextureState;
    private _createPipelineLayout;
    private _createPipelineLayoutWithTextureStage;
    private _getVertexInputDescriptor;
    private _createRenderPipeline;
}

/** @internal */
declare class WebGPUDataBuffer extends DataBuffer {
    private _buffer;
    engineId: number;
    set buffer(buffer: Nullable<GPUBuffer>);
    constructor(resource?: GPUBuffer, capacity?: number);
    get underlyingResource(): any;
}

/** @internal */
declare class WebGPUBufferManager {
    private _engine;
    private _device;
    private _deferredReleaseBuffers;
    private static _IsGPUBuffer;
    private static _FlagsToString;
    constructor(engine: WebGPUEngine, device: GPUDevice);
    createRawBuffer(viewOrSize: ArrayBufferView | number, flags: GPUBufferUsageFlags, mappedAtCreation?: boolean, label?: string): GPUBuffer;
    createBuffer(viewOrSize: ArrayBufferView | number, flags: GPUBufferUsageFlags, label?: string): WebGPUDataBuffer;
    setRawData(buffer: GPUBuffer, dstByteOffset: number, src: ArrayBufferView, srcByteOffset: number, byteLength: number): void;
    setSubData(dataBuffer: WebGPUDataBuffer, dstByteOffset: number, src: ArrayBufferView, srcByteOffset?: number, byteLength?: number): void;
    private _getHalfFloatAsFloatRGBAArrayBuffer;
    readDataFromBuffer(gpuBuffer: GPUBuffer, size: number, width: number, height: number, bytesPerRow: number, bytesPerRowAligned: number, type?: number, offset?: number, buffer?: Nullable<ArrayBufferView>, destroyBuffer?: boolean, noDataConversion?: boolean): Promise<ArrayBufferView>;
    releaseBuffer(buffer: DataBuffer | GPUBuffer): boolean;
    destroyDeferredBuffers(): void;
}

/** @internal */
declare class WebGPUHardwareTexture implements IHardwareTextureWrapper {
    private _engine;
    /**
     * Cache of RenderPassDescriptor and BindGroup used when generating mipmaps (see WebGPUTextureHelper.generateMipmaps)
     * @internal
     */
    _mipmapGenRenderPassDescr: GPURenderPassDescriptor[][];
    /** @internal */
    _mipmapGenBindGroup: GPUBindGroup[][];
    /**
     * Cache for the invertYPreMultiplyAlpha function (see WebGPUTextureHelper)
     * @internal
     */
    _copyInvertYTempTexture?: GPUTexture;
    /** @internal */
    _copyInvertYRenderPassDescr: GPURenderPassDescriptor;
    /** @internal */
    _copyInvertYBindGroup: GPUBindGroup;
    /** @internal */
    _copyInvertYBindGroupWithOfst: GPUBindGroup;
    /** @internal */
    _originalFormatIsRGB: boolean;
    private _webgpuTexture;
    private _webgpuMSAATexture;
    get underlyingResource(): Nullable<GPUTexture>;
    getMSAATexture(sampleCount: number, index?: number): GPUTexture;
    releaseMSAATextures(): void;
    view: Nullable<GPUTextureView>;
    viewForWriting: Nullable<GPUTextureView>;
    format: GPUTextureFormat;
    originalFormat: GPUTextureFormat;
    textureUsages: number;
    textureAdditionalUsages: number;
    constructor(_engine: WebGPUEngine, existingTexture?: Nullable<GPUTexture>);
    set(hardwareTexture: GPUTexture): void;
    setUsage(_textureSource: number, generateMipMaps: boolean, is2DArray: boolean, isCube: boolean, is3D: boolean, width: number, height: number, depth: number): void;
    createView(descriptor?: GPUTextureViewDescriptor, createViewForWriting?: boolean): void;
    reset(): void;
    release(): void;
    private _createMSAATexture;
}

/**
 * Class used to store an external texture (like GPUExternalTexture in WebGPU)
 */
declare class ExternalTexture {
    /**
     * Checks if a texture is an external or internal texture
     * @param texture the external or internal texture
     * @returns true if the texture is an external texture, else false
     */
    static IsExternalTexture(texture: ExternalTexture | InternalTexture): texture is ExternalTexture;
    private _video;
    /**
     * Get the class name of the texture.
     * @returns "ExternalTexture"
     */
    getClassName(): string;
    /**
     * Gets the underlying texture object
     */
    get underlyingResource(): any;
    /**
     * Gets a boolean indicating if the texture uses mipmaps
     */
    useMipMaps: boolean;
    /**
     * The type of the underlying texture is implementation dependent, so return "UNDEFINED" for the type
     */
    readonly type = 16;
    /**
     * The format of the underlying texture is implementation dependent, so return "UNDEFINED" for the format
     */
    readonly format = 4294967295;
    /**
     * Gets the unique id of this texture
     */
    readonly uniqueId: number;
    /**
     * Constructs the texture
     * @param video The video the texture should be wrapped around
     */
    constructor(video: HTMLVideoElement);
    /**
     * Get if the texture is ready to be used (downloaded, converted, mip mapped...).
     * @returns true if fully ready
     */
    isReady(): boolean;
    /**
     * Dispose the texture and release its associated resources.
     */
    dispose(): void;
}

/** @internal */
declare class WebGPUTextureManager {
    private _engine;
    private _device;
    private _bufferManager;
    private _mipmapSampler;
    private _videoSampler;
    private _ubCopyWithOfst;
    private _pipelines;
    private _compiledShaders;
    private _videoPipelines;
    private _videoCompiledShaders;
    private _deferredReleaseTextures;
    private _commandEncoderForCreation;
    constructor(engine: WebGPUEngine, device: GPUDevice, bufferManager: WebGPUBufferManager, enabledExtensions: GPUFeatureName[]);
    private _getPipeline;
    private _getVideoPipeline;
    setCommandEncoder(encoder: GPUCommandEncoder): void;
    copyVideoToTexture(video: ExternalTexture, texture: InternalTexture, format: GPUTextureFormat, invertY?: boolean, commandEncoder?: GPUCommandEncoder): void;
    invertYPreMultiplyAlpha(gpuOrHdwTexture: GPUTexture | WebGPUHardwareTexture, width: number, height: number, format: GPUTextureFormat, invertY?: boolean, premultiplyAlpha?: boolean, faceIndex?: number, mipLevel?: number, layers?: number, ofstX?: number, ofstY?: number, rectWidth?: number, rectHeight?: number, commandEncoder?: GPUCommandEncoder, allowGPUOptimization?: boolean): void;
    createTexture(imageBitmap: ImageBitmap | {
        width: number;
        height: number;
        layers: number;
    }, hasMipmaps?: boolean, generateMipmaps?: boolean, invertY?: boolean, premultiplyAlpha?: boolean, is3D?: boolean, format?: GPUTextureFormat, sampleCount?: number, commandEncoder?: GPUCommandEncoder, usage?: number, additionalUsages?: number, label?: string, mipLevelCount?: number): GPUTexture;
    createCubeTexture(imageBitmaps: ImageBitmap[] | {
        width: number;
        height: number;
        layers: number;
    }, hasMipmaps?: boolean, generateMipmaps?: boolean, invertY?: boolean, premultiplyAlpha?: boolean, format?: GPUTextureFormat, sampleCount?: number, commandEncoder?: GPUCommandEncoder, usage?: number, additionalUsages?: number, label?: string): GPUTexture;
    generateCubeMipmaps(gpuOrHdwTexture: GPUTexture | WebGPUHardwareTexture, mipLevelCount: number, commandEncoder?: GPUCommandEncoder): void;
    generateMipmaps(gpuOrHdwTexture: GPUTexture | WebGPUHardwareTexture, mipLevelCount: number, faceIndex?: number, commandEncoder?: GPUCommandEncoder): void;
    createGPUTextureForInternalTexture(texture: InternalTexture, width?: number, height?: number, depth?: number, creationFlags?: number): WebGPUHardwareTexture;
    createMSAATexture(gpuTexture: GPUTexture, format: GPUTextureFormat, samples: number): GPUTexture;
    resolveMSAADepthTexture(msaaTexture: GPUTexture, outputTexture: GPUTexture, commandEncoder?: GPUCommandEncoder): void;
    updateCubeTextures(imageBitmaps: ImageBitmap[] | Uint8Array[], gpuTexture: GPUTexture, width: number, height: number, format: GPUTextureFormat, invertY?: boolean, premultiplyAlpha?: boolean, offsetX?: number, offsetY?: number): void;
    updateTexture(imageBitmap: ImageBitmap | Uint8Array | ImageData | HTMLImageElement | HTMLVideoElement | VideoFrame | HTMLCanvasElement | OffscreenCanvas, texture: GPUTexture | InternalTexture, width: number, height: number, layers: number, format: GPUTextureFormat, faceIndex?: number, mipLevel?: number, invertY?: boolean, premultiplyAlpha?: boolean, offsetX?: number, offsetY?: number, allowGPUOptimization?: boolean): void;
    updateMipLevelCountForInternalTexture(texture: InternalTexture, mipLevelCount?: number): void;
    readPixels(texture: GPUTexture, x: number, y: number, width: number, height: number, format: GPUTextureFormat, faceIndex?: number, mipLevel?: number, buffer?: Nullable<ArrayBufferView>, noDataConversion?: boolean): Promise<ArrayBufferView>;
    releaseTexture(texture: InternalTexture | GPUTexture): void;
    destroyDeferredTextures(): void;
}

/**
 * Class used to define a WebGPU performance counter
 */
declare class WebGPUPerfCounter {
    private _gpuTimeInFrameId;
    /**
     * The GPU time in nanoseconds spent in the last frame
     */
    counter: PerfCounter;
    /**
     * @internal
     */
    _addDuration(currentFrameId: number, duration: number): void;
}

/** @internal */
interface IWebGPURenderItem {
    run(renderPass: GPURenderPassEncoder): void;
    clone(): IWebGPURenderItem;
}
/** @internal */
declare class WebGPUBundleList {
    private _device;
    private _bundleEncoder;
    private _list;
    private _listLength;
    private _currentItemIsBundle;
    private _currentBundleList;
    numDrawCalls: number;
    constructor(device: GPUDevice);
    addBundle(bundle?: GPURenderBundle): void;
    private _finishBundle;
    addItem(item: IWebGPURenderItem): void;
    getBundleEncoder(colorFormats: (GPUTextureFormat | null)[], depthStencilFormat: GPUTextureFormat | undefined, sampleCount: number): GPURenderBundleEncoder;
    close(): void;
    run(renderPass: GPURenderPassEncoder): void;
    reset(): void;
    clone(): WebGPUBundleList;
}

/** @internal */
declare class WebGPUSnapshotRendering {
    private _engine;
    private _record;
    private _play;
    private _playBundleListIndex;
    private _allBundleLists;
    private _modeSaved;
    private _bundleList;
    private _enabled;
    private _mode;
    constructor(engine: WebGPUEngine, renderingMode: number, bundleList: WebGPUBundleList);
    showDebugLogs: boolean;
    get enabled(): boolean;
    get play(): boolean;
    get record(): boolean;
    set enabled(activate: boolean);
    get mode(): number;
    set mode(mode: number);
    endRenderPass(currentRenderPass: GPURenderPassEncoder): boolean;
    endFrame(): void;
    reset(): void;
    private _log;
}

/** @internal */
declare class WebGPUTimestampQuery {
    private _engine;
    private _device;
    private _bufferManager;
    private _enabled;
    private _gpuFrameTimeCounter;
    private _measureDuration;
    private _measureDurationState;
    get gpuFrameTimeCounter(): PerfCounter;
    constructor(engine: WebGPUEngine, device: GPUDevice, bufferManager: WebGPUBufferManager);
    get enable(): boolean;
    set enable(value: boolean);
    startFrame(commandEncoder: GPUCommandEncoder): void;
    endFrame(commandEncoder: GPUCommandEncoder): void;
    startPass(descriptor: GPURenderPassDescriptor | GPUComputePassDescriptor, index: number): void;
    endPass(index: number, gpuPerfCounter?: WebGPUPerfCounter): void;
    dispose(): void;
}

/** @internal */
declare class WebGPUOcclusionQuery {
    private _engine;
    private _device;
    private _bufferManager;
    private _currentTotalIndices;
    private _countIncrement;
    private _querySet;
    private _availableIndices;
    private _lastBuffer;
    private _frameLastBuffer;
    private _frameQuerySetIsDirty;
    private _queryFrameId;
    get querySet(): GPUQuerySet;
    get hasQueries(): boolean;
    canBeginQuery(index: number): boolean;
    constructor(engine: WebGPUEngine, device: GPUDevice, bufferManager: WebGPUBufferManager, startCount?: number, incrementCount?: number);
    createQuery(): number;
    deleteQuery(index: number): void;
    isQueryResultAvailable(index: number): boolean;
    getQueryResult(index: number): number;
    private _retrieveQueryBuffer;
    private _allocateNewIndices;
    private _delayQuerySetDispose;
    dispose(): void;
}

/**
 * The base engine class for WebGPU
 */
declare abstract class ThinWebGPUEngine extends AbstractEngine {
    /** @internal */
    dbgShowShaderCode: boolean;
    /** @internal */
    dbgSanityChecks: boolean;
    /** @internal */
    dbgVerboseLogsNumFrames: number;
    /** @internal */
    dbgLogIfNotDrawWrapper: boolean;
    /** @internal */
    dbgShowEmptyEnableEffectCalls: boolean;
    /** @internal */
    dbgVerboseLogsForFirstFrames: boolean;
    /** @internal */
    _textureHelper: WebGPUTextureManager;
    /** @internal */
    _cacheRenderPipeline: WebGPUCacheRenderPipeline;
    /** @internal */
    _occlusionQuery: WebGPUOcclusionQuery;
    /** @internal */
    _renderEncoder: GPUCommandEncoder;
    /** @internal */
    _uploadEncoder: GPUCommandEncoder;
    /** @internal */
    _currentRenderPass: Nullable<GPURenderPassEncoder>;
    protected _snapshotRendering: WebGPUSnapshotRendering;
    protected _snapshotRenderingMode: number;
    /** @internal */
    _timestampQuery: WebGPUTimestampQuery;
    /** @internal */
    _timestampIndex: number;
    /**
     * Gets the GPU time spent in the main render pass for the last frame rendered (in nanoseconds).
     * You have to enable the "timestamp-query" extension in the engine constructor options and set engine.enableGPUTimingMeasurements = true.
     * It will only return time spent in the main pass, not additional render target / compute passes (if any)!
     */
    readonly gpuTimeInFrameForMainPass?: WebGPUPerfCounter;
    /**
     * Used for both the compatibilityMode=false and the snapshot rendering modes (as both can't be enabled at the same time)
     * @internal
     */
    _bundleList: WebGPUBundleList;
    /**
     * Enables or disables GPU timing measurements.
     * Note that this is only supported if the "timestamp-query" extension is enabled in the options.
     */
    get enableGPUTimingMeasurements(): boolean;
    set enableGPUTimingMeasurements(enable: boolean);
    protected _currentPassIsMainPass(): boolean;
    /** @internal */
    _endCurrentRenderPass(): number;
    /**
     * @internal
     */
    _generateMipmaps(texture: InternalTexture, commandEncoder?: GPUCommandEncoder): void;
}

/** @internal */
declare class WebGPUCacheSampler {
    private _samplers;
    private _device;
    disabled: boolean;
    constructor(device: GPUDevice);
    static GetSamplerHashCode(sampler: TextureSampler): number;
    private static _GetSamplerFilterDescriptor;
    private static _GetWrappingMode;
    private static _GetSamplerWrappingDescriptor;
    private static _GetSamplerDescriptor;
    static GetCompareFunction(compareFunction: Nullable<number>): GPUCompareFunction;
    getSampler(sampler: TextureSampler, bypassCache?: boolean, hash?: number, label?: string): GPUSampler;
}

/** @internal */
interface IWebGPUMaterialContextSamplerCache {
    sampler: Nullable<TextureSampler>;
    hashCode: number;
}
/** @internal */
interface IWebGPUMaterialContextTextureCache {
    texture: Nullable<InternalTexture | ExternalTexture>;
    isFloatOrDepthTexture: boolean;
    isExternalTexture: boolean;
}
/** @internal */
declare class WebGPUMaterialContext implements IMaterialContext {
    private static _Counter;
    uniqueId: number;
    updateId: number;
    isDirty: boolean;
    samplers: {
        [name: string]: Nullable<IWebGPUMaterialContextSamplerCache>;
    };
    textures: {
        [name: string]: Nullable<IWebGPUMaterialContextTextureCache>;
    };
    textureState: number;
    useVertexPulling: boolean;
    get forceBindGroupCreation(): boolean;
    get hasFloatOrDepthTextures(): boolean;
    protected _numFloatOrDepthTextures: number;
    protected _numExternalTextures: number;
    constructor();
    reset(): void;
    setSampler(name: string, sampler: Nullable<TextureSampler>): void;
    setTexture(name: string, texture: Nullable<InternalTexture | ExternalTexture>): void;
}

/** @internal */
interface WebGPUBindingInfo {
    groupIndex: number;
    bindingIndex: number;
}
/** @internal */
interface WebGPUTextureDescription {
    autoBindSampler?: boolean;
    isTextureArray: boolean;
    isStorageTexture: boolean;
    textures: Array<WebGPUBindingInfo>;
    sampleType?: GPUTextureSampleType;
}
/** @internal */
interface WebGPUSamplerDescription {
    binding: WebGPUBindingInfo;
    type: GPUSamplerBindingType;
}
/** @internal */
interface WebGPUBufferDescription {
    binding: WebGPUBindingInfo;
}
/** @internal */
interface WebGPUBindGroupLayoutEntryInfo {
    name: string;
    index: number;
    nameInArrayOfTexture?: string;
}
/**
 * @internal
 */
declare class WebGPUShaderProcessingContext implements _IShaderProcessingContext {
    /** @internal */
    static _SimplifiedKnownBindings: boolean;
    protected static _SimplifiedKnownUBOs: {
        [key: string]: WebGPUBufferDescription;
    };
    protected static _KnownUBOs: {
        [key: string]: WebGPUBufferDescription;
    };
    static get KnownUBOs(): {
        [key: string]: WebGPUBufferDescription;
    };
    shaderLanguage: ShaderLanguage;
    uboNextBindingIndex: number;
    freeGroupIndex: number;
    freeBindingIndex: number;
    availableVaryings: {
        [key: string]: number;
    };
    availableAttributes: {
        [key: string]: number;
    };
    availableBuffers: {
        [key: string]: WebGPUBufferDescription;
    };
    availableTextures: {
        [key: string]: WebGPUTextureDescription;
    };
    availableSamplers: {
        [key: string]: WebGPUSamplerDescription;
    };
    leftOverUniforms: {
        name: string;
        type: string;
        length: number;
    }[];
    orderedAttributes: string[];
    bindGroupLayoutEntries: GPUBindGroupLayoutEntry[][];
    bindGroupLayoutEntryInfo: WebGPUBindGroupLayoutEntryInfo[][];
    bindGroupEntries: GPUBindGroupEntry[][];
    bufferNames: string[];
    textureNames: string[];
    samplerNames: string[];
    attributeNamesFromEffect: string[];
    attributeLocationsFromEffect: number[];
    vertexBufferKindToNumberOfComponents: {
        [kind: string]: number;
    };
    private _attributeNextLocation;
    private _varyingNextLocation;
    constructor(shaderLanguage: ShaderLanguage, pureMode?: boolean);
    private _findStartingGroupBinding;
    getAttributeNextLocation(dataType: string, arrayLength?: number): number;
    getVaryingNextLocation(dataType: string, arrayLength?: number): number;
    getNextFreeUBOBinding(): {
        groupIndex: number;
        bindingIndex: number;
    };
    private _getNextFreeBinding;
}

/** @internal */
interface IWebGPURenderPipelineStageDescriptor {
    vertexStage: GPUProgrammableStage;
    fragmentStage?: GPUProgrammableStage;
}
/** @internal */
declare class WebGPUPipelineContext implements IPipelineContext {
    engine: WebGPUEngine;
    shaderProcessingContext: WebGPUShaderProcessingContext;
    protected _leftOverUniformsByName: {
        [name: string]: string;
    };
    vertexBufferKindToType: {
        [kind: string]: number;
    };
    sources: {
        vertex: string;
        fragment: string;
        rawVertex: string;
        rawFragment: string;
    };
    stages: Nullable<IWebGPURenderPipelineStageDescriptor>;
    bindGroupLayouts: {
        [textureState: number]: GPUBindGroupLayout[];
    };
    /**
     * Stores the left-over uniform buffer
     */
    uniformBuffer: Nullable<UniformBuffer>;
    onCompiled?: () => void;
    get isAsync(): boolean;
    get isReady(): boolean;
    /** @internal */
    _name: string;
    constructor(shaderProcessingContext: WebGPUShaderProcessingContext, engine: WebGPUEngine);
    _handlesSpectorRebuildCallback(): void;
    _fillEffectInformation(effect: Effect, uniformBuffersNames: {
        [key: string]: number;
    }, uniformsNames: string[], uniforms: {
        [key: string]: Nullable<WebGLUniformLocation>;
    }, samplerList: string[], samplers: {
        [key: string]: number;
    }, attributesNames: string[], attributes: number[]): void;
    /** @internal */
    /**
     * Build the uniform buffer used in the material.
     */
    buildUniformLayout(): void;
    setEngine(engine: AbstractEngine): void;
    /**
     * Release all associated resources.
     **/
    dispose(): void;
    /**
     * Sets an integer value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value Value to be set.
     */
    setInt(uniformName: string, value: number): void;
    /**
     * Sets an int2 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int2.
     * @param y Second int in int2.
     */
    setInt2(uniformName: string, x: number, y: number): void;
    /**
     * Sets an int3 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int3.
     * @param y Second int in int3.
     * @param z Third int in int3.
     */
    setInt3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets an int4 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int4.
     * @param y Second int in int4.
     * @param z Third int in int4.
     * @param w Fourth int in int4.
     */
    setInt4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets an int array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray2(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray3(uniformName: string, array: Int32Array): void;
    /**
     * Sets an int array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setIntArray4(uniformName: string, array: Int32Array): void;
    /**
     * Sets an unsigned integer value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value Value to be set.
     */
    setUInt(uniformName: string, value: number): void;
    /**
     * Sets an unsigned int2 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint2.
     * @param y Second unsigned int in uint2.
     */
    setUInt2(uniformName: string, x: number, y: number): void;
    /**
     * Sets an unsigned int3 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint3.
     * @param y Second unsigned int in uint3.
     * @param z Third unsigned int in uint3.
     */
    setUInt3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets an unsigned int4 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint4.
     * @param y Second unsigned int in uint4.
     * @param z Third unsigned int in uint4.
     * @param w Fourth unsigned int in uint4.
     */
    setUInt4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets an unsigned int array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray2(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray3(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an unsigned int array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setUIntArray4(uniformName: string, array: Uint32Array): void;
    /**
     * Sets an array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray(uniformName: string, array: number[]): void;
    /**
     * Sets an array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray2(uniformName: string, array: number[]): void;
    /**
     * Sets an array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray3(uniformName: string, array: number[]): void;
    /**
     * Sets an array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     */
    setArray4(uniformName: string, array: number[]): void;
    /**
     * Sets matrices on a uniform variable.
     * @param uniformName Name of the variable.
     * @param matrices matrices to be set.
     */
    setMatrices(uniformName: string, matrices: Float32Array): void;
    /**
     * Sets matrix on a uniform variable.
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix(uniformName: string, matrix: IMatrixLike): void;
    /**
     * Sets a 3x3 matrix on a uniform variable. (Specified as [1,2,3,4,5,6,7,8,9] will result in [1,2,3][4,5,6][7,8,9] matrix)
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix3x3(uniformName: string, matrix: Float32Array): void;
    /**
     * Sets a 2x2 matrix on a uniform variable. (Specified as [1,2,3,4] will result in [1,2][3,4] matrix)
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     */
    setMatrix2x2(uniformName: string, matrix: Float32Array): void;
    /**
     * Sets a float on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value value to be set.
     */
    setFloat(uniformName: string, value: number): void;
    /**
     * Sets a Vector2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector2 vector2 to be set.
     */
    setVector2(uniformName: string, vector2: IVector2Like): void;
    /**
     * Sets a float2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float2.
     * @param y Second float in float2.
     */
    setFloat2(uniformName: string, x: number, y: number): void;
    /**
     * Sets a Vector3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector3 Value to be set.
     */
    setVector3(uniformName: string, vector3: IVector3Like): void;
    /**
     * Sets a float3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float3.
     * @param y Second float in float3.
     * @param z Third float in float3.
     */
    setFloat3(uniformName: string, x: number, y: number, z: number): void;
    /**
     * Sets a Vector4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector4 Value to be set.
     */
    setVector4(uniformName: string, vector4: IVector4Like): void;
    /**
     * Sets a Quaternion on a uniform variable.
     * @param uniformName Name of the variable.
     * @param quaternion Value to be set.
     */
    setQuaternion(uniformName: string, quaternion: IQuaternionLike): void;
    /**
     * Sets a float4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float4.
     * @param y Second float in float4.
     * @param z Third float in float4.
     * @param w Fourth float in float4.
     */
    setFloat4(uniformName: string, x: number, y: number, z: number, w: number): void;
    /**
     * Sets a Color3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param color3 Value to be set.
     */
    setColor3(uniformName: string, color3: IColor3Like): void;
    /**
     * Sets a Color4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param color3 Value to be set.
     * @param alpha Alpha value to be set.
     */
    setColor4(uniformName: string, color3: IColor3Like, alpha: number): void;
    /**
     * Sets a Color4 on a uniform variable
     * @param uniformName defines the name of the variable
     * @param color4 defines the value to be set
     */
    setDirectColor4(uniformName: string, color4: IColor4Like): void;
    _getVertexShaderCode(): string | null;
    _getFragmentShaderCode(): string | null;
}

/**
 * WebGPU implementation of the IDrawContext interface.
 * This class manages the draw context for WebGPU, including buffers and indirect draw data.
 */
declare class WebGPUDrawContext implements IDrawContext {
    private _dummyIndexBuffer;
    private static _Counter;
    /**
     * Bundle used in fast mode (when compatibilityMode==false)
     */
    fastBundle?: GPURenderBundle;
    /**
     * Cache of the bind groups. Will be reused for the next draw if isDirty==false (and materialContext.isDirty==false)
     */
    bindGroups?: GPUBindGroup[];
    uniqueId: number;
    /**
     * @internal
     * By default, indirect draws are enabled in NON compatibility mode only
     * To enable indirect draws in compatibility mode (done by the end user), enableIndirectDraw must be set to true
     */
    _enableIndirectDrawInCompatMode: boolean;
    /**
     * Buffers (uniform / storage) used for the draw call
     */
    buffers: {
        [name: string]: Nullable<WebGPUDataBuffer>;
    };
    indirectDrawBuffer?: GPUBuffer;
    private _materialContextUpdateId;
    private _bufferManager;
    private _useInstancing;
    private _indirectDrawData?;
    private _currentInstanceCount;
    private _isDirty;
    private _enableIndirectDraw;
    private _vertexPullingEnabled;
    /**
     * Checks if the draw context is dirty.
     * @param materialContextUpdateId The update ID of the material context associated with the draw context.
     * @returns True if the draw or material context is dirty, false otherwise.
     */
    isDirty(materialContextUpdateId: number): boolean;
    /**
     * Resets the dirty state of the draw context.
     * @param materialContextUpdateId The update ID of the material context associated with the draw context.
     */
    resetIsDirty(materialContextUpdateId: number): void;
    get enableIndirectDraw(): boolean;
    set enableIndirectDraw(enable: boolean);
    get useInstancing(): boolean;
    set useInstancing(use: boolean);
    /**
     * Creates a new WebGPUDrawContext.
     * @param bufferManager The buffer manager used to manage WebGPU buffers.
     * @param _dummyIndexBuffer A dummy index buffer to be bound as the "indices"
     * storage buffer when no index buffer is provided.
     */
    constructor(bufferManager: WebGPUBufferManager, _dummyIndexBuffer: WebGPUDataBuffer);
    reset(): void;
    /**
     * Associates a buffer to the draw context.
     * @param name The name of the buffer.
     * @param buffer The buffer to set.
     */
    setBuffer(name: string, buffer: Nullable<WebGPUDataBuffer>): void;
    setIndirectData(indexOrVertexCount: number, instanceCount: number, firstIndexOrVertex: number, forceUpdate?: boolean): void;
    /**
     * Setup or disable vertex pulling as needed.
     * @param useVertexPulling Use vertex pulling or not
     * @param webgpuPipelineContext The WebGPU pipeline context
     * @param vertexBuffers The current vertex buffers
     * @param indexBuffer The current index buffer
     * @param overrideVertexBuffers The vertex buffers to override
     */
    setVertexPulling(useVertexPulling: boolean, webgpuPipelineContext: WebGPUPipelineContext, vertexBuffers: {
        [key: string]: Nullable<VertexBuffer>;
    }, indexBuffer: Nullable<DataBuffer>, overrideVertexBuffers: Nullable<{
        [kind: string]: Nullable<VertexBuffer>;
    }>): void;
    dispose(): void;
}

/**
 * Class used to store and describe the pipeline context associated with a compute effect
 */
interface IComputePipelineContext {
    /**
     * Gets a boolean indicating that this pipeline context is supporting asynchronous creating
     */
    isAsync: boolean;
    /**
     * Gets a boolean indicating that the context is ready to be used (like shader / pipeline are compiled and ready for instance)
     */
    isReady: boolean;
    /** @internal */
    _name?: string;
    /** @internal */
    _getComputeShaderCode(): string | null;
    /** Releases the resources associated with the pipeline. */
    dispose(): void;
}

/**
 * Defines the route to the shader code. The priority is as follows:
 *  * object: `{ computeSource: "compute shader code string"}` for directly passing the shader code
 *  * object: `{ computeElement: "vertexShaderCode" }`, used with shader code in script tags
 *  * object: `{ compute: "custom" }`, used with `Effect.ShadersStore["customVertexShader"]` and `Effect.ShadersStore["customFragmentShader"]`
 *  * string: `"./COMMON_NAME"`, used with external files COMMON_NAME.vertex.fx and COMMON_NAME.fragment.fx in index.html folder.
 */
type IComputeShaderPath = {
    /**
     * Directly pass the shader code
     */
    computeSource?: string;
    /**
     * Used with Effect.ShadersStore. If the `vertex` is set to `"custom`, then
     * Babylon.js will read from Effect.ShadersStore["customVertexShader"]
     */
    compute?: string;
    /**
     * Used with shader code in script tags
     */
    computeElement?: string;
};
/**
 * Options to be used when creating a compute effect.
 */
interface IComputeEffectCreationOptions {
    /**
     * Define statements that will be set in the shader.
     */
    defines: any;
    /**
     * The name of the entry point in the shader source (default: "main")
     */
    entryPoint?: string;
    /**
     * Callback that will be called when the shader is compiled.
     */
    onCompiled: Nullable<(effect: ComputeEffect) => void>;
    /**
     * Callback that will be called if an error occurs during shader compilation.
     */
    onError: Nullable<(effect: ComputeEffect, errors: string) => void>;
    /**
     * If provided, will be called with the shader code so that this code can be updated before it is compiled by the GPU
     */
    processFinalCode?: Nullable<(code: string) => string>;
}
/**
 * Effect wrapping a compute shader and let execute (dispatch) the shader
 */
declare class ComputeEffect {
    private static _UniqueIdSeed;
    /**
     * Enable logging of the shader code when a compilation error occurs
     */
    static LogShaderCodeOnCompilationError: boolean;
    /**
     * Name of the effect.
     */
    name: IComputeShaderPath | string;
    /**
     * String container all the define statements that should be set on the shader.
     */
    defines: string;
    /**
     * Callback that will be called when the shader is compiled.
     */
    onCompiled: Nullable<(effect: ComputeEffect) => void>;
    /**
     * Callback that will be called if an error occurs during shader compilation.
     */
    onError: Nullable<(effect: ComputeEffect, errors: string) => void>;
    /**
     * Unique ID of the effect.
     */
    uniqueId: number;
    /**
     * Observable that will be called when the shader is compiled.
     * It is recommended to use executeWhenCompile() or to make sure that scene.isReady() is called to get this observable raised.
     */
    onCompileObservable: Observable<ComputeEffect>;
    /**
     * Observable that will be called if an error occurs during shader compilation.
     */
    onErrorObservable: Observable<ComputeEffect>;
    /**
     * Observable that will be called when effect is bound.
     */
    onBindObservable: Observable<ComputeEffect>;
    /**
     * @internal
     * Specifies if the effect was previously ready
     */
    _wasPreviouslyReady: boolean;
    private _engine;
    private _isReady;
    private _compilationError;
    /** @internal */
    _key: string;
    private _computeSourceCodeOverride;
    /** @internal */
    _pipelineContext: Nullable<IComputePipelineContext>;
    /** @internal */
    _computeSourceCode: string;
    private _rawComputeSourceCode;
    private _entryPoint;
    private _shaderLanguage;
    private _shaderStore;
    private _shaderRepository;
    private _includeShaderStore;
    /**
     * Creates a compute effect that can be used to execute a compute shader
     * @param baseName Name of the effect
     * @param options Set of all options to create the effect
     * @param engine The engine the effect is created for
     * @param key Effect Key identifying uniquely compiled shader variants
     */
    constructor(baseName: IComputeShaderPath | string, options: IComputeEffectCreationOptions, engine: AbstractEngine, key?: string);
    private _useFinalCode;
    /**
     * Unique key for this effect
     */
    get key(): string;
    /**
     * If the effect has been compiled and prepared.
     * @returns if the effect is compiled and prepared.
     */
    isReady(): boolean;
    private _isReadyInternal;
    /**
     * The engine the effect was initialized with.
     * @returns the engine.
     */
    getEngine(): AbstractEngine;
    /**
     * The pipeline context for this effect
     * @returns the associated pipeline context
     */
    getPipelineContext(): Nullable<IComputePipelineContext>;
    /**
     * The error from the last compilation.
     * @returns the error string.
     */
    getCompilationError(): string;
    /**
     * Adds a callback to the onCompiled observable and call the callback immediately if already ready.
     * @param func The callback to be used.
     */
    executeWhenCompiled(func: (effect: ComputeEffect) => void): void;
    private _checkIsReady;
    private _loadShader;
    /**
     * Gets the compute shader source code of this effect
     */
    get computeSourceCode(): string;
    /**
     * Gets the compute shader source code before it has been processed by the preprocessor
     */
    get rawComputeSourceCode(): string;
    /**
     * Prepares the effect
     * @internal
     */
    _prepareEffect(): void;
    private _processCompilationErrors;
    /**
     * Release all associated resources.
     **/
    dispose(): void;
    /**
     * This function will add a new compute shader to the shader store
     * @param name the name of the shader
     * @param computeShader compute shader content
     */
    static RegisterShader(name: string, computeShader: string): void;
}

/**
 * Options to load the associated Twgsl library
 */
interface TwgslOptions {
    /**
     * Defines an existing instance of Twgsl (useful in modules who do not access the global instance).
     */
    twgsl?: any;
    /**
     * Defines the URL of the twgsl JS File.
     */
    jsPath?: string;
    /**
     * Defines the URL of the twgsl WASM File.
     */
    wasmPath?: string;
}

declare module "./buffer" {
    interface VertexBuffer {
        /**
         * Gets the effective byte stride, that is the byte stride of the buffer that is actually sent to the GPU.
         * It could be different from VertexBuffer.byteStride if a new buffer must be created under the hood because of the forceVertexBufferStrideAndOffsetMultiple4Bytes engine flag.
         */
        effectiveByteStride: number;
        /**
         * Gets the effective byte offset, that is the byte offset of the buffer that is actually sent to the GPU.
         * It could be different from VertexBuffer.byteOffset if a new buffer must be created under the hood because of the forceVertexBufferStrideAndOffsetMultiple4Bytes engine flag.
         */
        effectiveByteOffset: number;
        /**
         * Gets the effective buffer, that is the buffer that is actually sent to the GPU.
         * It could be different from VertexBuffer.getBuffer() if a new buffer must be created under the hood because of the forceVertexBufferStrideAndOffsetMultiple4Bytes engine flag.
         */
        effectiveBuffer: Nullable<DataBuffer>;
        /** @internal */
        _alignBuffer(): void;
        /** @internal */
        _alignedBuffer?: Buffer;
    }
}

/**
 * Class used to work with sound analyzer using fast fourier transform (FFT)
 * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic
 */
declare class Analyser {
    /**
     * Gets or sets the smoothing
     */
    SMOOTHING: number;
    /**
     * Gets or sets the FFT table size
     */
    FFT_SIZE: number;
    /**
     * Gets or sets the bar graph amplitude
     */
    BARGRAPHAMPLITUDE: number;
    /**
     * Gets or sets the position of the debug canvas
     */
    DEBUGCANVASPOS: {
        x: number;
        y: number;
    };
    /**
     * Gets or sets the debug canvas size
     */
    DEBUGCANVASSIZE: {
        width: number;
        height: number;
    };
    private _byteFreqs;
    private _byteTime;
    private _floatFreqs;
    private _webAudioAnalyser;
    private _debugCanvas;
    private _debugCanvasContext;
    private _scene;
    private _registerFunc;
    private _audioEngine;
    /**
     * Creates a new analyser
     * @param scene defines hosting scene
     */
    constructor(scene?: Nullable<Scene>);
    /**
     * Get the number of data values you will have to play with for the visualization
     * @see https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/frequencyBinCount
     * @returns a number
     */
    getFrequencyBinCount(): number;
    /**
     * Gets the current frequency data as a byte array
     * @see https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData
     * @returns a Uint8Array
     */
    getByteFrequencyData(): Uint8Array;
    /**
     * Gets the current waveform as a byte array
     * @see https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteTimeDomainData
     * @returns a Uint8Array
     */
    getByteTimeDomainData(): Uint8Array;
    /**
     * Gets the current frequency data as a float array
     * @see https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData
     * @returns a Float32Array
     */
    getFloatFrequencyData(): Float32Array;
    /**
     * Renders the debug canvas
     */
    drawDebugCanvas(): void;
    /**
     * Stops rendering the debug canvas and removes it
     */
    stopDebugCanvas(): void;
    /**
     * Connects two audio nodes
     * @param inputAudioNode defines first node to connect
     * @param outputAudioNode defines second node to connect
     */
    connectAudioNodes(inputAudioNode: AudioNode, outputAudioNode: AudioNode): void;
    /**
     * Releases all associated resources
     */
    dispose(): void;
}

/**
 * This represents an audio engine and it is responsible
 * to play, synchronize and analyse sounds throughout the application.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic
 */
interface IAudioEngine extends IDisposable {
    /**
     * Gets whether the current host supports Web Audio and thus could create AudioContexts.
     */
    readonly canUseWebAudio: boolean;
    /**
     * Gets the current AudioContext if available.
     */
    readonly audioContext: Nullable<AudioContext>;
    /**
     * The master gain node defines the global audio volume of your audio engine.
     */
    readonly masterGain: GainNode;
    /**
     * Gets whether or not mp3 are supported by your browser.
     */
    readonly isMP3supported: boolean;
    /**
     * Gets whether or not ogg are supported by your browser.
     */
    readonly isOGGsupported: boolean;
    /**
     * Defines if Babylon should emit a warning if WebAudio is not supported.
     * @ignoreNaming
     */
    WarnedWebAudioUnsupported: boolean;
    /**
     * Defines if the audio engine relies on a custom unlocked button.
     * In this case, the embedded button will not be displayed.
     */
    useCustomUnlockedButton: boolean;
    /**
     * Gets whether or not the audio engine is unlocked (require first a user gesture on some browser).
     */
    readonly unlocked: boolean;
    /**
     * Event raised when audio has been unlocked on the browser.
     */
    onAudioUnlockedObservable: Observable<IAudioEngine>;
    /**
     * Event raised when audio has been locked on the browser.
     */
    onAudioLockedObservable: Observable<IAudioEngine>;
    /**
     * Flags the audio engine in Locked state.
     * This happens due to new browser policies preventing audio to autoplay.
     */
    lock(): void;
    /**
     * Unlocks the audio engine once a user action has been done on the dom.
     * This is helpful to resume play once browser policies have been satisfied.
     */
    unlock(): void;
    /**
     * Gets the global volume sets on the master gain.
     * @returns the global volume if set or -1 otherwise
     */
    getGlobalVolume(): number;
    /**
     * Sets the global volume of your experience (sets on the master gain).
     * @param newVolume Defines the new global volume of the application
     */
    setGlobalVolume(newVolume: number): void;
    /**
     * Connect the audio engine to an audio analyser allowing some amazing
     * synchronization between the sounds/music and your visualization (VuMeter for instance).
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#using-the-analyser
     * @param analyser The analyser to connect to the engine
     */
    connectToAnalyser(analyser: Analyser): void;
    /** @internal */
    _resumeAudioContextOnStateChange(): void;
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * Sets the current alpha mode
         * @param mode defines the mode to use (one of the Engine.ALPHA_XXX)
         * @param noDepthWriteChange defines if depth writing state should remains unchanged (false by default)
         * @param targetIndex defines the index of the target to set the alpha mode for (default is 0)
         * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/advanced/transparent_rendering
         */
        setAlphaMode(mode: number, noDepthWriteChange?: boolean, targetIndex?: number): void;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * Update a raw texture
         * @param texture defines the texture to update
         * @param data defines the data to store in the texture
         * @param format defines the format of the data
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateRawTexture(texture: Nullable<InternalTexture>, data: Nullable<ArrayBufferView>, format: number, invertY: boolean): void;
        /**
         * Update a raw texture
         * @param texture defines the texture to update
         * @param data defines the data to store in the texture
         * @param format defines the format of the data
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the compression used (null by default)
         * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
         * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
         * @param mipLevel defines which mipLevel of the texture is going to be updated
         */
        updateRawTexture(texture: Nullable<InternalTexture>, data: Nullable<ArrayBufferView>, format: number, invertY: boolean, compression: Nullable<string>, type: number, useSRGBBuffer: boolean, mipLevel?: number): void;
        /**
         * Creates a new raw cube texture
         * @param data defines the array of data to use to create each face
         * @param size defines the size of the textures
         * @param format defines the format of the data
         * @param type defines the type of the data (like Engine.TEXTURETYPE_UNSIGNED_BYTE)
         * @param generateMipMaps  defines if the engine should generate the mip levels
         * @param invertY defines if data must be stored with Y axis inverted
         * @param samplingMode defines the required sampling mode (like Texture.NEAREST_SAMPLINGMODE)
         * @param compression defines the compression used (null by default)
         * @returns the cube texture as an InternalTexture
         */
        createRawCubeTexture(data: Nullable<ArrayBufferView[]>, size: number, format: number, type: number, generateMipMaps: boolean, invertY: boolean, samplingMode: number, compression: Nullable<string>): InternalTexture;
        /**
         * Update a raw cube texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateRawCubeTexture(texture: InternalTexture, data: ArrayBufferView[], format: number, type: number, invertY: boolean): void;
        /**
         * Update a raw cube texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the compression used (null by default)
         */
        updateRawCubeTexture(texture: InternalTexture, data: ArrayBufferView[], format: number, type: number, invertY: boolean, compression: Nullable<string>): void;
        /**
         * Update a raw cube texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the compression used (null by default)
         * @param level defines which level of the texture to update
         */
        updateRawCubeTexture(texture: InternalTexture, data: ArrayBufferView[], format: number, type: number, invertY: boolean, compression: Nullable<string>, level: number): void;
        /**
         * Creates a new raw cube texture from a specified url
         * @param url defines the url where the data is located
         * @param scene defines the current scene
         * @param size defines the size of the textures
         * @param format defines the format of the data
         * @param type defines the type fo the data (like Engine.TEXTURETYPE_UNSIGNED_BYTE)
         * @param noMipmap defines if the engine should avoid generating the mip levels
         * @param callback defines a callback used to extract texture data from loaded data
         * @param mipmapGenerator defines to provide an optional tool to generate mip levels
         * @param onLoad defines a callback called when texture is loaded
         * @param onError defines a callback called if there is an error
         * @returns the cube texture as an InternalTexture
         */
        createRawCubeTextureFromUrl(url: string, scene: Nullable<Scene>, size: number, format: number, type: number, noMipmap: boolean, callback: (ArrayBuffer: ArrayBuffer) => Nullable<ArrayBufferView[] | Promise<ArrayBufferView[]>>, mipmapGenerator: Nullable<(faces: ArrayBufferView[]) => ArrayBufferView[][]>, onLoad: Nullable<() => void>, onError: Nullable<(message?: string, exception?: any) => void>): InternalTexture;
        /**
         * Creates a new raw cube texture from a specified url
         * @param url defines the url where the data is located
         * @param scene defines the current scene
         * @param size defines the size of the textures
         * @param format defines the format of the data
         * @param type defines the type fo the data (like Engine.TEXTURETYPE_UNSIGNED_BYTE)
         * @param noMipmap defines if the engine should avoid generating the mip levels
         * @param callback defines a callback used to extract texture data from loaded data
         * @param mipmapGenerator defines to provide an optional tool to generate mip levels
         * @param onLoad defines a callback called when texture is loaded
         * @param onError defines a callback called if there is an error
         * @param samplingMode defines the required sampling mode (like Texture.NEAREST_SAMPLINGMODE)
         * @param invertY defines if data must be stored with Y axis inverted
         * @returns the cube texture as an InternalTexture
         */
        createRawCubeTextureFromUrl(url: string, scene: Nullable<Scene>, size: number, format: number, type: number, noMipmap: boolean, callback: (ArrayBuffer: ArrayBuffer) => Nullable<ArrayBufferView[] | Promise<ArrayBufferView[]>>, mipmapGenerator: Nullable<(faces: ArrayBufferView[]) => ArrayBufferView[][]>, onLoad: Nullable<() => void>, onError: Nullable<(message?: string, exception?: any) => void>, samplingMode: number, invertY: boolean): InternalTexture;
        /**
         * Update a raw 3D texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateRawTexture3D(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean): void;
        /**
         * Update a raw 3D texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the used compression (can be null)
         * @param textureType defines the texture Type (Engine.TEXTURETYPE_UNSIGNED_BYTE, Engine.TEXTURETYPE_FLOAT...)
         */
        updateRawTexture3D(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean, compression: Nullable<string>, textureType: number): void;
        /**
         * Update a raw 2D array texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateRawTexture2DArray(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean): void;
        /**
         * Update a raw 2D array texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the used compression (can be null)
         * @param textureType defines the texture Type (Engine.TEXTURETYPE_UNSIGNED_BYTE, Engine.TEXTURETYPE_FLOAT...)
         */
        updateRawTexture2DArray(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean, compression: Nullable<string>, textureType: number): void;
        /**
         * Update a raw 2D array texture
         * @param texture defines the texture to update
         * @param data defines the data to store
         * @param format defines the data format
         * @param invertY defines if data must be stored with Y axis inverted
         * @param compression defines the used compression (can be null)
         * @param textureType defines the texture Type (Engine.TEXTURETYPE_UNSIGNED_BYTE, Engine.TEXTURETYPE_FLOAT...)
         * @param mipLevel defines which mipLevel of the texture is going to be updated
         */
        updateRawTexture2DArray(texture: InternalTexture, data: Nullable<ArrayBufferView>, format: number, invertY: boolean, compression: Nullable<string>, textureType: number, mipLevel?: number): void;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /** @internal */
        _readTexturePixels(texture: InternalTexture, width: number, height: number, faceIndex?: number, level?: number, buffer?: Nullable<ArrayBufferView>, flushRenderer?: boolean, noDataConversion?: boolean, x?: number, y?: number): Promise<ArrayBufferView>;
        /** @internal */
        _readTexturePixelsSync(texture: InternalTexture, width: number, height: number, faceIndex?: number, level?: number, buffer?: Nullable<ArrayBufferView>, flushRenderer?: boolean, noDataConversion?: boolean, x?: number, y?: number): ArrayBufferView;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * @internal
         */
        _setCubeMapTextureParams(texture: InternalTexture, loadMipmap: boolean, maxLevel?: number): void;
        /**
         * Creates a depth stencil cube texture.
         * This is only available in WebGL 2.
         * @param size The size of face edge in the cube texture.
         * @param options The options defining the cube texture.
         * @returns The cube texture
         */
        _createDepthStencilCubeTexture(size: number, options: DepthTextureCreationOptions): InternalTexture;
        /**
         * Creates a cube texture
         * @param rootUrl defines the url where the files to load is located
         * @param scene defines the current scene
         * @param files defines the list of files to load (1 per face)
         * @param noMipmap defines a boolean indicating that no mipmaps shall be generated (false by default)
         * @param onLoad defines an optional callback raised when the texture is loaded
         * @param onError defines an optional callback raised if there is an issue to load the texture
         * @param format defines the format of the data
         * @param forcedExtension defines the extension to use to pick the right loader
         * @param createPolynomials if a polynomial sphere should be created for the cube texture
         * @param lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness
         * @param lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness
         * @param fallback defines texture to use while falling back when (compressed) texture file not found.
         * @param loaderOptions options to be passed to the loader
         * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
         * @param buffer defines the data buffer to load instead of loading the rootUrl
         * @returns the cube texture as an InternalTexture
         */
        createCubeTexture(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean | undefined, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any, createPolynomials: boolean, lodScale: number, lodOffset: number, fallback: Nullable<InternalTexture>, loaderOptions: any, useSRGBBuffer: boolean, buffer: Nullable<ArrayBufferView>): InternalTexture;
        /**
         * Creates a cube texture
         * @param rootUrl defines the url where the files to load is located
         * @param scene defines the current scene
         * @param files defines the list of files to load (1 per face)
         * @param noMipmap defines a boolean indicating that no mipmaps shall be generated (false by default)
         * @param onLoad defines an optional callback raised when the texture is loaded
         * @param onError defines an optional callback raised if there is an issue to load the texture
         * @param format defines the format of the data
         * @param forcedExtension defines the extension to use to pick the right loader
         * @returns the cube texture as an InternalTexture
         */
        createCubeTexture(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any): InternalTexture;
        /**
         * Creates a cube texture
         * @param rootUrl defines the url where the files to load is located
         * @param scene defines the current scene
         * @param files defines the list of files to load (1 per face)
         * @param noMipmap defines a boolean indicating that no mipmaps shall be generated (false by default)
         * @param onLoad defines an optional callback raised when the texture is loaded
         * @param onError defines an optional callback raised if there is an issue to load the texture
         * @param format defines the format of the data
         * @param forcedExtension defines the extension to use to pick the right loader
         * @param createPolynomials if a polynomial sphere should be created for the cube texture
         * @param lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness
         * @param lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness
         * @returns the cube texture as an InternalTexture
         */
        createCubeTexture(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any, createPolynomials: boolean, lodScale: number, lodOffset: number): InternalTexture;
        /** @internal */
        createCubeTextureBase(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap: boolean, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, format: number | undefined, forcedExtension: any, createPolynomials: boolean, lodScale: number, lodOffset: number, fallback: Nullable<InternalTexture>, beforeLoadCubeDataCallback: Nullable<(texture: InternalTexture, data: ArrayBufferView | ArrayBufferView[]) => void>, imageHandler: Nullable<(texture: InternalTexture, imgs: HTMLImageElement[] | ImageBitmap[]) => void>, useSRGBBuffer: boolean, buffer: Nullable<ArrayBufferView>): InternalTexture;
        /** @internal */
        _partialLoadFile(url: string, index: number, loadedFiles: ArrayBuffer[], onfinish: (files: ArrayBuffer[]) => void, onErrorCallBack: Nullable<(message?: string, exception?: any) => void>): void;
        /** @internal */
        _cascadeLoadFiles(scene: Nullable<Scene>, onfinish: (images: ArrayBuffer[]) => void, files: string[], onError: Nullable<(message?: string, exception?: any) => void>): void;
        /** @internal */
        _cascadeLoadImgs(scene: Nullable<Scene>, texture: InternalTexture, onfinish: Nullable<(texture: InternalTexture, images: HTMLImageElement[] | ImageBitmap[]) => void>, files: string[], onError: Nullable<(message?: string, exception?: any) => void>, mimeType?: string): void;
        /** @internal */
        _partialLoadImg(url: string, index: number, loadedImages: HTMLImageElement[] | ImageBitmap[], scene: Nullable<Scene>, texture: InternalTexture, onfinish: Nullable<(texture: InternalTexture, images: HTMLImageElement[] | ImageBitmap[]) => void>, onErrorCallBack: Nullable<(message?: string, exception?: any) => void>, mimeType?: string): void;
        /**
         * Force the mipmap generation for the given render target texture
         * @param texture defines the render target texture to use
         * @param unbind defines whether or not to unbind the texture after generation. Defaults to true.
         */
        generateMipMapsForCubemap(texture: InternalTexture, unbind?: boolean): void;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * Creates a new render target texture
         * @param size defines the size of the texture
         * @param options defines the options used to create the texture
         * @returns a new render target wrapper ready to render texture
         */
        createRenderTargetTexture(size: TextureSize, options: boolean | RenderTargetCreationOptions): RenderTargetWrapper;
        /**
         * Updates the sample count of a render target texture
         * @see https://doc.babylonjs.com/setup/support/webGL2#multisample-render-targets
         * @param rtWrapper defines the render target wrapper to update
         * @param samples defines the sample count to set
         * @returns the effective sample count (could be 0 if multisample render targets are not supported)
         */
        updateRenderTargetTextureSampleCount(rtWrapper: Nullable<RenderTargetWrapper>, samples: number): number;
        /** @internal */
        _createDepthStencilTexture(size: TextureSize, options: DepthTextureCreationOptions, rtWrapper: RenderTargetWrapper): InternalTexture;
        /** @internal */
        _createHardwareRenderTargetWrapper(isMulti: boolean, isCube: boolean, size: TextureSize): RenderTargetWrapper;
        /** @internal */
        _setupDepthStencilTexture(internalTexture: InternalTexture, size: TextureSize, bilinearFiltering: boolean, comparisonFunction: number, samples?: number): void;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * Sets a depth stencil texture from a render target to the according uniform.
         * @param channel The texture channel
         * @param uniform The uniform to set
         * @param texture The render target texture containing the depth stencil texture to apply
         * @param name The texture name
         */
        setDepthStencilTexture(channel: number, uniform: Nullable<WebGLUniformLocation>, texture: Nullable<RenderTargetTexture>, name?: string): void;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * Creates a new render target cube wrapper
         * @param size defines the size of the texture
         * @param options defines the options used to create the texture
         * @returns a new render target cube wrapper
         */
        createRenderTargetCubeTexture(size: number, options?: RenderTargetCreationOptions): RenderTargetWrapper;
    }
}

/** @internal */
type OcclusionQuery = WebGLQuery | number;
/** @internal */
declare class _OcclusionDataStorage {
    /** @internal */
    occlusionInternalRetryCounter: number;
    /** @internal */
    isOcclusionQueryInProgress: boolean;
    /** @internal */
    isOccluded: boolean;
    /** @internal */
    occlusionRetryCount: number;
    /** @internal */
    occlusionType: number;
    /** @internal */
    occlusionQueryAlgorithmType: number;
    /** @internal */
    forceRenderingWhenOccluded: boolean;
}
declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Create a new webGL query (you must be sure that queries are supported by checking getCaps() function)
         * @returns the new query
         */
        createQuery(): Nullable<OcclusionQuery>;
        /**
         * Delete and release a webGL query
         * @param query defines the query to delete
         * @returns the current engine
         */
        deleteQuery(query: OcclusionQuery): AbstractEngine /**
         * Check if a given query has resolved and got its value
         * @param query defines the query to check
         * @returns true if the query got its value
         */;
        isQueryResultAvailable(query: OcclusionQuery): boolean;
        /**
         * Gets the value of a given query
         * @param query defines the query to check
         * @returns the value of the query
         */
        getQueryResult(query: OcclusionQuery): number;
        /**
         * Initiates an occlusion query
         * @param algorithmType defines the algorithm to use
         * @param query defines the query to use
         * @returns the current engine
         * @see https://doc.babylonjs.com/features/featuresDeepDive/occlusionQueries
         */
        beginOcclusionQuery(algorithmType: number, query: OcclusionQuery): boolean;
        /**
         * Ends an occlusion query
         * @see https://doc.babylonjs.com/features/featuresDeepDive/occlusionQueries
         * @param algorithmType defines the algorithm to use
         * @returns the current engine
         */
        endOcclusionQuery(algorithmType: number): AbstractEngine;
    }
}
declare module "../../Meshes/abstractMesh" {
    interface AbstractMesh {
        /**
         * Backing filed
         * @internal
         */
        __occlusionDataStorage: _OcclusionDataStorage;
        /**
         * Access property
         * @internal
         */
        _occlusionDataStorage: _OcclusionDataStorage;
        /**
         * This number indicates the number of allowed retries before stop the occlusion query, this is useful if the occlusion query is taking long time before to the query result is retrieved, the query result indicates if the object is visible within the scene or not and based on that Babylon.Js engine decides to show or hide the object.
         * The default value is -1 which means don't break the query and wait till the result
         * @see https://doc.babylonjs.com/features/featuresDeepDive/occlusionQueries
         */
        occlusionRetryCount: number;
        /**
         * This property is responsible for starting the occlusion query within the Mesh or not, this property is also used to determine what should happen when the occlusionRetryCount is reached. It has supports 3 values:
         * * OCCLUSION_TYPE_NONE (Default Value): this option means no occlusion query within the Mesh.
         * * OCCLUSION_TYPE_OPTIMISTIC: this option is means use occlusion query and if occlusionRetryCount is reached and the query is broken show the mesh.
         * * OCCLUSION_TYPE_STRICT: this option is means use occlusion query and if occlusionRetryCount is reached and the query is broken restore the last state of the mesh occlusion if the mesh was visible then show the mesh if was hidden then hide don't show.
         * @see https://doc.babylonjs.com/features/featuresDeepDive/occlusionQueries
         */
        occlusionType: number;
        /**
         * This property determines the type of occlusion query algorithm to run in WebGl, you can use:
         * * AbstractMesh.OCCLUSION_ALGORITHM_TYPE_ACCURATE which is mapped to GL_ANY_SAMPLES_PASSED.
         * * AbstractMesh.OCCLUSION_ALGORITHM_TYPE_CONSERVATIVE (Default Value) which is mapped to GL_ANY_SAMPLES_PASSED_CONSERVATIVE which is a false positive algorithm that is faster than GL_ANY_SAMPLES_PASSED but less accurate.
         * @see https://doc.babylonjs.com/features/featuresDeepDive/occlusionQueries
         */
        occlusionQueryAlgorithmType: number;
        /**
         * Gets or sets whether the mesh is occluded or not, it is used also to set the initial state of the mesh to be occluded or not
         * @see https://doc.babylonjs.com/features/featuresDeepDive/occlusionQueries
         */
        isOccluded: boolean;
        /**
         * Flag to check the progress status of the query
         * @see https://doc.babylonjs.com/features/featuresDeepDive/occlusionQueries
         */
        isOcclusionQueryInProgress: boolean;
        /**
         * Flag to force rendering the mesh even if occluded
         * @see https://doc.babylonjs.com/features/featuresDeepDive/occlusionQueries
         */
        forceRenderingWhenOccluded: boolean;
    }
}

/** @internal */
interface IWebGPURenderPassWrapper {
    renderPassDescriptor: Nullable<GPURenderPassDescriptor>;
    colorAttachmentViewDescriptor: Nullable<GPUTextureViewDescriptor>;
    depthAttachmentViewDescriptor: Nullable<GPUTextureViewDescriptor>;
    colorAttachmentGPUTextures: (WebGPUHardwareTexture | null)[];
    depthTextureFormat: GPUTextureFormat | undefined;
}
/**
 * Options to load the associated Glslang library
 */
interface GlslangOptions {
    /**
     * Defines an existing instance of Glslang (useful in modules who do not access the global instance).
     */
    glslang?: any;
    /**
     * Defines the URL of the glslang JS File.
     */
    jsPath?: string;
    /**
     * Defines the URL of the glslang WASM File.
     */
    wasmPath?: string;
}
/**
 * Options to create the WebGPU engine
 */
interface WebGPUEngineOptions extends AbstractEngineOptions, GPURequestAdapterOptions {
    /**
     * The featureLevel property of the GPURequestAdapterOptions interface
     */
    featureLevel?: string;
    /**
     * Defines the category of adapter to use.
     * Is it the discrete or integrated device.
     */
    powerPreference?: GPUPowerPreference;
    /**
     * When set to true, indicates that only a fallback adapter may be returned when requesting an adapter.
     * If the user agent does not support a fallback adapter, will cause requestAdapter() to resolve to null.
     * Default: false
     */
    forceFallbackAdapter?: boolean;
    /**
     * Defines the device descriptor used to create a device once we have retrieved an appropriate adapter
     */
    deviceDescriptor?: GPUDeviceDescriptor;
    /**
     * When requesting the device, enable all the features supported by the adapter. Default: false
     * Note that this setting is ignored if you explicitely set deviceDescriptor.requiredFeatures
     */
    enableAllFeatures?: boolean;
    /**
     * When requesting the device, set the required limits to the maximum possible values (the ones from adapter.limits). Default: false
     * Note that this setting is ignored if you explicitely set deviceDescriptor.requiredLimits
     */
    setMaximumLimits?: boolean;
    /**
     * Defines the requested Swap Chain Format.
     */
    swapChainFormat?: GPUTextureFormat;
    /**
     * Defines whether we should generate debug markers in the gpu command lists (can be seen with PIX for eg). Default: false
     */
    enableGPUDebugMarkers?: boolean;
    /**
     * Options to load the associated Glslang library
     */
    glslangOptions?: GlslangOptions;
    /**
     * Options to load the associated Twgsl library
     */
    twgslOptions?: TwgslOptions;
}
/**
 * The web GPU engine class provides support for WebGPU version of babylon.js.
 * @since 5.0.0
 */
declare class WebGPUEngine extends ThinWebGPUEngine {
    private static readonly _GlslangDefaultOptions;
    private static _InstanceId;
    /** A unique id to identify this instance */
    readonly uniqueId = -1;
    private readonly _uploadEncoderDescriptor;
    private readonly _renderEncoderDescriptor;
    /** @internal */
    readonly _clearDepthValue = 1;
    /** @internal */
    readonly _clearReverseDepthValue = 0;
    /** @internal */
    _clearStencilValue: number;
    private readonly _defaultSampleCount;
    /** @internal */
    _options: WebGPUEngineOptions;
    private _glslang;
    private _tintWASM;
    private _glslangAndTintAreFullyLoaded;
    private _adapter;
    private _adapterSupportedExtensions;
    private _adapterInfo;
    private _adapterSupportedLimits;
    /** @internal */
    _device: GPUDevice;
    private _deviceEnabledExtensions;
    private _deviceLimits;
    private _context;
    private _mainPassSampleCount;
    private _glslangOptions?;
    private _twgslOptions?;
    /** @internal */
    _bufferManager: WebGPUBufferManager;
    private _clearQuad;
    /** @internal */
    _cacheSampler: WebGPUCacheSampler;
    private _cacheBindGroups;
    private _emptyVertexBuffer;
    /** @internal */
    _mrtAttachments: number[];
    /** @internal */
    _compiledComputeEffects: {
        [key: string]: ComputeEffect;
    };
    /** @internal */
    _counters: {
        numEnableEffects: number;
        numEnableDrawWrapper: number;
        numBundleCreationNonCompatMode: number;
        numBundleReuseNonCompatMode: number;
    };
    /**
     * Counters from last frame
     */
    readonly countersLastFrame: {
        numEnableEffects: number;
        numEnableDrawWrapper: number;
        numBundleCreationNonCompatMode: number;
        numBundleReuseNonCompatMode: number;
    };
    /**
     * Max number of uncaptured error messages to log
     */
    numMaxUncapturedErrors: number;
    /**
     * Gets the list of created scenes
     */
    scenes: Scene[];
    /** @internal */
    _virtualScenes: Scene[];
    private _mainTexture;
    private _depthTexture;
    private _mainTextureExtends;
    private _depthTextureFormat;
    private _colorFormat;
    /** @internal */
    _ubInvertY: WebGPUDataBuffer;
    /** @internal */
    _ubDontInvertY: WebGPUDataBuffer;
    private _commandBuffers;
    private _mainRenderPassWrapper;
    private _rttRenderPassWrapper;
    private _defaultDrawContext;
    private _defaultMaterialContext;
    /** @internal */
    _currentDrawContext: WebGPUDrawContext;
    /** @internal */
    _currentMaterialContext: WebGPUMaterialContext;
    private _currentVertexBuffers;
    private _currentOverrideVertexBuffers;
    private _currentIndexBuffer;
    private _dummyIndexBuffer;
    private _colorWriteLocal;
    private _forceEnableEffect;
    /**
     * Gets or sets the snapshot rendering mode
     */
    get snapshotRenderingMode(): number;
    set snapshotRenderingMode(mode: number);
    /**
     * Creates a new snapshot at the next frame using the current snapshotRenderingMode
     */
    snapshotRenderingReset(): void;
    /**
     * Enables or disables the snapshot rendering mode
     * Note that the WebGL engine does not support snapshot rendering so setting the value won't have any effect for this engine
     */
    get snapshotRendering(): boolean;
    set snapshotRendering(activate: boolean);
    /**
     * Sets this to true to disable the cache for the samplers. You should do it only for testing purpose!
     */
    get disableCacheSamplers(): boolean;
    set disableCacheSamplers(disable: boolean);
    /**
     * Sets this to true to disable the cache for the render pipelines. You should do it only for testing purpose!
     */
    get disableCacheRenderPipelines(): boolean;
    set disableCacheRenderPipelines(disable: boolean);
    /**
     * Sets this to true to disable the cache for the bind groups. You should do it only for testing purpose!
     */
    get disableCacheBindGroups(): boolean;
    set disableCacheBindGroups(disable: boolean);
    /**
     * Gets a boolean indicating if all created effects are ready
     * @returns true if all effects are ready
     */
    areAllEffectsReady(): boolean;
    /**
     * Get Font size information
     * @param font font name
     * @returns an object containing ascent, height and descent
     */
    getFontOffset(font: string): {
        ascent: number;
        height: number;
        descent: number;
    };
    /**
     * Gets a Promise<boolean> indicating if the engine can be instantiated (ie. if a WebGPU context can be found)
     */
    static get IsSupportedAsync(): Promise<boolean>;
    /**
     * Not supported by WebGPU, you should call IsSupportedAsync instead!
     */
    static get IsSupported(): boolean;
    /**
     * Gets a boolean indicating that the engine supports uniform buffers
     */
    get supportsUniformBuffers(): boolean;
    /** Gets the supported extensions by the WebGPU adapter */
    get supportedExtensions(): Immutable<GPUFeatureName[]>;
    /** Gets the currently enabled extensions on the WebGPU device */
    get enabledExtensions(): Immutable<GPUFeatureName[]>;
    /** Gets the supported limits by the WebGPU adapter */
    get supportedLimits(): GPUSupportedLimits;
    /** Gets the current limits of the WebGPU device */
    get currentLimits(): GPUSupportedLimits;
    /**
     * Returns a string describing the current engine
     */
    get description(): string;
    /**
     * Returns the version of the engine
     */
    get version(): number;
    /**
     * Gets an object containing information about the current engine context
     * @returns an object containing the vendor, the renderer and the version of the current engine context
     */
    getInfo(): {
        vendor: string;
        renderer: string;
        version: string;
    };
    /**
     * (WebGPU only) True (default) to be in compatibility mode, meaning rendering all existing scenes without artifacts (same rendering than WebGL).
     * Setting the property to false will improve performances but may not work in some scenes if some precautions are not taken.
     * See https://doc.babylonjs.com/setup/support/webGPU/webGPUOptimization/webGPUNonCompatibilityMode for more details
     */
    get compatibilityMode(): boolean;
    set compatibilityMode(mode: boolean);
    /** @internal */
    get currentSampleCount(): number;
    /**
     * Create a new instance of the gpu engine asynchronously
     * @param canvas Defines the canvas to use to display the result
     * @param options Defines the options passed to the engine to create the GPU context dependencies
     * @returns a promise that resolves with the created engine
     */
    static CreateAsync(canvas: HTMLCanvasElement, options?: WebGPUEngineOptions): Promise<WebGPUEngine>;
    /**
     * Indicates if the z range in NDC space is 0..1 (value: true) or -1..1 (value: false)
     */
    readonly isNDCHalfZRange: boolean;
    /**
     * Indicates that the origin of the texture/framebuffer space is the bottom left corner. If false, the origin is top left
     */
    readonly hasOriginBottomLeft: boolean;
    /**
     * Create a new instance of the gpu engine.
     * @param canvas Defines the canvas to use to display the result
     * @param options Defines the options passed to the engine to create the GPU context dependencies
     */
    constructor(canvas: HTMLCanvasElement | OffscreenCanvas, options?: WebGPUEngineOptions);
    private _workingGlslangAndTintPromise;
    /**
     * Load the glslang and tintWASM libraries and prepare them for use.
     * @returns a promise that resolves when the engine is ready to use the glslang and tintWASM
     */
    prepareGlslangAndTintAsync(): Promise<void>;
    /**
     * Initializes the WebGPU context and dependencies.
     * @param glslangOptions Defines the GLSLang compiler options if necessary
     * @param twgslOptions Defines the Twgsl compiler options if necessary
     * @returns a promise notifying the readiness of the engine.
     */
    initAsync(glslangOptions?: GlslangOptions, twgslOptions?: TwgslOptions): Promise<void>;
    private _initGlslangAsync;
    private _initializeLimits;
    private _initializeContextAndSwapChain;
    private _initializeMainAttachments;
    /**
     * Shared initialization across engines types.
     * @param canvas The canvas associated with this instance of the engine.
     */
    protected _sharedInit(canvas: HTMLCanvasElement): void;
    private _configureContext;
    /**
     * Resize an image and returns the image data as an uint8array
     * @param image image to resize
     * @param bufferWidth destination buffer width
     * @param bufferHeight destination buffer height
     * @returns an uint8array containing RGBA values of bufferWidth * bufferHeight size
     */
    resizeImageBitmap(image: HTMLImageElement | ImageBitmap, bufferWidth: number, bufferHeight: number): Uint8Array;
    /**
     * Engine abstraction for loading and creating an image bitmap from a given source string.
     * @param imageSource source to load the image from.
     * @param options An object that sets options for the image's extraction.
     * @returns ImageBitmap
     */
    _createImageBitmapFromSource(imageSource: string, options?: ImageBitmapOptions): Promise<ImageBitmap>;
    /**
     * Toggle full screen mode
     * @param requestPointerLock defines if a pointer lock should be requested from the user
     */
    switchFullscreen(requestPointerLock: boolean): void;
    /**
     * Enters full screen mode
     * @param requestPointerLock defines if a pointer lock should be requested from the user
     */
    enterFullscreen(requestPointerLock: boolean): void;
    /**
     * Exits full screen mode
     */
    exitFullscreen(): void;
    /**
     * Enters Pointerlock mode
     */
    enterPointerlock(): void;
    /**
     * Exits Pointerlock mode
     */
    exitPointerlock(): void;
    protected _rebuildBuffers(): void;
    protected _restoreEngineAfterContextLost(initEngine: () => void): void;
    /**
     * Force a specific size of the canvas
     * @param width defines the new canvas' width
     * @param height defines the new canvas' height
     * @param forceSetSize true to force setting the sizes of the underlying canvas
     * @returns true if the size was changed
     */
    setSize(width: number, height: number, forceSetSize?: boolean): boolean;
    private _shaderProcessorWGSL;
    /**
     * @internal
     */
    _getShaderProcessor(shaderLanguage: ShaderLanguage): Nullable<IShaderProcessor>;
    /**
     * @internal
     */
    _getShaderProcessingContext(shaderLanguage: ShaderLanguage, pureMode: boolean): Nullable<_IShaderProcessingContext>;
    private _getCurrentRenderPass;
    /** @internal */
    _getCurrentRenderPassWrapper(): IWebGPURenderPassWrapper;
    /** @internal */
    applyStates(): void;
    /**
     * Force the entire cache to be cleared
     * You should not have to use this function unless your engine needs to share the WebGPU context with another engine
     * @param bruteForce defines a boolean to force clearing ALL caches (including stencil, detoh and alpha states)
     */
    wipeCaches(bruteForce?: boolean): void;
    /**
     * Enable or disable color writing
     * @param enable defines the state to set
     */
    setColorWrite(enable: boolean): void;
    /**
     * Gets a boolean indicating if color writing is enabled
     * @returns the current color writing state
     */
    getColorWrite(): boolean;
    private _viewportsCurrent;
    private _mustUpdateViewport;
    private _applyViewport;
    /**
     * @internal
     */
    _viewport(x: number, y: number, width: number, height: number): void;
    private _scissorsCurrent;
    protected _scissorCached: {
        x: number;
        y: number;
        z: number;
        w: number;
    };
    private _mustUpdateScissor;
    private _applyScissor;
    private _scissorIsActive;
    enableScissor(x: number, y: number, width: number, height: number): void;
    disableScissor(): void;
    private _stencilRefsCurrent;
    private _mustUpdateStencilRef;
    private _applyStencilRef;
    private _blendColorsCurrent;
    private _mustUpdateBlendColor;
    private _applyBlendColor;
    private _resetRenderPassStates;
    /**
     * Clear the current render buffer or the current render target (if any is set up)
     * @param color defines the color to use
     * @param backBuffer defines if the back buffer must be cleared
     * @param depth defines if the depth buffer must be cleared
     * @param stencil defines if the stencil buffer must be cleared
     * @param stencilClearValue defines the value to use to clear the stencil buffer (default is 0)
     */
    clear(color: Nullable<IColor4Like>, backBuffer: boolean, depth: boolean, stencil?: boolean, stencilClearValue?: number): void;
    private _clearFullQuad;
    /**
     * Creates a vertex buffer
     * @param data the data or the size for the vertex buffer
     * @param _updatable whether the buffer should be created as updatable
     * @param label defines the label of the buffer (for debug purpose)
     * @returns the new buffer
     */
    createVertexBuffer(data: DataArray | number, _updatable?: boolean, label?: string): DataBuffer;
    /**
     * Creates a vertex buffer
     * @param data the data for the dynamic vertex buffer
     * @param label defines the label of the buffer (for debug purpose)
     * @returns the new buffer
     */
    createDynamicVertexBuffer(data: DataArray, label?: string): DataBuffer;
    /**
     * Creates a new index buffer
     * @param indices defines the content of the index buffer
     * @param _updatable defines if the index buffer must be updatable
     * @param label defines the label of the buffer (for debug purpose)
     * @returns a new buffer
     */
    createIndexBuffer(indices: IndicesArray, _updatable?: boolean, label?: string): DataBuffer;
    /**
     * Update a dynamic index buffer
     * @param indexBuffer defines the target index buffer
     * @param indices defines the data to update
     * @param offset defines the offset in the target index buffer where update should start
     */
    updateDynamicIndexBuffer(indexBuffer: DataBuffer, indices: IndicesArray, offset?: number): void;
    /**
     * Updates a dynamic vertex buffer.
     * @param vertexBuffer the vertex buffer to update
     * @param data the data used to update the vertex buffer
     * @param byteOffset the byte offset of the data
     * @param byteLength the byte length of the data
     */
    updateDynamicVertexBuffer(vertexBuffer: DataBuffer, data: DataArray, byteOffset?: number, byteLength?: number): void;
    /**
     * @internal
     */
    _createBuffer(data: DataArray | number, creationFlags: number, label?: string): DataBuffer;
    /**
     * @internal
     */
    bindBuffersDirectly(): void;
    /**
     * @internal
     */
    updateAndBindInstancesBuffer(): void;
    /**
     * Unbind all instance attributes
     */
    unbindInstanceAttributes(): void;
    /**
     * Bind a list of vertex buffers with the engine
     * @param vertexBuffers defines the list of vertex buffers to bind
     * @param indexBuffer defines the index buffer to bind
     * @param _effect defines the effect associated with the vertex buffers
     * @param overrideVertexBuffers defines optional list of avertex buffers that overrides the entries in vertexBuffers
     */
    bindBuffers(vertexBuffers: {
        [key: string]: Nullable<VertexBuffer>;
    }, indexBuffer: Nullable<DataBuffer>, _effect: Effect, overrideVertexBuffers?: {
        [kind: string]: Nullable<VertexBuffer>;
    }): void;
    /**
     * @internal
     */
    _releaseBuffer(buffer: DataBuffer): boolean;
    /**
     * Create an uniform buffer
     * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
     * @param elements defines the content of the uniform buffer
     * @param label defines a name for the buffer (for debugging purpose)
     * @returns the webGL uniform buffer
     */
    createUniformBuffer(elements: FloatArray, label?: string): DataBuffer;
    /**
     * Create a dynamic uniform buffer (no different from a non dynamic uniform buffer in WebGPU)
     * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
     * @param elements defines the content of the uniform buffer
     * @param label defines a name for the buffer (for debugging purpose)
     * @returns the webGL uniform buffer
     */
    createDynamicUniformBuffer(elements: FloatArray, label?: string): DataBuffer;
    /**
     * Update an existing uniform buffer
     * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
     * @param uniformBuffer defines the target uniform buffer
     * @param elements defines the content to update
     * @param offset defines the offset in the uniform buffer where update should start
     * @param count defines the size of the data to update
     */
    updateUniformBuffer(uniformBuffer: DataBuffer, elements: FloatArray, offset?: number, count?: number): void;
    /**
     * Bind a buffer to the current draw context
     * @param buffer defines the buffer to bind
     * @param _location not used in WebGPU
     * @param name Name of the uniform variable to bind
     */
    bindUniformBufferBase(buffer: DataBuffer, _location: number, name: string): void;
    /**
     * Unused in WebGPU
     */
    bindUniformBlock(): void;
    /**
     * Create a new effect (used to store vertex/fragment shaders)
     * @param baseName defines the base name of the effect (The name of file without .fragment.fx or .vertex.fx)
     * @param attributesNamesOrOptions defines either a list of attribute names or an IEffectCreationOptions object
     * @param uniformsNamesOrEngine defines either a list of uniform names or the engine to use
     * @param samplers defines an array of string used to represent textures
     * @param defines defines the string containing the defines to use to compile the shaders
     * @param fallbacks defines the list of potential fallbacks to use if shader compilation fails
     * @param onCompiled defines a function to call when the effect creation is successful
     * @param onError defines a function to call when the effect creation has failed
     * @param indexParameters defines an object containing the index values to use to compile shaders (like the maximum number of simultaneous lights)
     * @param shaderLanguage the language the shader is written in (default: GLSL)
     * @param extraInitializationsAsync additional async code to run before preparing the effect
     * @returns the new Effect
     */
    createEffect(baseName: string | (IShaderPath & {
        vertexToken?: string;
        fragmentToken?: string;
    }), attributesNamesOrOptions: string[] | IEffectCreationOptions, uniformsNamesOrEngine: string[] | AbstractEngine, samplers?: string[], defines?: string, fallbacks?: EffectFallbacks, onCompiled?: Nullable<(effect: Effect) => void>, onError?: Nullable<(effect: Effect, errors: string) => void>, indexParameters?: any, shaderLanguage?: ShaderLanguage, extraInitializationsAsync?: () => Promise<void>): Effect;
    private _compileRawShaderToSpirV;
    private _compileShaderToSpirV;
    private _getWGSLShader;
    private _createPipelineStageDescriptor;
    private _compileRawPipelineStageDescriptor;
    private _compilePipelineStageDescriptor;
    /**
     * @internal
     */
    createRawShaderProgram(): WebGLProgram;
    /**
     * @internal
     */
    createShaderProgram(): WebGLProgram;
    /**
     * Inline functions in shader code that are marked to be inlined
     * @param code code to inline
     * @returns inlined code
     */
    inlineShaderCode(code: string): string;
    /**
     * Creates a new pipeline context
     * @param shaderProcessingContext defines the shader processing context used during the processing if available
     * @returns the new pipeline
     */
    createPipelineContext(shaderProcessingContext: Nullable<_IShaderProcessingContext>): IPipelineContext;
    /**
     * Creates a new material context
     * @returns the new context
     */
    createMaterialContext(): WebGPUMaterialContext | undefined;
    /**
     * Creates a new draw context
     * @returns the new context
     */
    createDrawContext(): WebGPUDrawContext | undefined;
    /**
     * @internal
     */
    _preparePipelineContextAsync(pipelineContext: IPipelineContext, vertexSourceCode: string, fragmentSourceCode: string, createAsRaw: boolean, rawVertexSourceCode: string, rawFragmentSourceCode: string, _rebuildRebind: any, defines: Nullable<string>, _transformFeedbackVaryings: Nullable<string[]>, _key: string, onReady: () => void): Promise<void>;
    /**
     * Gets the list of active attributes for a given WebGPU program
     * @param pipelineContext defines the pipeline context to use
     * @param attributesNames defines the list of attribute names to get
     * @returns an array of indices indicating the offset of each attribute
     */
    getAttributes(pipelineContext: IPipelineContext, attributesNames: string[]): number[];
    /**
     * Activates an effect, making it the current one (ie. the one used for rendering)
     * @param effect defines the effect to activate
     */
    enableEffect(effect: Nullable<Effect | DrawWrapper>): void;
    /**
     * @internal
     */
    _releaseEffect(effect: Effect): void;
    /**
     * Force the engine to release all cached effects. This means that next effect compilation will have to be done completely even if a similar effect was already compiled
     */
    releaseEffects(): void;
    _deletePipelineContext(pipelineContext: IPipelineContext): void;
    /**
     * Gets a boolean indicating that only power of 2 textures are supported
     * Please note that you can still use non power of 2 textures but in this case the engine will forcefully convert them
     */
    get needPOTTextures(): boolean;
    /** @internal */
    _createHardwareTexture(): IHardwareTextureWrapper;
    /**
     * @internal
     */
    _releaseTexture(texture: InternalTexture): void;
    /**
     * @internal
     */
    _getRGBABufferInternalSizedFormat(): number;
    updateTextureComparisonFunction(texture: InternalTexture, comparisonFunction: number): void;
    /**
     * Creates an internal texture without binding it to a framebuffer
     * @internal
     * @param size defines the size of the texture
     * @param options defines the options used to create the texture
     * @param delayGPUTextureCreation true to delay the texture creation the first time it is really needed. false to create it right away
     * @param source source type of the texture
     * @returns a new internal texture
     */
    _createInternalTexture(size: TextureSize, options: boolean | InternalTextureCreationOptions, delayGPUTextureCreation?: boolean, source?: InternalTextureSource): InternalTexture;
    /**
     * Usually called from Texture.ts.
     * Passed information to create a hardware texture
     * @param url defines a value which contains one of the following:
     * * A conventional http URL, e.g. 'http://...' or 'file://...'
     * * A base64 string of in-line texture data, e.g. 'data:image/jpg;base64,/...'
     * * An indicator that data being passed using the buffer parameter, e.g. 'data:mytexture.jpg'
     * @param noMipmap defines a boolean indicating that no mipmaps shall be generated.  Ignored for compressed textures.  They must be in the file
     * @param invertY when true, image is flipped when loaded.  You probably want true. Certain compressed textures may invert this if their default is inverted (eg. ktx)
     * @param scene needed for loading to the correct scene
     * @param samplingMode mode with should be used sample / access the texture (Default: Texture.TRILINEAR_SAMPLINGMODE)
     * @param onLoad optional callback to be called upon successful completion
     * @param onError optional callback to be called upon failure
     * @param buffer a source of a file previously fetched as either a base64 string, an ArrayBuffer (compressed or image format), HTMLImageElement (image format), or a Blob
     * @param fallback an internal argument in case the function must be called again, due to etc1 not having alpha capabilities
     * @param format internal format.  Default: RGB when extension is '.jpg' else RGBA.  Ignored for compressed textures
     * @param forcedExtension defines the extension to use to pick the right loader
     * @param mimeType defines an optional mime type
     * @param loaderOptions options to be passed to the loader
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
     * @returns a InternalTexture for assignment back into BABYLON.Texture
     */
    createTexture(url: Nullable<string>, noMipmap: boolean, invertY: boolean, scene: Nullable<ISceneLike>, samplingMode?: number, onLoad?: Nullable<(texture: InternalTexture) => void>, onError?: Nullable<(message: string, exception: any) => void>, buffer?: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>, fallback?: Nullable<InternalTexture>, format?: Nullable<number>, forcedExtension?: Nullable<string>, mimeType?: string, loaderOptions?: any, creationFlags?: number, useSRGBBuffer?: boolean): InternalTexture;
    /**
     * Wraps an external web gpu texture in a Babylon texture.
     * @param texture defines the external texture
     * @returns the babylon internal texture
     */
    wrapWebGPUTexture(texture: GPUTexture): InternalTexture;
    /**
     * Wraps an external web gl texture in a Babylon texture.
     * @returns the babylon internal texture
     */
    wrapWebGLTexture(): InternalTexture;
    /**
     * @internal
     */
    _getUseSRGBBuffer(useSRGBBuffer: boolean, _noMipmap: boolean): boolean;
    /**
     * @internal
     */
    _unpackFlipY(_value: boolean): void;
    /**
     * Update the sampling mode of a given texture
     * @param samplingMode defines the required sampling mode
     * @param texture defines the texture to update
     * @param generateMipMaps defines whether to generate mipmaps for the texture
     */
    updateTextureSamplingMode(samplingMode: number, texture: InternalTexture, generateMipMaps?: boolean): void;
    /**
     * Update the sampling mode of a given texture
     * @param texture defines the texture to update
     * @param wrapU defines the texture wrap mode of the u coordinates
     * @param wrapV defines the texture wrap mode of the v coordinates
     * @param wrapR defines the texture wrap mode of the r coordinates
     */
    updateTextureWrappingMode(texture: InternalTexture, wrapU: Nullable<number>, wrapV?: Nullable<number>, wrapR?: Nullable<number>): void;
    /**
     * Update the dimensions of a texture
     * @param texture texture to update
     * @param width new width of the texture
     * @param height new height of the texture
     * @param depth new depth of the texture
     */
    updateTextureDimensions(texture: InternalTexture, width: number, height: number, depth?: number): void;
    /**
     * @internal
     */
    _setInternalTexture(name: string, texture: Nullable<InternalTexture | ExternalTexture>, baseName?: string): void;
    /**
     * Create a cube texture from prefiltered data (ie. the mipmaps contain ready to use data for PBR reflection)
     * @param rootUrl defines the url where the file to load is located
     * @param scene defines the current scene
     * @param lodScale defines scale to apply to the mip map selection
     * @param lodOffset defines offset to apply to the mip map selection
     * @param onLoad defines an optional callback raised when the texture is loaded
     * @param onError defines an optional callback raised if there is an issue to load the texture
     * @param format defines the format of the data
     * @param forcedExtension defines the extension to use to pick the right loader
     * @param createPolynomials defines wheter or not to create polynomails harmonics for the texture
     * @returns the cube texture as an InternalTexture
     */
    createPrefilteredCubeTexture(rootUrl: string, scene: Nullable<Scene>, lodScale: number, lodOffset: number, onLoad?: Nullable<(internalTexture: Nullable<InternalTexture>) => void>, onError?: Nullable<(message?: string, exception?: any) => void>, format?: number, forcedExtension?: any, createPolynomials?: boolean): InternalTexture;
    /**
     * Sets a texture to the according uniform.
     * @param channel The texture channel
     * @param unused unused parameter
     * @param texture The texture to apply
     * @param name The name of the uniform in the effect
     */
    setTexture(channel: number, unused: Nullable<WebGLUniformLocation>, texture: Nullable<BaseTexture>, name: string): void;
    /**
     * Sets an array of texture to the WebGPU context
     * @param channel defines the channel where the texture array must be set
     * @param unused unused parameter
     * @param textures defines the array of textures to bind
     * @param name name of the channel
     */
    setTextureArray(channel: number, unused: Nullable<WebGLUniformLocation>, textures: BaseTexture[], name: string): void;
    /**
     * @internal
     */
    _setTexture(channel: number, texture: Nullable<BaseTexture>, isPartOfTextureArray?: boolean, depthStencilTexture?: boolean, name?: string, baseName?: string): boolean;
    /**
     * @internal
     */
    _setAnisotropicLevel(target: number, internalTexture: InternalTexture, anisotropicFilteringLevel: number): void;
    /**
     * @internal
     */
    _bindTexture(channel: number, texture: Nullable<InternalTexture>, name: string): void;
    /**
     * Generates the mipmaps for a texture
     * @param texture texture to generate the mipmaps for
     */
    generateMipmaps(texture: InternalTexture): void;
    /**
     * Update a portion of an internal texture
     * @param texture defines the texture to update
     * @param imageData defines the data to store into the texture
     * @param xOffset defines the x coordinates of the update rectangle
     * @param yOffset defines the y coordinates of the update rectangle
     * @param width defines the width of the update rectangle
     * @param height defines the height of the update rectangle
     * @param faceIndex defines the face index if texture is a cube (0 by default)
     * @param lod defines the lod level to update (0 by default)
     * @param generateMipMaps defines whether to generate mipmaps or not
     */
    updateTextureData(texture: InternalTexture, imageData: ArrayBufferView, xOffset: number, yOffset: number, width: number, height: number, faceIndex?: number, lod?: number, generateMipMaps?: boolean): void;
    /**
     * @internal
     */
    _uploadCompressedDataToTextureDirectly(texture: InternalTexture, internalFormat: number, width: number, height: number, imageData: ArrayBufferView, faceIndex?: number, lod?: number): void;
    /**
     * @internal
     */
    _uploadDataToTextureDirectly(texture: InternalTexture, imageData: ArrayBufferView, faceIndex?: number, lod?: number, babylonInternalFormat?: number, useTextureWidthAndHeight?: boolean): void;
    /**
     * @internal
     */
    _uploadArrayBufferViewToTexture(texture: InternalTexture, imageData: ArrayBufferView, faceIndex?: number, lod?: number): void;
    /**
     * @internal
     */
    _uploadImageToTexture(texture: InternalTexture, image: HTMLImageElement | ImageBitmap, faceIndex?: number, lod?: number): void;
    /**
     * Reads pixels from the current frame buffer. Please note that this function can be slow
     * @param x defines the x coordinate of the rectangle where pixels must be read
     * @param y defines the y coordinate of the rectangle where pixels must be read
     * @param width defines the width of the rectangle where pixels must be read
     * @param height defines the height of the rectangle where pixels must be read
     * @param _hasAlpha defines whether the output should have alpha or not (defaults to true)
     * @param flushRenderer true to flush the renderer from the pending commands before reading the pixels
     * @param data defines the data to fill with the read pixels (if not provided, a new one will be created)
     * @returns a ArrayBufferView promise (Uint8Array) containing RGBA colors
     */
    readPixels(x: number, y: number, width: number, height: number, _hasAlpha?: boolean, flushRenderer?: boolean, data?: Nullable<Uint8Array>): Promise<ArrayBufferView>;
    private _measureFps;
    private _performanceMonitor;
    /**
     * Gets the performance monitor attached to this engine
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#engineinstrumentation
     */
    get performanceMonitor(): PerformanceMonitor;
    /**
     * Begin a new frame
     */
    beginFrame(): void;
    /**
     * End the current frame
     */
    endFrame(): void;
    /**Gets driver info if available */
    extractDriverInfo(): string;
    /**
     * Force a WebGPU flush (ie. a flush of all waiting commands)
     */
    flushFramebuffer(): void;
    /** @internal */
    _currentFrameBufferIsDefaultFrameBuffer(): boolean;
    /** @internal */
    _startRenderTargetRenderPass(renderTargetWrapper: RenderTargetWrapper, setClearStates: boolean, clearColor: Nullable<IColor4Like>, clearDepth: boolean, clearStencil: boolean): void;
    private _startMainRenderPass;
    /**
     * Binds the frame buffer to the specified texture.
     * @param texture The render target wrapper to render to
     * @param faceIndex The face of the texture to render to in case of cube texture
     * @param requiredWidth The width of the target to render to
     * @param requiredHeight The height of the target to render to
     * @param forceFullscreenViewport Forces the viewport to be the entire texture/screen if true
     * @param lodLevel defines the lod level to bind to the frame buffer
     * @param layer defines the 2d array index to bind to frame buffer to
     */
    bindFramebuffer(texture: RenderTargetWrapper, faceIndex?: number, requiredWidth?: number, requiredHeight?: number, forceFullscreenViewport?: boolean, lodLevel?: number, layer?: number): void;
    /**
     * Unbind the current render target texture from the WebGPU context
     * @param texture defines the render target wrapper to unbind
     * @param disableGenerateMipMaps defines a boolean indicating that mipmaps must not be generated
     * @param onBeforeUnbind defines a function which will be called before the effective unbind
     */
    unBindFramebuffer(texture: RenderTargetWrapper, disableGenerateMipMaps?: boolean, onBeforeUnbind?: () => void): void;
    private _resolveAndGenerateMipMapsFramebuffer;
    /**
     * Generates mipmaps for the texture of the (single) render target
     * @param texture The render target containing the texture to generate the mipmaps for
     */
    generateMipMapsFramebuffer(texture: RenderTargetWrapper): void;
    /**
     * Resolves the MSAA texture of the render target into its non-MSAA version.
     * Note that if "texture" is not a MSAA render target, no resolve is performed.
     * @param texture The render target texture containing the MSAA texture to resolve
     * @param resolveColors If true, resolve the color textures (default: true) - still subject to texture.resolveMSAAColors
     */
    resolveFramebuffer(texture: RenderTargetWrapper, resolveColors?: boolean): void;
    /**
     * Unbind the current render target
     */
    restoreDefaultFramebuffer(): void;
    /**
     * @internal
     */
    _setColorFormat(wrapper: IWebGPURenderPassWrapper): void;
    /**
     * @internal
     */
    _setDepthTextureFormat(wrapper: IWebGPURenderPassWrapper): void;
    setDitheringState(): void;
    setRasterizerState(): void;
    /**
     * @internal
     */
    _executeWhenRenderingStateIsCompiled(pipelineContext: IPipelineContext, action: () => void): void;
    /**
     * @internal
     */
    bindSamplers(): void;
    /** @internal */
    _getUnpackAlignement(): number;
    /**
     * @internal
     */
    _bindTextureDirectly(): boolean;
    setStateCullFaceType(cullBackFaces?: boolean, force?: boolean): void;
    /**
     * Set various states to the webGL context
     * @param culling defines culling state: true to enable culling, false to disable it
     * @param zOffset defines the value to apply to zOffset (0 by default)
     * @param force defines if states must be applied even if cache is up to date
     * @param reverseSide defines if culling must be reversed (CCW if false, CW if true)
     * @param cullBackFaces true to cull back faces, false to cull front faces (if culling is enabled)
     * @param stencil stencil states to set
     * @param zOffsetUnits defines the value to apply to zOffsetUnits (0 by default)
     */
    setState(culling: boolean, zOffset?: number, force?: boolean, reverseSide?: boolean, cullBackFaces?: boolean, stencil?: IStencilState, zOffsetUnits?: number): void;
    private _applyRenderPassChanges;
    private _draw;
    /**
     * Draw a list of indexed primitives
     * @param fillMode defines the primitive to use
     * @param indexStart defines the starting index
     * @param indexCount defines the number of index to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    drawElementsType(fillMode: number, indexStart: number, indexCount: number, instancesCount?: number): void;
    /**
     * Draw a list of unindexed primitives
     * @param fillMode defines the primitive to use
     * @param verticesStart defines the index of first vertex to draw
     * @param verticesCount defines the count of vertices to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    drawArraysType(fillMode: number, verticesStart: number, verticesCount: number, instancesCount?: number): void;
    /**
     * Dispose and release all associated resources
     */
    dispose(): void;
    /**
     * Gets the current render width
     * @param useScreen defines if screen size must be used (or the current render target if any)
     * @returns a number defining the current render width
     */
    getRenderWidth(useScreen?: boolean): number;
    /**
     * Gets the current render height
     * @param useScreen defines if screen size must be used (or the current render target if any)
     * @returns a number defining the current render height
     */
    getRenderHeight(useScreen?: boolean): number;
    /**
     * Get the current error code of the WebGPU context
     * @returns the error code
     */
    getError(): number;
    /**
     * Creates an external texture
     * @param video video element
     * @returns the external texture, or null if external textures are not supported by the engine
     */
    createExternalTexture(video: HTMLVideoElement): Nullable<ExternalTexture>;
    /**
     * Sets an internal texture to the according uniform.
     * @param name The name of the uniform in the effect
     * @param texture The texture to apply
     */
    setExternalTexture(name: string, texture: Nullable<ExternalTexture>): void;
    /**
     * Sets a texture sampler to the according uniform.
     * @param name The name of the uniform in the effect
     * @param sampler The sampler to apply
     */
    setTextureSampler(name: string, sampler: Nullable<TextureSampler>): void;
    /**
     * Creates a storage buffer
     * @param data the data for the storage buffer or the size of the buffer
     * @param creationFlags flags to use when creating the buffer (see Constants.BUFFER_CREATIONFLAG_XXX). The BUFFER_CREATIONFLAG_STORAGE flag will be automatically added
     * @param label defines the label of the buffer (for debug purpose)
     * @returns the new buffer
     */
    createStorageBuffer(data: DataArray | number, creationFlags: number, label?: string): DataBuffer;
    /**
     * Clears a storage buffer to zeroes
     * @param storageBuffer the storage buffer to clear
     * @param byteOffset the byte offset to start clearing (optional)
     * @param byteLength the byte length to clear (optional)
     */
    clearStorageBuffer(storageBuffer: DataBuffer, byteOffset?: number, byteLength?: number): void;
    /**
     * Updates a storage buffer
     * @param buffer the storage buffer to update
     * @param data the data used to update the storage buffer
     * @param byteOffset the byte offset of the data
     * @param byteLength the byte length of the data
     */
    updateStorageBuffer(buffer: DataBuffer, data: DataArray, byteOffset?: number, byteLength?: number): void;
    private _readFromGPUBuffer;
    /**
     * Read data from a storage buffer
     * @param storageBuffer The storage buffer to read from
     * @param offset The offset in the storage buffer to start reading from (default: 0)
     * @param size  The number of bytes to read from the storage buffer (default: capacity of the buffer)
     * @param buffer The buffer to write the data we have read from the storage buffer to (optional)
     * @param noDelay If true, a call to flushFramebuffer will be issued so that the data can be read back immediately and not in engine.onEndFrameObservable. This can speed up data retrieval, at the cost of a small perf penalty (default: false).
     * @returns If not undefined, returns the (promise) buffer (as provided by the 4th parameter) filled with the data, else it returns a (promise) Uint8Array with the data read from the storage buffer
     */
    readFromStorageBuffer(storageBuffer: DataBuffer, offset?: number, size?: number, buffer?: ArrayBufferView, noDelay?: boolean): Promise<ArrayBufferView>;
    /**
     * Read data from multiple storage buffers
     * @param storageBuffers The list of storage buffers to read from
     * @param offset The offset in the storage buffer to start reading from (default: 0). This is the same offset for all storage buffers!
     * @param size  The number of bytes to read from each storage buffer (default: capacity of the first buffer)
     * @param buffer The buffer to write the data we have read from the storage buffers to (optional). If provided, the buffer should be large enough to hold the data from all storage buffers!
     * @param noDelay If true, a call to flushFramebuffer will be issued so that the data can be read back immediately and not in engine.onEndFrameObservable. This can speed up data retrieval, at the cost of a small perf penalty (default: false).
     * @returns If not undefined, returns the (promise) buffer (as provided by the 4th parameter) filled with the data, else it returns a (promise) Uint8Array with the data read from the storage buffer
     */
    readFromMultipleStorageBuffers(storageBuffers: DataBuffer[], offset?: number, size?: number, buffer?: ArrayBufferView, noDelay?: boolean): Promise<ArrayBufferView>;
    /**
     * Sets a storage buffer in the shader
     * @param name Defines the name of the storage buffer as defined in the shader
     * @param buffer Defines the value to give to the uniform
     */
    setStorageBuffer(name: string, buffer: Nullable<StorageBuffer>): void;
}

/**
 * This class is a small wrapper around a native buffer that can be read and/or written
 */
declare class StorageBuffer {
    private _engine;
    private _buffer;
    private _bufferSize;
    private _creationFlags;
    private _label?;
    /**
     * Creates a new storage buffer instance
     * @param engine The engine the buffer will be created inside
     * @param size The size of the buffer in bytes
     * @param creationFlags flags to use when creating the buffer (see Constants.BUFFER_CREATIONFLAG_XXX). The BUFFER_CREATIONFLAG_STORAGE flag will be automatically added.
     * @param label defines the label of the buffer (for debug purpose)
     */
    constructor(engine: WebGPUEngine, size: number, creationFlags?: number, label?: string);
    private _create;
    /** @internal */
    _rebuild(): void;
    /**
     * Gets underlying native buffer
     * @returns underlying native buffer
     */
    getBuffer(): DataBuffer;
    /**
     * Clears the storage buffer to zeros
     * @param byteOffset the byte offset to start clearing (optional)
     * @param byteLength the byte length to clear (optional)
     */
    clear(byteOffset?: number, byteLength?: number): void;
    /**
     * Updates the storage buffer
     * @param data the data used to update the storage buffer
     * @param byteOffset the byte offset of the data (optional)
     * @param byteLength the byte length of the data (optional)
     */
    update(data: DataArray, byteOffset?: number, byteLength?: number): void;
    /**
     * Reads data from the storage buffer
     * @param offset The offset in the storage buffer to start reading from (default: 0)
     * @param size  The number of bytes to read from the storage buffer (default: capacity of the buffer)
     * @param buffer The buffer to write the data we have read from the storage buffer to (optional)
     * @param noDelay If true, a call to flushFramebuffer will be issued so that the data can be read back immediately. This can speed up data retrieval, at the cost of a small perf penalty (default: false).
     * @returns If not undefined, returns the (promise) buffer (as provided by the 4th parameter) filled with the data, else it returns a (promise) Uint8Array with the data read from the storage buffer
     */
    read(offset?: number, size?: number, buffer?: ArrayBufferView, noDelay?: boolean): Promise<ArrayBufferView>;
    /**
     * Disposes the storage buffer
     */
    dispose(): void;
}

/**
 * Base class of materials working in push mode in babylon JS
 * @internal
 */
declare class PushMaterial extends Material {
    protected _activeEffect?: Effect;
    protected _normalMatrix: Matrix;
    constructor(name: string, scene?: Scene, storeEffectOnSubMeshes?: boolean, forceGLSL?: boolean);
    getEffect(): Effect;
    isReady(mesh?: AbstractMesh, useInstances?: boolean): boolean;
    protected _isReadyForSubMesh(subMesh: SubMesh): boolean;
    /**
     * Binds the given world matrix to the active effect
     *
     * @param world the matrix to bind
     */
    bindOnlyWorldMatrix(world: Matrix): void;
    /**
     * Binds the given normal matrix to the active effect
     *
     * @param normalMatrix the matrix to bind
     */
    bindOnlyNormalMatrix(normalMatrix: Matrix): void;
    bind(world: Matrix, mesh?: Mesh): void;
    protected _afterBind(mesh?: AbstractMesh, effect?: Nullable<Effect>, subMesh?: SubMesh): void;
    protected _mustRebind(scene: Scene, effect: Effect, subMesh: SubMesh, visibility?: number): boolean;
    dispose(forceDisposeEffect?: boolean, forceDisposeTextures?: boolean, notBoundToMesh?: boolean): void;
}

/**
 * Defines the options associated with the creation of a shader material.
 */
interface IShaderMaterialOptions {
    /**
     * Does the material work in alpha blend mode
     */
    needAlphaBlending: boolean;
    /**
     * Does the material work in alpha test mode
     */
    needAlphaTesting: boolean;
    /**
     * The list of attribute names used in the shader
     */
    attributes: string[];
    /**
     * The list of uniform names used in the shader
     */
    uniforms: string[];
    /**
     * The list of UBO names used in the shader
     */
    uniformBuffers: string[];
    /**
     * The list of sampler (texture) names used in the shader
     */
    samplers: string[];
    /**
     * The list of external texture names used in the shader
     */
    externalTextures: string[];
    /**
     * The list of sampler object names used in the shader
     */
    samplerObjects: string[];
    /**
     * The list of storage buffer names used in the shader
     */
    storageBuffers: string[];
    /**
     * The list of defines used in the shader
     */
    defines: string[];
    /**
     * Defines if clip planes have to be turned on: true to turn them on, false to turn them off and null to turn them on/off depending on the scene configuration (scene.clipPlaneX)
     */
    useClipPlane: Nullable<boolean>;
    /**
     * The language the shader is written in (default: GLSL)
     */
    shaderLanguage?: ShaderLanguage;
    /**
     * Defines additional code to call to prepare the shader code
     */
    extraInitializationsAsync?: () => Promise<void>;
}
/**
 * The ShaderMaterial object has the necessary methods to pass data from your scene to the Vertex and Fragment Shaders and returns a material that can be applied to any mesh.
 *
 * This returned material effects how the mesh will look based on the code in the shaders.
 *
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/shaders/shaderMaterial
 */
declare class ShaderMaterial extends PushMaterial {
    private _shaderPath;
    private _options;
    private _textures;
    private _internalTextures;
    private _textureArrays;
    private _externalTextures;
    private _floats;
    private _ints;
    private _uints;
    private _floatsArrays;
    private _colors3;
    private _colors3Arrays;
    private _colors4;
    private _colors4Arrays;
    private _vectors2;
    private _vectors3;
    private _vectors4;
    private _quaternions;
    private _quaternionsArrays;
    private _matrices;
    private _matrixArrays;
    private _matrices3x3;
    private _matrices2x2;
    private _vectors2Arrays;
    private _vectors3Arrays;
    private _vectors4Arrays;
    private _uniformBuffers;
    private _textureSamplers;
    private _storageBuffers;
    private _cachedWorldViewMatrix;
    private _cachedWorldViewProjectionMatrix;
    private _multiview;
    private _vertexPullingMetadata;
    /**
     * @internal
     */
    _materialHelperNeedsPreviousMatrices: boolean;
    /** Define the Url to load snippets */
    static SnippetUrl: string;
    /** Snippet ID if the material was created from the snippet server */
    snippetId: string;
    /**
     * Instantiate a new shader material.
     * The ShaderMaterial object has the necessary methods to pass data from your scene to the Vertex and Fragment Shaders and returns a material that can be applied to any mesh.
     * This returned material effects how the mesh will look based on the code in the shaders.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/shaders/shaderMaterial
     * @param name Define the name of the material in the scene
     * @param scene Define the scene the material belongs to
     * @param shaderPath Defines  the route to the shader code.
     * @param options Define the options used to create the shader
     * @param storeEffectOnSubMeshes true to store effect on submeshes, false to store the effect directly in the material class.
     */
    constructor(name: string, scene: Scene, shaderPath: IShaderPath | string, options?: Partial<IShaderMaterialOptions>, storeEffectOnSubMeshes?: boolean);
    /**
     * Gets the shader path used to define the shader code
     * It can be modified to trigger a new compilation
     */
    get shaderPath(): IShaderPath | string;
    /**
     * Sets the shader path used to define the shader code
     * It can be modified to trigger a new compilation
     */
    set shaderPath(shaderPath: IShaderPath | string);
    /**
     * Gets the options used to compile the shader.
     * They can be modified to trigger a new compilation
     */
    get options(): IShaderMaterialOptions;
    /**
     * is multiview set to true?
     */
    get isMultiview(): boolean;
    /**
     * Gets the current class name of the material e.g. "ShaderMaterial"
     * Mainly use in serialization.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Specifies if the material will require alpha blending
     * @returns a boolean specifying if alpha blending is needed
     */
    needAlphaBlending(): boolean;
    /**
     * Specifies if this material should be rendered in alpha test mode
     * @returns a boolean specifying if an alpha test is needed.
     */
    needAlphaTesting(): boolean;
    private _checkUniform;
    /**
     * Set a texture in the shader.
     * @param name Define the name of the uniform samplers as defined in the shader
     * @param texture Define the texture to bind to this sampler
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setTexture(name: string, texture: BaseTexture): ShaderMaterial;
    /**
     * Set an internal texture in the shader.
     * @param name Define the name of the uniform samplers as defined in the shader
     * @param texture Define the texture to bind to this sampler
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setInternalTexture(name: string, texture: InternalTexture): ShaderMaterial;
    /**
     * Remove a texture from the material.
     * @param name Define the name of the texture to remove
     */
    removeTexture(name: string): void;
    /**
     * Set a texture array in the shader.
     * @param name Define the name of the uniform sampler array as defined in the shader
     * @param textures Define the list of textures to bind to this sampler
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setTextureArray(name: string, textures: BaseTexture[]): ShaderMaterial;
    /**
     * Set an internal texture in the shader.
     * @param name Define the name of the uniform samplers as defined in the shader
     * @param texture Define the texture to bind to this sampler
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setExternalTexture(name: string, texture: ExternalTexture): ShaderMaterial;
    /**
     * Set a float in the shader.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setFloat(name: string, value: number): ShaderMaterial;
    /**
     * Set a int in the shader.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setInt(name: string, value: number): ShaderMaterial;
    /**
     * Set a unsigned int in the shader.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setUInt(name: string, value: number): ShaderMaterial;
    /**
     * Set an array of floats in the shader.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setFloats(name: string, value: number[]): ShaderMaterial;
    /**
     * Set a vec3 in the shader from a Color3.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setColor3(name: string, value: IColor3Like): ShaderMaterial;
    /**
     * Set a vec3 array in the shader from a IColor3Like array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setColor3Array(name: string, value: IColor3Like[]): ShaderMaterial;
    /**
     * Set a vec4 in the shader from a Color4.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setColor4(name: string, value: IColor4Like): ShaderMaterial;
    /**
     * Set a vec4 array in the shader from a IColor4Like array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setColor4Array(name: string, value: IColor4Like[]): ShaderMaterial;
    /**
     * Set a vec2 in the shader from a Vector2.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setVector2(name: string, value: IVector2Like): ShaderMaterial;
    /**
     * Set a vec3 in the shader from a Vector3.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setVector3(name: string, value: IVector3Like): ShaderMaterial;
    /**
     * Set a vec4 in the shader from a Vector4.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setVector4(name: string, value: IVector4Like): ShaderMaterial;
    /**
     * Set a vec4 in the shader from a Quaternion.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setQuaternion(name: string, value: Quaternion): ShaderMaterial;
    /**
     * Set a vec4 array in the shader from a Quaternion array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setQuaternionArray(name: string, value: Quaternion[]): ShaderMaterial;
    /**
     * Set a mat4 in the shader from a Matrix.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setMatrix(name: string, value: Matrix): ShaderMaterial;
    /**
     * Set a float32Array in the shader from a matrix array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setMatrices(name: string, value: Matrix[]): ShaderMaterial;
    /**
     * Set a mat3 in the shader from a Float32Array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setMatrix3x3(name: string, value: Float32Array | Array<number>): ShaderMaterial;
    /**
     * Set a mat2 in the shader from a Float32Array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setMatrix2x2(name: string, value: Float32Array | Array<number>): ShaderMaterial;
    /**
     * Set a vec2 array in the shader from a number array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setArray2(name: string, value: number[]): ShaderMaterial;
    /**
     * Set a vec3 array in the shader from a number array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setArray3(name: string, value: number[]): ShaderMaterial;
    /**
     * Set a vec4 array in the shader from a number array.
     * @param name Define the name of the uniform as defined in the shader
     * @param value Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setArray4(name: string, value: number[]): ShaderMaterial;
    /**
     * Set a uniform buffer in the shader
     * @param name Define the name of the uniform as defined in the shader
     * @param buffer Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setUniformBuffer(name: string, buffer: UniformBuffer): ShaderMaterial;
    /**
     * Set a texture sampler in the shader
     * @param name Define the name of the uniform as defined in the shader
     * @param sampler Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setTextureSampler(name: string, sampler: TextureSampler): ShaderMaterial;
    /**
     * Set a storage buffer in the shader
     * @param name Define the name of the storage buffer as defined in the shader
     * @param buffer Define the value to give to the uniform
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setStorageBuffer(name: string, buffer: StorageBuffer): ShaderMaterial;
    /**
     * Adds, removes, or replaces the specified shader define and value.
     * * setDefine("MY_DEFINE", true); // enables a boolean define
     * * setDefine("MY_DEFINE", "0.5"); // adds "#define MY_DEFINE 0.5" to the shader (or sets and replaces the value of any existing define with that name)
     * * setDefine("MY_DEFINE", false); // disables and removes the define
     * Note if the active defines do change, the shader will be recompiled and this can be expensive.
     * @param define the define name e.g., "OUTPUT_TO_SRGB" or "#define OUTPUT_TO_SRGB". If the define was passed into the constructor already, the version used should match that, and in either case, it should not include any appended value.
     * @param value either the value of the define (e.g. a numerical value) or for booleans, true if the define should be enabled or false if it should be disabled
     * @returns the material itself allowing "fluent" like uniform updates
     */
    setDefine(define: string, value: boolean | string): ShaderMaterial;
    /**
     * Specifies that the submesh is ready to be used
     * @param mesh defines the mesh to check
     * @param subMesh defines which submesh to check
     * @param useInstances specifies that instances should be used
     * @returns a boolean indicating that the submesh is ready or not
     */
    isReadyForSubMesh(mesh: AbstractMesh, subMesh: SubMesh, useInstances?: boolean): boolean;
    /**
     * Checks if the material is ready to render the requested mesh
     * @param mesh Define the mesh to render
     * @param useInstances Define whether or not the material is used with instances
     * @param subMesh defines which submesh to render
     * @returns true if ready, otherwise false
     */
    isReady(mesh?: AbstractMesh, useInstances?: boolean, subMesh?: SubMesh): boolean;
    /**
     * Binds the world matrix to the material
     * @param world defines the world transformation matrix
     * @param effectOverride - If provided, use this effect instead of internal effect
     */
    bindOnlyWorldMatrix(world: Matrix, effectOverride?: Nullable<Effect>): void;
    /**
     * Binds the submesh to this material by preparing the effect and shader to draw
     * @param world defines the world transformation matrix
     * @param mesh defines the mesh containing the submesh
     * @param subMesh defines the submesh to bind the material to
     */
    bindForSubMesh(world: Matrix, mesh: Mesh, subMesh: SubMesh): void;
    /**
     * Binds the material to the mesh
     * @param world defines the world transformation matrix
     * @param mesh defines the mesh to bind the material to
     * @param effectOverride - If provided, use this effect instead of internal effect
     * @param subMesh defines the submesh to bind the material to
     */
    bind(world: Matrix, mesh?: AbstractMesh, effectOverride?: Nullable<Effect>, subMesh?: SubMesh): void;
    /**
     * Gets the active textures from the material
     * @returns an array of textures
     */
    getActiveTextures(): BaseTexture[];
    /**
     * Specifies if the material uses a texture
     * @param texture defines the texture to check against the material
     * @returns a boolean specifying if the material uses the texture
     */
    hasTexture(texture: BaseTexture): boolean;
    /**
     * Makes a duplicate of the material, and gives it a new name
     * @param name defines the new name for the duplicated material
     * @returns the cloned material
     */
    clone(name: string): ShaderMaterial;
    /**
     * Disposes the material
     * @param forceDisposeEffect specifies if effects should be forcefully disposed
     * @param forceDisposeTextures specifies if textures should be forcefully disposed
     * @param notBoundToMesh specifies if the material that is being disposed is known to be not bound to any mesh
     */
    dispose(forceDisposeEffect?: boolean, forceDisposeTextures?: boolean, notBoundToMesh?: boolean): void;
    /**
     * Serializes this material in a JSON representation
     * @returns the serialized material object
     */
    serialize(): any;
    /**
     * Creates a shader material from parsed shader material data
     * @param source defines the JSON representation of the material
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a new material
     */
    static Parse(source: any, scene: Scene, rootUrl: string): ShaderMaterial;
    /**
     * Creates a new ShaderMaterial from a snippet saved in a remote file
     * @param name defines the name of the ShaderMaterial to create (can be null or empty to use the one from the json data)
     * @param url defines the url to load from
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a promise that will resolve to the new ShaderMaterial
     */
    static ParseFromFileAsync(name: Nullable<string>, url: string, scene: Scene, rootUrl?: string): Promise<ShaderMaterial>;
    /**
     * Creates a ShaderMaterial from a snippet saved by the Inspector
     * @param snippetId defines the snippet to load
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a promise that will resolve to the new ShaderMaterial
     */
    static ParseFromSnippetAsync(snippetId: string, scene: Scene, rootUrl?: string): Promise<ShaderMaterial>;
    /**
     * Creates a ShaderMaterial from a snippet saved by the Inspector
     * @deprecated Please use ParseFromSnippetAsync instead
     * @param snippetId defines the snippet to load
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a promise that will resolve to the new ShaderMaterial
     */
    static CreateFromSnippetAsync: typeof ShaderMaterial.ParseFromSnippetAsync;
}

declare module "../scene" {
    interface Scene {
        /** @internal */
        _edgeRenderLineShader: Nullable<ShaderMaterial>;
    }
}
declare module "../Meshes/abstractMesh" {
    interface AbstractMesh {
        /**
         * Gets the edgesRenderer associated with the mesh
         */
        edgesRenderer: Nullable<EdgesRenderer>;
    }
}
declare module "../Meshes/linesMesh" {
    interface LinesMesh {
        /**
         * Enables the edge rendering mode on the mesh.
         * This mode makes the mesh edges visible
         * @param epsilon defines the maximal distance between two angles to detect a face
         * @param checkVerticesInsteadOfIndices indicates that we should check vertex list directly instead of faces
         * @returns the currentAbstractMesh
         * @see https://www.babylonjs-playground.com/#19O9TU#0
         */
        enableEdgesRendering(epsilon?: number, checkVerticesInsteadOfIndices?: boolean): AbstractMesh;
    }
}
declare module "../Meshes/linesMesh" {
    interface InstancedLinesMesh {
        /**
         * Enables the edge rendering mode on the mesh.
         * This mode makes the mesh edges visible
         * @param epsilon defines the maximal distance between two angles to detect a face
         * @param checkVerticesInsteadOfIndices indicates that we should check vertex list directly instead of faces
         * @returns the current InstancedLinesMesh
         * @see https://www.babylonjs-playground.com/#19O9TU#0
         */
        enableEdgesRendering(epsilon?: number, checkVerticesInsteadOfIndices?: boolean): InstancedLinesMesh;
    }
}
/**
 * Defines the minimum contract an Edges renderer should follow.
 */
interface IEdgesRenderer extends IDisposable {
    /**
     * Gets or sets a boolean indicating if the edgesRenderer is active
     */
    isEnabled: boolean;
    /**
     * Renders the edges of the attached mesh,
     */
    render(): void;
    /**
     * Checks whether or not the edges renderer is ready to render.
     * @returns true if ready, otherwise false.
     */
    isReady(): boolean;
    /**
     * List of instances to render in case the source mesh has instances
     */
    customInstances: SmartArray<Matrix>;
}
/**
 * Defines the additional options of the edges renderer
 */
interface IEdgesRendererOptions {
    /**
     * Gets or sets a boolean indicating that the alternate edge finder algorithm must be used
     * If not defined, the default value is true
     */
    useAlternateEdgeFinder?: boolean;
    /**
     * Gets or sets a boolean indicating that the vertex merger fast processing must be used.
     * If not defined, the default value is true.
     * You should normally leave it undefined (or set it to true), except if you see some artifacts in the edges rendering (can happen with complex geometries)
     * This option is used only if useAlternateEdgeFinder = true
     */
    useFastVertexMerger?: boolean;
    /**
     * During edges processing, the vertices are merged if they are close enough: epsilonVertexMerge is the limit within which vertices are considered to be equal.
     * The default value is 1e-6
     * This option is used only if useAlternateEdgeFinder = true
     */
    epsilonVertexMerge?: number;
    /**
     * Gets or sets a boolean indicating that tessellation should be applied before finding the edges. You may need to activate this option if your geometry is a bit
     * unusual, like having a vertex of a triangle in-between two vertices of an edge of another triangle. It happens often when using CSG to construct meshes.
     * This option is used only if useAlternateEdgeFinder = true
     */
    applyTessellation?: boolean;
    /**
     * The limit under which 3 vertices are considered to be aligned. 3 vertices PQR are considered aligned if distance(PQ) + distance(QR) - distance(PR) < epsilonVertexAligned
     * The default value is 1e-6
     * This option is used only if useAlternateEdgeFinder = true
     */
    epsilonVertexAligned?: number;
    /**
     * Gets or sets a boolean indicating that degenerated triangles should not be processed.
     * Degenerated triangles are triangles that have 2 or 3 vertices with the same coordinates
     */
    removeDegeneratedTriangles?: boolean;
}
/**
 * This class is used to generate edges of the mesh that could then easily be rendered in a scene.
 */
declare class EdgesRenderer implements IEdgesRenderer {
    /**
     * Define the size of the edges with an orthographic camera
     */
    edgesWidthScalerForOrthographic: number;
    /**
     * Define the size of the edges with a perspective camera
     */
    edgesWidthScalerForPerspective: number;
    protected _source: AbstractMesh;
    protected _linesPositions: number[];
    protected _linesNormals: number[];
    protected _linesIndices: number[];
    protected _epsilon: number;
    protected _indicesCount: number;
    protected _drawWrapper?: DrawWrapper;
    protected _lineShader: ShaderMaterial;
    protected _ib: DataBuffer;
    protected _buffers: {
        [key: string]: Nullable<VertexBuffer>;
    };
    protected _buffersForInstances: {
        [key: string]: Nullable<VertexBuffer>;
    };
    protected _checkVerticesInsteadOfIndices: boolean;
    protected _options: Nullable<IEdgesRendererOptions>;
    private _meshRebuildObserver;
    private _meshDisposeObserver;
    /** Gets or sets a boolean indicating if the edgesRenderer is active */
    isEnabled: boolean;
    /** Gets the vertices generated by the edge renderer */
    get linesPositions(): Immutable<Array<number>>;
    /** Gets the normals generated by the edge renderer */
    get linesNormals(): Immutable<Array<number>>;
    /** Gets the indices generated by the edge renderer */
    get linesIndices(): Immutable<Array<number>>;
    /**
     * Gets or sets the shader used to draw the lines
     */
    get lineShader(): ShaderMaterial;
    set lineShader(shader: ShaderMaterial);
    /**
     * List of instances to render in case the source mesh has instances
     */
    customInstances: SmartArray<Matrix>;
    private static _GetShader;
    /** Shader language used*/
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Creates an instance of the EdgesRenderer. It is primarily use to display edges of a mesh.
     * Beware when you use this class with complex objects as the adjacencies computation can be really long
     * @param  source Mesh used to create edges
     * @param  epsilon sum of angles in adjacency to check for edge
     * @param  checkVerticesInsteadOfIndices bases the edges detection on vertices vs indices. Note that this parameter is not used if options.useAlternateEdgeFinder = true
     * @param  generateEdgesLines - should generate Lines or only prepare resources.
     * @param  options The options to apply when generating the edges
     */
    constructor(source: AbstractMesh, epsilon?: number, checkVerticesInsteadOfIndices?: boolean, generateEdgesLines?: boolean, options?: IEdgesRendererOptions);
    protected _prepareResources(): void;
    /** @internal */
    _rebuild(): void;
    /**
     * Releases the required resources for the edges renderer
     */
    dispose(): void;
    protected _processEdgeForAdjacencies(pa: number, pb: number, p0: number, p1: number, p2: number): number;
    protected _processEdgeForAdjacenciesWithVertices(pa: Vector3, pb: Vector3, p0: Vector3, p1: Vector3, p2: Vector3): number;
    /**
     * Checks if the pair of p0 and p1 is en edge
     * @param faceIndex
     * @param edge
     * @param faceNormals
     * @param  p0
     * @param  p1
     * @private
     */
    protected _checkEdge(faceIndex: number, edge: number, faceNormals: Array<Vector3>, p0: Vector3, p1: Vector3): void;
    /**
     * push line into the position, normal and index buffer
     * @param p0
     * @param p1
     * @param offset
     * @protected
     */
    protected createLine(p0: Vector3, p1: Vector3, offset: number): void;
    /**
     * See https://playground.babylonjs.com/#R3JR6V#1 for a visual display of the algorithm
     * @param edgePoints
     * @param indexTriangle
     * @param indices
     * @param remapVertexIndices
     */
    private _tessellateTriangle;
    private _generateEdgesLinesAlternate;
    /**
     * Generates lines edges from adjacencjes
     * @private
     */
    _generateEdgesLines(): void;
    /**
     * Checks whether or not the edges renderer is ready to render.
     * @returns true if ready, otherwise false.
     */
    isReady(): boolean;
    /**
     * Renders the edges of the attached mesh,
     */
    render(): void;
}

/**
 * This represents the object necessary to create a rendering group.
 * This is exclusively used and created by the rendering manager.
 * To modify the behavior, you use the available helpers in your scene or meshes.
 * @internal
 */
declare class RenderingGroup {
    index: number;
    private static _ZeroVector;
    private _scene;
    private _opaqueSubMeshes;
    /** @internal */
    _transparentSubMeshes: SmartArray<SubMesh>;
    private _alphaTestSubMeshes;
    private _depthOnlySubMeshes;
    private _particleSystems;
    private _spriteManagers;
    private _opaqueSortCompareFn;
    private _alphaTestSortCompareFn;
    private _transparentSortCompareFn;
    private _renderOpaque;
    private _renderAlphaTest;
    /** @internal */
    _renderTransparent: (subMeshes: SmartArray<SubMesh>) => void;
    /** @internal */
    _empty: boolean;
    /** @internal */
    _edgesRenderers: SmartArrayNoDuplicate<IEdgesRenderer>;
    onBeforeTransparentRendering: () => void;
    disableDepthPrePass: boolean;
    /**
     * Set the opaque sort comparison function.
     * If null the sub meshes will be render in the order they were created
     */
    set opaqueSortCompareFn(value: Nullable<(a: SubMesh, b: SubMesh) => number>);
    /**
     * Set the alpha test sort comparison function.
     * If null the sub meshes will be render in the order they were created
     */
    set alphaTestSortCompareFn(value: Nullable<(a: SubMesh, b: SubMesh) => number>);
    /**
     * Set the transparent sort comparison function.
     * If null the sub meshes will be render in the order they were created
     */
    set transparentSortCompareFn(value: Nullable<(a: SubMesh, b: SubMesh) => number>);
    /**
     * Creates a new rendering group.
     * @param index The rendering group index
     * @param scene
     * @param opaqueSortCompareFn The opaque sort comparison function. If null no order is applied
     * @param alphaTestSortCompareFn The alpha test sort comparison function. If null no order is applied
     * @param transparentSortCompareFn The transparent sort comparison function. If null back to front + alpha index sort is applied
     */
    constructor(index: number, scene: Scene, opaqueSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, alphaTestSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, transparentSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>);
    /**
     * Render all the sub meshes contained in the group.
     * @param customRenderFunction Used to override the default render behaviour of the group.
     * @param renderSprites
     * @param renderParticles
     * @param activeMeshes
     * @param renderDepthOnlyMeshes
     * @param renderOpaqueMeshes
     * @param renderAlphaTestMeshes
     * @param renderTransparentMeshes
     * @param customRenderTransparentSubMeshes
     */
    render(customRenderFunction: Nullable<(opaqueSubMeshes: SmartArray<SubMesh>, transparentSubMeshes: SmartArray<SubMesh>, alphaTestSubMeshes: SmartArray<SubMesh>, depthOnlySubMeshes: SmartArray<SubMesh>) => void>, renderSprites: boolean, renderParticles: boolean, activeMeshes: Nullable<AbstractMesh[]>, renderDepthOnlyMeshes?: boolean, renderOpaqueMeshes?: boolean, renderAlphaTestMeshes?: boolean, renderTransparentMeshes?: boolean, customRenderTransparentSubMeshes?: (transparentSubMeshes: SmartArray<SubMesh>) => void): void;
    /**
     * Renders the opaque submeshes in the order from the opaqueSortCompareFn.
     * @param subMeshes The submeshes to render
     */
    private _renderOpaqueSorted;
    /**
     * Renders the opaque submeshes in the order from the alphatestSortCompareFn.
     * @param subMeshes The submeshes to render
     */
    private _renderAlphaTestSorted;
    /**
     * Renders the opaque submeshes in the order from the transparentSortCompareFn.
     * @param subMeshes The submeshes to render
     */
    private _renderTransparentSorted;
    /**
     * Renders the submeshes in a specified order.
     * @param subMeshes The submeshes to sort before render
     * @param sortCompareFn The comparison function use to sort
     * @param camera The camera position use to preprocess the submeshes to help sorting
     * @param transparent Specifies to activate blending if true
     * @param disableDepthPrePass Specifies to disable depth pre-pass if true (default: false)
     */
    private static _RenderSorted;
    /**
     * Build in function which can be applied to ensure meshes of a special queue (opaque, alpha test, transparent)
     * are rendered back to front if in the same alpha index.
     *
     * @param a The first submesh
     * @param b The second submesh
     * @returns The result of the comparison
     */
    static defaultTransparentSortCompare(a: SubMesh, b: SubMesh): number;
    /**
     * Build in function which can be applied to ensure meshes of a special queue (opaque, alpha test, transparent)
     * are rendered back to front.
     *
     * @param a The first submesh
     * @param b The second submesh
     * @returns The result of the comparison
     */
    static backToFrontSortCompare(a: SubMesh, b: SubMesh): number;
    /**
     * Build in function which can be applied to ensure meshes of a special queue (opaque, alpha test, transparent)
     * are rendered front to back (prevent overdraw).
     *
     * @param a The first submesh
     * @param b The second submesh
     * @returns The result of the comparison
     */
    static frontToBackSortCompare(a: SubMesh, b: SubMesh): number;
    /**
     * Build in function which can be applied to ensure meshes of a special queue (opaque, alpha test, transparent)
     * are grouped by material then geometry.
     *
     * @param a The first submesh
     * @param b The second submesh
     * @returns The result of the comparison
     */
    static PainterSortCompare(a: SubMesh, b: SubMesh): number;
    /**
     * Resets the different lists of submeshes to prepare a new frame.
     */
    prepare(): void;
    /**
     * Resets the different lists of sprites to prepare a new frame.
     */
    prepareSprites(): void;
    dispose(): void;
    /**
     * Inserts the submesh in its correct queue depending on its material.
     * @param subMesh The submesh to dispatch
     * @param [mesh] Optional reference to the submeshes's mesh. Provide if you have an exiting reference to improve performance.
     * @param [material] Optional reference to the submeshes's material. Provide if you have an exiting reference to improve performance.
     */
    dispatch(subMesh: SubMesh, mesh?: AbstractMesh, material?: Nullable<Material>): void;
    dispatchSprites(spriteManager: ISpriteManager): void;
    dispatchParticles(particleSystem: IParticleSystem): void;
    private _renderParticles;
    private _renderSprites;
}

/**
 * Interface describing the different options available in the rendering manager
 * regarding Auto Clear between groups.
 */
interface IRenderingManagerAutoClearSetup {
    /**
     * Defines whether or not autoclear is enable.
     */
    autoClear: boolean;
    /**
     * Defines whether or not to autoclear the depth buffer.
     */
    depth: boolean;
    /**
     * Defines whether or not to autoclear the stencil buffer.
     */
    stencil: boolean;
}
/**
 * This class is used by the onRenderingGroupObservable
 */
declare class RenderingGroupInfo {
    /**
     * The Scene that being rendered
     */
    scene: Scene;
    /**
     * The camera currently used for the rendering pass
     */
    camera: Nullable<Camera>;
    /**
     * The ID of the renderingGroup being processed
     */
    renderingGroupId: number;
    /**
     * The rendering manager
     */
    renderingManager: RenderingManager;
}
/**
 * This is the manager responsible of all the rendering for meshes sprites and particles.
 * It is enable to manage the different groups as well as the different necessary sort functions.
 * This should not be used directly aside of the few static configurations
 */
declare class RenderingManager {
    /**
     * The max id used for rendering groups (not included)
     */
    static MAX_RENDERINGGROUPS: number;
    /**
     * The min id used for rendering groups (included)
     */
    static MIN_RENDERINGGROUPS: number;
    /**
     * Used to globally prevent autoclearing scenes.
     */
    static AUTOCLEAR: boolean;
    /**
     * @internal
     */
    _useSceneAutoClearSetup: boolean;
    private _disableDepthPrePass;
    /**
     * Specifies to disable depth pre-pass if true (default: false)
     */
    get disableDepthPrePass(): boolean;
    set disableDepthPrePass(value: boolean);
    private _scene;
    private _renderingGroups;
    private _depthStencilBufferAlreadyCleaned;
    private _autoClearDepthStencil;
    private _customOpaqueSortCompareFn;
    private _customAlphaTestSortCompareFn;
    private _customTransparentSortCompareFn;
    private _renderingGroupInfo;
    private _maintainStateBetweenFrames;
    /**
     * Gets or sets a boolean indicating that the manager will not reset between frames.
     * This means that if a mesh becomes invisible or transparent it will not be visible until this boolean is set to false again.
     * By default, the rendering manager will dispatch all active meshes per frame (moving them to the transparent, opaque or alpha testing lists).
     * By turning this property on, you will accelerate the rendering by keeping all these lists unchanged between frames.
     */
    get maintainStateBetweenFrames(): boolean;
    set maintainStateBetweenFrames(value: boolean);
    /**
     * Restore wasDispatched flags on the lists of elements to render.
     */
    restoreDispachedFlags(): void;
    /**
     * Instantiates a new rendering group for a particular scene
     * @param scene Defines the scene the groups belongs to
     */
    constructor(scene: Scene);
    /**
     * @returns the list of rendering groups managed by the manager.
     */
    get renderingGroups(): Immutable<RenderingGroup[]>;
    /**
     * @returns the rendering group with the specified id.
     * @param id the id of the rendering group (0 by default)
     */
    getRenderingGroup(id: number): RenderingGroup;
    private _clearDepthStencilBuffer;
    /**
     * Renders the entire managed groups. This is used by the scene or the different render targets.
     * @internal
     */
    render(customRenderFunction: Nullable<(opaqueSubMeshes: SmartArray<SubMesh>, transparentSubMeshes: SmartArray<SubMesh>, alphaTestSubMeshes: SmartArray<SubMesh>, depthOnlySubMeshes: SmartArray<SubMesh>) => void>, activeMeshes: Nullable<AbstractMesh[]>, renderParticles: boolean, renderSprites: boolean, renderDepthOnlyMeshes?: boolean, renderOpaqueMeshes?: boolean, renderAlphaTestMeshes?: boolean, renderTransparentMeshes?: boolean, customRenderTransparentSubMeshes?: (transparentSubMeshes: SmartArray<SubMesh>) => void): void;
    /**
     * Resets the different information of the group to prepare a new frame
     * @internal
     */
    reset(): void;
    /**
     * Resets the sprites information of the group to prepare a new frame
     * @internal
     */
    resetSprites(): void;
    /**
     * Dispose and release the group and its associated resources.
     * @internal
     */
    dispose(): void;
    /**
     * Clear the info related to rendering groups preventing retention points during dispose.
     */
    freeRenderingGroups(): void;
    private _prepareRenderingGroup;
    /**
     * Add a sprite manager to the rendering manager in order to render it this frame.
     * @param spriteManager Define the sprite manager to render
     */
    dispatchSprites(spriteManager: ISpriteManager): void;
    /**
     * Add a particle system to the rendering manager in order to render it this frame.
     * @param particleSystem Define the particle system to render
     */
    dispatchParticles(particleSystem: IParticleSystem): void;
    /**
     * Add a submesh to the manager in order to render it this frame
     * @param subMesh The submesh to dispatch
     * @param mesh Optional reference to the submeshes's mesh. Provide if you have an exiting reference to improve performance.
     * @param material Optional reference to the submeshes's material. Provide if you have an exiting reference to improve performance.
     */
    dispatch(subMesh: SubMesh, mesh?: AbstractMesh, material?: Nullable<Material>): void;
    /**
     * Overrides the default sort function applied in the rendering group to prepare the meshes.
     * This allowed control for front to back rendering or reversely depending of the special needs.
     *
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param opaqueSortCompareFn The opaque queue comparison function use to sort.
     * @param alphaTestSortCompareFn The alpha test queue comparison function use to sort.
     * @param transparentSortCompareFn The transparent queue comparison function use to sort.
     */
    setRenderingOrder(renderingGroupId: number, opaqueSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, alphaTestSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, transparentSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>): void;
    /**
     * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups.
     *
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
     * @param depth Automatically clears depth between groups if true and autoClear is true.
     * @param stencil Automatically clears stencil between groups if true and autoClear is true.
     */
    setRenderingAutoClearDepthStencil(renderingGroupId: number, autoClearDepthStencil: boolean, depth?: boolean, stencil?: boolean): void;
    /**
     * Gets the current auto clear configuration for one rendering group of the rendering
     * manager.
     * @param index the rendering group index to get the information for
     * @returns The auto clear setup for the requested rendering group
     */
    getAutoClearDepthStencilSetup(index: number): IRenderingManagerAutoClearSetup;
}

/**
 * Defines the options of the object renderer
 */
interface ObjectRendererOptions {
    /** The number of passes the renderer will support (1 by default) */
    numPasses?: number;
    /** True (default) to not change the aspect ratio of the scene in the RTT */
    doNotChangeAspectRatio?: boolean;
    /** True to enable clustered lights (default: false) */
    enableClusteredLights?: boolean;
}
/**
 * A class that renders objects to the currently bound render target.
 * This class only renders objects, and is not concerned with the output texture or post-processing.
 */
declare class ObjectRenderer {
    /**
     * Objects will only be rendered once which can be useful to improve performance if everything in your render is static for instance.
     */
    static readonly REFRESHRATE_RENDER_ONCE: number;
    /**
     * Objects will be rendered every frame and is recommended for dynamic contents.
     */
    static readonly REFRESHRATE_RENDER_ONEVERYFRAME: number;
    /**
     * Objects will be rendered every 2 frames which could be enough if your dynamic objects are not
     * the central point of your effect and can save a lot of performances.
     */
    static readonly REFRESHRATE_RENDER_ONEVERYTWOFRAMES: number;
    /**
     * Use this predicate to dynamically define the list of mesh you want to render.
     * If set, the renderList property will be overwritten.
     */
    renderListPredicate: (AbstractMesh: AbstractMesh) => boolean;
    private _renderList;
    private _unObserveRenderList;
    /**
     * Use this list to define the list of mesh you want to render.
     */
    get renderList(): Nullable<Array<AbstractMesh>>;
    set renderList(value: Nullable<Array<AbstractMesh>>);
    private _renderListHasChanged;
    /**
     * Define the list of particle systems to render. If not provided, will render all the particle systems of the scene.
     * Note that the particle systems are rendered only if renderParticles is set to true.
     */
    particleSystemList: Nullable<Array<IParticleSystem>>;
    /**
     * Use this function to overload the renderList array at rendering time.
     * Return null to render with the current renderList, else return the list of meshes to use for rendering.
     * For 2DArray, layerOrFace is the index of the layer that is going to be rendered, else it is the faceIndex of
     * the cube (if the RTT is a cube, else layerOrFace=0).
     * The renderList passed to the function is the current render list (the one that will be used if the function returns null).
     * The length of this list is passed through renderListLength: don't use renderList.length directly because the array can
     * hold dummy elements!
     */
    getCustomRenderList: Nullable<(layerOrFace: number, renderList: Nullable<Immutable<Array<AbstractMesh>>>, renderListLength: number) => Nullable<Array<AbstractMesh>>>;
    /**
     * Define if meshes should be rendered (default is true).
     */
    renderMeshes: boolean;
    /**
     * Define if depth only meshes should be rendered (default is true). No effect if renderMeshes is false.
     */
    renderDepthOnlyMeshes: boolean;
    /**
     * Define if opaque meshes should be rendered (default is true). No effect if renderMeshes is false.
     */
    renderOpaqueMeshes: boolean;
    /**
     * Define if alpha test meshes should be rendered (default is true). No effect if renderMeshes is false.
     */
    renderAlphaTestMeshes: boolean;
    /**
     * Define if transparent meshes should be rendered (default is true). No effect if renderMeshes is false.
     */
    renderTransparentMeshes: boolean;
    /**
     * Custom render function for transparent submeshes.
     */
    customRenderTransparentSubMeshes?: (transparentSubMeshes: SmartArray<SubMesh>) => void;
    /**
     * Define if particles should be rendered (default is true).
     */
    renderParticles: boolean;
    /**
     * Define if sprites should be rendered (default is false).
     */
    renderSprites: boolean;
    /**
     * Force checking the layerMask property even if a custom list of meshes is provided (ie. if renderList is not undefined)
     */
    forceLayerMaskCheck: boolean;
    /**
     * Enables the rendering of bounding boxes for meshes (still subject to Mesh.showBoundingBox or scene.forceShowBoundingBoxes). Default is false.
     */
    enableBoundingBoxRendering: boolean;
    /**
     * Enables the rendering of outline/overlay for meshes (still subject to Mesh.renderOutline/Mesh.renderOverlay). Default is true.
     */
    enableOutlineRendering: boolean;
    /**
     * Define the camera used to render the objects.
     */
    activeCamera: Nullable<Camera>;
    /**
     * Define the camera used to calculate the LOD of the objects.
     * If not defined, activeCamera will be used. If not defined nor activeCamera, scene's active camera will be used.
     */
    cameraForLOD: Nullable<Camera>;
    private _disableImageProcessing;
    /**
     * If true, the object renderer will render all objects without any image processing applied.
     * If false (default value), the renderer will use the current setting of the scene's image processing configuration.
     */
    get disableImageProcessing(): boolean;
    set disableImageProcessing(value: boolean);
    /**
     * If true, the object renderer will not set the view/projection/transformation matrices for the active camera (default: false).
     * By default, the view/projection/transformation matrices are set from the active camera (either ObjectRenderer.activeCamera or scene.activeCamera).
     * Sets this property to true if you want to define your own transformation matrices (use the onInitRenderingObservable observable
     * to set your own matrices, to be sure they will be correctly taken into account)
     */
    dontSetTransformationMatrix: boolean;
    private _disableDepthPrePass;
    /**
     * Specifies to disable depth pre-pass if true (default: false)
     */
    get disableDepthPrePass(): boolean;
    set disableDepthPrePass(value: boolean);
    /**
     * Override the mesh isReady function with your own one.
     */
    customIsReadyFunction: (mesh: AbstractMesh, refreshRate: number, preWarm?: boolean) => boolean;
    /**
     * Override the render function with your own one.
     */
    customRenderFunction: (opaqueSubMeshes: SmartArray<SubMesh>, alphaTestSubMeshes: SmartArray<SubMesh>, transparentSubMeshes: SmartArray<SubMesh>, depthOnlySubMeshes: SmartArray<SubMesh>, beforeTransparents?: () => void) => void;
    /**
     * An event triggered before rendering the objects
     */
    readonly onBeforeRenderObservable: Observable<number>;
    /**
     * An event triggered after rendering the objects
     */
    readonly onAfterRenderObservable: Observable<number>;
    /**
     * An event triggered before the rendering group is processed
     */
    readonly onBeforeRenderingManagerRenderObservable: Observable<number>;
    /**
     * An event triggered after the rendering group is processed
     */
    readonly onAfterRenderingManagerRenderObservable: Observable<number>;
    /**
     * An event triggered when initRender is called
     */
    readonly onInitRenderingObservable: Observable<ObjectRenderer>;
    /**
     * An event triggered when finishRender is called
     */
    readonly onFinishRenderingObservable: Observable<ObjectRenderer>;
    /**
     * An event triggered when fast path rendering is used
     */
    readonly onFastPathRenderObservable: Observable<number>;
    protected _engine: AbstractEngine;
    protected _scene: Scene;
    protected _renderingManager: RenderingManager;
    /** @internal */
    _waitingRenderList?: string[];
    protected _currentRefreshId: number;
    protected _refreshRate: number;
    protected _currentApplyByPostProcessSetting: boolean;
    protected _activeMeshes: SmartArray<AbstractMesh>;
    protected _activeBoundingBoxes: SmartArray<BoundingBox>;
    protected _useUBO: boolean;
    protected _sceneUBOs: UniformBuffer[];
    protected _currentSceneUBO: UniformBuffer;
    protected _currentFrameId: number;
    protected _currentSceneUBOIndex: number;
    /**
     * The options used by the object renderer
     */
    options: Required<ObjectRendererOptions>;
    private _name;
    /**
     * Friendly name of the object renderer
     */
    get name(): string;
    set name(value: string);
    /**
     * Current render pass id. Note it can change over the rendering as there's a separate id for each face of a cube / each layer of an array layer!
     */
    renderPassId: number;
    private readonly _renderPassIds;
    /**
     * Gets the render pass ids used by the object renderer.
     */
    get renderPassIds(): readonly number[];
    /**
     * Gets the current value of the refreshId counter
     */
    get currentRefreshId(): number;
    /**
     * Gets the array of active meshes
     * @returns an array of AbstractMesh
     */
    getActiveMeshes(): SmartArray<AbstractMesh>;
    /**
     * Sets a specific material to be used to render a mesh/a list of meshes with this object renderer
     * @param mesh mesh or array of meshes
     * @param material material or array of materials to use for this render pass. If undefined is passed, no specific material will be used but the regular material instead (mesh.material). It's possible to provide an array of materials to use a different material for each rendering pass.
     */
    setMaterialForRendering(mesh: AbstractMesh | AbstractMesh[], material?: Material | Material[]): void;
    /** @internal */
    _isFrozen: boolean;
    /** @internal */
    _freezeActiveMeshesCancel: Nullable<() => void>;
    /** @internal */
    _freezeActiveMeshes(freezeMeshes: boolean): void;
    /** @internal */
    _unfreezeActiveMeshes(): void;
    /**
     * Instantiates an object renderer.
     * @param name The friendly name of the object renderer
     * @param scene The scene the renderer belongs to
     * @param options The options used to create the renderer (optional)
     */
    constructor(name: string, scene: Scene, options?: ObjectRendererOptions);
    private _releaseRenderPassId;
    private _createRenderPassId;
    private _createSceneUBO;
    private _getSceneUBO;
    /**
     * Resets the refresh counter of the renderer and start back from scratch.
     * Could be useful to re-render if it is setup to render only once.
     */
    resetRefreshCounter(): void;
    /**
     * Defines the refresh rate of the rendering or the rendering frequency.
     * Use 0 to render just once, 1 to render on every frame, 2 to render every two frames and so on...
     */
    get refreshRate(): number;
    set refreshRate(value: number);
    /**
     * Indicates if the renderer should render the current frame.
     * The output is based on the specified refresh rate.
     * @returns true if the renderer should render the current frame
     */
    shouldRender(): boolean;
    /**
     * This function will check if the renderer is ready to render (textures are loaded, shaders are compiled)
     * @param viewportWidth defines the width of the viewport
     * @param viewportHeight defines the height of the viewport
     * @returns true if all required resources are ready
     */
    isReadyForRendering(viewportWidth: number, viewportHeight: number): boolean;
    /**
     * Makes sure the list of meshes is ready to be rendered
     * You should call this function before "initRender", but if you know the render list is ok, you may call "initRender" directly
     */
    prepareRenderList(): void;
    private _defaultRenderListPrepared;
    private _currentSceneCamera;
    /**
     * This method makes sure everything is setup before "render" can be called
     * @param viewportWidth Width of the viewport to render to
     * @param viewportHeight Height of the viewport to render to
     */
    initRender(viewportWidth: number, viewportHeight: number): void;
    /**
     * This method must be called after the "render" call(s), to complete the rendering process.
     */
    finishRender(): void;
    /**
     * Renders all the objects (meshes, particles systems, sprites) to the currently bound render target texture.
     * @param passIndex defines the pass index to use (default: 0)
     * @param skipOnAfterRenderObservable defines a flag to skip raising the onAfterRenderObservable
     */
    render(passIndex?: number, skipOnAfterRenderObservable?: boolean): void;
    /** @internal */
    _checkReadiness(): boolean;
    private _prepareRenderingManager;
    /**
     * Gets the rendering manager
     */
    get renderingManager(): RenderingManager;
    /**
     * Overrides the default sort function applied in the rendering group to prepare the meshes.
     * This allowed control for front to back rendering or reversely depending of the special needs.
     *
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param opaqueSortCompareFn The opaque queue comparison function use to sort.
     * @param alphaTestSortCompareFn The alpha test queue comparison function use to sort.
     * @param transparentSortCompareFn The transparent queue comparison function use to sort.
     */
    setRenderingOrder(renderingGroupId: number, opaqueSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, alphaTestSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, transparentSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>): void;
    /**
     * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups.
     *
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
     * @param depth Automatically clears depth between groups if true and autoClear is true.
     * @param stencil Automatically clears stencil between groups if true and autoClear is true.
     */
    setRenderingAutoClearDepthStencil(renderingGroupId: number, autoClearDepthStencil: boolean, depth?: boolean, stencil?: boolean): void;
    /**
     * Clones the renderer.
     * @returns the cloned renderer
     */
    clone(): ObjectRenderer;
    /**
     * Dispose the renderer and release its associated resources.
     */
    dispose(): void;
    /** @internal */
    _rebuild(): void;
    /**
     * Clear the info related to rendering groups preventing retention point in material dispose.
     */
    freeRenderingGroups(): void;
}

declare module "../effect" {
    interface Effect {
        /**
         * Sets a depth stencil texture from a render target on the engine to be used in the shader.
         * @param channel Name of the sampler variable.
         * @param texture Texture to set.
         */
        setDepthStencilTexture(channel: string, texture: Nullable<RenderTargetTexture>): void;
    }
}
/**
 * Options for the RenderTargetTexture constructor
 */
interface RenderTargetTextureOptions {
    /** True (default: false) if mipmaps need to be generated after render */
    generateMipMaps?: boolean;
    /** True (default) to not change the aspect ratio of the scene in the RTT */
    doNotChangeAspectRatio?: boolean;
    /** The type of the buffer in the RTT (byte (default), half float, float...) */
    type?: number;
    /** True (default: false) if a cube texture needs to be created */
    isCube?: boolean;
    /** The sampling mode to be used with the render target (Trilinear (default), Linear, Nearest...) */
    samplingMode?: number;
    /** True (default) to generate a depth buffer */
    generateDepthBuffer?: boolean;
    /** True (default: false) to generate a stencil buffer */
    generateStencilBuffer?: boolean;
    /** True (default: false) if multiple textures need to be created (Draw Buffers) */
    isMulti?: boolean;
    /** The internal format of the buffer in the RTT (RED, RG, RGB, RGBA (default), ALPHA...) */
    format?: number;
    /** True (default: false) if the texture allocation should be delayed */
    delayAllocation?: boolean;
    /** Sample count to use when creating the RTT */
    samples?: number;
    /** specific flags to use when creating the texture (e.g., Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures) */
    creationFlags?: number;
    /** True (default: false) to indicate that no color target should be created. (e.g., if you only want to write to the depth buffer) */
    noColorAttachment?: boolean;
    /** Specifies the internal texture to use directly instead of creating one (ignores `noColorAttachment` flag when set) **/
    colorAttachment?: InternalTexture;
    /** True (default: false) to create a SRGB texture */
    useSRGBBuffer?: boolean;
    /** Defines the underlying texture texture space */
    gammaSpace?: boolean;
    /** If not provided (default), a new object renderer instance will be created */
    existingObjectRenderer?: ObjectRenderer;
    /** True to enable clustered lights (default: false) */
    enableClusteredLights?: boolean;
}
/**
 * This Helps creating a texture that will be created from a camera in your scene.
 * It is basically a dynamic texture that could be used to create special effects for instance.
 * Actually, It is the base of lot of effects in the framework like post process, shadows, effect layers and rendering pipelines...
 */
declare class RenderTargetTexture extends Texture implements IRenderTargetTexture {
    /**
     * The texture will only be rendered once which can be useful to improve performance if everything in your render is static for instance.
     */
    static readonly REFRESHRATE_RENDER_ONCE: number;
    /**
     * The texture will be rendered every frame and is recommended for dynamic contents.
     */
    static readonly REFRESHRATE_RENDER_ONEVERYFRAME: number;
    /**
     * The texture will be rendered every 2 frames which could be enough if your dynamic objects are not
     * the central point of your effect and can save a lot of performances.
     */
    static readonly REFRESHRATE_RENDER_ONEVERYTWOFRAMES: number;
    /**
     * Use this predicate to dynamically define the list of mesh you want to render.
     * If set, the renderList property will be overwritten.
     */
    get renderListPredicate(): (AbstractMesh: AbstractMesh) => boolean;
    set renderListPredicate(value: (AbstractMesh: AbstractMesh) => boolean);
    /**
     * Use this list to define the list of mesh you want to render.
     */
    get renderList(): Nullable<Array<AbstractMesh>>;
    set renderList(value: Nullable<Array<AbstractMesh>>);
    /**
     * Define the list of particle systems to render in the texture. If not provided, will render all the particle systems of the scene.
     * Note that the particle systems are rendered only if renderParticles is set to true.
     */
    get particleSystemList(): Nullable<Array<IParticleSystem>>;
    set particleSystemList(value: Nullable<Array<IParticleSystem>>);
    /**
     * Use this function to overload the renderList array at rendering time.
     * Return null to render with the current renderList, else return the list of meshes to use for rendering.
     * For 2DArray RTT, layerOrFace is the index of the layer that is going to be rendered, else it is the faceIndex of
     * the cube (if the RTT is a cube, else layerOrFace=0).
     * The renderList passed to the function is the current render list (the one that will be used if the function returns null).
     * The length of this list is passed through renderListLength: don't use renderList.length directly because the array can
     * hold dummy elements!
     */
    get getCustomRenderList(): Nullable<(layerOrFace: number, renderList: Nullable<Immutable<Array<AbstractMesh>>>, renderListLength: number) => Nullable<Array<AbstractMesh>>>;
    set getCustomRenderList(value: Nullable<(layerOrFace: number, renderList: Nullable<Immutable<Array<AbstractMesh>>>, renderListLength: number) => Nullable<Array<AbstractMesh>>>);
    /**
     * Define if particles should be rendered in your texture (default: true).
     */
    get renderParticles(): boolean;
    set renderParticles(value: boolean);
    /**
     * Define if sprites should be rendered in your texture (default: false).
     */
    get renderSprites(): boolean;
    set renderSprites(value: boolean);
    /**
     * Define if bounding box rendering should be enabled (still subject to Mesh.showBoundingBox or scene.forceShowBoundingBoxes). (Default: false).
     */
    get enableBoundingBoxRendering(): boolean;
    set enableBoundingBoxRendering(value: boolean);
    /**
     * Define if outline/overlay rendering should be enabled (still subject to Mesh.renderOutline/Mesh.renderOverlay). (Default: true).
     */
    get enableOutlineRendering(): boolean;
    set enableOutlineRendering(value: boolean);
    /**
     * Force checking the layerMask property even if a custom list of meshes is provided (ie. if renderList is not undefined) (default: false).
     */
    get forceLayerMaskCheck(): boolean;
    set forceLayerMaskCheck(value: boolean);
    /**
     * Define the camera used to render the texture.
     */
    get activeCamera(): Nullable<Camera>;
    set activeCamera(value: Nullable<Camera>);
    /**
     * Define the camera used to calculate the LOD of the objects.
     * If not defined, activeCamera will be used. If not defined nor activeCamera, scene's active camera will be used.
     */
    get cameraForLOD(): Nullable<Camera>;
    set cameraForLOD(value: Nullable<Camera>);
    /**
     * If true, the renderer will render all objects without any image processing applied.
     * If false (default value), the renderer will use the current setting of the scene's image processing configuration.
     */
    get disableImageProcessing(): boolean;
    set disableImageProcessing(value: boolean);
    /**
     * Override the mesh isReady function with your own one.
     */
    get customIsReadyFunction(): (mesh: AbstractMesh, refreshRate: number, preWarm?: boolean) => boolean;
    set customIsReadyFunction(value: (mesh: AbstractMesh, refreshRate: number, preWarm?: boolean) => boolean);
    /**
     * Override the render function of the texture with your own one.
     */
    get customRenderFunction(): (opaqueSubMeshes: SmartArray<SubMesh>, alphaTestSubMeshes: SmartArray<SubMesh>, transparentSubMeshes: SmartArray<SubMesh>, depthOnlySubMeshes: SmartArray<SubMesh>, beforeTransparents?: () => void) => void;
    set customRenderFunction(value: (opaqueSubMeshes: SmartArray<SubMesh>, alphaTestSubMeshes: SmartArray<SubMesh>, transparentSubMeshes: SmartArray<SubMesh>, depthOnlySubMeshes: SmartArray<SubMesh>, beforeTransparents?: () => void) => void);
    /**
     * Define if camera post processes should be use while rendering the texture.
     */
    useCameraPostProcesses: boolean;
    /**
     * Define if the camera viewport should be respected while rendering the texture or if the render should be done to the entire texture.
     */
    ignoreCameraViewport: boolean;
    private _postProcessManager;
    /**
     * Post-processes for this render target
     */
    get postProcesses(): PostProcess[];
    private _postProcesses;
    private _resizeObserver;
    private get _prePassEnabled();
    /**
     * An event triggered when the texture is unbind.
     */
    onBeforeBindObservable: Observable<RenderTargetTexture>;
    /**
     * An event triggered when the texture is unbind.
     */
    onAfterUnbindObservable: Observable<RenderTargetTexture>;
    private _onAfterUnbindObserver;
    /**
     * Set a after unbind callback in the texture.
     * This has been kept for backward compatibility and use of onAfterUnbindObservable is recommended.
     */
    set onAfterUnbind(callback: () => void);
    /**
     * An event triggered before rendering the texture
     */
    get onBeforeRenderObservable(): Observable<number>;
    private _onBeforeRenderObserver;
    /**
     * Set a before render callback in the texture.
     * This has been kept for backward compatibility and use of onBeforeRenderObservable is recommended.
     */
    set onBeforeRender(callback: (faceIndex: number) => void);
    /**
     * An event triggered after rendering the texture
     */
    get onAfterRenderObservable(): Observable<number>;
    private _onAfterRenderObserver;
    /**
     * Set a after render callback in the texture.
     * This has been kept for backward compatibility and use of onAfterRenderObservable is recommended.
     */
    set onAfterRender(callback: (faceIndex: number) => void);
    /**
     * An event triggered after the texture clear
     */
    onClearObservable: Observable<AbstractEngine>;
    private _onClearObserver;
    /**
     * Set a clear callback in the texture.
     * This has been kept for backward compatibility and use of onClearObservable is recommended.
     */
    set onClear(callback: (Engine: AbstractEngine) => void);
    /**
     * An event triggered when the texture is resized.
     */
    onResizeObservable: Observable<RenderTargetTexture>;
    /**
     * Define the clear color of the Render Target if it should be different from the scene.
     */
    clearColor: Color4;
    /** @internal */
    _size: TextureSize;
    protected _initialSizeParameter: TextureSize | {
        ratio: number;
    };
    protected _sizeRatio: Nullable<number>;
    /** @internal */
    _generateMipMaps: boolean;
    /** @internal */
    _cleared: boolean;
    /**
     * Skip the initial clear of the rtt at the beginning of the frame render loop
     */
    skipInitialClear: boolean;
    /** @internal */
    get _waitingRenderList(): string[] | undefined;
    /** @internal */
    set _waitingRenderList(value: string[] | undefined);
    protected _objectRenderer: ObjectRenderer;
    protected _doNotChangeAspectRatio: boolean;
    protected _textureMatrix: Matrix;
    protected _samples: number;
    protected _renderTargetOptions: RenderTargetCreationOptions;
    private _canRescale;
    protected _renderTarget: Nullable<RenderTargetWrapper>;
    private _currentFaceIndex;
    private _currentLayer;
    private _currentUseCameraPostProcess;
    private _currentDumpForDebug;
    private _dontDisposeObjectRenderer;
    /**
     * Current render pass id of the render target texture. Note it can change over the rendering as there's a separate id for each face of a cube / each layer of an array layer!
     */
    get renderPassId(): number;
    /**
     * Gets the render pass ids used by the render target texture. For a single render target the array length will be 1, for a cube texture it will be 6 and for
     * a 2D texture array it will return an array of ids the size of the 2D texture array
     */
    get renderPassIds(): readonly number[];
    /**
     * Gets the current value of the refreshId counter
     */
    get currentRefreshId(): number;
    /**
     * Sets a specific material to be used to render a mesh/a list of meshes in this render target texture
     * @param mesh mesh or array of meshes
     * @param material material or array of materials to use for this render pass. If undefined is passed, no specific material will be used but the regular material instead (mesh.material). It's possible to provide an array of materials to use a different material for each rendering in the case of a cube texture (6 rendering) and a 2D texture array (as many rendering as the length of the array)
     */
    setMaterialForRendering(mesh: AbstractMesh | AbstractMesh[], material?: Material | Material[]): void;
    /**
     * Define if the texture has multiple draw buffers or if false a single draw buffer.
     */
    get isMulti(): boolean;
    /**
     * Gets render target creation options that were used.
     */
    get renderTargetOptions(): RenderTargetCreationOptions;
    /**
     * Gets the render target wrapper associated with this render target
     */
    get renderTarget(): Nullable<RenderTargetWrapper>;
    protected _onRatioRescale(): void;
    /**
     * Gets or sets the center of the bounding box associated with the texture (when in cube mode)
     * It must define where the camera used to render the texture is set
     */
    boundingBoxPosition: Vector3;
    private _boundingBoxSize;
    /**
     * Gets or sets the size of the bounding box associated with the texture (when in cube mode)
     * When defined, the cubemap will switch to local mode
     * @see https://community.arm.com/graphics/b/blog/posts/reflections-based-on-local-cubemaps-in-unity
     * @example https://www.babylonjs-playground.com/#RNASML
     */
    set boundingBoxSize(value: Vector3);
    get boundingBoxSize(): Vector3;
    /**
     * In case the RTT has been created with a depth texture, get the associated
     * depth texture.
     * Otherwise, return null.
     */
    get depthStencilTexture(): Nullable<InternalTexture>;
    /** @internal */
    _disableEngineStages: boolean;
    private readonly _onBeforeRenderingManagerRenderObserver;
    private readonly _onAfterRenderingManagerRenderObserver;
    private readonly _onFastPathRenderObserver;
    /**
     * Instantiate a render target texture. This is mainly used to render the scene off screen, to apply (for instance) post processing effects
     * or use a shadow or depth texture...
     * @param name The friendly name of the texture
     * @param size The size of the RTT (number if square, or {width: number, height:number} or {ratio:} to define a ratio from the main scene)
     * @param scene The scene the RTT belongs to. Default is the last created scene.
     * @param options The options for creating the render target texture.
     */
    constructor(name: string, size: TextureSize | {
        ratio: number;
    }, scene?: Nullable<Scene>, options?: RenderTargetTextureOptions);
    /**
     * Instantiate a render target texture. This is mainly used to render the scene off screen, to apply (for instance) post processing effects
     * or use a shadow or depth texture...
     * @param name The friendly name of the texture
     * @param size The size of the RTT (number if square, or {width: number, height:number} or {ratio:} to define a ratio from the main scene)
     * @param scene The scene the RTT belongs to. Default is the last created scene
     * @param generateMipMaps True (default: false) if mipmaps need to be generated after render
     * @param doNotChangeAspectRatio True (default) to not change the aspect ratio of the scene in the RTT
     * @param type The type of the buffer in the RTT (byte (default), half float, float...)
     * @param isCube True (default: false) if a cube texture needs to be created
     * @param samplingMode The sampling mode to be used with the render target (Trilinear (default), Linear, Nearest...)
     * @param generateDepthBuffer True (default) to generate a depth buffer
     * @param generateStencilBuffer True (default: false) to generate a stencil buffer
     * @param isMulti True (default: false) if multiple textures need to be created (Draw Buffers)
     * @param format The internal format of the buffer in the RTT (RED, RG, RGB, RGBA (default), ALPHA...)
     * @param delayAllocation True (default: false) if the texture allocation should be delayed
     * @param samples Sample count to use when creating the RTT
     * @param creationFlags specific flags to use when creating the texture (e.g., Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures)
     * @param noColorAttachment True (default: false) to indicate that no color target should be created. (e.g., if you only want to write to the depth buffer)
     * @param useSRGBBuffer True (default: false) to create a SRGB texture
     */
    constructor(name: string, size: TextureSize | {
        ratio: number;
    }, scene?: Nullable<Scene>, generateMipMaps?: boolean, doNotChangeAspectRatio?: boolean, type?: number, isCube?: boolean, samplingMode?: number, generateDepthBuffer?: boolean, generateStencilBuffer?: boolean, isMulti?: boolean, format?: number, delayAllocation?: boolean, samples?: number, creationFlags?: number, noColorAttachment?: boolean, useSRGBBuffer?: boolean);
    /**
     * Creates a depth stencil texture.
     * This is only available in WebGL 2 or with the depth texture extension available.
     * @param comparisonFunction Specifies the comparison function to set on the texture. If 0 or undefined, the texture is not in comparison mode (default: 0)
     * @param bilinearFiltering Specifies whether or not bilinear filtering is enable on the texture (default: true)
     * @param generateStencil Specifies whether or not a stencil should be allocated in the texture (default: false)
     * @param samples sample count of the depth/stencil texture (default: 1)
     * @param format format of the depth texture (default: Constants.TEXTUREFORMAT_DEPTH32_FLOAT)
     * @param label defines the label of the texture (for debugging purpose)
     */
    createDepthStencilTexture(comparisonFunction?: number, bilinearFiltering?: boolean, generateStencil?: boolean, samples?: number, format?: number, label?: string): void;
    protected _processSizeParameter(size: TextureSize | {
        ratio: number;
    }): void;
    /**
     * Define the number of samples to use in case of MSAA.
     * It defaults to one meaning no MSAA has been enabled.
     */
    get samples(): number;
    set samples(value: number);
    /**
     * Adds a post process to the render target rendering passes.
     * @param postProcess define the post process to add
     */
    addPostProcess(postProcess: PostProcess): void;
    /**
     * Clear all the post processes attached to the render target
     * @param dispose define if the cleared post processes should also be disposed (false by default)
     */
    clearPostProcesses(dispose?: boolean): void;
    /**
     * Remove one of the post process from the list of attached post processes to the texture
     * @param postProcess define the post process to remove from the list
     */
    removePostProcess(postProcess: PostProcess): void;
    /**
     * Resets the refresh counter of the texture and start bak from scratch.
     * Could be useful to regenerate the texture if it is setup to render only once.
     */
    resetRefreshCounter(): void;
    /**
     * Define the refresh rate of the texture or the rendering frequency.
     * Use 0 to render just once, 1 to render on every frame, 2 to render every two frames and so on...
     */
    get refreshRate(): number;
    set refreshRate(value: number);
    /** @internal */
    _shouldRender(): boolean;
    /**
     * Gets the actual render size of the texture.
     * @returns the width of the render size
     */
    getRenderSize(): number;
    /**
     * Gets the actual render width of the texture.
     * @returns the width of the render size
     */
    getRenderWidth(): number;
    /**
     * Gets the actual render height of the texture.
     * @returns the height of the render size
     */
    getRenderHeight(): number;
    /**
     * Gets the actual number of layers of the texture or, in the case of a 3D texture, return the depth.
     * @returns the number of layers
     */
    getRenderLayers(): number;
    /**
     * Don't allow this render target texture to rescale. Mainly used to prevent rescaling by the scene optimizer.
     */
    disableRescaling(): void;
    /**
     * Get if the texture can be rescaled or not.
     */
    get canRescale(): boolean;
    /**
     * Resize the texture using a ratio.
     * @param ratio the ratio to apply to the texture size in order to compute the new target size
     */
    scale(ratio: number): void;
    /**
     * Get the texture reflection matrix used to rotate/transform the reflection.
     * @returns the reflection matrix
     */
    getReflectionTextureMatrix(): Matrix;
    /**
     * Resize the texture to a new desired size.
     * Be careful as it will recreate all the data in the new texture.
     * @param size Define the new size. It can be:
     *   - a number for squared texture,
     *   - an object containing { width: number, height: number }
     *   - or an object containing a ratio { ratio: number }
     */
    resize(size: TextureSize | {
        ratio: number;
    }): void;
    /**
     * Renders all the objects from the render list into the texture.
     * @param useCameraPostProcess Define if camera post processes should be used during the rendering
     * @param dumpForDebug Define if the rendering result should be dumped (copied) for debugging purpose
     */
    render(useCameraPostProcess?: boolean, dumpForDebug?: boolean): void;
    private _dumpToolsLoading;
    private _dumpTools;
    /**
     * This function will check if the render target texture can be rendered (textures are loaded, shaders are compiled)
     * @returns true if all required resources are ready
     */
    isReadyForRendering(): boolean;
    private _render;
    private _bestReflectionRenderTargetDimension;
    /**
     * @internal
     * @param faceIndex face index to bind to if this is a cubetexture
     * @param layer defines the index of the texture to bind in the array
     */
    _bindFrameBuffer(faceIndex?: number, layer?: number): void;
    protected _unbindFrameBuffer(engine: AbstractEngine, faceIndex: number): void;
    /**
     * @internal
     */
    _prepareFrame(scene: Scene, faceIndex?: number, layer?: number, useCameraPostProcess?: boolean): void;
    private _renderToTarget;
    /**
     * Overrides the default sort function applied in the rendering group to prepare the meshes.
     * This allowed control for front to back rendering or reversely depending of the special needs.
     *
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param opaqueSortCompareFn The opaque queue comparison function use to sort.
     * @param alphaTestSortCompareFn The alpha test queue comparison function use to sort.
     * @param transparentSortCompareFn The transparent queue comparison function use to sort.
     */
    setRenderingOrder(renderingGroupId: number, opaqueSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, alphaTestSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, transparentSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>): void;
    /**
     * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups.
     *
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
     */
    setRenderingAutoClearDepthStencil(renderingGroupId: number, autoClearDepthStencil: boolean): void;
    /**
     * Clones the texture.
     * @returns the cloned texture
     */
    clone(): RenderTargetTexture;
    /**
     * Serialize the texture to a JSON representation we can easily use in the respective Parse function.
     * @returns The JSON representation of the texture
     */
    serialize(): any;
    /**
     *  This will remove the attached framebuffer objects. The texture will not be able to be used as render target anymore
     */
    disposeFramebufferObjects(): void;
    /**
     * Release and destroy the underlying lower level texture aka internalTexture.
     */
    releaseInternalTexture(): void;
    /**
     * Dispose the texture and release its associated resources.
     */
    dispose(): void;
    /** @internal */
    _rebuild(): void;
    /**
     * Clear the info related to rendering groups preventing retention point in material dispose.
     */
    freeRenderingGroups(): void;
    /**
     * Gets the number of views the corresponding to the texture (eg. a MultiviewRenderTarget will have > 1)
     * @returns the view count
     */
    getViewCount(): number;
}

/**
 * Mirror texture can be used to simulate the view from a mirror in a scene.
 * It will dynamically be rendered every frame to adapt to the camera point of view.
 * You can then easily use it as a reflectionTexture on a flat surface.
 * In case the surface is not a plane, please consider relying on reflection probes.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#mirrortexture
 */
declare class MirrorTexture extends RenderTargetTexture {
    /**
     * Define the reflection plane we want to use. The mirrorPlane is usually set to the constructed reflector.
     * It is possible to directly set the mirrorPlane by directly using a Plane(a, b, c, d) where a, b and c give the plane normal vector (a, b, c) and d is a scalar displacement from the mirrorPlane to the origin. However in all but the very simplest of situations it is more straight forward to set it to the reflector as stated in the doc.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#mirrors
     */
    mirrorPlane: Plane;
    /**
     * Define the blur ratio used to blur the reflection if needed.
     */
    set blurRatio(value: number);
    get blurRatio(): number;
    /**
     * Define the adaptive blur kernel used to blur the reflection if needed.
     * This will autocompute the closest best match for the `blurKernel`
     */
    set adaptiveBlurKernel(value: number);
    /**
     * Define the blur kernel used to blur the reflection if needed.
     * Please consider using `adaptiveBlurKernel` as it could find the closest best value for you.
     */
    set blurKernel(value: number);
    /**
     * Define the blur kernel on the X Axis used to blur the reflection if needed.
     * Please consider using `adaptiveBlurKernel` as it could find the closest best value for you.
     */
    set blurKernelX(value: number);
    get blurKernelX(): number;
    /**
     * Define the blur kernel on the Y Axis used to blur the reflection if needed.
     * Please consider using `adaptiveBlurKernel` as it could find the closest best value for you.
     */
    set blurKernelY(value: number);
    get blurKernelY(): number;
    private _autoComputeBlurKernel;
    resize(size: TextureSize | {
        ratio: number;
    }): void;
    protected _onRatioRescale(): void;
    private _updateGammaSpace;
    private _imageProcessingConfigChangeObserver;
    private _transformMatrix;
    private _mirrorMatrix;
    private _blurX;
    private _blurY;
    private _adaptiveBlurKernel;
    private _blurKernelX;
    private _blurKernelY;
    private _blurRatio;
    private _sceneUBO;
    private _currentSceneUBO;
    /**
     * Instantiates a Mirror Texture.
     * Mirror texture can be used to simulate the view from a mirror in a scene.
     * It will dynamically be rendered every frame to adapt to the camera point of view.
     * You can then easily use it as a reflectionTexture on a flat surface.
     * In case the surface is not a plane, please consider relying on reflection probes.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#mirrors
     * @param name
     * @param size
     * @param scene
     * @param generateMipMaps
     * @param type
     * @param samplingMode
     * @param generateDepthBuffer
     */
    constructor(name: string, size: number | {
        width: number;
        height: number;
    } | {
        ratio: number;
    }, scene?: Scene, generateMipMaps?: boolean, type?: number, samplingMode?: number, generateDepthBuffer?: boolean);
    private _preparePostProcesses;
    /**
     * Clone the mirror texture.
     * @returns the cloned texture
     */
    clone(): MirrorTexture;
    /**
     * Serialize the texture to a JSON representation you could use in Parse later on
     * @returns the serialized JSON representation
     */
    serialize(): any;
    /**
     * Dispose the texture and release its associated resources.
     */
    dispose(): void;
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Update a video texture
         * @param texture defines the texture to update
         * @param video defines the video element to use
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateVideoTexture(texture: Nullable<InternalTexture>, video: HTMLVideoElement | Nullable<ExternalTexture>, invertY: boolean): void;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Creates a dynamic texture
         * @param width defines the width of the texture
         * @param height defines the height of the texture
         * @param generateMipMaps defines if the engine should generate the mip levels
         * @param samplingMode defines the required sampling mode (Texture.NEAREST_SAMPLINGMODE by default)
         * @returns the dynamic texture inside an InternalTexture
         */
        createDynamicTexture(width: number, height: number, generateMipMaps: boolean, samplingMode: number): InternalTexture;
        /**
         * Update the content of a dynamic texture
         * @param texture defines the texture to update
         * @param source defines the source containing the data
         * @param invertY defines if data must be stored with Y axis inverted
         * @param premulAlpha defines if alpha is stored as premultiplied
         * @param format defines the format of the data
         * @param forceBindTexture if the texture should be forced to be bound eg. after a graphics context loss (Default: false)
         * @param allowGPUOptimization true to allow some specific GPU optimizations (subject to engine feature "allowGPUOptimizationsForGUI" being true)
         */
        updateDynamicTexture(texture: Nullable<InternalTexture>, source: ImageSource | ICanvas, invertY?: boolean, premulAlpha?: boolean, format?: number, forceBindTexture?: boolean, allowGPUOptimization?: boolean): void;
    }
}

/**
 * Settings for finer control over video usage
 */
interface VideoTextureSettings {
    /**
     * Applies `autoplay` to video, if specified
     */
    autoPlay?: boolean;
    /**
     * Applies `muted` to video, if specified
     */
    muted?: boolean;
    /**
     * Applies `loop` to video, if specified
     */
    loop?: boolean;
    /**
     * Automatically updates internal texture from video at every frame in the render loop
     */
    autoUpdateTexture: boolean;
    /**
     * Image src displayed during the video loading or until the user interacts with the video.
     */
    poster?: string;
    /**
     * Defines the associated texture format.
     */
    format?: number;
    /**
     * Notify babylon to not modify any video settings and not control the video's playback.
     * Set this to true if you are controlling the way the video is being played, stopped and paused.
     */
    independentVideoSource?: boolean;
}
/**
 * If you want to display a video in your scene, this is the special texture for that.
 * This special texture works similar to other textures, with the exception of a few parameters.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/videoTexture
 */
declare class VideoTexture extends Texture {
    /**
     * Tells whether textures will be updated automatically or user is required to call `updateTexture` manually
     */
    readonly autoUpdateTexture: boolean;
    /**
     * The video instance used by the texture internally
     */
    readonly video: HTMLVideoElement;
    private _externalTexture;
    private _onUserActionRequestedObservable;
    /**
     * Event triggered when a dom action is required by the user to play the video.
     * This happens due to recent changes in browser policies preventing video to auto start.
     */
    get onUserActionRequestedObservable(): Observable<Texture>;
    private _generateMipMaps;
    private _stillImageCaptured;
    private _displayingPosterTexture;
    private _settings;
    private _createInternalTextureOnEvent;
    private _frameId;
    private _currentSrc;
    private _onError?;
    private _errorFound;
    /**
     * Serialize the flag to define this texture as a video texture
     */
    readonly isVideo = true;
    private _processError;
    private _handlePlay;
    /**
     * Creates a video texture.
     * If you want to display a video in your scene, this is the special texture for that.
     * This special texture works similar to other textures, with the exception of a few parameters.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/videoTexture
     * @param name optional name, will detect from video source, if not defined
     * @param src can be used to provide an url, array of urls or an already setup HTML video element.
     * @param scene is obviously the current scene.
     * @param generateMipMaps can be used to turn on mipmaps (Can be expensive for videoTextures because they are often updated).
     * @param invertY is false by default but can be used to invert video on Y axis
     * @param samplingMode controls the sampling method and is set to TRILINEAR_SAMPLINGMODE by default
     * @param settings allows finer control over video usage
     * @param onError defines a callback triggered when an error occurred during the loading session
     * @param format defines the texture format to use (Engine.TEXTUREFORMAT_RGBA by default)
     */
    constructor(name: Nullable<string>, src: string | string[] | HTMLVideoElement, scene: Nullable<Scene>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, settings?: Partial<VideoTextureSettings>, onError?: Nullable<(message?: string, exception?: any) => void>, format?: number);
    /**
     * Get the current class name of the video texture useful for serialization or dynamic coding.
     * @returns "VideoTexture"
     */
    getClassName(): string;
    private _getName;
    private _getVideo;
    private _resizeInternalTexture;
    private _createInternalTexture;
    private _reset;
    /**
     * @internal Internal method to initiate `update`.
     */
    _rebuild(): void;
    /**
     * Update Texture in the `auto` mode. Does not do anything if `settings.autoUpdateTexture` is false.
     */
    update(): void;
    /**
     * Update Texture in `manual` mode. Does not do anything if not visible or paused.
     * @param isVisible Visibility state, detected by user using `scene.getActiveMeshes()` or otherwise.
     */
    updateTexture(isVisible: boolean): void;
    protected _updateInternalTexture: () => void;
    /**
     * Get the underlying external texture (if supported by the current engine, else null)
     */
    get externalTexture(): Nullable<ExternalTexture>;
    /**
     * Change video content. Changing video instance or setting multiple urls (as in constructor) is not supported.
     * @param url New url.
     */
    updateURL(url: string): void;
    /**
     * Clones the texture.
     * @returns the cloned texture
     */
    clone(): VideoTexture;
    /**
     * Dispose the texture and release its associated resources.
     */
    dispose(): void;
    /**
     * Creates a video texture straight from a stream.
     * @param scene Define the scene the texture should be created in
     * @param stream Define the stream the texture should be created from
     * @param constraints video constraints
     * @param invertY Defines if the video should be stored with invert Y set to true (true by default)
     * @returns The created video texture as a promise
     */
    static CreateFromStreamAsync(scene: Scene, stream: MediaStream, constraints: any, invertY?: boolean): Promise<VideoTexture>;
    /**
     * Creates a video texture straight from your WebCam video feed.
     * @param scene Define the scene the texture should be created in
     * @param constraints Define the constraints to use to create the web cam feed from WebRTC
     * @param audioConstaints Define the audio constraints to use to create the web cam feed from WebRTC
     * @param invertY Defines if the video should be stored with invert Y set to true (true by default)
     * @returns The created video texture as a promise
     */
    static CreateFromWebCamAsync(scene: Scene, constraints: {
        minWidth: number;
        maxWidth: number;
        minHeight: number;
        maxHeight: number;
        deviceId: string;
    } & MediaTrackConstraints, audioConstaints?: boolean | MediaTrackConstraints, invertY?: boolean): Promise<VideoTexture>;
    /**
     * Creates a video texture straight from your WebCam video feed.
     * @param scene Defines the scene the texture should be created in
     * @param onReady Defines a callback to triggered once the texture will be ready
     * @param constraints Defines the constraints to use to create the web cam feed from WebRTC
     * @param audioConstaints Defines the audio constraints to use to create the web cam feed from WebRTC
     * @param invertY Defines if the video should be stored with invert Y set to true (true by default)
     */
    static CreateFromWebCam(scene: Scene, onReady: (videoTexture: VideoTexture) => void, constraints: {
        minWidth: number;
        maxWidth: number;
        minHeight: number;
        maxHeight: number;
        deviceId: string;
    } & MediaTrackConstraints, audioConstaints?: boolean | MediaTrackConstraints, invertY?: boolean): void;
}

/**
 * Defines the available options when creating a texture
 */
interface ITextureCreationOptions {
    /** Defines if the texture will require mip maps or not (default: false) */
    noMipmap?: boolean;
    /** Defines if the texture needs to be inverted on the y axis during loading (default: true) */
    invertY?: boolean;
    /** Defines the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...) (default: Texture.TRILINEAR_SAMPLINGMODE) */
    samplingMode?: number;
    /** Defines a callback triggered when the texture has been loaded (default: null) */
    onLoad?: Nullable<() => void>;
    /** Defines a callback triggered when an error occurred during the loading session (default: null) */
    onError?: Nullable<(message?: string, exception?: any) => void>;
    /** Defines the buffer to load the texture from in case the texture is loaded from a buffer representation (default: null) */
    buffer?: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>;
    /** Defines if the buffer we are loading the texture from should be deleted after load (default: false) */
    deleteBuffer?: boolean;
    /** Defines the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...) (default: ) */
    format?: number;
    /** Defines an optional mime type information (default: undefined) */
    mimeType?: string;
    /** Options to be passed to the loader (default: undefined) */
    loaderOptions?: any;
    /** Specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg) (default: undefined) */
    creationFlags?: number;
    /** Defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU) (default: false) */
    useSRGBBuffer?: boolean;
    /** Defines the underlying texture from an already existing one */
    internalTexture?: InternalTexture;
    /** Defines the underlying texture texture space */
    gammaSpace?: boolean;
    /** Defines the extension to use to pick the right loader */
    forcedExtension?: string;
}
/**
 * This represents a texture in babylon. It can be easily loaded from a network, base64 or html input.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction#texture
 */
declare class Texture extends BaseTexture {
    /**
     * Gets or sets a general boolean used to indicate that textures containing direct data (buffers) must be saved as part of the serialization process
     */
    static SerializeBuffers: boolean;
    /**
     * Gets or sets a general boolean used to indicate that texture buffers must be saved as part of the serialization process.
     * If no buffer exists, one will be created as base64 string from the internal webgl data.
     */
    static ForceSerializeBuffers: boolean;
    /**
     * This observable will notify when any texture had a loading error
     */
    static OnTextureLoadErrorObservable: Observable<BaseTexture>;
    /** @internal */
    static _SerializeInternalTextureUniqueId: boolean;
    /**
     * @internal
     */
    static _CubeTextureParser: (jsonTexture: any, scene: Scene, rootUrl: string) => CubeTexture;
    /**
     * @internal
     */
    static _CreateMirror: (name: string, renderTargetSize: number, scene: Scene, generateMipMaps: boolean) => MirrorTexture;
    /**
     * @internal
     */
    static _CreateRenderTargetTexture: (name: string, renderTargetSize: number, scene: Scene, generateMipMaps: boolean, creationFlags?: number) => RenderTargetTexture;
    /**
     * @internal
     */
    static _CreateVideoTexture(name: Nullable<string>, src: string | string[] | HTMLVideoElement, scene: Nullable<Scene>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, settings?: Partial<VideoTextureSettings>, onError?: Nullable<(message?: string, exception?: any) => void>, format?: number): VideoTexture;
    /** nearest is mag = nearest and min = nearest and no mip */
    static readonly NEAREST_SAMPLINGMODE = 1;
    /** nearest is mag = nearest and min = nearest and mip = linear */
    static readonly NEAREST_NEAREST_MIPLINEAR = 8;
    /** Bilinear is mag = linear and min = linear and no mip */
    static readonly BILINEAR_SAMPLINGMODE = 2;
    /** Bilinear is mag = linear and min = linear and mip = nearest */
    static readonly LINEAR_LINEAR_MIPNEAREST = 11;
    /** Trilinear is mag = linear and min = linear and mip = linear */
    static readonly TRILINEAR_SAMPLINGMODE = 3;
    /** Trilinear is mag = linear and min = linear and mip = linear */
    static readonly LINEAR_LINEAR_MIPLINEAR = 3;
    /** mag = nearest and min = nearest and mip = nearest */
    static readonly NEAREST_NEAREST_MIPNEAREST = 4;
    /** mag = nearest and min = linear and mip = nearest */
    static readonly NEAREST_LINEAR_MIPNEAREST = 5;
    /** mag = nearest and min = linear and mip = linear */
    static readonly NEAREST_LINEAR_MIPLINEAR = 6;
    /** mag = nearest and min = linear and mip = none */
    static readonly NEAREST_LINEAR = 7;
    /** mag = nearest and min = nearest and mip = none */
    static readonly NEAREST_NEAREST = 1;
    /** mag = linear and min = nearest and mip = nearest */
    static readonly LINEAR_NEAREST_MIPNEAREST = 9;
    /** mag = linear and min = nearest and mip = linear */
    static readonly LINEAR_NEAREST_MIPLINEAR = 10;
    /** mag = linear and min = linear and mip = none */
    static readonly LINEAR_LINEAR = 2;
    /** mag = linear and min = nearest and mip = none */
    static readonly LINEAR_NEAREST = 12;
    /** Explicit coordinates mode */
    static readonly EXPLICIT_MODE = 0;
    /** Spherical coordinates mode */
    static readonly SPHERICAL_MODE = 1;
    /** Planar coordinates mode */
    static readonly PLANAR_MODE = 2;
    /** Cubic coordinates mode */
    static readonly CUBIC_MODE = 3;
    /** Projection coordinates mode */
    static readonly PROJECTION_MODE = 4;
    /** Inverse Cubic coordinates mode */
    static readonly SKYBOX_MODE = 5;
    /** Inverse Cubic coordinates mode */
    static readonly INVCUBIC_MODE = 6;
    /** Equirectangular coordinates mode */
    static readonly EQUIRECTANGULAR_MODE = 7;
    /** Equirectangular Fixed coordinates mode */
    static readonly FIXED_EQUIRECTANGULAR_MODE = 8;
    /** Equirectangular Fixed Mirrored coordinates mode */
    static readonly FIXED_EQUIRECTANGULAR_MIRRORED_MODE = 9;
    /** Texture is not repeating outside of 0..1 UVs */
    static readonly CLAMP_ADDRESSMODE = 0;
    /** Texture is repeating outside of 0..1 UVs */
    static readonly WRAP_ADDRESSMODE = 1;
    /** Texture is repeating and mirrored */
    static readonly MIRROR_ADDRESSMODE = 2;
    /**
     * Gets or sets a boolean which defines if the texture url must be build from the serialized URL instead of just using the name and loading them side by side with the scene file
     */
    static UseSerializedUrlIfAny: boolean;
    /**
     * Define the url of the texture.
     */
    url: Nullable<string>;
    /**
     * Define an offset on the texture to offset the u coordinates of the UVs
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/moreMaterials#offsetting
     */
    uOffset: number;
    /**
     * Define an offset on the texture to offset the v coordinates of the UVs
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/moreMaterials#offsetting
     */
    vOffset: number;
    /**
     * Define an offset on the texture to scale the u coordinates of the UVs
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/moreMaterials#tiling
     */
    uScale: number;
    /**
     * Define an offset on the texture to scale the v coordinates of the UVs
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/moreMaterials#tiling
     */
    vScale: number;
    /**
     * Define an offset on the texture to rotate around the u coordinates of the UVs
     * The angle is defined in radians.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/moreMaterials
     */
    uAng: number;
    /**
     * Define an offset on the texture to rotate around the v coordinates of the UVs
     * The angle is defined in radians.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/moreMaterials
     */
    vAng: number;
    /**
     * Define an offset on the texture to rotate around the w coordinates of the UVs (in case of 3d texture)
     * The angle is defined in radians.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/moreMaterials
     */
    wAng: number;
    /**
     * Defines the center of rotation (U)
     */
    uRotationCenter: number;
    /**
     * Defines the center of rotation (V)
     */
    vRotationCenter: number;
    /**
     * Defines the center of rotation (W)
     */
    wRotationCenter: number;
    /**
     * Sets this property to true to avoid deformations when rotating the texture with non-uniform scaling
     */
    homogeneousRotationInUVTransform: boolean;
    /**
     * Are mip maps generated for this texture or not.
     */
    get noMipmap(): boolean;
    /**
     * List of inspectable custom properties (used by the Inspector)
     * @see https://doc.babylonjs.com/toolsAndResources/inspector#extensibility
     */
    inspectableCustomProperties: Nullable<IInspectable[]>;
    /** @internal */
    _noMipmap: boolean;
    /** @internal */
    _invertY: boolean;
    private _rowGenerationMatrix;
    private _cachedTextureMatrix;
    private _projectionModeMatrix;
    private _t0;
    private _t1;
    private _t2;
    private _cachedUOffset;
    private _cachedVOffset;
    private _cachedUScale;
    private _cachedVScale;
    private _cachedUAng;
    private _cachedVAng;
    private _cachedWAng;
    private _cachedReflectionProjectionMatrixId;
    private _cachedURotationCenter;
    private _cachedVRotationCenter;
    private _cachedWRotationCenter;
    private _cachedHomogeneousRotationInUVTransform;
    private _cachedIdentity3x2;
    private _cachedReflectionTextureMatrix;
    private _cachedReflectionUOffset;
    private _cachedReflectionVOffset;
    private _cachedReflectionUScale;
    private _cachedReflectionVScale;
    private _cachedReflectionCoordinatesMode;
    /** @internal */
    _buffer: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>;
    private _deleteBuffer;
    protected _format: Nullable<number>;
    private _delayedOnLoad;
    private _delayedOnError;
    private _mimeType?;
    private _loaderOptions?;
    private _creationFlags?;
    /** @internal */
    _useSRGBBuffer?: boolean;
    private _forcedExtension?;
    /** Returns the texture mime type if it was defined by a loader (undefined else) */
    get mimeType(): string | undefined;
    /**
     * Observable triggered once the texture has been loaded.
     */
    onLoadObservable: Observable<Texture>;
    protected _isBlocking: boolean;
    /**
     * Is the texture preventing material to render while loading.
     * If false, a default texture will be used instead of the loading one during the preparation step.
     */
    set isBlocking(value: boolean);
    get isBlocking(): boolean;
    /**
     * Gets a boolean indicating if the texture needs to be inverted on the y axis during loading
     */
    get invertY(): boolean;
    /**
     * Instantiates a new texture.
     * This represents a texture in babylon. It can be easily loaded from a network, base64 or html input.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction#texture
     * @param url defines the url of the picture to load as a texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
     * @param invertY defines if the texture needs to be inverted on the y axis during loading
     * @param samplingMode defines the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
     * @param onLoad defines a callback triggered when the texture has been loaded
     * @param onError defines a callback triggered when an error occurred during the loading session
     * @param buffer defines the buffer to load the texture from in case the texture is loaded from a buffer representation
     * @param deleteBuffer defines if the buffer we are loading the texture from should be deleted after load
     * @param format defines the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
     * @param mimeType defines an optional mime type information
     * @param loaderOptions options to be passed to the loader
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param forcedExtension defines the extension to use to pick the right loader
     */
    constructor(url: Nullable<string>, sceneOrEngine?: Nullable<Scene | AbstractEngine>, noMipmapOrOptions?: boolean | ITextureCreationOptions, invertY?: boolean, samplingMode?: number, onLoad?: Nullable<() => void>, onError?: Nullable<(message?: string, exception?: any) => void>, buffer?: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>, deleteBuffer?: boolean, format?: number, mimeType?: string, loaderOptions?: any, creationFlags?: number, forcedExtension?: string);
    /**
     * Update the url (and optional buffer) of this texture if url was null during construction.
     * @param url the url of the texture
     * @param buffer the buffer of the texture (defaults to null)
     * @param onLoad callback called when the texture is loaded  (defaults to null)
     * @param forcedExtension defines the extension to use to pick the right loader
     */
    updateURL(url: string, buffer?: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>, onLoad?: () => void, forcedExtension?: string): void;
    /**
     * Finish the loading sequence of a texture flagged as delayed load.
     * @internal
     */
    delayLoad(): void;
    private _prepareRowForTextureGeneration;
    /**
     * Get the current texture matrix which includes the requested offsetting, tiling and rotation components.
     * @param uBase The horizontal base offset multiplier (1 by default)
     * @returns the transform matrix of the texture.
     */
    getTextureMatrix(uBase?: number): Matrix;
    /**
     * Get the current matrix used to apply reflection. This is useful to rotate an environment texture for instance.
     * @returns The reflection texture transform
     */
    getReflectionTextureMatrix(): Matrix;
    /**
     * Clones the texture.
     * @returns the cloned texture
     */
    clone(): Texture;
    /**
     * Serialize the texture to a JSON representation we can easily use in the respective Parse function.
     * @returns The JSON representation of the texture
     */
    serialize(): any;
    /**
     * Get the current class name of the texture useful for serialization or dynamic coding.
     * @returns "Texture"
     */
    getClassName(): string;
    /**
     * Dispose the texture and release its associated resources.
     */
    dispose(): void;
    /**
     * Parse the JSON representation of a texture in order to recreate the texture in the given scene.
     * @param parsedTexture Define the JSON representation of the texture
     * @param scene Define the scene the parsed texture should be instantiated in
     * @param rootUrl Define the root url of the parsing sequence in the case of relative dependencies
     * @returns The parsed texture if successful
     */
    static Parse(parsedTexture: any, scene: Scene, rootUrl: string): Nullable<BaseTexture>;
    /**
     * Creates a texture from its base 64 representation.
     * @param data Define the base64 payload without the data: prefix
     * @param name Define the name of the texture in the scene useful fo caching purpose for instance
     * @param scene Define the scene the texture should belong to
     * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
     * @param invertY define if the texture needs to be inverted on the y axis during loading
     * @param samplingMode define the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
     * @param onLoad define a callback triggered when the texture has been loaded
     * @param onError define a callback triggered when an error occurred during the loading session
     * @param format define the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param forcedExtension defines the extension to use to pick the right loader
     * @returns the created texture
     */
    static CreateFromBase64String(data: string, name: string, scene: Scene, noMipmapOrOptions?: boolean | ITextureCreationOptions, invertY?: boolean, samplingMode?: number, onLoad?: Nullable<() => void>, onError?: Nullable<() => void>, format?: number, creationFlags?: number, forcedExtension?: string): Texture;
    /**
     * Creates a texture from its data: representation. (data: will be added in case only the payload has been passed in)
     * @param name Define the name of the texture in the scene useful fo caching purpose for instance
     * @param buffer define the buffer to load the texture from in case the texture is loaded from a buffer representation
     * @param scene Define the scene the texture should belong to
     * @param deleteBuffer define if the buffer we are loading the texture from should be deleted after load
     * @param noMipmapOrOptions defines if the texture will require mip maps or not or set of all options to create the texture
     * @param invertY define if the texture needs to be inverted on the y axis during loading
     * @param samplingMode define the sampling mode we want for the texture while fetching from it (Texture.NEAREST_SAMPLINGMODE...)
     * @param onLoad define a callback triggered when the texture has been loaded
     * @param onError define a callback triggered when an error occurred during the loading session
     * @param format define the format of the texture we are trying to load (Engine.TEXTUREFORMAT_RGBA...)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param forcedExtension defines the extension to use to pick the right loader
     * @returns the created texture
     */
    static LoadFromDataString(name: string, buffer: any, scene: Scene, deleteBuffer?: boolean, noMipmapOrOptions?: boolean | ITextureCreationOptions, invertY?: boolean, samplingMode?: number, onLoad?: Nullable<() => void>, onError?: Nullable<(message?: string, exception?: any) => void>, format?: number, creationFlags?: number, forcedExtension?: string): Texture;
}

/**
 * Raw texture can help creating a texture directly from an array of data.
 * This can be super useful if you either get the data from an uncompressed source or
 * if you wish to create your texture pixel by pixel.
 */
declare class RawTexture extends Texture {
    /**
     * Define the format of the data (RGB, RGBA... Engine.TEXTUREFORMAT_xxx)
     */
    format: number;
    private _waitingForData;
    /**
     * Instantiates a new RawTexture.
     * Raw texture can help creating a texture directly from an array of data.
     * This can be super useful if you either get the data from an uncompressed source or
     * if you wish to create your texture pixel by pixel.
     * @param data define the array of data to use to create the texture (null to create an empty texture)
     * @param width define the width of the texture
     * @param height define the height of the texture
     * @param format define the format of the data (RGB, RGBA... Engine.TEXTUREFORMAT_xxx)
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps define whether mip maps should be generated or not
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @param type define the format of the data (int, float... Engine.TEXTURETYPE_xxx)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
     * @param waitDataToBeReady If set to true Rawtexture will wait data to be set in order to be flaged as ready.
     * @param mipLevelCount defines the number of mip levels to allocate for the texture
     */
    constructor(data: Nullable<ArrayBufferView>, width: number, height: number, 
    /**
     * Define the format of the data (RGB, RGBA... Engine.TEXTUREFORMAT_xxx)
     */
    format: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, type?: number, creationFlags?: number, useSRGBBuffer?: boolean, waitDataToBeReady?: boolean, mipLevelCount?: number);
    /**
     * Updates the texture underlying data.
     * @param data Define the new data of the texture
     */
    update(data: ArrayBufferView): void;
    /**
     * Updates a specific mip level of the texture.
     * @param data The new data for the mip level
     * @param mipLevel The mip level to update (0 is the base level)
     */
    updateMipLevel(data: ArrayBufferView, mipLevel: number): void;
    /**
     * Clones the texture.
     * @returns the cloned texture
     */
    clone(): Texture;
    isReady(): boolean;
    /**
     * Creates a luminance texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @returns the luminance texture
     */
    static CreateLuminanceTexture(data: Nullable<ArrayBufferView>, width: number, height: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number): RawTexture;
    /**
     * Creates a luminance alpha texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @returns the luminance alpha texture
     */
    static CreateLuminanceAlphaTexture(data: Nullable<ArrayBufferView>, width: number, height: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number): RawTexture;
    /**
     * Creates an alpha texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @returns the alpha texture
     */
    static CreateAlphaTexture(data: Nullable<ArrayBufferView>, width: number, height: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number): RawTexture;
    /**
     * Creates a RGB texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @param type define the format of the data (int, float... Engine.TEXTURETYPE_xxx)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
     * @returns the RGB alpha texture
     */
    static CreateRGBTexture(data: Nullable<ArrayBufferView>, width: number, height: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, type?: number, creationFlags?: number, useSRGBBuffer?: boolean): RawTexture;
    /**
     * Creates a RGBA texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @param type define the format of the data (int, float... Engine.TEXTURETYPE_xxx)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
     * @param waitDataToBeReady if set to true this will force texture to wait for data to be set before it is considered ready.
     * @returns the RGBA texture
     */
    static CreateRGBATexture(data: Nullable<ArrayBufferView>, width: number, height: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, type?: number, creationFlags?: number, useSRGBBuffer?: boolean, waitDataToBeReady?: boolean): RawTexture;
    /**
     * Creates a RGBA storage texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @param type define the format of the data (int, float... Engine.TEXTURETYPE_xxx)
     * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
     * @returns the RGBA texture
     */
    static CreateRGBAStorageTexture(data: Nullable<ArrayBufferView>, width: number, height: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, type?: number, useSRGBBuffer?: boolean): RawTexture;
    /**
     * Creates a R texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @param type define the format of the data (int, float... Engine.TEXTURETYPE_xxx)
     * @returns the R texture
     */
    static CreateRTexture(data: Nullable<ArrayBufferView>, width: number, height: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, type?: number): RawTexture;
    /**
     * Creates a R storage texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param sceneOrEngine defines the scene or engine the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @param type define the format of the data (int, float... Engine.TEXTURETYPE_xxx)
     * @returns the R texture
     */
    static CreateRStorageTexture(data: Nullable<ArrayBufferView>, width: number, height: number, sceneOrEngine: Nullable<Scene | AbstractEngine>, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, type?: number): RawTexture;
}

declare module "../scene" {
    interface Scene {
        /**
         * Sort active animatables based on their playOrder property
         */
        sortActiveAnimatables(): void;
        /**
         * Will start the animation sequence of a given target
         * @param target defines the target
         * @param from defines from which frame should animation start
         * @param to defines until which frame should animation run.
         * @param weight defines the weight to apply to the animation (1.0 by default)
         * @param loop defines if the animation loops
         * @param speedRatio defines the speed in which to run the animation (1.0 by default)
         * @param onAnimationEnd defines the function to be executed when the animation ends
         * @param animatable defines an animatable object. If not provided a new one will be created from the given params
         * @param targetMask defines if the target should be animated if animations are present (this is called recursively on descendant animatables regardless of return value)
         * @param onAnimationLoop defines the callback to call when an animation loops
         * @param isAdditive defines whether the animation should be evaluated additively (false by default)
         * @returns the animatable object created for this animation
         */
        beginWeightedAnimation(target: any, from: number, to: number, weight: number, loop?: boolean, speedRatio?: number, onAnimationEnd?: () => void, animatable?: Animatable, targetMask?: (target: any) => boolean, onAnimationLoop?: () => void, isAdditive?: boolean): Animatable;
        /**
         * Will start the animation sequence of a given target
         *
         * Note that it is possible that the value(s) of speedRatio from and to will be changed if the animation is inverted
         * @param target defines the target
         * @param from defines from which frame should animation start
         * @param to defines until which frame should animation run.
         * @param loop defines if the animation loops
         * @param speedRatio defines the speed in which to run the animation (1.0 by default)
         * @param onAnimationEnd defines the function to be executed when the animation ends
         * @param animatable defines an animatable object. If not provided a new one will be created from the given params
         * @param stopCurrent defines if the current animations must be stopped first (true by default)
         * @param targetMask defines if the target should be animate if animations are present (this is called recursively on descendant animatables regardless of return value)
         * @param onAnimationLoop defines the callback to call when an animation loops
         * @param isAdditive defines whether the animation should be evaluated additively (false by default)
         * @returns the animatable object created for this animation
         */
        beginAnimation(target: any, from: number, to: number, loop?: boolean, speedRatio?: number, onAnimationEnd?: () => void, animatable?: Animatable, stopCurrent?: boolean, targetMask?: (target: any) => boolean, onAnimationLoop?: () => void, isAdditive?: boolean): Animatable;
        /**
         * Will start the animation sequence of a given target and its hierarchy
         * @param target defines the target
         * @param directDescendantsOnly if true only direct descendants will be used, if false direct and also indirect (children of children, an so on in a recursive manner) descendants will be used.
         * @param from defines from which frame should animation start
         * @param to defines until which frame should animation run.
         * @param loop defines if the animation loops
         * @param speedRatio defines the speed in which to run the animation (1.0 by default)
         * @param onAnimationEnd defines the function to be executed when the animation ends
         * @param animatable defines an animatable object. If not provided a new one will be created from the given params
         * @param stopCurrent defines if the current animations must be stopped first (true by default)
         * @param targetMask defines if the target should be animated if animations are present (this is called recursively on descendant animatables regardless of return value)
         * @param onAnimationLoop defines the callback to call when an animation loops
         * @param isAdditive defines whether the animation should be evaluated additively (false by default)
         * @returns the list of created animatables
         */
        beginHierarchyAnimation(target: any, directDescendantsOnly: boolean, from: number, to: number, loop?: boolean, speedRatio?: number, onAnimationEnd?: () => void, animatable?: Animatable, stopCurrent?: boolean, targetMask?: (target: any) => boolean, onAnimationLoop?: () => void, isAdditive?: boolean): Animatable[];
        /**
         * Begin a new animation on a given node
         *
         * Note that it is possible that the value(s) of speedRatio from and to will be changed if the animation is inverted
         * @param target defines the target where the animation will take place
         * @param animations defines the list of animations to start
         * @param from defines the initial value
         * @param to defines the final value
         * @param loop defines if you want animation to loop (off by default)
         * @param speedRatio defines the speed ratio to apply to all animations
         * @param onAnimationEnd defines the callback to call when an animation ends (will be called once per node)
         * @param onAnimationLoop defines the callback to call when an animation loops
         * @param isAdditive defines whether the animation should be evaluated additively (false by default)
         * @returns the list of created animatables
         */
        beginDirectAnimation(target: any, animations: Animation[], from: number, to: number, loop?: boolean, speedRatio?: number, onAnimationEnd?: () => void, onAnimationLoop?: () => void, isAdditive?: boolean): Animatable;
        /**
         * Begin a new animation on a given node and its hierarchy
         * @param target defines the root node where the animation will take place
         * @param directDescendantsOnly if true only direct descendants will be used, if false direct and also indirect (children of children, an so on in a recursive manner) descendants will be used.
         * @param animations defines the list of animations to start
         * @param from defines the initial value
         * @param to defines the final value
         * @param loop defines if you want animation to loop (off by default)
         * @param speedRatio defines the speed ratio to apply to all animations
         * @param onAnimationEnd defines the callback to call when an animation ends (will be called once per node)
         * @param onAnimationLoop defines the callback to call when an animation loops
         * @param isAdditive defines whether the animation should be evaluated additively (false by default)
         * @returns the list of animatables created for all nodes
         */
        beginDirectHierarchyAnimation(target: Node, directDescendantsOnly: boolean, animations: Animation[], from: number, to: number, loop?: boolean, speedRatio?: number, onAnimationEnd?: () => void, onAnimationLoop?: () => void, isAdditive?: boolean): Animatable[];
        /**
         * Gets the animatable associated with a specific target
         * @param target defines the target of the animatable
         * @returns the required animatable if found
         */
        getAnimatableByTarget(target: any): Nullable<Animatable>;
        /**
         * Gets all animatables associated with a given target
         * @param target defines the target to look animatables for
         * @returns an array of Animatables
         */
        getAllAnimatablesByTarget(target: any): Array<Animatable>;
        /**
         * Stops and removes all animations that have been applied to the scene
         */
        stopAllAnimations(): void;
    }
}
declare module "../Bones/bone" {
    interface Bone {
        /**
         * Copy an animation range from another bone
         * @param source defines the source bone
         * @param rangeName defines the range name to copy
         * @param frameOffset defines the frame offset
         * @param rescaleAsRequired defines if rescaling must be applied if required
         * @param skelDimensionsRatio defines the scaling ratio
         * @returns true if operation was successful
         */
        copyAnimationRange(source: Bone, rangeName: string, frameOffset: number, rescaleAsRequired: boolean, skelDimensionsRatio: Nullable<Vector3>): boolean;
    }
}

/**
 * Defines a runtime animation
 */
declare class RuntimeAnimation {
    private _events;
    /**
     * The current frame of the runtime animation
     */
    private _currentFrame;
    /**
     * The animation used by the runtime animation
     */
    _animation: Animation;
    /**
     * The target of the runtime animation
     */
    private _target;
    /**
     * The initiating animatable
     */
    private _host;
    /**
     * The original value of the runtime animation
     */
    private _originalValue;
    /**
     * The original blend value of the runtime animation
     */
    private _originalBlendValue;
    /**
     * The offsets cache of the runtime animation
     */
    private _offsetsCache;
    /**
     * The high limits cache of the runtime animation
     */
    private _highLimitsCache;
    /**
     * Specifies if the runtime animation has been stopped
     */
    private _stopped;
    /**
     * The blending factor of the runtime animation
     */
    private _blendingFactor;
    /**
     * The BabylonJS scene
     */
    private _scene;
    /**
     * The current value of the runtime animation
     */
    private _currentValue;
    /** @internal */
    _animationState: _IAnimationState;
    /**
     * The active target of the runtime animation
     */
    private _activeTargets;
    private _currentActiveTarget;
    private _directTarget;
    /**
     * The target path of the runtime animation
     */
    private _targetPath;
    /**
     * The weight of the runtime animation
     */
    private _weight;
    /**
     * The absolute frame offset of the runtime animation
     */
    private _absoluteFrameOffset;
    /**
     * The previous elapsed time (since start of animation) of the runtime animation
     */
    private _previousElapsedTime;
    private _yoyoDirection;
    /**
     * The previous absolute frame of the runtime animation (meaning, without taking into account the from/to values, only the elapsed time and the fps)
     */
    private _previousAbsoluteFrame;
    private _enableBlending;
    private _keys;
    private _minFrame;
    private _maxFrame;
    private _targetIsArray;
    /** @internal */
    _coreRuntimeAnimation: RuntimeAnimation | null;
    /**
     * Gets the current frame of the runtime animation
     */
    get currentFrame(): number;
    /**
     * Gets the weight of the runtime animation
     */
    get weight(): number;
    /**
     * Gets the current value of the runtime animation
     */
    get currentValue(): any;
    /**
     * Gets or sets the target path of the runtime animation
     */
    get targetPath(): string;
    /**
     * Gets the actual target of the runtime animation
     */
    get target(): any;
    /**
     * Gets the additive state of the runtime animation
     */
    get isAdditive(): boolean;
    /** @internal */
    _onLoop: () => void;
    /**
     * Create a new RuntimeAnimation object
     * @param target defines the target of the animation
     * @param animation defines the source animation object
     * @param scene defines the hosting scene
     * @param host defines the initiating Animatable
     */
    constructor(target: any, animation: Animation, scene: Scene, host: Animatable);
    private _preparePath;
    /**
     * Gets the animation from the runtime animation
     */
    get animation(): Animation;
    /**
     * Resets the runtime animation to the beginning
     * @param restoreOriginal defines whether to restore the target property to the original value
     */
    reset(restoreOriginal?: boolean): void;
    /**
     * Specifies if the runtime animation is stopped
     * @returns Boolean specifying if the runtime animation is stopped
     */
    isStopped(): boolean;
    /**
     * Disposes of the runtime animation
     */
    dispose(): void;
    /**
     * Apply the interpolated value to the target
     * @param currentValue defines the value computed by the animation
     * @param weight defines the weight to apply to this value (Defaults to 1.0)
     */
    setValue(currentValue: any, weight: number): void;
    private _getOriginalValues;
    private _registerTargetForLateAnimationBinding;
    private _setValue;
    /**
     * Gets the loop pmode of the runtime animation
     * @returns Loop Mode
     */
    private _getCorrectLoopMode;
    /**
     * Move the current animation to a given frame
     * @param frame defines the frame to move to
     * @param weight defines the weight to apply to the animation (-1.0 by default)
     */
    goToFrame(frame: number, weight?: number): void;
    /**
     * @internal Internal use only
     */
    _prepareForSpeedRatioChange(newSpeedRatio: number): void;
    /**
     * Execute the current animation
     * @param elapsedTimeSinceAnimationStart defines the elapsed time (in milliseconds) since the animation was started
     * @param from defines the lower frame of the animation range
     * @param to defines the upper frame of the animation range
     * @param loop defines if the current animation must loop
     * @param speedRatio defines the current speed ratio
     * @param weight defines the weight of the animation (default is -1 so no weight)
     * @returns a boolean indicating if the animation is running
     */
    animate(elapsedTimeSinceAnimationStart: number, from: number, to: number, loop: boolean, speedRatio: number, weight?: number): boolean;
}

/**
 * Class used to store an actual running animation
 */
declare class Animatable {
    /** defines the target object */
    target: any;
    /** [0] defines the starting frame number (default is 0) */
    fromFrame: number;
    /** [100] defines the ending frame number (default is 100) */
    toFrame: number;
    /** [false] defines if the animation must loop (default is false)  */
    loopAnimation: boolean;
    /** defines a callback to call when animation ends if it is not looping */
    onAnimationEnd?: Nullable<() => void> | undefined;
    /** defines a callback to call when animation loops */
    onAnimationLoop?: Nullable<() => void> | undefined;
    /** [false] defines whether the animation should be evaluated additively */
    isAdditive: boolean;
    /** [0] defines the order in which this animatable should be processed in the list of active animatables (default: 0) */
    playOrder: number;
    /**
     * If true, the animatable will be processed even if it is considered actively paused (weight of 0 and previous weight of 0).
     * This can be used to force the full processing of paused animatables in the animation engine.
     * Default is false.
     */
    static ProcessPausedAnimatables: boolean;
    private _localDelayOffset;
    private _pausedDelay;
    private _manualJumpDelay;
    /** @hidden */
    _runtimeAnimations: RuntimeAnimation[];
    private _paused;
    private _scene;
    private _speedRatio;
    private _weight;
    private _previousWeight;
    private _syncRoot;
    private _frameToSyncFromJump;
    private _goToFrame;
    /**
     * Gets or sets a boolean indicating if the animatable must be disposed and removed at the end of the animation.
     * This will only apply for non looping animation (default is true)
     */
    disposeOnEnd: boolean;
    /**
     * Gets a boolean indicating if the animation has started
     */
    animationStarted: boolean;
    /**
     * Observer raised when the animation ends
     */
    onAnimationEndObservable: Observable<Animatable>;
    /**
     * Observer raised when the animation loops
     */
    onAnimationLoopObservable: Observable<Animatable>;
    /**
     * Gets the root Animatable used to synchronize and normalize animations
     */
    get syncRoot(): Nullable<Animatable>;
    /**
     * Gets the current frame of the first RuntimeAnimation
     * Used to synchronize Animatables
     */
    get masterFrame(): number;
    /**
     * Gets or sets the animatable weight (-1.0 by default meaning not weighted)
     */
    get weight(): number;
    set weight(value: number);
    /**
     * Gets or sets the speed ratio to apply to the animatable (1.0 by default)
     */
    get speedRatio(): number;
    set speedRatio(value: number);
    /**
     * Gets the elapsed time since the animatable started in milliseconds
     */
    get elapsedTime(): number;
    /**
     * Creates a new Animatable
     * @param scene defines the hosting scene
     * @param target defines the target object
     * @param fromFrame defines the starting frame number (default is 0)
     * @param toFrame defines the ending frame number (default is 100)
     * @param loopAnimation defines if the animation must loop (default is false)
     * @param speedRatio defines the factor to apply to animation speed (default is 1)
     * @param onAnimationEnd defines a callback to call when animation ends if it is not looping
     * @param animations defines a group of animation to add to the new Animatable
     * @param onAnimationLoop defines a callback to call when animation loops
     * @param isAdditive defines whether the animation should be evaluated additively
     * @param playOrder defines the order in which this animatable should be processed in the list of active animatables (default: 0)
     */
    constructor(scene: Scene, 
    /** defines the target object */
    target: any, 
    /** [0] defines the starting frame number (default is 0) */
    fromFrame?: number, 
    /** [100] defines the ending frame number (default is 100) */
    toFrame?: number, 
    /** [false] defines if the animation must loop (default is false)  */
    loopAnimation?: boolean, speedRatio?: number, 
    /** defines a callback to call when animation ends if it is not looping */
    onAnimationEnd?: Nullable<() => void> | undefined, animations?: Animation[], 
    /** defines a callback to call when animation loops */
    onAnimationLoop?: Nullable<() => void> | undefined, 
    /** [false] defines whether the animation should be evaluated additively */
    isAdditive?: boolean, 
    /** [0] defines the order in which this animatable should be processed in the list of active animatables (default: 0) */
    playOrder?: number);
    /**
     * Synchronize and normalize current Animatable with a source Animatable
     * This is useful when using animation weights and when animations are not of the same length
     * @param root defines the root Animatable to synchronize with (null to stop synchronizing)
     * @returns the current Animatable
     */
    syncWith(root: Nullable<Animatable>): Animatable;
    /**
     * Gets the list of runtime animations
     * @returns an array of RuntimeAnimation
     */
    getAnimations(): RuntimeAnimation[];
    /**
     * Adds more animations to the current animatable
     * @param target defines the target of the animations
     * @param animations defines the new animations to add
     */
    appendAnimations(target: any, animations: Animation[]): void;
    /**
     * Gets the source animation for a specific property
     * @param property defines the property to look for
     * @returns null or the source animation for the given property
     */
    getAnimationByTargetProperty(property: string): Nullable<Animation>;
    /**
     * Gets the runtime animation for a specific property
     * @param property defines the property to look for
     * @returns null or the runtime animation for the given property
     */
    getRuntimeAnimationByTargetProperty(property: string): Nullable<RuntimeAnimation>;
    /**
     * Resets the animatable to its original state
     */
    reset(): void;
    /**
     * Allows the animatable to blend with current running animations
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#animation-blending
     * @param blendingSpeed defines the blending speed to use
     */
    enableBlending(blendingSpeed: number): void;
    /**
     * Disable animation blending
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#animation-blending
     */
    disableBlending(): void;
    /**
     * Jump directly to a given frame
     * @param frame defines the frame to jump to
     * @param useWeight defines whether the animation weight should be applied to the image to be jumped to (false by default)
     */
    goToFrame(frame: number, useWeight?: boolean): void;
    /**
     * Returns true if the animations for this animatable are paused
     */
    get paused(): boolean;
    /**
     * Pause the animation
     */
    pause(): void;
    /**
     * Restart the animation
     */
    restart(): void;
    private _raiseOnAnimationEnd;
    /**
     * Stop and delete the current animation
     * @param animationName defines a string used to only stop some of the runtime animations instead of all
     * @param targetMask a function that determines if the animation should be stopped based on its target (all animations will be stopped if both this and animationName are empty)
     * @param useGlobalSplice if true, the animatables will be removed by the caller of this function (false by default)
     * @param skipOnAnimationEnd defines if the system should not raise onAnimationEnd. Default is false
     */
    stop(animationName?: string, targetMask?: (target: any) => boolean, useGlobalSplice?: boolean, skipOnAnimationEnd?: boolean): void;
    /**
     * Wait asynchronously for the animation to end
     * @returns a promise which will be fulfilled when the animation ends
     */
    waitAsync(): Promise<Animatable>;
    /**
     * @internal
     */
    _animate(delay: number): boolean;
}

/**
 * Represents the range of an animation
 */
declare class AnimationRange {
    /**The name of the animation range**/
    name: string;
    /**The starting frame of the animation */
    from: number;
    /**The ending frame of the animation*/
    to: number;
    /**
     * Initializes the range of an animation
     * @param name The name of the animation range
     * @param from The starting frame of the animation
     * @param to The ending frame of the animation
     */
    constructor(
    /**The name of the animation range**/
    name: string, 
    /**The starting frame of the animation */
    from: number, 
    /**The ending frame of the animation*/
    to: number);
    /**
     * Makes a copy of the animation range
     * @returns A copy of the animation range
     */
    clone(): AnimationRange;
}

/**
 * Class used to handle skinning animations
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/bonesSkeletons
 */
declare class Skeleton implements IAnimatable {
    /** defines the skeleton name */
    name: string;
    /** defines the skeleton Id */
    id: string;
    /**
     * Defines the list of child bones
     */
    bones: Bone[];
    /**
     * Defines an estimate of the dimension of the skeleton at rest
     */
    dimensionsAtRest: Vector3;
    /**
     * Defines a boolean indicating if the root matrix is provided by meshes or by the current skeleton (this is the default value)
     */
    needInitialSkinMatrix: boolean;
    /**
     * Gets the list of animations attached to this skeleton
     */
    animations: Array<Animation>;
    private _scene;
    private _isDirty;
    private _transformMatrices;
    private _transformMatrixTexture;
    private _meshesWithPoseMatrix;
    private _animatables;
    private _identity;
    private _synchronizedWithMesh;
    private _currentRenderId;
    private _ranges;
    private _absoluteTransformIsDirty;
    private _canUseTextureForBones;
    private _uniqueId;
    /** @internal */
    _numBonesWithLinkedTransformNode: number;
    /** @internal */
    _hasWaitingData: Nullable<boolean>;
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /**
     * Specifies if the skeleton should be serialized
     */
    doNotSerialize: boolean;
    private _useTextureToStoreBoneMatrices;
    /**
     * Gets or sets a boolean indicating that bone matrices should be stored as a texture instead of using shader uniforms (default is true).
     * Please note that this option is not available if the hardware does not support it
     */
    get useTextureToStoreBoneMatrices(): boolean;
    set useTextureToStoreBoneMatrices(value: boolean);
    private _animationPropertiesOverride;
    /**
     * Gets or sets the animation properties override
     */
    get animationPropertiesOverride(): Nullable<AnimationPropertiesOverride>;
    set animationPropertiesOverride(value: Nullable<AnimationPropertiesOverride>);
    /**
     * List of inspectable custom properties (used by the Inspector)
     * @see https://doc.babylonjs.com/toolsAndResources/inspector#extensibility
     */
    inspectableCustomProperties: IInspectable[];
    /**
     * An observable triggered before computing the skeleton's matrices
     */
    onBeforeComputeObservable: Observable<Skeleton>;
    /**
     * Gets a boolean indicating that the skeleton effectively stores matrices into a texture
     */
    get isUsingTextureForMatrices(): boolean;
    /**
     * Gets the unique ID of this skeleton
     */
    get uniqueId(): number;
    /**
     * Gets or sets an object used to store user defined information for the skeleton
     */
    metadata: any;
    /**
     * Creates a new skeleton
     * @param name defines the skeleton name
     * @param id defines the skeleton Id
     * @param scene defines the hosting scene
     */
    constructor(
    /** defines the skeleton name */
    name: string, 
    /** defines the skeleton Id */
    id: string, scene: Scene);
    /**
     * Gets the current object class name.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Returns an array containing the root bones
     * @returns an array containing the root bones
     */
    getChildren(): Array<Bone>;
    /**
     * Gets the list of transform matrices to send to shaders (one matrix per bone)
     * @param mesh defines the mesh to use to get the root matrix (if needInitialSkinMatrix === true)
     * @returns a Float32Array containing matrices data
     */
    getTransformMatrices(mesh: Nullable<AbstractMesh>): Float32Array;
    /**
     * Gets the list of transform matrices to send to shaders inside a texture (one matrix per bone)
     * @param mesh defines the mesh to use to get the root matrix (if needInitialSkinMatrix === true)
     * @returns a raw texture containing the data
     */
    getTransformMatrixTexture(mesh: AbstractMesh): Nullable<RawTexture>;
    /**
     * Gets the current hosting scene
     * @returns a scene object
     */
    getScene(): Scene;
    /**
     * Gets a string representing the current skeleton data
     * @param fullDetails defines a boolean indicating if we want a verbose version
     * @returns a string representing the current skeleton data
     */
    toString(fullDetails?: boolean): string;
    /**
     * Get bone's index searching by name
     * @param name defines bone's name to search for
     * @returns the indice of the bone. Returns -1 if not found
     */
    getBoneIndexByName(name: string): number;
    /**
     * Create a new animation range
     * @param name defines the name of the range
     * @param from defines the start key
     * @param to defines the end key
     */
    createAnimationRange(name: string, from: number, to: number): void;
    /**
     * Delete a specific animation range
     * @param name defines the name of the range
     * @param deleteFrames defines if frames must be removed as well
     */
    deleteAnimationRange(name: string, deleteFrames?: boolean): void;
    /**
     * Gets a specific animation range
     * @param name defines the name of the range to look for
     * @returns the requested animation range or null if not found
     */
    getAnimationRange(name: string): Nullable<AnimationRange>;
    /**
     * Gets the list of all animation ranges defined on this skeleton
     * @returns an array
     */
    getAnimationRanges(): Nullable<AnimationRange>[];
    /**
     * Copy animation range from a source skeleton.
     * This is not for a complete retargeting, only between very similar skeleton's with only possible bone length differences
     * @param source defines the source skeleton
     * @param name defines the name of the range to copy
     * @param rescaleAsRequired defines if rescaling must be applied if required
     * @returns true if operation was successful
     */
    copyAnimationRange(source: Skeleton, name: string, rescaleAsRequired?: boolean): boolean;
    /**
     * Forces the skeleton to go to rest pose
     */
    returnToRest(): void;
    private _getHighestAnimationFrame;
    /**
     * Begin a specific animation range
     * @param name defines the name of the range to start
     * @param loop defines if looping must be turned on (false by default)
     * @param speedRatio defines the speed ratio to apply (1 by default)
     * @param onAnimationEnd defines a callback which will be called when animation will end
     * @returns a new animatable
     */
    beginAnimation(name: string, loop?: boolean, speedRatio?: number, onAnimationEnd?: () => void): Nullable<Animatable>;
    /**
     * Convert the keyframes for a range of animation on a skeleton to be relative to a given reference frame.
     * @param skeleton defines the Skeleton containing the animation range to convert
     * @param referenceFrame defines the frame that keyframes in the range will be relative to
     * @param range defines the name of the AnimationRange belonging to the Skeleton to convert
     * @returns the original skeleton
     */
    static MakeAnimationAdditive(skeleton: Skeleton, referenceFrame: number | undefined, range: string): Nullable<Skeleton>;
    /** @internal */
    _markAsDirty(): void;
    /**
     * @internal
     */
    _registerMeshWithPoseMatrix(mesh: AbstractMesh): void;
    /**
     * @internal
     */
    _unregisterMeshWithPoseMatrix(mesh: AbstractMesh): void;
    private _computeTransformMatrices;
    /**
     * Build all resources required to render a skeleton
     * @param dontCheckFrameId defines a boolean indicating if prepare should be run without checking first the current frame id (default: false)
     */
    prepare(dontCheckFrameId?: boolean): void;
    /**
     * Gets the list of animatables currently running for this skeleton
     * @returns an array of animatables
     */
    getAnimatables(): IAnimatable[];
    /**
     * Clone the current skeleton
     * @param name defines the name of the new skeleton
     * @param id defines the id of the new skeleton
     * @returns the new skeleton
     */
    clone(name: string, id?: string): Skeleton;
    /**
     * Enable animation blending for this skeleton
     * @param blendingSpeed defines the blending speed to apply
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#animation-blending
     */
    enableBlending(blendingSpeed?: number): void;
    /**
     * Releases all resources associated with the current skeleton
     */
    dispose(): void;
    /**
     * Serialize the skeleton in a JSON object
     * @returns a JSON object
     */
    serialize(): any;
    /**
     * Creates a new skeleton from serialized data
     * @param parsedSkeleton defines the serialized data
     * @param scene defines the hosting scene
     * @returns a new skeleton
     */
    static Parse(parsedSkeleton: any, scene: Scene): Skeleton;
    /**
     * Compute all node absolute matrices
     * @param forceUpdate defines if computation must be done even if cache is up to date
     */
    computeAbsoluteMatrices(forceUpdate?: boolean): void;
    /**
     * Compute all node absolute matrices
     * @param forceUpdate defines if computation must be done even if cache is up to date
     * @deprecated Please use computeAbsoluteMatrices instead
     */
    computeAbsoluteTransforms(forceUpdate?: boolean): void;
    /**
     * Gets the root pose matrix
     * @returns a matrix
     */
    getPoseMatrix(): Nullable<Matrix>;
    /**
     * Sorts bones per internal index
     */
    sortBones(): void;
    private _sortBones;
    /**
     * Set the current local matrix as the restPose for all bones in the skeleton.
     */
    setCurrentPoseAsRest(): void;
}

/**
 * Defines a target to use with MorphTargetManager
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/morphTargets
 */
declare class MorphTarget implements IAnimatable {
    /** defines the name of the target */
    name: string;
    /**
     * Gets or sets the list of animations
     */
    animations: Animation[];
    private _scene;
    private _positions;
    private _normals;
    private _tangents;
    private _uvs;
    private _uv2s;
    private _colors;
    private _influence;
    private _uniqueId;
    /**
     * Observable raised when the influence changes
     */
    onInfluenceChanged: Observable<boolean>;
    /** @internal */
    _onDataLayoutChanged: Observable<void>;
    /**
     * Gets or sets the influence of this target (ie. its weight in the overall morphing)
     */
    get influence(): number;
    set influence(influence: number);
    /**
     * Gets or sets the id of the morph Target
     */
    id: string;
    private _animationPropertiesOverride;
    /**
     * Gets or sets the animation properties override
     */
    get animationPropertiesOverride(): Nullable<AnimationPropertiesOverride>;
    set animationPropertiesOverride(value: Nullable<AnimationPropertiesOverride>);
    /**
     * Creates a new MorphTarget
     * @param name defines the name of the target
     * @param influence defines the influence to use
     * @param scene defines the scene the morphtarget belongs to
     */
    constructor(
    /** defines the name of the target */
    name: string, influence?: number, scene?: Nullable<Scene>);
    /**
     * Gets the unique ID of this manager
     */
    get uniqueId(): number;
    /**
     * Gets a boolean defining if the target contains position data
     */
    get hasPositions(): boolean;
    /**
     * Gets a boolean defining if the target contains normal data
     */
    get hasNormals(): boolean;
    /**
     * Gets a boolean defining if the target contains tangent data
     */
    get hasTangents(): boolean;
    /**
     * Gets a boolean defining if the target contains texture coordinates data
     */
    get hasUVs(): boolean;
    /**
     * Gets a boolean defining if the target contains texture coordinates 2 data
     */
    get hasUV2s(): boolean;
    get hasColors(): boolean;
    /**
     * Gets the number of vertices stored in this target
     */
    get vertexCount(): number;
    /**
     * Affects position data to this target
     * @param data defines the position data to use
     */
    setPositions(data: Nullable<FloatArray>): void;
    /**
     * Gets the position data stored in this target
     * @returns a FloatArray containing the position data (or null if not present)
     */
    getPositions(): Nullable<FloatArray>;
    /**
     * Affects normal data to this target
     * @param data defines the normal data to use
     */
    setNormals(data: Nullable<FloatArray>): void;
    /**
     * Gets the normal data stored in this target
     * @returns a FloatArray containing the normal data (or null if not present)
     */
    getNormals(): Nullable<FloatArray>;
    /**
     * Affects tangent data to this target
     * @param data defines the tangent data to use
     */
    setTangents(data: Nullable<FloatArray>): void;
    /**
     * Gets the tangent data stored in this target
     * @returns a FloatArray containing the tangent data (or null if not present)
     */
    getTangents(): Nullable<FloatArray>;
    /**
     * Affects texture coordinates data to this target
     * @param data defines the texture coordinates data to use
     */
    setUVs(data: Nullable<FloatArray>): void;
    /**
     * Gets the texture coordinates data stored in this target
     * @returns a FloatArray containing the texture coordinates data (or null if not present)
     */
    getUVs(): Nullable<FloatArray>;
    /**
     * Affects texture coordinates 2 data to this target
     * @param data defines the texture coordinates 2 data to use
     */
    setUV2s(data: Nullable<FloatArray>): void;
    /**
     * Gets the texture coordinates 2 data stored in this target
     * @returns a FloatArray containing the texture coordinates 2 data (or null if not present)
     */
    getUV2s(): Nullable<FloatArray>;
    /**
     * Affects color data to this target
     * @param data defines the color data to use
     */
    setColors(data: Nullable<FloatArray>): void;
    /**
     * Gets the color data stored in this target
     * @returns a FloatArray containing the color data (or null if not present)
     */
    getColors(): Nullable<FloatArray>;
    /**
     * Clone the current target
     * @returns a new MorphTarget
     */
    clone(): MorphTarget;
    /**
     * Serializes the current target into a Serialization object
     * @returns the serialized object
     */
    serialize(): any;
    /**
     * Returns the string "MorphTarget"
     * @returns "MorphTarget"
     */
    getClassName(): string;
    /**
     * Creates a new target from serialized data
     * @param serializationObject defines the serialized data to use
     * @param scene defines the hosting scene
     * @returns a new MorphTarget
     */
    static Parse(serializationObject: any, scene?: Scene): MorphTarget;
    /**
     * Creates a MorphTarget from mesh data
     * @param mesh defines the source mesh
     * @param name defines the name to use for the new target
     * @param influence defines the influence to attach to the target
     * @returns a new MorphTarget
     */
    static FromMesh(mesh: AbstractMesh, name?: string, influence?: number): MorphTarget;
}

/**
 * Class used to store 2D array textures containing user data
 */
declare class RawTexture2DArray extends Texture {
    /** Gets or sets the texture format to use */
    format: number;
    private _depth;
    /**
     * Gets the number of layers of the texture
     */
    get depth(): number;
    /**
     * Create a new RawTexture2DArray
     * @param data defines the data of the texture
     * @param width defines the width of the texture
     * @param height defines the height of the texture
     * @param depth defines the number of layers of the texture
     * @param format defines the texture format to use
     * @param scene defines the hosting scene
     * @param generateMipMaps defines a boolean indicating if mip levels should be generated (true by default)
     * @param invertY defines if texture must be stored with Y axis inverted
     * @param samplingMode defines the sampling mode to use (Texture.TRILINEAR_SAMPLINGMODE by default)
     * @param textureType defines the texture Type (Engine.TEXTURETYPE_UNSIGNED_BYTE, Engine.TEXTURETYPE_FLOAT...)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param mipLevelCount defines the number of mip levels to allocate for the texture
     */
    constructor(data: Nullable<ArrayBufferView>, width: number, height: number, depth: number, 
    /** Gets or sets the texture format to use */
    format: number, scene: Scene, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, textureType?: number, creationFlags?: number, mipLevelCount?: number);
    /**
     * Update the texture with new data
     * @param data defines the data to store in the texture
     */
    update(data: ArrayBufferView): void;
    /**
     * Updates a specific mip level of the texture.
     * @param data The new data for the mip level
     * @param mipLevel The mip level to update (0 is the base level)
     */
    updateMipLevel(data: ArrayBufferView, mipLevel: number): void;
    /**
     * Creates a RGBA texture from some data.
     * @param data Define the texture data
     * @param width Define the width of the texture
     * @param height Define the height of the texture
     * @param depth defines the number of layers of the texture
     * @param scene defines the scene the texture will belong to
     * @param generateMipMaps Define whether or not to create mip maps for the texture
     * @param invertY define if the data should be flipped on Y when uploaded to the GPU
     * @param samplingMode define the texture sampling mode (Texture.xxx_SAMPLINGMODE)
     * @param type define the format of the data (int, float... Engine.TEXTURETYPE_xxx)
     * @returns the RGBA texture
     */
    static CreateRGBATexture(data: ArrayBufferView, width: number, height: number, depth: number, scene: Scene, generateMipMaps?: boolean, invertY?: boolean, samplingMode?: number, type?: number): RawTexture2DArray;
}

/**
 * This class is used to deform meshes using morphing between different targets
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/morphTargets
 */
declare class MorphTargetManager implements IDisposable {
    /** Enable storing morph target data into textures when set to true (true by default) */
    static EnableTextureStorage: boolean;
    /** Maximum number of active morph targets supported in the "vertex attribute" mode (i.e., not the "texture" mode) */
    static MaxActiveMorphTargetsInVertexAttributeMode: number;
    /**
     * When used in texture mode, if greather than 0, this will override the the morph manager numMaxInfluencers value.
     */
    static ConstantTargetCountForTextureMode: number;
    private _targets;
    private _targetInfluenceChangedObservers;
    private _targetDataLayoutChangedObservers;
    private _activeTargets;
    private _scene;
    private _influences;
    private _supportsPositions;
    private _supportsNormals;
    private _supportsTangents;
    private _supportsUVs;
    private _supportsUV2s;
    private _supportsColors;
    private _vertexCount;
    private _uniqueId;
    private _tempInfluences;
    private _canUseTextureForTargets;
    private _blockCounter;
    private _mustSynchronize;
    private _forceUpdateWhenUnfrozen;
    /** @internal */
    _textureVertexStride: number;
    /** @internal */
    _textureWidth: number;
    /** @internal */
    _textureHeight: number;
    /** @internal */
    _morphTargetTextureIndices: Float32Array;
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /** @internal */
    _targetStoreTexture: Nullable<RawTexture2DArray>;
    /**
     * Gets or sets a boolean indicating if influencers must be optimized (eg. recompiling the shader if less influencers are used)
     */
    optimizeInfluencers: boolean;
    /**
     * Gets or sets a boolean indicating if positions must be morphed
     */
    enablePositionMorphing: boolean;
    /**
     * Gets or sets a boolean indicating if normals must be morphed
     */
    enableNormalMorphing: boolean;
    /**
     * Gets or sets a boolean indicating if tangents must be morphed
     */
    enableTangentMorphing: boolean;
    /**
     * Gets or sets a boolean indicating if UV must be morphed
     */
    enableUVMorphing: boolean;
    /**
     * Gets or sets a boolean indicating if UV2 must be morphed
     */
    enableUV2Morphing: boolean;
    /**
     * Gets or sets a boolean indicating if colors must be morphed
     */
    enableColorMorphing: boolean;
    /**
     * Sets a boolean indicating that adding new target or updating an existing target will not update the underlying data buffers
     */
    set areUpdatesFrozen(block: boolean);
    get areUpdatesFrozen(): boolean;
    /**
     * Creates a new MorphTargetManager
     * @param scene defines the current scene
     */
    constructor(scene?: Nullable<Scene>);
    private _numMaxInfluencers;
    /**
     * Gets or sets the maximum number of influencers (targets) (default value: 0).
     * Setting a value for this property can lead to a smoother experience, as only one shader will be compiled, which will use this value as the maximum number of influencers.
     * If you leave the value at 0 (default), a new shader will be compiled every time the number of active influencers changes. This can cause problems, as compiling a shader takes time.
     * If you assign a non-zero value to this property, you need to ensure that this value is greater than the maximum number of (active) influencers you'll need for this morph manager.
     * Otherwise, the number of active influencers will be truncated at the value you set for this property, which can lead to unexpected results.
     * Note that this property has no effect if "useTextureToStoreTargets" is false.
     * Note as well that if MorphTargetManager.ConstantTargetCountForTextureMode is greater than 0, this property will be ignored and the constant value will be used instead.
     */
    get numMaxInfluencers(): number;
    set numMaxInfluencers(value: number);
    /**
     * Gets the unique ID of this manager
     */
    get uniqueId(): number;
    /**
     * Gets the number of vertices handled by this manager
     */
    get vertexCount(): number;
    /**
     * Gets a boolean indicating if this manager supports morphing of positions
     */
    get supportsPositions(): boolean;
    /**
     * Gets a boolean indicating if this manager supports morphing of normals
     */
    get supportsNormals(): boolean;
    /**
     * Gets a boolean indicating if this manager supports morphing of tangents
     */
    get supportsTangents(): boolean;
    /**
     * Gets a boolean indicating if this manager supports morphing of texture coordinates
     */
    get supportsUVs(): boolean;
    /**
     * Gets a boolean indicating if this manager supports morphing of texture coordinates 2
     */
    get supportsUV2s(): boolean;
    /**
     * Gets a boolean indicating if this manager supports morphing of colors
     */
    get supportsColors(): boolean;
    /**
     * Gets a boolean indicating if this manager has data for morphing positions
     */
    get hasPositions(): boolean;
    /**
     * Gets a boolean indicating if this manager has data for morphing normals
     */
    get hasNormals(): boolean;
    /**
     * Gets a boolean indicating if this manager has data for morphing tangents
     */
    get hasTangents(): boolean;
    /**
     * Gets a boolean indicating if this manager has data for morphing texture coordinates
     */
    get hasUVs(): boolean;
    /**
     * Gets a boolean indicating if this manager has data for morphing texture coordinates 2
     */
    get hasUV2s(): boolean;
    /**
     * Gets a boolean indicating if this manager has data for morphing colors
     */
    get hasColors(): boolean;
    /**
     * Gets the number of targets stored in this manager
     */
    get numTargets(): number;
    /**
     * Gets the number of influencers (ie. the number of targets with influences > 0)
     */
    get numInfluencers(): number;
    /**
     * Gets the list of influences (one per target)
     */
    get influences(): Float32Array;
    private _useTextureToStoreTargets;
    /**
     * Gets or sets a boolean indicating that targets should be stored as a texture instead of using vertex attributes (default is true).
     * Please note that this option is not available if the hardware does not support it
     */
    get useTextureToStoreTargets(): boolean;
    set useTextureToStoreTargets(value: boolean);
    /**
     * Gets a boolean indicating that the targets are stored into a texture (instead of as attributes)
     */
    get isUsingTextureForTargets(): boolean;
    /**
     * Gets or sets an object used to store user defined information for the MorphTargetManager
     */
    metadata: any;
    /**
     * Gets the active target at specified index. An active target is a target with an influence > 0
     * @param index defines the index to check
     * @returns the requested target
     */
    getActiveTarget(index: number): MorphTarget;
    /**
     * Gets the target at specified index
     * @param index defines the index to check
     * @returns the requested target
     */
    getTarget(index: number): MorphTarget;
    /**
     * Gets the first target with the specified name
     * @param name defines the name to check
     * @returns the requested target
     */
    getTargetByName(name: string): Nullable<MorphTarget>;
    private _influencesAreDirty;
    private _needUpdateInfluences;
    /**
     * Add a new target to this manager
     * @param target defines the target to add
     */
    addTarget(target: MorphTarget): void;
    /**
     * Removes a target from the manager
     * @param target defines the target to remove
     */
    removeTarget(target: MorphTarget): void;
    /**
     * @internal
     */
    _bind(effect: Effect): void;
    /**
     * Clone the current manager
     * @returns a new MorphTargetManager
     */
    clone(): MorphTargetManager;
    /**
     * Serializes the current manager into a Serialization object
     * @returns the serialized object
     */
    serialize(): any;
    private _syncActiveTargets;
    /**
     * Synchronize the targets with all the meshes using this morph target manager
     */
    synchronize(): void;
    /**
     * Release all resources
     */
    dispose(): void;
    /**
     * Creates a new MorphTargetManager from serialized data
     * @param serializationObject defines the serialized data
     * @param scene defines the hosting scene
     * @returns the new MorphTargetManager
     */
    static Parse(serializationObject: any, scene: Scene): MorphTargetManager;
}

/**
 * Enum used to define the mode for an animation group mask
 */
declare const enum AnimationGroupMaskMode {
    /**
     * The mask defines the animatable target names that should be included
     */
    Include = 0,
    /**
     * The mask defines the animatable target names in a "exclude" mode: all animatable targets will be animated except the ones defined in the mask
     */
    Exclude = 1
}
/**
 * Defines a mask used to filter animation targets.
 * If you apply a mask to an animation group (see the AnimationGroup.mask property), only the animations whose target names match the mask will play.
 * Note that a target is defined by its name (string). This means that the same mask can be used for several animation groups, provided that their targets are named in the same way.
 */
declare class AnimationGroupMask {
    /**
     * [0] Defines the mode for the mask
     */
    mode: AnimationGroupMaskMode;
    /**
     * The set of target names included in the mask. If mode is AnimationGroupMaskMode.Exclude, the targets in this set will be excluded from the mask instead.
     */
    private _targetNames;
    /**
     * Gets or sets a boolean indicating if the mask is disabled (default is false)
     */
    disabled: boolean;
    /**
     * Creates a new mask
     * @param names The list of target names to add to the mask (optional)
     * @param mode Defines the mode for the mask (default: AnimationGroupMaskMode.Include)
     */
    constructor(names?: string[], 
    /**
     * [0] Defines the mode for the mask
     */
    mode?: AnimationGroupMaskMode);
    /**
     * Adds one or several target names to the mask
     * @param name The name(s) to add to the mask
     */
    addTargetName(name: string | string[]): void;
    /**
     * Removes one or several target names from the mask
     * @param name The name(s) to remove from the mask
     */
    removeTargetName(name: string | string[]): void;
    /**
     * Checks if the mask includes a target name.
     * This method is intended to know if a given target name is included in the mask, not if the name is actually retained by the mask (see retainsTarget() instead).
     * @param name The name to check with the mask
     * @returns True if the mask includes the name, false otherwise
     */
    hasTarget(name: string): boolean;
    /**
     * Checks if the mask retains a target name.
     * Note that in the "Exclude" mode, this will return false if the mask includes the name, and true otherwise!
     * This method is intended to know if a given target name is retained by the mask, not if the name is in the list of target names.
     * @param name The name to check with the mask
     * @returns True if the mask retains the name, false otherwise
     */
    retainsTarget(name: string): boolean;
}

/**
 * This class defines the direct association between an animation and a target
 */
declare class TargetedAnimation {
    readonly parent: AnimationGroup;
    /**
     * Animation to perform
     */
    animation: Animation;
    /**
     * Target to animate
     */
    target: any;
    /**
     * Gets or sets the unique id of the targeted animation
     */
    readonly uniqueId: number;
    /**
     * Returns the string "TargetedAnimation"
     * @returns "TargetedAnimation"
     */
    getClassName(): string;
    /**
     * Creates a new targeted animation
     * @param parent The animation group to which the animation belongs
     */
    constructor(parent: AnimationGroup);
    /**
     * Serialize the object
     * @returns the JSON object representing the current entity
     */
    serialize(): any;
}
/**
 * Options to be used when creating an additive group animation
 */
interface IMakeAnimationGroupAdditiveOptions extends IMakeAnimationAdditiveOptions {
    /**
     * Defines if the animation group should be cloned or not (default is false)
     */
    cloneOriginalAnimationGroup?: boolean;
    /**
     * The name of the cloned animation group if cloneOriginalAnimationGroup is true
     */
    clonedAnimationGroupName?: string;
}
/**
 * Use this class to create coordinated animations on multiple targets
 */
declare class AnimationGroup implements IDisposable {
    /** The name of the animation group */
    name: string;
    private _scene;
    private _targetedAnimations;
    private _animatables;
    private _from;
    private _to;
    private _isStarted;
    private _isPaused;
    private _speedRatio;
    private _loopAnimation;
    private _isAdditive;
    private _weight;
    private _playOrder;
    private _enableBlending;
    private _blendingSpeed;
    private _numActiveAnimatables;
    private _shouldStart;
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /**
     * Gets or sets the unique id of the node
     */
    uniqueId: number;
    /**
     * This observable will notify when one animation have ended
     */
    onAnimationEndObservable: Observable<TargetedAnimation>;
    /**
     * Observer raised when one animation loops
     */
    onAnimationLoopObservable: Observable<TargetedAnimation>;
    /**
     * Observer raised when all animations have looped
     */
    onAnimationGroupLoopObservable: Observable<AnimationGroup>;
    /**
     * This observable will notify when all animations have ended.
     */
    onAnimationGroupEndObservable: Observable<AnimationGroup>;
    /**
     * This observable will notify when all animations have paused.
     */
    onAnimationGroupPauseObservable: Observable<AnimationGroup>;
    /**
     * This observable will notify when all animations are playing.
     */
    onAnimationGroupPlayObservable: Observable<AnimationGroup>;
    /**
     * Gets or sets an object used to store user defined information for the node
     */
    metadata: any;
    private _mask;
    /**
     * Gets or sets the mask associated with this animation group. This mask is used to filter which objects should be animated.
     */
    get mask(): Nullable<AnimationGroupMask>;
    set mask(value: Nullable<AnimationGroupMask>);
    /**
     * Makes sure that the animations are either played or stopped according to the animation group mask.
     * Note however that the call won't have any effect if the animation group has not been started yet.
     * @param forceUpdate If true, forces to loop over the animatables even if no mask is defined (used internally, you shouldn't need to use it). Default: false.
     */
    syncWithMask(forceUpdate?: boolean): void;
    /**
     * Removes all animations for the targets not retained by the animation group mask.
     * Use this function if you know you won't need those animations anymore and if you want to free memory.
     */
    removeUnmaskedAnimations(): void;
    /**
     * Gets or sets the first frame
     */
    get from(): number;
    set from(value: number);
    /**
     * Gets or sets the last frame
     */
    get to(): number;
    set to(value: number);
    /**
     * Define if the animations are started
     */
    get isStarted(): boolean;
    /**
     * Gets a value indicating that the current group is playing
     */
    get isPlaying(): boolean;
    /**
     * Gets or sets the speed ratio to use for all animations
     */
    get speedRatio(): number;
    /**
     * Gets or sets the speed ratio to use for all animations
     */
    set speedRatio(value: number);
    /**
     * Gets or sets if all animations should loop or not
     */
    get loopAnimation(): boolean;
    set loopAnimation(value: boolean);
    /**
     * Gets or sets if all animations should be evaluated additively
     */
    get isAdditive(): boolean;
    set isAdditive(value: boolean);
    /**
     * Gets or sets the weight to apply to all animations of the group
     */
    get weight(): number;
    set weight(value: number);
    /**
     * Gets the targeted animations for this animation group
     */
    get targetedAnimations(): Array<TargetedAnimation>;
    /**
     * returning the list of animatables controlled by this animation group.
     */
    get animatables(): Array<Animatable>;
    /**
     * Gets the list of target animations
     */
    get children(): TargetedAnimation[];
    /**
     * Gets or sets the order of play of the animation group (default: 0)
     */
    get playOrder(): number;
    set playOrder(value: number);
    /**
     * Allows the animations of the animation group to blend with current running animations
     * Note that a null value means that each animation will use their own existing blending configuration (Animation.enableBlending)
     */
    get enableBlending(): Nullable<boolean>;
    set enableBlending(value: Nullable<boolean>);
    /**
     * Gets or sets the animation blending speed
     * Note that a null value means that each animation will use their own existing blending configuration (Animation.blendingSpeed)
     */
    get blendingSpeed(): Nullable<number>;
    set blendingSpeed(value: Nullable<number>);
    /**
     * Gets the length (in seconds) of the animation group
     * This function assumes that all animations are played at the same framePerSecond speed!
     * Note: you can only call this method after you've added at least one targeted animation!
     * @param from Starting frame range (default is AnimationGroup.from)
     * @param to Ending frame range (default is AnimationGroup.to)
     * @returns The length in seconds
     */
    getLength(from?: number, to?: number): number;
    /**
     * Merge the array of animation groups into a new animation group
     * @param animationGroups List of animation groups to merge
     * @param disposeSource If true, animation groups will be disposed after being merged (default: true)
     * @param normalize If true, animation groups will be normalized before being merged, so that all animations have the same "from" and "to" frame (default: false)
     * @param weight Weight for the new animation group. If not provided, it will inherit the weight from the first animation group of the array
     * @returns The new animation group or null if no animation groups were passed
     */
    static MergeAnimationGroups(animationGroups: Array<AnimationGroup>, disposeSource?: boolean, normalize?: boolean, weight?: number): Nullable<AnimationGroup>;
    /**
     * Gets the scene the animation group belongs to
     * @returns The scene the animation group belongs to
     */
    getScene(): Scene;
    /**
     * Instantiates a new Animation Group.
     * This helps managing several animations at once.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/groupAnimations
     * @param name Defines the name of the group
     * @param scene Defines the scene the group belongs to
     * @param weight Defines the weight to use for animations in the group (-1.0 by default, meaning "no weight")
     * @param playOrder Defines the order of play of the animation group (default is 0)
     */
    constructor(
    /** The name of the animation group */
    name: string, scene?: Nullable<Scene>, weight?: number, playOrder?: number);
    /**
     * Add an animation (with its target) in the group
     * @param animation defines the animation we want to add
     * @param target defines the target of the animation
     * @returns the TargetedAnimation object
     */
    addTargetedAnimation(animation: Animation, target: any): TargetedAnimation;
    /**
     * Remove an animation from the group
     * @param animation defines the animation we want to remove
     */
    removeTargetedAnimation(animation: Animation): void;
    /**
     * This function will normalize every animation in the group to make sure they all go from beginFrame to endFrame
     * It can add constant keys at begin or end
     * @param beginFrame defines the new begin frame for all animations or the smallest begin frame of all animations if null (defaults to null)
     * @param endFrame defines the new end frame for all animations or the largest end frame of all animations if null (defaults to null)
     * @returns the animation group
     */
    normalize(beginFrame?: Nullable<number>, endFrame?: Nullable<number>): AnimationGroup;
    private _animationLoopCount;
    private _animationLoopFlags;
    private _processLoop;
    /**
     * Start all animations on given targets
     * @param loop defines if animations must loop
     * @param speedRatio defines the ratio to apply to animation speed (1 by default)
     * @param from defines the from key (optional)
     * @param to defines the to key (optional)
     * @param isAdditive defines the additive state for the resulting animatables (optional)
     * @returns the current animation group
     */
    start(loop?: boolean, speedRatio?: number, from?: number, to?: number, isAdditive?: boolean): AnimationGroup;
    /**
     * Pause all animations
     * @returns the animation group
     */
    pause(): AnimationGroup;
    /**
     * Play all animations to initial state
     * This function will start() the animations if they were not started or will restart() them if they were paused
     * @param loop defines if animations must loop
     * @returns the animation group
     */
    play(loop?: boolean): AnimationGroup;
    /**
     * Reset all animations to initial state
     * @returns the animation group
     */
    reset(): AnimationGroup;
    /**
     * Restart animations from after pausing it
     * @returns the animation group
     */
    restart(): AnimationGroup;
    /**
     * Stop all animations
     * @param skipOnAnimationEnd defines if the system should not raise onAnimationEnd. Default is false
     * @returns the animation group
     */
    stop(skipOnAnimationEnd?: boolean): AnimationGroup;
    /**
     * Set animation weight for all animatables
     *
     * @since 6.12.4
     *  You can pass the weight to the AnimationGroup constructor, or use the weight property to set it after the group has been created,
     *  making it easier to define the overall animation weight than calling setWeightForAllAnimatables() after the animation group has been started
     * @param weight defines the weight to use
     * @returns the animationGroup
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#animation-weights
     */
    setWeightForAllAnimatables(weight: number): AnimationGroup;
    /**
     * Synchronize and normalize all animatables with a source animatable
     * @param root defines the root animatable to synchronize with (null to stop synchronizing)
     * @returns the animationGroup
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#animation-weights
     */
    syncAllAnimationsWith(root: Nullable<Animatable>): AnimationGroup;
    /**
     * Goes to a specific frame in this animation group. Note that the animation group must be in playing or paused status
     * @param frame the frame number to go to
     * @param useWeight defines whether the animation weight should be applied to the image to be jumped to (false by default)
     * @returns the animationGroup
     */
    goToFrame(frame: number, useWeight?: boolean): AnimationGroup;
    /**
     * Helper to get the current frame. This will return 0 if the AnimationGroup is not running, and it might return wrong results if multiple animations are running in different frames.
     * @returns current animation frame.
     */
    getCurrentFrame(): number;
    /**
     * Dispose all associated resources
     */
    dispose(): void;
    private _checkAnimationGroupEnded;
    /**
     * Clone the current animation group and returns a copy
     * @param newName defines the name of the new group
     * @param targetConverter defines an optional function used to convert current animation targets to new ones
     * @param cloneAnimations defines if the animations should be cloned or referenced
     * @returns the new animation group
     */
    clone(newName: string, targetConverter?: (oldTarget: any) => any, cloneAnimations?: boolean): AnimationGroup;
    /**
     * Serializes the animationGroup to an object
     * @returns Serialized object
     */
    serialize(): any;
    /**
     * Returns a new AnimationGroup object parsed from the source provided.
     * @param parsedAnimationGroup defines the source
     * @param scene defines the scene that will receive the animationGroup
     * @param nodeMap a map of node.id to node in this scene, to accelerate node lookup
     * @returns a new AnimationGroup
     */
    static Parse(parsedAnimationGroup: any, scene: Scene, nodeMap?: Map<Node["id"], Node>): AnimationGroup;
    /**
     * Convert the keyframes for all animations belonging to the group to be relative to a given reference frame.
     * @param sourceAnimationGroup defines the AnimationGroup containing animations to convert
     * @param referenceFrame defines the frame that keyframes in the range will be relative to (default: 0)
     * @param range defines the name of the AnimationRange belonging to the animations in the group to convert
     * @param cloneOriginal defines whether or not to clone the group and convert the clone or convert the original group (default is false)
     * @param clonedName defines the name of the resulting cloned AnimationGroup if cloneOriginal is true
     * @returns a new AnimationGroup if cloneOriginal is true or the original AnimationGroup if cloneOriginal is false
     */
    static MakeAnimationAdditive(sourceAnimationGroup: AnimationGroup, referenceFrame: number, range?: string, cloneOriginal?: boolean, clonedName?: string): AnimationGroup;
    /**
     * Convert the keyframes for all animations belonging to the group to be relative to a given reference frame.
     * @param sourceAnimationGroup defines the AnimationGroup containing animations to convert
     * @param options defines the options to use when converting keyframes
     * @returns a new AnimationGroup if options.cloneOriginalAnimationGroup is true or the original AnimationGroup if options.cloneOriginalAnimationGroup is false
     */
    static MakeAnimationAdditive(sourceAnimationGroup: AnimationGroup, options?: IMakeAnimationGroupAdditiveOptions): AnimationGroup;
    /**
     * Creates a new animation, keeping only the keys that are inside a given key range
     * @param sourceAnimationGroup defines the animation group on which to operate
     * @param fromKey defines the lower bound of the range
     * @param toKey defines the upper bound of the range
     * @param name defines the name of the new animation group. If not provided, use the same name as animationGroup
     * @param dontCloneAnimations defines whether or not the animations should be cloned before clipping the keys. Default is false, so animations will be cloned
     * @returns a new animation group stripped from all the keys outside the given range
     */
    static ClipKeys(sourceAnimationGroup: AnimationGroup, fromKey: number, toKey: number, name?: string, dontCloneAnimations?: boolean): AnimationGroup;
    /**
     * Updates an existing animation, keeping only the keys that are inside a given key range
     * @param animationGroup defines the animation group on which to operate
     * @param fromKey defines the lower bound of the range
     * @param toKey defines the upper bound of the range
     * @param dontCloneAnimations defines whether or not the animations should be cloned before clipping the keys. Default is false, so animations will be cloned
     * @returns the animationGroup stripped from all the keys outside the given range
     */
    static ClipKeysInPlace(animationGroup: AnimationGroup, fromKey: number, toKey: number, dontCloneAnimations?: boolean): AnimationGroup;
    /**
     * Creates a new animation, keeping only the frames that are inside a given frame range
     * @param sourceAnimationGroup defines the animation group on which to operate
     * @param fromFrame defines the lower bound of the range
     * @param toFrame defines the upper bound of the range
     * @param name defines the name of the new animation group. If not provided, use the same name as animationGroup
     * @param dontCloneAnimations defines whether or not the animations should be cloned before clipping the frames. Default is false, so animations will be cloned
     * @returns a new animation group stripped from all the frames outside the given range
     */
    static ClipFrames(sourceAnimationGroup: AnimationGroup, fromFrame: number, toFrame: number, name?: string, dontCloneAnimations?: boolean): AnimationGroup;
    /**
     * Updates an existing animation, keeping only the frames that are inside a given frame range
     * @param animationGroup defines the animation group on which to operate
     * @param fromFrame defines the lower bound of the range
     * @param toFrame defines the upper bound of the range
     * @param dontCloneAnimations defines whether or not the animations should be cloned before clipping the frames. Default is false, so animations will be cloned
     * @returns the animationGroup stripped from all the frames outside the given range
     */
    static ClipFramesInPlace(animationGroup: AnimationGroup, fromFrame: number, toFrame: number, dontCloneAnimations?: boolean): AnimationGroup;
    /**
     * Updates an existing animation, keeping only the keys that are inside a given key or frame range
     * @param animationGroup defines the animation group on which to operate
     * @param start defines the lower bound of the range
     * @param end defines the upper bound of the range
     * @param dontCloneAnimations defines whether or not the animations should be cloned before clipping the keys. Default is false, so animations will be cloned
     * @param useFrame defines if the range is defined by frame numbers or key indices (default is false which means use key indices)
     * @returns the animationGroup stripped from all the keys outside the given range
     */
    static ClipInPlace(animationGroup: AnimationGroup, start: number, end: number, dontCloneAnimations?: boolean, useFrame?: boolean): AnimationGroup;
    /**
     * Returns the string "AnimationGroup"
     * @returns "AnimationGroup"
     */
    getClassName(): string;
    /**
     * Creates a detailed string about the object
     * @param fullDetails defines if the output string will support multiple levels of logging within scene loading
     * @returns a string representing the object
     */
    toString(fullDetails?: boolean): string;
}

/**
 * A multi-material is used to apply different materials to different parts of the same object without the need of
 * separate meshes. This can be use to improve performances.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/multiMaterials
 */
declare class MultiMaterial extends Material {
    private _subMaterials;
    /** @internal */
    _waitingSubMaterialsUniqueIds: string[];
    /**
     * Gets or Sets the list of Materials used within the multi material.
     * They need to be ordered according to the submeshes order in the associated mesh
     */
    get subMaterials(): Nullable<Material>[];
    set subMaterials(value: Nullable<Material>[]);
    /**
     * Function used to align with Node.getChildren()
     * @returns the list of Materials used within the multi material
     */
    getChildren(): Nullable<Material>[];
    /**
     * Instantiates a new Multi Material
     * A multi-material is used to apply different materials to different parts of the same object without the need of
     * separate meshes. This can be use to improve performances.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/multiMaterials
     * @param name Define the name in the scene
     * @param scene Define the scene the material belongs to
     */
    constructor(name: string, scene?: Scene);
    private _hookArray;
    /**
     * Get one of the submaterial by its index in the submaterials array
     * @param index The index to look the sub material at
     * @returns The Material if the index has been defined
     */
    getSubMaterial(index: number): Nullable<Material>;
    /**
     * Get the list of active textures for the whole sub materials list.
     * @returns All the textures that will be used during the rendering
     */
    getActiveTextures(): BaseTexture[];
    /**
     * Specifies if any sub-materials of this multi-material use a given texture.
     * @param texture Defines the texture to check against this multi-material's sub-materials.
     * @returns A boolean specifying if any sub-material of this multi-material uses the texture.
     */
    hasTexture(texture: BaseTexture): boolean;
    /**
     * Gets the current class name of the material e.g. "MultiMaterial"
     * Mainly use in serialization.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Checks if the material is ready to render the requested sub mesh
     * @param mesh Define the mesh the submesh belongs to
     * @param subMesh Define the sub mesh to look readiness for
     * @param useInstances Define whether or not the material is used with instances
     * @returns true if ready, otherwise false
     */
    isReadyForSubMesh(mesh: AbstractMesh, subMesh: SubMesh, useInstances?: boolean): boolean;
    /**
     * Clones the current material and its related sub materials
     * @param name Define the name of the newly cloned material
     * @param cloneChildren Define if submaterial will be cloned or shared with the parent instance
     * @returns the cloned material
     */
    clone(name: string, cloneChildren?: boolean): MultiMaterial;
    /**
     * Serializes the materials into a JSON representation.
     * @returns the JSON representation
     */
    serialize(): any;
    /**
     * Dispose the material and release its associated resources
     * @param forceDisposeEffect Define if we want to force disposing the associated effect (if false the shader is not released and could be reuse later on)
     * @param forceDisposeTextures Define if we want to force disposing the associated textures (if false, they will not be disposed and can still be use elsewhere in the app)
     * @param forceDisposeChildren Define if we want to force disposing the associated submaterials (if false, they will not be disposed and can still be use elsewhere in the app)
     */
    dispose(forceDisposeEffect?: boolean, forceDisposeTextures?: boolean, forceDisposeChildren?: boolean): void;
    /**
     * Creates a MultiMaterial from parsed MultiMaterial data.
     * @param parsedMultiMaterial defines parsed MultiMaterial data.
     * @param scene defines the hosting scene
     * @returns a new MultiMaterial
     */
    static ParseMultiMaterial(parsedMultiMaterial: any, scene: Scene): MultiMaterial;
}

/**
 * Interface used to define options for Sound class
 */
interface ISoundOptions {
    /**
     * Does the sound autoplay once loaded.
     */
    autoplay?: boolean;
    /**
     * Does the sound loop after it finishes playing once.
     */
    loop?: boolean;
    /**
     * Sound's volume
     */
    volume?: number;
    /**
     * Is it a spatial sound?
     */
    spatialSound?: boolean;
    /**
     * Maximum distance to hear that sound
     */
    maxDistance?: number;
    /**
     * Uses user defined attenuation function
     */
    useCustomAttenuation?: boolean;
    /**
     * Define the roll off factor of spatial sounds.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
     */
    rolloffFactor?: number;
    /**
     * Define the reference distance the sound should be heard perfectly.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
     */
    refDistance?: number;
    /**
     * Define the distance attenuation model the sound will follow.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
     */
    distanceModel?: "linear" | "inverse" | "exponential";
    /**
     * Defines the playback speed (1 by default)
     */
    playbackRate?: number;
    /**
     * Defines if the sound is from a streaming source
     */
    streaming?: boolean;
    /**
     * Defines an optional length (in seconds) inside the sound file
     */
    length?: number;
    /**
     * Defines an optional offset (in seconds) inside the sound file
     */
    offset?: number;
    /**
     * If true, URLs will not be required to state the audio file codec to use.
     */
    skipCodecCheck?: boolean;
}

/**
 * Defines a sound that can be played in the application.
 * The sound can either be an ambient track or a simple sound played in reaction to a user action.
 * @see https://doc.babylonjs.com/legacy/audio
 */
declare class Sound {
    /**
     * The name of the sound in the scene.
     */
    get name(): string;
    set name(value: string);
    /**
     * Does the sound autoplay once loaded.
     */
    get autoplay(): boolean;
    set autoplay(value: boolean);
    /**
     * Does the sound loop after it finishes playing once.
     */
    get loop(): boolean;
    set loop(value: boolean);
    /**
     * Does the sound use a custom attenuation curve to simulate the falloff
     * happening when the source gets further away from the camera.
     * @see https://doc.babylonjs.com/legacy/audio#creating-your-own-custom-attenuation-function
     */
    useCustomAttenuation: boolean;
    /**
     * The sound track id this sound belongs to.
     */
    soundTrackId: number;
    /**
     * Is this sound currently played.
     */
    get isPlaying(): boolean;
    /**
     * Is this sound currently paused.
     */
    get isPaused(): boolean;
    /**
     * Define the reference distance the sound should be heard perfectly.
     * @see https://doc.babylonjs.com/legacy/audio#creating-a-spatial-3d-sound
     */
    refDistance: number;
    /**
     * Define the roll off factor of spatial sounds.
     * @see https://doc.babylonjs.com/legacy/audio#creating-a-spatial-3d-sound
     */
    rolloffFactor: number;
    /**
     * Define the max distance the sound should be heard (intensity just became 0 at this point).
     * @see https://doc.babylonjs.com/legacy/audio#creating-a-spatial-3d-sound
     */
    get maxDistance(): number;
    set maxDistance(value: number);
    /**
     * Define the distance attenuation model the sound will follow.
     * @see https://doc.babylonjs.com/legacy/audio#creating-a-spatial-3d-sound
     */
    get distanceModel(): "linear" | "inverse" | "exponential";
    set distanceModel(value: "linear" | "inverse" | "exponential");
    /**
     * @internal
     * Back Compat
     **/
    onended: () => any;
    /**
     * Gets or sets an object used to store user defined information for the sound.
     */
    metadata: any;
    /**
     * Observable event when the current playing sound finishes.
     */
    onEndedObservable: Observable<Sound>;
    /**
     * Gets the current time for the sound.
     */
    get currentTime(): number;
    /**
     * Does this sound enables spatial sound.
     * @see https://doc.babylonjs.com/legacy/audio#creating-a-spatial-3d-sound
     */
    get spatialSound(): boolean;
    /**
     * Does this sound enables spatial sound.
     * @see https://doc.babylonjs.com/legacy/audio#creating-a-spatial-3d-sound
     */
    set spatialSound(newValue: boolean);
    private _localDirection;
    private _volume;
    private _isReadyToPlay;
    private _isDirectional;
    private _readyToPlayCallback;
    private _scene;
    private _connectedTransformNode;
    private _customAttenuationFunction;
    private _registerFunc;
    private _isOutputConnected;
    private _url;
    private readonly _optionsV2;
    private readonly _soundV2;
    private _onReadyObservable;
    private get _onReady();
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    /**
     * Create a sound and attach it to a scene
     * @param name Name of your sound
     * @param urlOrArrayBuffer Url to the sound to load async or ArrayBuffer, it also works with MediaStreams and AudioBuffers
     * @param scene defines the scene the sound belongs to
     * @param readyToPlayCallback Provide a callback function if you'd like to load your code once the sound is ready to be played
     * @param options Objects to provide with the current available options: autoplay, loop, volume, spatialSound, maxDistance, rolloffFactor, refDistance, distanceModel, panningModel, streaming
     */
    constructor(name: string, urlOrArrayBuffer: any, scene?: Nullable<Scene>, readyToPlayCallback?: Nullable<() => void>, options?: ISoundOptions);
    private _onReadyToPlay;
    /**
     * Release the sound and its associated resources
     */
    dispose(): void;
    /**
     * Gets if the sounds is ready to be played or not.
     * @returns true if ready, otherwise false
     */
    isReady(): boolean;
    /**
     * Get the current class name.
     * @returns current class name
     */
    getClassName(): string;
    /**
     * Sets the data of the sound from an audiobuffer
     * @param audioBuffer The audioBuffer containing the data
     */
    setAudioBuffer(audioBuffer: AudioBuffer): void;
    /**
     * Updates the current sounds options such as maxdistance, loop...
     * @param options A JSON object containing values named as the object properties
     */
    updateOptions(options: ISoundOptions): void;
    private _updateSpatialParameters;
    /**
     * Switch the panning model to HRTF:
     * Renders a stereo output of higher quality than equalpower  it uses a convolution with measured impulse responses from human subjects.
     * @see https://doc.babylonjs.com/legacy/audio#creating-a-spatial-3d-sound
     */
    switchPanningModelToHRTF(): void;
    /**
     * Switch the panning model to Equal Power:
     * Represents the equal-power panning algorithm, generally regarded as simple and efficient. equalpower is the default value.
     * @see https://doc.babylonjs.com/legacy/audio#creating-a-spatial-3d-sound
     */
    switchPanningModelToEqualPower(): void;
    /**
     * Connect this sound to a sound track audio node like gain...
     * @param soundTrackAudioNode the sound track audio node to connect to
     */
    connectToSoundTrackAudioNode(soundTrackAudioNode: AudioNode): void;
    /**
     * Transform this sound into a directional source
     * @param coneInnerAngle Size of the inner cone in degree
     * @param coneOuterAngle Size of the outer cone in degree
     * @param coneOuterGain Volume of the sound outside the outer cone (between 0.0 and 1.0)
     */
    setDirectionalCone(coneInnerAngle: number, coneOuterAngle: number, coneOuterGain: number): void;
    /**
     * Gets or sets the inner angle for the directional cone.
     */
    get directionalConeInnerAngle(): number;
    /**
     * Gets or sets the inner angle for the directional cone.
     */
    set directionalConeInnerAngle(value: number);
    /**
     * Gets or sets the outer angle for the directional cone.
     */
    get directionalConeOuterAngle(): number;
    /**
     * Gets or sets the outer angle for the directional cone.
     */
    set directionalConeOuterAngle(value: number);
    /**
     * Sets the position of the emitter if spatial sound is enabled
     * @param newPosition Defines the new position
     */
    setPosition(newPosition: Vector3): void;
    /**
     * Sets the local direction of the emitter if spatial sound is enabled
     * @param newLocalDirection Defines the new local direction
     */
    setLocalDirectionToMesh(newLocalDirection: Vector3): void;
    private _updateDirection;
    private _initSpatial;
    /** @internal */
    updateDistanceFromListener(): void;
    /**
     * Sets a new custom attenuation function for the sound.
     * @param callback Defines the function used for the attenuation
     * @see https://doc.babylonjs.com/legacy/audio#creating-your-own-custom-attenuation-function
     */
    setAttenuationFunction(callback: (currentVolume: number, currentDistance: number, maxDistance: number, refDistance: number, rolloffFactor: number) => number): void;
    /**
     * Play the sound
     * @param time (optional) Start the sound after X seconds. Start immediately (0) by default.
     * @param offset (optional) Start the sound at a specific time in seconds
     * @param length (optional) Sound duration (in seconds)
     */
    play(time?: number, offset?: number, length?: number): void;
    private _onended;
    /**
     * Stop the sound
     * @param time (optional) Stop the sound after X seconds. Stop immediately (0) by default.
     */
    stop(time?: number): void;
    /**
     * Put the sound in pause
     */
    pause(): void;
    /**
     * Sets a dedicated volume for this sounds
     * @param newVolume Define the new volume of the sound
     * @param time Define time for gradual change to new volume
     */
    setVolume(newVolume: number, time?: number): void;
    /**
     * Set the sound play back rate
     * @param newPlaybackRate Define the playback rate the sound should be played at
     */
    setPlaybackRate(newPlaybackRate: number): void;
    /**
     * Gets the sound play back rate.
     * @returns the  play back rate of the sound
     */
    getPlaybackRate(): number;
    /**
     * Gets the volume of the sound.
     * @returns the volume of the sound
     */
    getVolume(): number;
    /**
     * Attach the sound to a dedicated mesh
     * @param transformNode The transform node to connect the sound with
     * @see https://doc.babylonjs.com/legacy/audio#attaching-a-sound-to-a-mesh
     */
    attachToMesh(transformNode: TransformNode): void;
    /**
     * Detach the sound from the previously attached mesh
     * @see https://doc.babylonjs.com/legacy/audio#attaching-a-sound-to-a-mesh
     */
    detachFromMesh(): void;
    private _onRegisterAfterWorldMatrixUpdate;
    /**
     * Clone the current sound in the scene.
     * @returns the new sound clone
     */
    clone(): Nullable<Sound>;
    /**
     * Gets the current underlying audio buffer containing the data
     * @returns the audio buffer
     */
    getAudioBuffer(): Nullable<AudioBuffer>;
    /**
     * Gets the WebAudio AudioBufferSourceNode, lets you keep track of and stop instances of this Sound.
     * @returns the source node
     */
    getSoundSource(): Nullable<AudioBufferSourceNode>;
    /**
     * Gets the WebAudio GainNode, gives you precise control over the gain of instances of this Sound.
     * @returns the gain node
     */
    getSoundGain(): Nullable<GainNode>;
    /**
     * Serializes the Sound in a JSON representation
     * @returns the JSON representation of the sound
     */
    serialize(): any;
    /**
     * Parse a JSON representation of a sound to instantiate in a given scene
     * @param parsedSound Define the JSON representation of the sound (usually coming from the serialize method)
     * @param scene Define the scene the new parsed sound should be created in
     * @param rootUrl Define the rooturl of the load in case we need to fetch relative dependencies
     * @param sourceSound Define a sound place holder if do not need to instantiate a new one
     * @returns the newly parsed sound
     */
    static Parse(parsedSound: any, scene: Scene, rootUrl: string, sourceSound?: Sound): Sound;
}

/**
 * This represents a full screen 2d layer.
 * This can be useful to display a picture in the  background of your scene for instance.
 * @see https://www.babylonjs-playground.com/#08A2BS#1
 */
declare class Layer {
    /**
     * Define the name of the layer.
     */
    name: string;
    /**
     * Force all the layers to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * Define the texture the layer should display.
     */
    texture: Nullable<BaseTexture>;
    /**
     * Is the layer in background or foreground.
     */
    isBackground: boolean;
    private _applyPostProcess;
    /**
     * Determines if the layer is drawn before (true) or after (false) post-processing.
     * If the layer is background, it is always before.
     */
    set applyPostProcess(value: boolean);
    get applyPostProcess(): boolean;
    /**
     * Define the color of the layer (instead of texture).
     */
    color: Color4;
    /**
     * Define the scale of the layer in order to zoom in out of the texture.
     */
    scale: Vector2;
    /**
     * Define an offset for the layer in order to shift the texture.
     */
    offset: Vector2;
    /**
     * Define the alpha blending mode used in the layer in case the texture or color has an alpha.
     */
    alphaBlendingMode: number;
    /**
     * Define if the layer should alpha test or alpha blend with the rest of the scene.
     * Alpha test will not mix with the background color in case of transparency.
     * It will either use the texture color or the background depending on the alpha value of the current pixel.
     */
    alphaTest: boolean;
    /**
     * Define a mask to restrict the layer to only some of the scene cameras.
     */
    layerMask: number;
    /**
     * Define the list of render target the layer is visible into.
     */
    renderTargetTextures: RenderTargetTexture[];
    /**
     * Define if the layer is only used in renderTarget or if it also
     * renders in the main frame buffer of the canvas.
     */
    renderOnlyInRenderTargetTextures: boolean;
    /**
     * Define if the colors of the layer should be generated in linear space (default: false)
     */
    convertToLinearSpace: boolean;
    /**
     * Define if the layer is enabled (ie. should be displayed). Default: true
     */
    isEnabled: boolean;
    private _scene;
    private _vertexBuffers;
    private _indexBuffer;
    private _drawWrapper;
    private _previousDefines;
    /**
     * An event triggered when the layer is disposed.
     */
    onDisposeObservable: Observable<Layer>;
    private _onDisposeObserver;
    /**
     * Back compatibility with callback before the onDisposeObservable existed.
     * The set callback will be triggered when the layer has been disposed.
     */
    set onDispose(callback: () => void);
    /**
     * An event triggered before rendering the scene
     */
    onBeforeRenderObservable: Observable<Layer>;
    private _onBeforeRenderObserver;
    /**
     * Back compatibility with callback before the onBeforeRenderObservable existed.
     * The set callback will be triggered just before rendering the layer.
     */
    set onBeforeRender(callback: () => void);
    /**
     * An event triggered after rendering the scene
     */
    onAfterRenderObservable: Observable<Layer>;
    private _onAfterRenderObserver;
    /**
     * Back compatibility with callback before the onAfterRenderObservable existed.
     * The set callback will be triggered just after rendering the layer.
     */
    set onAfterRender(callback: () => void);
    /** Shader language used by the material */
    private _shaderLanguage;
    /**
     * Gets the shader language used in this material.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Instantiates a new layer.
     * This represents a full screen 2d layer.
     * This can be useful to display a picture in the  background of your scene for instance.
     * @see https://www.babylonjs-playground.com/#08A2BS#1
     * @param name Define the name of the layer in the scene
     * @param imgUrl Define the url of the texture to display in the layer
     * @param scene Define the scene the layer belongs to
     * @param isBackground Defines whether the layer is displayed in front or behind the scene
     * @param color Defines a color for the layer
     * @param forceGLSL Use the GLSL code generation for the shader (even on WebGPU). Default is false
     */
    constructor(
    /**
     * Define the name of the layer.
     */
    name: string, imgUrl: Nullable<string>, scene: Nullable<Scene>, isBackground?: boolean, color?: Color4, forceGLSL?: boolean);
    private _shadersLoaded;
    private _createIndexBuffer;
    /** @internal */
    _rebuild(): void;
    /**
     * Checks if the layer is ready to be rendered
     * @returns true if the layer is ready. False otherwise.
     */
    isReady(): boolean;
    /**
     * Renders the layer in the scene.
     */
    render(): void;
    /**
     * Disposes and releases the associated resources.
     */
    dispose(): void;
}

/**
 * Effect layer options. This helps customizing the behaviour
 * of the effect layer.
 */
interface IThinEffectLayerOptions {
    /**
     * Multiplication factor apply to the canvas size to compute the render target size
     * used to generated the glowing objects (the smaller the faster). Default: 0.5
     */
    mainTextureRatio?: number;
    /**
     * Enforces a fixed size texture to ensure resize independent blur. Default: undefined
     */
    mainTextureFixedSize?: number;
    /**
     * The type of the main texture. Default: TEXTURETYPE_UNSIGNED_BYTE
     */
    mainTextureType?: number;
    /**
     * Alpha blending mode used to apply the blur. Default depends of the implementation. Default: ALPHA_COMBINE
     */
    alphaBlendingMode?: number;
    /**
     * The camera attached to the layer. Default: null
     */
    camera?: Nullable<Camera>;
    /**
     * The rendering group to draw the layer in. Default: -1
     */
    renderingGroupId?: number;
}
/**
 * @internal
 */
declare class ThinEffectLayer {
    private _additionalImportShadersAsync?;
    private _vertexBuffers;
    private _indexBuffer;
    private _mergeDrawWrapper;
    private _dontCheckIfReady;
    protected _scene: Scene;
    protected _engine: AbstractEngine;
    /** @internal */
    _options: Required<IThinEffectLayerOptions>;
    protected _objectRenderer: ObjectRenderer;
    /** @internal */
    _shouldRender: boolean;
    /** @internal */
    _emissiveTextureAndColor: {
        texture: Nullable<BaseTexture>;
        color: Color4;
    };
    /** @internal */
    _effectIntensity: {
        [meshUniqueId: number]: number;
    };
    /** @internal */
    _postProcesses: EffectWrapper[];
    /**
     * Force all the effect layers to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * The name of the layer
     */
    name: string;
    /**
     * The clear color of the texture used to generate the glow map.
     */
    neutralColor: Color4;
    /**
     * Specifies whether the effect layer is enabled or not.
     */
    isEnabled: boolean;
    /**
     * Gets/sets the camera attached to the layer.
     */
    get camera(): Nullable<Camera>;
    set camera(camera: Nullable<Camera>);
    /**
     * Gets the rendering group id the layer should render in.
     */
    get renderingGroupId(): number;
    set renderingGroupId(renderingGroupId: number);
    /**
     * Specifies if the bounding boxes should be rendered normally or if they should undergo the effect of the layer
     */
    disableBoundingBoxesFromEffectLayer: boolean;
    /**
     * An event triggered when the effect layer has been disposed.
     */
    onDisposeObservable: Observable<ThinEffectLayer>;
    /**
     * An event triggered when the effect layer is about rendering the main texture with the glowy parts.
     */
    onBeforeRenderLayerObservable: Observable<ThinEffectLayer>;
    /**
     * An event triggered when the generated texture is being merged in the scene.
     */
    onBeforeComposeObservable: Observable<ThinEffectLayer>;
    /**
     * An event triggered when the mesh is rendered into the effect render target.
     */
    onBeforeRenderMeshToEffect: Observable<AbstractMesh>;
    /**
     * An event triggered after the mesh has been rendered into the effect render target.
     */
    onAfterRenderMeshToEffect: Observable<AbstractMesh>;
    /**
     * An event triggered when the generated texture has been merged in the scene.
     */
    onAfterComposeObservable: Observable<ThinEffectLayer>;
    /**
     * An event triggered when the layer is being blurred.
     */
    onBeforeBlurObservable: Observable<ThinEffectLayer>;
    /**
     * An event triggered when the layer has been blurred.
     */
    onAfterBlurObservable: Observable<ThinEffectLayer>;
    /**
     * Gets the object renderer used to render objects in the layer
     */
    get objectRenderer(): ObjectRenderer;
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this material.
     */
    get shaderLanguage(): ShaderLanguage;
    private _materialForRendering;
    /**
     * Sets a specific material to be used to render a mesh/a list of meshes in the layer
     * @param mesh mesh or array of meshes
     * @param material material to use by the layer when rendering the mesh(es). If undefined is passed, the specific material created by the layer will be used.
     */
    setMaterialForRendering(mesh: AbstractMesh | AbstractMesh[], material?: Material): void;
    /**
     * Gets the intensity of the effect for a specific mesh.
     * @param mesh The mesh to get the effect intensity for
     * @returns The intensity of the effect for the mesh
     */
    getEffectIntensity(mesh: AbstractMesh): number;
    /**
     * Sets the intensity of the effect for a specific mesh.
     * @param mesh The mesh to set the effect intensity for
     * @param intensity The intensity of the effect for the mesh
     */
    setEffectIntensity(mesh: AbstractMesh, intensity: number): void;
    /**
     * Instantiates a new effect Layer
     * @param name The name of the layer
     * @param scene The scene to use the layer in
     * @param forceGLSL Use the GLSL code generation for the shader (even on WebGPU). Default is false
     * @param dontCheckIfReady Specifies if the layer should disable checking whether all the post processes are ready (default: false). To save performance, this should be set to true and you should call `isReady` manually before rendering to the layer.
     * @param _additionalImportShadersAsync Additional shaders to import when the layer is created
     */
    constructor(name: string, scene?: Scene, forceGLSL?: boolean, dontCheckIfReady?: boolean, _additionalImportShadersAsync?: (() => Promise<void>) | undefined);
    /** @internal */
    _shadersLoaded: boolean;
    /**
     * Get the effect name of the layer.
     * @returns The effect name
     */
    getEffectName(): string;
    /**
     * Checks for the readiness of the element composing the layer.
     * @param _subMesh the mesh to check for
     * @param _useInstances specify whether or not to use instances to render the mesh
     * @returns true if ready otherwise, false
     */
    isReady(_subMesh: SubMesh, _useInstances: boolean): boolean;
    /**
     * Returns whether or not the layer needs stencil enabled during the mesh rendering.
     * @returns true if the effect requires stencil during the main canvas render pass.
     */
    needStencil(): boolean;
    /** @internal */
    _createMergeEffect(): Effect;
    /** @internal */
    _createTextureAndPostProcesses(): void;
    /** @internal */
    bindTexturesForCompose: (effect: Effect) => void;
    /** @internal */
    _internalCompose(_effect: Effect, _renderIndex: number): void;
    /** @internal */
    _setEmissiveTextureAndColor(_mesh: Mesh, _subMesh: SubMesh, _material: Material): void;
    /** @internal */
    _numInternalDraws(): number;
    /** @internal */
    _init(options: IThinEffectLayerOptions): void;
    private _generateIndexBuffer;
    private _generateVertexBuffer;
    protected _createObjectRenderer(): void;
    /** @internal */
    _addCustomEffectDefines(_defines: string[]): void;
    /** @internal */
    _internalIsSubMeshReady(subMesh: SubMesh, useInstances: boolean, emissiveTexture: Nullable<BaseTexture>): boolean;
    /** @internal */
    _isSubMeshReady(subMesh: SubMesh, useInstances: boolean, emissiveTexture: Nullable<BaseTexture>): boolean;
    protected _importShadersAsync(): Promise<void>;
    /** @internal */
    _internalIsLayerReady(): boolean;
    /**
     * Checks if the layer is ready to be used.
     * @returns true if the layer is ready to be used
     */
    isLayerReady(): boolean;
    /**
     * Renders the glowing part of the scene by blending the blurred glowing meshes on top of the rendered scene.
     * @returns true if the rendering was successful
     */
    compose(): boolean;
    /** @internal */
    _internalHasMesh(mesh: AbstractMesh): boolean;
    /**
     * Determine if a given mesh will be used in the current effect.
     * @param mesh mesh to test
     * @returns true if the mesh will be used
     */
    hasMesh(mesh: AbstractMesh): boolean;
    /** @internal */
    _internalShouldRender(): boolean;
    /**
     * Returns true if the layer contains information to display, otherwise false.
     * @returns true if the glow layer should be rendered
     */
    shouldRender(): boolean;
    /** @internal */
    _shouldRenderMesh(_mesh: AbstractMesh): boolean;
    /** @internal */
    _internalCanRenderMesh(mesh: AbstractMesh, material: Material): boolean;
    /** @internal */
    _canRenderMesh(mesh: AbstractMesh, material: Material): boolean;
    protected _renderSubMesh(subMesh: SubMesh, enableAlphaMode?: boolean): void;
    /** @internal */
    _useMeshMaterial(_mesh: AbstractMesh): boolean;
    /** @internal */
    _rebuild(): void;
    /**
     * Dispose the effect layer and free resources.
     */
    dispose(): void;
}

/**
 * Effect layer options. This helps customizing the behaviour
 * of the effect layer.
 */
interface IEffectLayerOptions {
    /**
     * Multiplication factor apply to the canvas size to compute the render target size
     * used to generated the objects (the smaller the faster). Default: 0.5
     */
    mainTextureRatio: number;
    /**
     * Enforces a fixed size texture to ensure effect stability across devices. Default: undefined
     */
    mainTextureFixedSize?: number;
    /**
     * Alpha blending mode used to apply the blur. Default depends of the implementation. Default: ALPHA_COMBINE
     */
    alphaBlendingMode: number;
    /**
     * The camera attached to the layer. Default: null
     */
    camera: Nullable<Camera>;
    /**
     * The rendering group to draw the layer in. Default: -1
     */
    renderingGroupId: number;
    /**
     * The type of the main texture. Default: TEXTURETYPE_UNSIGNED_BYTE
     */
    mainTextureType: number;
    /**
     * Whether or not to generate a stencil buffer. Default: false
     */
    generateStencilBuffer: boolean;
}
/**
 * The effect layer Helps adding post process effect blended with the main pass.
 *
 * This can be for instance use to generate glow or highlight effects on the scene.
 *
 * The effect layer class can not be used directly and is intented to inherited from to be
 * customized per effects.
 */
declare abstract class EffectLayer {
    private _effectLayerOptions;
    protected _mainTextureCreatedSize: ISize;
    protected _scene: Scene;
    protected _engine: AbstractEngine;
    protected _maxSize: number;
    protected _mainTextureDesiredSize: ISize;
    protected _mainTexture: RenderTargetTexture;
    protected get _shouldRender(): boolean;
    protected set _shouldRender(value: boolean);
    protected _postProcesses: PostProcess[];
    protected _textures: BaseTexture[];
    protected get _emissiveTextureAndColor(): {
        texture: Nullable<BaseTexture>;
        color: Color4;
    };
    protected set _emissiveTextureAndColor(value: {
        texture: Nullable<BaseTexture>;
        color: Color4;
    });
    protected get _effectIntensity(): {
        [meshUniqueId: number]: number;
    };
    protected set _effectIntensity(value: {
        [meshUniqueId: number]: number;
    });
    protected readonly _thinEffectLayer: ThinEffectLayer;
    private readonly _internalThinEffectLayer;
    /**
     * Force all the effect layers to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static get ForceGLSL(): boolean;
    static set ForceGLSL(value: boolean);
    /**
     * The unique id of the layer
     */
    readonly uniqueId: number;
    /**
     * The name of the layer
     */
    get name(): string;
    set name(value: string);
    /**
     * The clear color of the texture used to generate the glow map.
     */
    get neutralColor(): Color4;
    set neutralColor(value: Color4);
    /**
     * Specifies whether the highlight layer is enabled or not.
     */
    get isEnabled(): boolean;
    set isEnabled(value: boolean);
    /**
     * Gets the camera attached to the layer.
     */
    get camera(): Nullable<Camera>;
    /**
     * Gets the rendering group id the layer should render in.
     */
    get renderingGroupId(): number;
    set renderingGroupId(renderingGroupId: number);
    /**
     * Specifies if the bounding boxes should be rendered normally or if they should undergo the effect of the layer
     */
    get disableBoundingBoxesFromEffectLayer(): boolean;
    set disableBoundingBoxesFromEffectLayer(value: boolean);
    /**
     * An event triggered when the effect layer has been disposed.
     */
    onDisposeObservable: Observable<EffectLayer>;
    /**
     * An event triggered when the effect layer is about rendering the main texture with the glowy parts.
     */
    onBeforeRenderMainTextureObservable: Observable<EffectLayer>;
    /**
     * An event triggered when the generated texture is being merged in the scene.
     */
    onBeforeComposeObservable: Observable<EffectLayer>;
    /**
     * An event triggered when the mesh is rendered into the effect render target.
     */
    onBeforeRenderMeshToEffect: Observable<AbstractMesh>;
    /**
     * An event triggered after the mesh has been rendered into the effect render target.
     */
    onAfterRenderMeshToEffect: Observable<AbstractMesh>;
    /**
     * An event triggered when the generated texture has been merged in the scene.
     */
    onAfterComposeObservable: Observable<EffectLayer>;
    /**
     * An event triggered when the effect layer changes its size.
     */
    onSizeChangedObservable: Observable<EffectLayer>;
    /**
     * Gets the main texture where the effect is rendered
     */
    get mainTexture(): RenderTargetTexture;
    protected get _shaderLanguage(): ShaderLanguage;
    /**
     * Gets the shader language used in this material.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    /**
     * Sets a specific material to be used to render a mesh/a list of meshes in the layer
     * @param mesh mesh or array of meshes
     * @param material material to use by the layer when rendering the mesh(es). If undefined is passed, the specific material created by the layer will be used.
     */
    setMaterialForRendering(mesh: AbstractMesh | AbstractMesh[], material?: Material): void;
    /**
     * Gets the intensity of the effect for a specific mesh.
     * @param mesh The mesh to get the effect intensity for
     * @returns The intensity of the effect for the mesh
     */
    getEffectIntensity(mesh: AbstractMesh): number;
    /**
     * Sets the intensity of the effect for a specific mesh.
     * @param mesh The mesh to set the effect intensity for
     * @param intensity The intensity of the effect for the mesh
     */
    setEffectIntensity(mesh: AbstractMesh, intensity: number): void;
    /**
     * Instantiates a new effect Layer and references it in the scene.
     * @param name The name of the layer
     * @param scene The scene to use the layer in
     * @param forceGLSL Use the GLSL code generation for the shader (even on WebGPU). Default is false
     * @param thinEffectLayer The thin instance of the effect layer (optional)
     */
    constructor(
    /** The Friendly of the effect in the scene */
    name: string, scene?: Scene, forceGLSL?: boolean, thinEffectLayer?: ThinEffectLayer);
    protected get _shadersLoaded(): boolean;
    protected set _shadersLoaded(value: boolean);
    /**
     * Get the effect name of the layer.
     * @returns The effect name
     */
    abstract getEffectName(): string;
    /**
     * Checks for the readiness of the element composing the layer.
     * @param subMesh the mesh to check for
     * @param useInstances specify whether or not to use instances to render the mesh
     * @returns true if ready otherwise, false
     */
    abstract isReady(subMesh: SubMesh, useInstances: boolean): boolean;
    /**
     * Returns whether or not the layer needs stencil enabled during the mesh rendering.
     * @returns true if the effect requires stencil during the main canvas render pass.
     */
    abstract needStencil(): boolean;
    /**
     * Create the merge effect. This is the shader use to blit the information back
     * to the main canvas at the end of the scene rendering.
     * @returns The effect containing the shader used to merge the effect on the  main canvas
     */
    protected abstract _createMergeEffect(): Effect;
    /**
     * Creates the render target textures and post processes used in the effect layer.
     */
    protected abstract _createTextureAndPostProcesses(): void;
    /**
     * Implementation specific of rendering the generating effect on the main canvas.
     * @param effect The effect used to render through
     * @param renderNum Index of the _internalRender call (0 for the first time _internalRender is called, 1 for the second time, etc. _internalRender is called the number of times returned by _numInternalDraws())
     */
    protected abstract _internalRender(effect: Effect, renderIndex: number): void;
    /**
     * Sets the required values for both the emissive texture and and the main color.
     */
    protected abstract _setEmissiveTextureAndColor(mesh: Mesh, subMesh: SubMesh, material: Material): void;
    /**
     * Free any resources and references associated to a mesh.
     * Internal use
     * @param mesh The mesh to free.
     */
    abstract _disposeMesh(mesh: Mesh): void;
    /**
     * Serializes this layer (Glow or Highlight for example)
     * @returns a serialized layer object
     */
    abstract serialize?(): any;
    /**
     * Number of times _internalRender will be called. Some effect layers need to render the mesh several times, so they should override this method with the number of times the mesh should be rendered
     * @returns Number of times a mesh must be rendered in the layer
     */
    protected _numInternalDraws(): number;
    /**
     * Initializes the effect layer with the required options.
     * @param options Sets of none mandatory options to use with the layer (see IEffectLayerOptions for more information)
     */
    protected _init(options: Partial<IEffectLayerOptions>): void;
    /**
     * Sets the main texture desired size which is the closest power of two
     * of the engine canvas size.
     */
    private _setMainTextureSize;
    /**
     * Creates the main texture for the effect layer.
     */
    protected _createMainTexture(): void;
    /**
     * Adds specific effects defines.
     * @param defines The defines to add specifics to.
     */
    protected _addCustomEffectDefines(defines: string[]): void;
    /**
     * Checks for the readiness of the element composing the layer.
     * @param subMesh the mesh to check for
     * @param useInstances specify whether or not to use instances to render the mesh
     * @param emissiveTexture the associated emissive texture used to generate the glow
     * @returns true if ready otherwise, false
     */
    protected _isReady(subMesh: SubMesh, useInstances: boolean, emissiveTexture: Nullable<BaseTexture>): boolean;
    protected _importShadersAsync(): Promise<void>;
    protected _arePostProcessAndMergeReady(): boolean;
    /**
     * Checks if the layer is ready to be used.
     * @returns true if the layer is ready to be used
     */
    isLayerReady(): boolean;
    /**
     * Renders the glowing part of the scene by blending the blurred glowing meshes on top of the rendered scene.
     */
    render(): void;
    /**
     * Determine if a given mesh will be used in the current effect.
     * @param mesh mesh to test
     * @returns true if the mesh will be used
     */
    hasMesh(mesh: AbstractMesh): boolean;
    /**
     * Returns true if the layer contains information to display, otherwise false.
     * @returns true if the glow layer should be rendered
     */
    shouldRender(): boolean;
    /**
     * Returns true if the mesh should render, otherwise false.
     * @param mesh The mesh to render
     * @returns true if it should render otherwise false
     */
    protected _shouldRenderMesh(mesh: AbstractMesh): boolean;
    /**
     * Returns true if the mesh can be rendered, otherwise false.
     * @param mesh The mesh to render
     * @param material The material used on the mesh
     * @returns true if it can be rendered otherwise false
     */
    protected _canRenderMesh(mesh: AbstractMesh, material: Material): boolean;
    /**
     * Returns true if the mesh should render, otherwise false.
     * @returns true if it should render otherwise false
     */
    protected _shouldRenderEmissiveTextureForMesh(): boolean;
    /**
     * Defines whether the current material of the mesh should be use to render the effect.
     * @param mesh defines the current mesh to render
     * @returns true if the mesh material should be use
     */
    protected _useMeshMaterial(mesh: AbstractMesh): boolean;
    /**
     * Rebuild the required buffers.
     * @internal Internal use only.
     */
    _rebuild(): void;
    /**
     * Dispose only the render target textures and post process.
     */
    private _disposeTextureAndPostProcesses;
    /**
     * Dispose the highlight layer and free resources.
     */
    dispose(): void;
    /**
     * Gets the class name of the effect layer
     * @returns the string with the class name of the effect layer
     */
    getClassName(): string;
    /**
     * Creates an effect layer from parsed effect layer data
     * @param parsedEffectLayer defines effect layer data
     * @param scene defines the current scene
     * @param rootUrl defines the root URL containing the effect layer information
     * @returns a parsed effect Layer
     */
    static Parse(parsedEffectLayer: any, scene: Scene, rootUrl: string): EffectLayer;
}

declare module "../scene" {
    interface Scene {
        /**
         * The list of reflection probes added to the scene
         * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/reflectionProbes
         */
        reflectionProbes: Array<ReflectionProbe>;
        /**
         * Removes the given reflection probe from this scene.
         * @param toRemove The reflection probe to remove
         * @returns The index of the removed reflection probe
         */
        removeReflectionProbe(toRemove: ReflectionProbe): number;
        /**
         * Adds the given reflection probe to this scene.
         * @param newReflectionProbe The reflection probe to add
         */
        addReflectionProbe(newReflectionProbe: ReflectionProbe): void;
    }
}
/**
 * Class used to generate realtime reflection / refraction cube textures
 * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/reflectionProbes
 */
declare class ReflectionProbe {
    /** defines the name of the probe */
    name: string;
    private _scene;
    private _renderTargetTexture;
    private _projectionMatrix;
    private _viewMatrix;
    private _target;
    private _add;
    private _attachedMesh;
    private _invertYAxis;
    private _sceneUBOs;
    private _currentSceneUBO;
    /** Gets or sets probe position (center of the cube map) */
    position: Vector3;
    /**
     * Gets or sets an object used to store user defined information for the reflection probe.
     */
    metadata: any;
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /**
     * Creates a new reflection probe
     * @param name defines the name of the probe
     * @param size defines the texture resolution (for each face)
     * @param scene defines the hosting scene
     * @param generateMipMaps defines if mip maps should be generated automatically (true by default)
     * @param useFloat defines if HDR data (float data) should be used to store colors (false by default)
     * @param linearSpace defines if the probe should be generated in linear space or not (false by default)
     */
    constructor(
    /** defines the name of the probe */
    name: string, size: number, scene: Scene, generateMipMaps?: boolean, useFloat?: boolean, linearSpace?: boolean);
    /** Gets or sets the number of samples to use for multi-sampling (0 by default). Required WebGL2 */
    get samples(): number;
    set samples(value: number);
    /** Gets or sets the refresh rate to use (on every frame by default) */
    get refreshRate(): number;
    set refreshRate(value: number);
    /**
     * Gets the hosting scene
     * @returns a Scene
     */
    getScene(): Scene;
    /** Gets the internal CubeTexture used to render to */
    get cubeTexture(): RenderTargetTexture;
    /** Gets or sets the list of meshes to render */
    get renderList(): Nullable<AbstractMesh[]>;
    set renderList(value: Nullable<AbstractMesh[]>);
    /**
     * Attach the probe to a specific mesh (Rendering will be done from attached mesh's position)
     * @param mesh defines the mesh to attach to
     */
    attachToMesh(mesh: Nullable<AbstractMesh>): void;
    /**
     * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
     */
    setRenderingAutoClearDepthStencil(renderingGroupId: number, autoClearDepthStencil: boolean): void;
    /**
     * Clean all associated resources
     */
    dispose(): void;
    /**
     * Converts the reflection probe information to a readable string for debug purpose.
     * @param fullDetails Supports for multiple levels of logging within scene loading
     * @returns the human readable reflection probe info
     */
    toString(fullDetails?: boolean): string;
    /**
     * Get the class name of the refection probe.
     * @returns "ReflectionProbe"
     */
    getClassName(): string;
    /**
     * Serialize the reflection probe to a JSON representation we can easily use in the respective Parse function.
     * @returns The JSON representation of the texture
     */
    serialize(): any;
    /**
     * Parse the JSON representation of a reflection probe in order to recreate the reflection probe in the given scene.
     * @param parsedReflectionProbe Define the JSON representation of the reflection probe
     * @param scene Define the scene the parsed reflection probe should be instantiated in
     * @param rootUrl Define the root url of the parsing sequence in the case of relative dependencies
     * @returns The parsed reflection probe if successful
     */
    static Parse(parsedReflectionProbe: any, scene: Scene, rootUrl: string): Nullable<ReflectionProbe>;
}

/**
 * This represents one of the lens effect in a `lensFlareSystem`.
 * It controls one of the individual texture used in the effect.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/lenseFlare
 */
declare class LensFlare {
    /**
     * Define the size of the lens flare in the system (a floating value between 0 and 1)
     */
    size: number;
    /**
     * Define the position of the lens flare in the system. (a floating value between -1 and 1). A value of 0 is located on the emitter. A value greater than 0 is beyond the emitter and a value lesser than 0 is behind.
     */
    position: number;
    /**
     * Define the lens color.
     */
    color: Color3;
    /**
     * Define the lens texture.
     */
    texture: Nullable<Texture>;
    /**
     * Define the alpha mode to render this particular lens.
     */
    alphaMode: number;
    /** @internal */
    _drawWrapper: DrawWrapper;
    private _system;
    /**
     * Creates a new Lens Flare.
     * This represents one of the lens effect in a `lensFlareSystem`.
     * It controls one of the individual texture used in the effect.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/lenseFlare
     * @param size Define the size of the lens flare (a floating value between 0 and 1)
     * @param position Define the position of the lens flare in the system. (a floating value between -1 and 1). A value of 0 is located on the emitter. A value greater than 0 is beyond the emitter and a value lesser than 0 is behind.
     * @param color Define the lens color
     * @param imgUrl Define the lens texture url
     * @param system Define the `lensFlareSystem` this flare is part of
     * @returns The newly created Lens Flare
     */
    static AddFlare(size: number, position: number, color: Color3, imgUrl: string, system: LensFlareSystem): LensFlare;
    /**
     * Instantiates a new Lens Flare.
     * This represents one of the lens effect in a `lensFlareSystem`.
     * It controls one of the individual texture used in the effect.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/lenseFlare
     * @param size Define the size of the lens flare in the system (a floating value between 0 and 1)
     * @param position Define the position of the lens flare in the system. (a floating value between -1 and 1). A value of 0 is located on the emitter. A value greater than 0 is beyond the emitter and a value lesser than 0 is behind.
     * @param color Define the lens color
     * @param imgUrl Define the lens texture url
     * @param system Define the `lensFlareSystem` this flare is part of
     */
    constructor(
    /**
     * Define the size of the lens flare in the system (a floating value between 0 and 1)
     */
    size: number, 
    /**
     * Define the position of the lens flare in the system. (a floating value between -1 and 1). A value of 0 is located on the emitter. A value greater than 0 is beyond the emitter and a value lesser than 0 is behind.
     */
    position: number, color: Color3, imgUrl: string, system: LensFlareSystem);
    /**
     * Dispose and release the lens flare with its associated resources.
     */
    dispose(): void;
}

/**
 * This represents a Lens Flare System or the shiny effect created by the light reflection on the  camera lenses.
 * It is usually composed of several `lensFlare`.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/lenseFlare
 */
declare class LensFlareSystem {
    /**
     * Define the name of the lens flare system
     */
    name: string;
    /**
     * Force all the lens flare systems to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * List of lens flares used in this system.
     */
    lensFlares: LensFlare[];
    /**
     * Define a limit from the border the lens flare can be visible.
     */
    borderLimit: number;
    /**
     * Define a viewport border we do not want to see the lens flare in.
     */
    viewportBorder: number;
    /**
     * Define a predicate which could limit the list of meshes able to occlude the effect.
     */
    meshesSelectionPredicate: (mesh: AbstractMesh) => boolean;
    /**
     * Restricts the rendering of the effect to only the camera rendering this layer mask.
     */
    layerMask: number;
    /** Gets the scene */
    get scene(): Scene;
    /** Shader language used by the system */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this system.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Define the id of the lens flare system in the scene.
     * (equal to name by default)
     */
    id: string;
    private _scene;
    private _emitter;
    private _vertexBuffers;
    private _indexBuffer;
    private _positionX;
    private _positionY;
    private _isEnabled;
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    /**
     * Instantiates a lens flare system.
     * This represents a Lens Flare System or the shiny effect created by the light reflection on the  camera lenses.
     * It is usually composed of several `lensFlare`.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/lenseFlare
     * @param name Define the name of the lens flare system in the scene
     * @param emitter Define the source (the emitter) of the lens flares (it can be a camera, a light or a mesh).
     * @param scene Define the scene the lens flare system belongs to
     */
    constructor(
    /**
     * Define the name of the lens flare system
     */
    name: string, emitter: any, scene: Scene);
    /** @internal */
    _onShadersLoaded: Observable<void>;
    private _shadersLoaded;
    protected _initShaderSourceAsync(): Promise<void>;
    private _createIndexBuffer;
    /**
     * Define if the lens flare system is enabled.
     */
    get isEnabled(): boolean;
    set isEnabled(value: boolean);
    /**
     * Get the scene the effects belongs to.
     * @returns the scene holding the lens flare system
     */
    getScene(): Scene;
    /**
     * Get the emitter of the lens flare system.
     * It defines the source of the lens flares (it can be a camera, a light or a mesh).
     * @returns the emitter of the lens flare system
     */
    getEmitter(): any;
    /**
     * Set the emitter of the lens flare system.
     * It defines the source of the lens flares (it can be a camera, a light or a mesh).
     * @param newEmitter Define the new emitter of the system
     */
    setEmitter(newEmitter: any): void;
    /**
     * Get the lens flare system emitter position.
     * The emitter defines the source of the lens flares (it can be a camera, a light or a mesh).
     * @returns the position
     */
    getEmitterPosition(): Vector3;
    /**
     * @internal
     */
    computeEffectivePosition(globalViewport: Viewport): boolean;
    /** @internal */
    _isVisible(): boolean;
    /**
     * @internal
     */
    render(): boolean;
    /**
     * Rebuilds the lens flare system
     */
    rebuild(): void;
    /**
     * Dispose and release the lens flare with its associated resources.
     */
    dispose(): void;
    /**
     * Parse a lens flare system from a JSON representation
     * @param parsedLensFlareSystem Define the JSON to parse
     * @param scene Define the scene the parsed system should be instantiated in
     * @param rootUrl Define the rootUrl of the load sequence to easily find a load relative dependencies such as textures
     * @returns the parsed system
     */
    static Parse(parsedLensFlareSystem: any, scene: Scene, rootUrl: string): LensFlareSystem;
    /**
     * Serialize the current Lens Flare System into a JSON representation.
     * @returns the serialized JSON
     */
    serialize(): any;
}

/**
 * Interface defining container for the different elements composing a scene.
 * This class is dynamically extended by the different components of the scene increasing
 * flexibility and reducing coupling
 */
interface IAssetContainer {
    /**
     * Gets the list of root nodes (ie. nodes with no parent)
     */
    rootNodes: Node[];
    /** All of the cameras added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras
     */
    cameras: Camera[];
    /**
     * All of the lights added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
     */
    lights: Light[];
    /**
     * All of the (abstract) meshes added to this scene
     */
    meshes: AbstractMesh[];
    /**
     * The list of skeletons added to the scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/bonesSkeletons
     */
    skeletons: Skeleton[];
    /**
     * All of the particle systems added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/particles/particle_system/particle_system_intro
     */
    particleSystems: IParticleSystem[];
    /**
     * Gets a list of Animations associated with the scene
     */
    animations: Animation[];
    /**
     * All of the animation groups added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/groupAnimations
     */
    animationGroups: AnimationGroup[];
    /**
     * All of the multi-materials added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/multiMaterials
     */
    multiMaterials: MultiMaterial[];
    /**
     * All of the materials added to this scene
     * In the context of a Scene, it is not supposed to be modified manually.
     * Any addition or removal should be done using the addMaterial and removeMaterial Scene methods.
     * Note also that the order of the Material within the array is not significant and might change.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction
     */
    materials: Material[];
    /**
     * The list of morph target managers added to the scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/dynamicMeshMorph
     */
    morphTargetManagers: MorphTargetManager[];
    /**
     * The list of geometries used in the scene.
     */
    geometries: Geometry[];
    /**
     * All of the transform nodes added to this scene
     * In the context of a Scene, it is not supposed to be modified manually.
     * Any addition or removal should be done using the addTransformNode and removeTransformNode Scene methods.
     * Note also that the order of the TransformNode within the array is not significant and might change.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/parent_pivot/transform_node
     */
    transformNodes: TransformNode[];
    /**
     * ActionManagers available on the scene.
     * @deprecated
     */
    actionManagers: AbstractActionManager[];
    /**
     * Textures to keep.
     */
    textures: BaseTexture[];
    /**
     * Texture used in all pbr material as the reflection texture.
     * As in the majority of the scene they are the same (exception for multi room and so on),
     * this is easier to reference from here than from all the materials.
     */
    environmentTexture: Nullable<BaseTexture>;
    /**
     * The list of postprocesses added to the scene
     */
    postProcesses: PostProcess[];
    /**
     * The list of sound added to the scene
     */
    sounds: Nullable<Sound[]>;
    /**
     * The list of effect layers added to the scene
     */
    effectLayers: EffectLayer[];
    /**
     * The list of layers added to the scene
     */
    layers: Layer[];
    /**
     * The list of reflection probes added to the scene
     */
    reflectionProbes: ReflectionProbe[];
    /**
     * The list of lens flare system added to the scene
     */
    lensFlareSystems: LensFlareSystem[];
    /**
     * The list of procedural textures added to the scene
     */
    proceduralTextures: ProceduralTexture[];
    /**
     * The list of sprite managers added to the scene
     */
    spriteManagers?: ISpriteManager[];
    /**
     * @returns all meshes, lights, cameras, transformNodes and bones
     */
    getNodes(): Array<Node>;
}

/**
 * Class used to store geometry data (vertex buffers + index buffer)
 */
declare class Geometry implements IGetSetVerticesData {
    /**
     * Gets or sets the ID of the geometry
     */
    id: string;
    /**
     * Gets or sets the unique ID of the geometry
     */
    uniqueId: number;
    /**
     * Gets the delay loading state of the geometry (none by default which means not delayed)
     */
    delayLoadState: number;
    /**
     * Gets the file containing the data to load when running in delay load state
     */
    delayLoadingFile: Nullable<string>;
    /**
     * Callback called when the geometry is updated
     */
    onGeometryUpdated: (geometry: Geometry, kind?: string) => void;
    private _scene;
    private _engine;
    private _meshes;
    private _totalVertices;
    private _totalIndices?;
    /** @internal */
    _loadedUniqueId: string;
    /** @internal */
    _indices: IndicesArray;
    /** @internal */
    _vertexBuffers: {
        [key: string]: VertexBuffer;
    };
    private _isDisposed;
    private _extend;
    private _boundingBias;
    /** @internal */
    _delayInfo: Array<string>;
    private _indexBuffer;
    private _indexBufferIsUpdatable;
    /** @internal */
    _boundingInfo: Nullable<BoundingInfo>;
    /** @internal */
    _delayLoadingFunction: Nullable<(any: any, geometry: Geometry) => void>;
    /** @internal */
    _softwareSkinningFrameId: number;
    private _vertexArrayObjects;
    private _updatable;
    /** @internal */
    _positions: Nullable<Vector3[]>;
    private _positionsCache;
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /**
     *  Gets or sets the Bias Vector to apply on the bounding elements (box/sphere), the max extend is computed as v += v * bias.x + bias.y, the min is computed as v -= v * bias.x + bias.y
     */
    get boundingBias(): Vector2;
    /**
     *  Gets or sets the Bias Vector to apply on the bounding elements (box/sphere), the max extend is computed as v += v * bias.x + bias.y, the min is computed as v -= v * bias.x + bias.y
     */
    set boundingBias(value: Vector2);
    /**
     * Static function used to attach a new empty geometry to a mesh
     * @param mesh defines the mesh to attach the geometry to
     * @returns the new Geometry
     */
    static CreateGeometryForMesh(mesh: Mesh): Geometry;
    /** Get the list of meshes using this geometry */
    get meshes(): Mesh[];
    /**
     * If set to true (false by default), the bounding info applied to the meshes sharing this geometry will be the bounding info defined at the class level
     * and won't be computed based on the vertex positions (which is what we get when useBoundingInfoFromGeometry = false)
     */
    useBoundingInfoFromGeometry: boolean;
    /**
     * Creates a new geometry
     * @param id defines the unique ID
     * @param scene defines the hosting scene
     * @param vertexData defines the VertexData used to get geometry data
     * @param updatable defines if geometry must be updatable (false by default)
     * @param mesh defines the mesh that will be associated with the geometry
     * @param totalVertices defines the total number of vertices (optional)
     */
    constructor(id: string, scene?: Scene, vertexData?: VertexData, updatable?: boolean, mesh?: Nullable<Mesh>, totalVertices?: Nullable<number>);
    /**
     * Gets the current extend of the geometry
     */
    get extend(): {
        minimum: Vector3;
        maximum: Vector3;
    };
    /**
     * Gets the hosting scene
     * @returns the hosting Scene
     */
    getScene(): Scene;
    /**
     * Gets the hosting engine
     * @returns the hosting Engine
     */
    getEngine(): AbstractEngine;
    /**
     * Defines if the geometry is ready to use
     * @returns true if the geometry is ready to be used
     */
    isReady(): boolean;
    /**
     * Gets a value indicating that the geometry should not be serialized
     */
    get doNotSerialize(): boolean;
    /** @internal */
    _rebuild(): void;
    /**
     * Affects all geometry data in one call
     * @param vertexData defines the geometry data
     * @param updatable defines if the geometry must be flagged as updatable (false as default)
     */
    setAllVerticesData(vertexData: VertexData, updatable?: boolean): void;
    /**
     * Set specific vertex data
     * @param kind defines the data kind (Position, normal, etc...)
     * @param data defines the vertex data to use
     * @param updatable defines if the vertex must be flagged as updatable (false as default)
     * @param stride defines the stride to use (0 by default). This value is deduced from the kind value if not specified
     */
    setVerticesData(kind: string, data: FloatArray, updatable?: boolean, stride?: number): void;
    /**
     * Removes a specific vertex data
     * @param kind defines the data kind (Position, normal, etc...)
     */
    removeVerticesData(kind: string): void;
    /**
     * Affect a vertex buffer to the geometry. the vertexBuffer.getKind() function is used to determine where to store the data
     * @param buffer defines the vertex buffer to use
     * @param totalVertices defines the total number of vertices for position kind (could be null)
     * @param disposeExistingBuffer disposes the existing buffer, if any (default: true)
     */
    setVerticesBuffer(buffer: VertexBuffer, totalVertices?: Nullable<number>, disposeExistingBuffer?: boolean): void;
    /**
     * Update a specific vertex buffer
     * This function will directly update the underlying DataBuffer according to the passed numeric array or Float32Array
     * It will do nothing if the buffer is not updatable
     * @param kind defines the data kind (Position, normal, etc...)
     * @param data defines the data to use
     * @param offset defines the offset in the target buffer where to store the data
     * @param useBytes set to true if the offset is in bytes
     */
    updateVerticesDataDirectly(kind: string, data: DataArray, offset: number, useBytes?: boolean): void;
    /**
     * Update a specific vertex buffer
     * This function will create a new buffer if the current one is not updatable
     * @param kind defines the data kind (Position, normal, etc...)
     * @param data defines the data to use
     * @param updateExtends defines if the geometry extends must be recomputed (false by default)
     */
    updateVerticesData(kind: string, data: FloatArray, updateExtends?: boolean): void;
    private _updateBoundingInfo;
    /**
     * @internal
     */
    _bind(effect: Nullable<Effect>, indexToBind?: Nullable<DataBuffer>, overrideVertexBuffers?: {
        [kind: string]: Nullable<VertexBuffer>;
    }, overrideVertexArrayObjects?: {
        [key: string]: WebGLVertexArrayObject;
    }): void;
    /**
     * Gets total number of vertices
     * @returns the total number of vertices
     */
    getTotalVertices(): number;
    /**
     * Gets a specific vertex data attached to this geometry. Float data is constructed if the vertex buffer data cannot be returned directly.
     * @param kind defines the data kind (Position, normal, etc...)
     * @param copyWhenShared defines if the returned array must be cloned upon returning it if the current geometry is shared between multiple meshes
     * @param forceCopy defines a boolean indicating that the returned array must be cloned upon returning it
     * @returns a float array containing vertex data
     */
    getVerticesData(kind: string, copyWhenShared?: boolean, forceCopy?: boolean): Nullable<FloatArray>;
    /**
     * Copies the requested vertex data kind into the given vertex data map. Float data is constructed if the map doesn't have the data.
     * @param kind defines the data kind (Position, normal, etc...)
     * @param vertexData defines the map that stores the resulting data
     */
    copyVerticesData(kind: string, vertexData: {
        [kind: string]: Float32Array;
    }): void;
    /**
     * Returns a boolean defining if the vertex data for the requested `kind` is updatable
     * @param kind defines the data kind (Position, normal, etc...)
     * @returns true if the vertex buffer with the specified kind is updatable
     */
    isVertexBufferUpdatable(kind: string): boolean;
    /**
     * Gets a specific vertex buffer
     * @param kind defines the data kind (Position, normal, etc...)
     * @returns a VertexBuffer
     */
    getVertexBuffer(kind: string): Nullable<VertexBuffer>;
    /**
     * Returns all vertex buffers
     * @returns an object holding all vertex buffers indexed by kind
     */
    getVertexBuffers(): Nullable<{
        [key: string]: VertexBuffer;
    }>;
    /**
     * Gets a boolean indicating if specific vertex buffer is present
     * @param kind defines the data kind (Position, normal, etc...)
     * @returns true if data is present
     */
    isVerticesDataPresent(kind: string): boolean;
    /**
     * Gets a list of all attached data kinds (Position, normal, etc...)
     * @returns a list of string containing all kinds
     */
    getVerticesDataKinds(): string[];
    /**
     * Update index buffer
     * @param indices defines the indices to store in the index buffer
     * @param offset defines the offset in the target buffer where to store the data
     * @param gpuMemoryOnly defines a boolean indicating that only the GPU memory must be updated leaving the CPU version of the indices unchanged (false by default)
     */
    updateIndices(indices: IndicesArray, offset?: number, gpuMemoryOnly?: boolean): void;
    /**
     * Sets the index buffer for this geometry.
     * @param indexBuffer Defines the index buffer to use for this geometry
     * @param totalVertices Defines the total number of vertices used by the buffer
     * @param totalIndices Defines the total number of indices in the index buffer
     * @param is32Bits Defines if the indices are 32 bits. If null (default), the value is guessed from the number of vertices
     */
    setIndexBuffer(indexBuffer: DataBuffer, totalVertices: number, totalIndices: number, is32Bits?: Nullable<boolean>): void;
    /**
     * Creates a new index buffer
     * @param indices defines the indices to store in the index buffer
     * @param totalVertices defines the total number of vertices (could be null)
     * @param updatable defines if the index buffer must be flagged as updatable (false by default)
     * @param dontForceSubMeshRecreation defines a boolean indicating that we don't want to force the recreation of sub-meshes if we don't have to (false by default)
     */
    setIndices(indices: IndicesArray, totalVertices?: Nullable<number>, updatable?: boolean, dontForceSubMeshRecreation?: boolean): void;
    /**
     * Return the total number of indices
     * @returns the total number of indices
     */
    getTotalIndices(): number;
    /**
     * Gets the index buffer array
     * @param copyWhenShared defines if the returned array must be cloned upon returning it if the current geometry is shared between multiple meshes
     * @param forceCopy defines a boolean indicating that the returned array must be cloned upon returning it
     * @returns the index buffer array
     */
    getIndices(copyWhenShared?: boolean, forceCopy?: boolean): Nullable<IndicesArray>;
    /**
     * Gets the index buffer
     * @returns the index buffer
     */
    getIndexBuffer(): Nullable<DataBuffer>;
    /**
     * @internal
     */
    _releaseVertexArrayObject(effect?: Nullable<Effect>): void;
    /**
     * Release the associated resources for a specific mesh
     * @param mesh defines the source mesh
     * @param shouldDispose defines if the geometry must be disposed if there is no more mesh pointing to it
     */
    releaseForMesh(mesh: Mesh, shouldDispose?: boolean): void;
    /**
     * Apply current geometry to a given mesh
     * @param mesh defines the mesh to apply geometry to
     */
    applyToMesh(mesh: Mesh): void;
    private _updateExtend;
    private _applyToMesh;
    private _notifyUpdate;
    /**
     * Load the geometry if it was flagged as delay loaded
     * @param scene defines the hosting scene
     * @param onLoaded defines a callback called when the geometry is loaded
     */
    load(scene: Scene, onLoaded?: () => void): void;
    private _queueLoad;
    /**
     * Invert the geometry to move from a right handed system to a left handed one.
     */
    toLeftHanded(): void;
    /** @internal */
    _resetPointsArrayCache(): void;
    /** @internal */
    _generatePointsArray(): boolean;
    /**
     * Gets a value indicating if the geometry is disposed
     * @returns true if the geometry was disposed
     */
    isDisposed(): boolean;
    private _disposeVertexArrayObjects;
    /**
     * Free all associated resources
     */
    dispose(): void;
    /**
     * Clone the current geometry into a new geometry
     * @param id defines the unique ID of the new geometry
     * @returns a new geometry object
     */
    copy(id: string): Geometry;
    /**
     * Serialize the current geometry info (and not the vertices data) into a JSON object
     * @returns a JSON representation of the current geometry data (without the vertices data)
     */
    serialize(): any;
    private _toNumberArray;
    /**
     * Release any memory retained by the cached data on the Geometry.
     *
     * Call this function to reduce memory footprint of the mesh.
     * Vertex buffers will not store CPU data anymore (this will prevent picking, collisions or physics to work correctly)
     */
    clearCachedData(): void;
    /**
     * Serialize all vertices data into a JSON object
     * @returns a JSON representation of the current geometry data
     */
    serializeVerticeData(): any;
    /**
     * Extracts a clone of a mesh geometry
     * @param mesh defines the source mesh
     * @param id defines the unique ID of the new geometry object
     * @returns the new geometry object
     */
    static ExtractFromMesh(mesh: Mesh, id: string): Nullable<Geometry>;
    /**
     * You should now use Tools.RandomId(), this method is still here for legacy reasons.
     * Implementation from http://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid-in-javascript/2117523#answer-2117523
     * Be aware Math.random() could cause collisions, but:
     * "All but 6 of the 128 bits of the ID are randomly generated, which means that for any two ids, there's a 1 in 2^^122 (or 5.3x10^^36) chance they'll collide"
     * @returns a string containing a new GUID
     */
    static RandomId(): string;
    private static _GetGeometryByLoadedUniqueId;
    /**
     * @internal
     */
    static _ImportGeometry(parsedGeometry: any, mesh: Mesh): void;
    private static _CleanMatricesWeights;
    /**
     * Create a new geometry from persisted data (Using .babylon file format)
     * @param parsedVertexData defines the persisted data
     * @param scene defines the hosting scene
     * @param rootUrl defines the root url to use to load assets (like delayed data)
     * @returns the new geometry object
     */
    static Parse(parsedVertexData: any, scene: Scene, rootUrl: string): Nullable<Geometry>;
}

/**
 * Class used to represent a specific level of detail of a mesh
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/LOD
 */
declare class MeshLODLevel {
    /** Either distance from the center of the object to show this level or the screen coverage if `useLODScreenCoverage` is set to `true` on the mesh*/
    distanceOrScreenCoverage: number;
    /** Defines the mesh to use to render this level */
    mesh: Nullable<Mesh>;
    /**
     * Creates a new LOD level
     * @param distanceOrScreenCoverage defines either the distance or the screen coverage where this level should start being displayed
     * @param mesh defines the mesh to use to render this level
     */
    constructor(
    /** Either distance from the center of the object to show this level or the screen coverage if `useLODScreenCoverage` is set to `true` on the mesh*/
    distanceOrScreenCoverage: number, 
    /** Defines the mesh to use to render this level */
    mesh: Nullable<Mesh>);
}

/**
 * Defines the set of goldberg data used to create the polygon
 */
type GoldbergData = {
    /**
     * The list of Goldberg faces colors
     */
    faceColors: Color4[];
    /**
     * The list of Goldberg faces centers
     */
    faceCenters: Vector3[];
    /**
     * The list of Goldberg faces Z axis
     */
    faceZaxis: Vector3[];
    /**
     * The list of Goldberg faces Y axis
     */
    faceXaxis: Vector3[];
    /**
     * The list of Goldberg faces X axis
     */
    faceYaxis: Vector3[];
    /**
     * Defines the number of shared faces
     */
    nbSharedFaces: number;
    /**
     * Defines the number of unshared faces
     */
    nbUnsharedFaces: number;
    /**
     * Defines the total number of goldberg faces
     */
    nbFaces: number;
    /**
     * Defines the number of goldberg faces at the pole
     */
    nbFacesAtPole: number;
    /**
     * Defines the number of adjacent faces per goldberg faces
     */
    adjacentFaces: number[][];
};
/**
 * Mesh for a Goldberg Polyhedron which is made from 12 pentagonal and the rest hexagonal faces
 * @see https://en.wikipedia.org/wiki/Goldberg_polyhedron
 */
declare class GoldbergMesh extends Mesh {
    /**
     * Defines the specific Goldberg data used in this mesh construction.
     */
    goldbergData: GoldbergData;
    /**
     * Gets the related Goldberg face from pole infos
     * @param poleOrShared Defines the pole index or the shared face index if the fromPole parameter is passed in
     * @param fromPole Defines an optional pole index to find the related info from
     * @returns the goldberg face number
     */
    relatedGoldbergFace(poleOrShared: number, fromPole?: number): number;
    private _changeGoldbergFaceColors;
    /**
     * Set new goldberg face colors
     * @param colorRange the new color to apply to the mesh
     */
    setGoldbergFaceColors(colorRange: (number | Color4)[][]): void;
    /**
     * Updates new goldberg face colors
     * @param colorRange the new color to apply to the mesh
     */
    updateGoldbergFaceColors(colorRange: (number | Color4)[][]): void;
    private _changeGoldbergFaceUVs;
    /**
     * set new goldberg face UVs
     * @param uvRange the new UVs to apply to the mesh
     */
    setGoldbergFaceUVs(uvRange: (number | Vector2)[][]): void;
    /**
     * Updates new goldberg face UVs
     * @param uvRange the new UVs to apply to the mesh
     */
    updateGoldbergFaceUVs(uvRange: (number | Vector2)[][]): void;
    /**
     * Places a mesh on a particular face of the goldberg polygon
     * @param mesh Defines the mesh to position
     * @param face Defines the face to position onto
     * @param position Defines the position relative to the face we are positioning the mesh onto
     */
    placeOnGoldbergFaceAt(mesh: Mesh, face: number, position: Vector3): void;
    /**
     * Serialize current mesh
     * @param serializationObject defines the object which will receive the serialization data
     */
    serialize(serializationObject: any): void;
    /**
     * Parses a serialized goldberg mesh
     * @param parsedMesh the serialized mesh
     * @param scene the scene to create the goldberg mesh in
     * @returns the created goldberg mesh
     */
    static Parse(parsedMesh: any, scene: Scene): GoldbergMesh;
}

/**
 * Creates an instance based on a source mesh.
 */
declare class InstancedMesh extends AbstractMesh {
    private _sourceMesh;
    private _currentLOD;
    private _billboardWorldMatrix;
    /** @internal */
    _indexInSourceMeshInstanceArray: number;
    /** @internal */
    _distanceToCamera: number;
    /** @internal */
    _previousWorldMatrix: Nullable<Matrix>;
    /**
     * Creates a new InstancedMesh object from the mesh source.
     * @param name defines the name of the instance
     * @param source the mesh to create the instance from
     */
    constructor(name: string, source: Mesh);
    /**
     * @returns the string "InstancedMesh".
     */
    getClassName(): string;
    /** Gets the list of lights affecting that mesh */
    get lightSources(): Light[];
    _resyncLightSources(): void;
    _resyncLightSource(): void;
    _removeLightSource(): void;
    /**
     * If the source mesh receives shadows
     */
    get receiveShadows(): boolean;
    set receiveShadows(_value: boolean);
    /**
     * The material of the source mesh
     */
    get material(): Nullable<Material>;
    set material(_value: Nullable<Material>);
    /**
     * Visibility of the source mesh
     */
    get visibility(): number;
    set visibility(_value: number);
    /**
     * Skeleton of the source mesh
     */
    get skeleton(): Nullable<Skeleton>;
    set skeleton(_value: Nullable<Skeleton>);
    /**
     * Rendering ground id of the source mesh
     */
    get renderingGroupId(): number;
    set renderingGroupId(value: number);
    /**
     * @returns the total number of vertices (integer).
     */
    getTotalVertices(): number;
    /**
     * Returns a positive integer : the total number of indices in this mesh geometry.
     * @returns the number of indices or zero if the mesh has no geometry.
     */
    getTotalIndices(): number;
    /**
     * The source mesh of the instance
     */
    get sourceMesh(): Mesh;
    /**
     * Gets the mesh internal Geometry object
     */
    get geometry(): Nullable<Geometry>;
    /**
     * Creates a new InstancedMesh object from the mesh model.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/copies/instances
     * @param name defines the name of the new instance
     * @returns a new InstancedMesh
     */
    createInstance(name: string): InstancedMesh;
    /**
     * Is this node ready to be used/rendered
     * @param completeCheck defines if a complete check (including materials and lights) has to be done (false by default)
     * @returns {boolean} is it ready
     */
    isReady(completeCheck?: boolean): boolean;
    /**
     * Returns an array of integers or a typed array (Int32Array, Uint32Array, Uint16Array) populated with the mesh indices.
     * @param kind kind of verticies to retrieve (eg. positions, normals, uvs, etc.)
     * @param copyWhenShared If true (default false) and and if the mesh geometry is shared among some other meshes, the returned array is a copy of the internal one.
     * @param forceCopy defines a boolean forcing the copy of the buffer no matter what the value of copyWhenShared is
     * @returns a float array or a Float32Array of the requested kind of data : positions, normals, uvs, etc.
     */
    getVerticesData(kind: string, copyWhenShared?: boolean, forceCopy?: boolean): Nullable<FloatArray>;
    copyVerticesData(kind: string, vertexData: {
        [kind: string]: Float32Array;
    }): void;
    getVertexBuffer(kind: string, bypassInstanceData?: boolean): Nullable<VertexBuffer>;
    /**
     * Sets the vertex data of the mesh geometry for the requested `kind`.
     * If the mesh has no geometry, a new Geometry object is set to the mesh and then passed this vertex data.
     * The `data` are either a numeric array either a Float32Array.
     * The parameter `updatable` is passed as is to the underlying Geometry object constructor (if initially none) or updater.
     * The parameter `stride` is an optional positive integer, it is usually automatically deducted from the `kind` (3 for positions or normals, 2 for UV, etc).
     * Note that a new underlying VertexBuffer object is created each call.
     * If the `kind` is the `PositionKind`, the mesh BoundingInfo is renewed, so the bounding box and sphere, and the mesh World Matrix is recomputed.
     *
     * Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     *
     * Returns the Mesh.
     * @param kind defines vertex data kind
     * @param data defines the data source
     * @param updatable defines if the data must be flagged as updatable (false as default)
     * @param stride defines the vertex stride (optional)
     * @returns the current mesh
     */
    setVerticesData(kind: string, data: FloatArray, updatable?: boolean, stride?: number): AbstractMesh;
    /**
     * Updates the existing vertex data of the mesh geometry for the requested `kind`.
     * If the mesh has no geometry, it is simply returned as it is.
     * The `data` are either a numeric array either a Float32Array.
     * No new underlying VertexBuffer object is created.
     * If the `kind` is the `PositionKind` and if `updateExtends` is true, the mesh BoundingInfo is renewed, so the bounding box and sphere, and the mesh World Matrix is recomputed.
     * If the parameter `makeItUnique` is true, a new global geometry is created from this positions and is set to the mesh.
     *
     * Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     *
     * Returns the Mesh.
     * @param kind defines vertex data kind
     * @param data defines the data source
     * @param updateExtends defines if extends info of the mesh must be updated (can be null). This is mostly useful for "position" kind
     * @param makeItUnique defines it the updated vertex buffer must be flagged as unique (false by default)
     * @returns the source mesh
     */
    updateVerticesData(kind: string, data: FloatArray, updateExtends?: boolean, makeItUnique?: boolean): Mesh;
    /**
     * Sets the mesh indices.
     * Expects an array populated with integers or a typed array (Int32Array, Uint32Array, Uint16Array).
     * If the mesh has no geometry, a new Geometry object is created and set to the mesh.
     * This method creates a new index buffer each call.
     * Returns the Mesh.
     * @param indices the source data
     * @param totalVertices defines the total number of vertices referenced by indices (could be null)
     * @returns source mesh
     */
    setIndices(indices: IndicesArray, totalVertices?: Nullable<number>): Mesh;
    /**
     * Boolean : True if the mesh owns the requested kind of data.
     * @param kind defines which buffer to check (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @returns true if data kind is present
     */
    isVerticesDataPresent(kind: string): boolean;
    /**
     * @returns an array of indices (IndicesArray).
     */
    getIndices(): Nullable<IndicesArray>;
    get _positions(): Nullable<Vector3[]>;
    refreshBoundingInfo(applySkeletonOrOptions?: boolean | IMeshDataOptions, applyMorph?: boolean): InstancedMesh;
    /** @internal */
    _preActivate(): InstancedMesh;
    /**
     * @internal
     */
    _activate(renderId: number, intermediateRendering: boolean): boolean;
    /** @internal */
    _postActivate(): void;
    getWorldMatrix(): Matrix;
    get isAnInstance(): boolean;
    /**
     * Returns the current associated LOD AbstractMesh.
     * @param camera defines the camera to use to pick the LOD level
     * @returns a Mesh or `null` if no LOD is associated with the AbstractMesh
     */
    getLOD(camera: Camera): AbstractMesh;
    /**
     * @internal
     */
    _preActivateForIntermediateRendering(renderId: number): Mesh;
    /** @internal */
    _syncSubMeshes(): InstancedMesh;
    /** @internal */
    _generatePointsArray(): boolean;
    /** @internal */
    _updateBoundingInfo(): AbstractMesh;
    /**
     * Creates a new InstancedMesh from the current mesh.
     *
     * Returns the clone.
     * @param name the cloned mesh name
     * @param newParent the optional Node to parent the clone to.
     * @param doNotCloneChildren if `true` the model children aren't cloned.
     * @param newSourceMesh if set this mesh will be used as the source mesh instead of ths instance's one
     * @returns the clone
     */
    clone(name: string, newParent?: Nullable<Node>, doNotCloneChildren?: boolean, newSourceMesh?: Mesh): InstancedMesh;
    /**
     * Disposes the InstancedMesh.
     * Returns nothing.
     * @param doNotRecurse Set to true to not recurse into each children (recurse into each children by default)
     * @param disposeMaterialAndTextures Set to true to also dispose referenced materials and textures (false by default)
     */
    dispose(doNotRecurse?: boolean, disposeMaterialAndTextures?: boolean): void;
    /**
     * @internal
     */
    _serializeAsParent(serializationObject: any): void;
    /**
     * Instantiate (when possible) or clone that node with its hierarchy
     * @param newParent defines the new parent to use for the instance (or clone)
     * @param options defines options to configure how copy is done
     * @param options.doNotInstantiate defines if the model must be instantiated or just cloned
     * @param options.newSourcedMesh newSourcedMesh the new source mesh for the instance (or clone)
     * @param onNewNodeCreated defines an option callback to call when a clone or an instance is created
     * @returns an instance (or a clone) of the current node with its hierarchy
     */
    instantiateHierarchy(newParent?: Nullable<TransformNode>, options?: {
        doNotInstantiate: boolean | ((node: TransformNode) => boolean);
        newSourcedMesh?: Mesh;
    }, onNewNodeCreated?: (source: TransformNode, clone: TransformNode) => void): Nullable<TransformNode>;
}
declare module "./mesh" {
    interface Mesh {
        /**
         * Register a custom buffer that will be instanced
         * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/copies/instances#custom-buffers
         * @param kind defines the buffer kind
         * @param stride defines the stride in floats
         */
        registerInstancedBuffer(kind: string, stride: number): void;
        /**
         * Invalidate VertexArrayObjects belonging to the mesh (but not to the Geometry of the mesh).
         */
        _invalidateInstanceVertexArrayObject(): void;
        /**
         * true to use the edge renderer for all instances of this mesh
         */
        edgesShareWithInstances: boolean;
        /** @internal */
        _userInstancedBuffersStorage: {
            data: {
                [key: string]: Float32Array;
            };
            sizes: {
                [key: string]: number;
            };
            vertexBuffers: {
                [key: string]: Nullable<VertexBuffer>;
            };
            strides: {
                [key: string]: number;
            };
            vertexArrayObjects?: {
                [key: string]: WebGLVertexArrayObject;
            };
            renderPasses?: {
                [renderPassId: number]: {
                    [kind: string]: Nullable<VertexBuffer>;
                };
            };
        };
    }
}
declare module "./abstractMesh" {
    interface AbstractMesh {
        /**
         * Object used to store instanced buffers defined by user
         * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/copies/instances#custom-buffers
         */
        instancedBuffers: {
            [key: string]: any;
        };
    }
}

/**
 * This is a holder class for the physics constraint created by the physics plugin
 * It holds a set of functions to control the underlying constraint
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
declare class PhysicsConstraint {
    /**
     * V2 Physics plugin private data for a physics material
     */
    _pluginData: any;
    /**
     * The V2 plugin used to create and manage this Physics Body
     */
    protected _physicsPlugin: IPhysicsEnginePluginV2;
    protected _options: PhysicsConstraintParameters;
    protected _type: PhysicsConstraintType;
    /**
     * @internal
     * The internal options that were used to init the constraint
     */
    _initOptions?: PhysicsConstraintParameters;
    /**
     * Constructs a new constraint for the physics constraint.
     * @param type The type of constraint to create.
     * @param options The options for the constraint.
     * @param scene The scene the constraint belongs to.
     *
     * This code is useful for creating a new constraint for the physics engine. It checks if the scene has a physics engine, and if the plugin version is correct.
     * If all checks pass, it initializes the constraint with the given type and options.
     */
    constructor(type: PhysicsConstraintType, options: PhysicsConstraintParameters, scene: Scene);
    /**
     * Gets the type of the constraint.
     *
     * @returns The type of the constraint.
     *
     */
    get type(): PhysicsConstraintType;
    /**
     * Retrieves the options of the physics constraint.
     *
     * @returns The physics constraint parameters.
     *
     */
    get options(): PhysicsConstraintParameters;
    /**
     * Enable/disable the constraint
     * @param isEnabled value for the constraint
     */
    set isEnabled(isEnabled: boolean);
    /**
     *
     * @returns true if constraint is enabled
     */
    get isEnabled(): boolean;
    /**
     * Enables or disables collisions for the physics engine.
     *
     * @param isEnabled - A boolean value indicating whether collisions should be enabled or disabled.
     *
     */
    set isCollisionsEnabled(isEnabled: boolean);
    /**
     * Gets whether collisions are enabled for this physics object.
     *
     * @returns `true` if collisions are enabled, `false` otherwise.
     *
     */
    get isCollisionsEnabled(): boolean;
    /**
     * Gets all bodies that are using this constraint
     * @returns
     */
    getBodiesUsingConstraint(): ConstrainedBodyPair[];
    /**
     * Disposes the constraint from the physics engine.
     *
     * This method is useful for cleaning up the physics engine when a body is no longer needed. Disposing the body will free up resources and prevent memory leaks.
     */
    dispose(): void;
}

/**
 * PhysicsBody is useful for creating a physics body that can be used in a physics engine. It allows
 * the user to set the mass and velocity of the body, which can then be used to calculate the
 * motion of the body in the physics engine.
 */
declare class PhysicsBody {
    /**
     * V2 Physics plugin private data for single Transform
     */
    _pluginData: any;
    /**
     * V2 Physics plugin private data for instances
     */
    _pluginDataInstances: Array<any>;
    /**
     * The V2 plugin used to create and manage this Physics Body
     */
    private _physicsPlugin;
    /**
     * The engine used to create and manage this Physics Body
     */
    private _physicsEngine;
    /**
     * If the collision callback is enabled
     */
    private _collisionCBEnabled;
    /**
     * If the collision ended callback is enabled
     */
    private _collisionEndedCBEnabled;
    /**
     * The transform node associated with this Physics Body
     */
    transformNode: TransformNode;
    /**
     * Disable pre-step that consists in updating Physics Body from Transform Node Translation/Orientation.
     * True by default for maximum performance.
     */
    get disablePreStep(): boolean;
    set disablePreStep(value: boolean);
    /**
     * Disable sync from physics to transformNode. This value is set to true at body creation or at motionType setting when the body is not dynamic.
     */
    disableSync: boolean;
    /**
     * Physics engine will try to make this body sleeping and not active
     */
    startAsleep: boolean;
    private _nodeDisposeObserver;
    private _isDisposed;
    private _shape;
    private _prestepType;
    /**
     * Constructs a new physics body for the given node.
     * @param transformNode - The Transform Node to construct the physics body for. For better performance, it is advised that this node does not have a parent.
     * @param motionType - The motion type of the physics body. The options are:
     *  - PhysicsMotionType.STATIC - Static bodies are not moving and unaffected by forces or collisions. They are good for level boundaries or terrain.
     *  - PhysicsMotionType.DYNAMIC - Dynamic bodies are fully simulated. They can move and collide with other objects.
     *  - PhysicsMotionType.ANIMATED - They behave like dynamic bodies, but they won't be affected by other bodies, but still push other bodies out of the way.
     * @param startsAsleep - Whether the physics body should start in a sleeping state (not a guarantee). Defaults to false.
     * @param scene - The scene containing the physics engine.
     *
     * This code is useful for creating a physics body for a given Transform Node in a scene.
     * It checks the version of the physics engine and the physics plugin, and initializes the body accordingly.
     * It also sets the node's rotation quaternion if it is not already set. Finally, it adds the body to the physics engine.
     */
    constructor(transformNode: TransformNode, motionType: PhysicsMotionType, startsAsleep: boolean, scene: Scene);
    /**
     * Returns the string "PhysicsBody".
     * @returns "PhysicsBody"
     */
    getClassName(): string;
    /**
     * Clone the PhysicsBody to a new body and assign it to the transformNode parameter
     * @param transformNode transformNode that will be used for the cloned PhysicsBody
     * @returns the newly cloned PhysicsBody
     */
    clone(transformNode: TransformNode): PhysicsBody;
    /**
     * If a physics body is connected to an instanced node, update the number physic instances to match the number of node instances.
     */
    updateBodyInstances(): void;
    /**
     * This returns the number of internal instances of the physics body
     */
    get numInstances(): number;
    /**
     * Get the motion type of the physics body. Can be STATIC, DYNAMIC, or ANIMATED.
     */
    get motionType(): PhysicsMotionType;
    /**
     * Sets the shape of the physics body.
     * @param shape - The shape of the physics body.
     *
     * This method is useful for setting the shape of the physics body, which is necessary for the physics engine to accurately simulate the body's behavior.
     * The shape is used to calculate the body's mass, inertia, and other properties.
     */
    set shape(shape: Nullable<PhysicsShape>);
    /**
     * Retrieves the physics shape associated with this object.
     *
     * @returns The physics shape associated with this object, or `undefined` if no
     * shape is associated.
     *
     * This method is useful for retrieving the physics shape associated with this object,
     * which can be used to apply physical forces to the object or to detect collisions.
     */
    get shape(): Nullable<PhysicsShape>;
    /**
     * Returns the bounding box of the physics body.
     * @returns The bounding box of the physics body.
     */
    getBoundingBox(): BoundingBox;
    /**
     * Sets the event mask for the physics engine.
     *
     * @param eventMask - A bitmask that determines which events will be sent to the physics engine.
     * @param instanceIndex - If this body is instanced, the index of the instance to set the event mask for.
     *
     * This method is useful for setting the event mask for the physics engine, which determines which events
     * will be sent to the physics engine. This allows the user to control which events the physics engine will respond to.
     */
    setEventMask(eventMask: number, instanceIndex?: number): void;
    /**
     * Gets the event mask of the physics engine.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the event mask for.
     * @returns The event mask of the physics engine.
     *
     * This method is useful for getting the event mask of the physics engine,
     * which is used to determine which events the engine will respond to.
     * This is important for ensuring that the engine is responding to the correct events and not
     * wasting resources on unnecessary events.
     */
    getEventMask(instanceIndex?: number): number;
    /**
     * Sets the motion type of the physics body. Can be STATIC, DYNAMIC, or ANIMATED.
     * @param motionType - The motion type to set.
     * @param instanceIndex - If this body is instanced, the index of the instance to set the motion type for. If body is instanced but instanceIndex is undefined, the motion type will be set for all instances.
     */
    setMotionType(motionType: PhysicsMotionType, instanceIndex?: number): void;
    /**
     * Gets the motion type of the physics body. Can be STATIC, DYNAMIC, or ANIMATED.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the motion type for.
     * @returns The motion type of the physics body.
     */
    getMotionType(instanceIndex?: number): PhysicsMotionType;
    /**
     * Set the prestep type of the body
     * @param prestepType prestep type provided by PhysicsPrestepType
     */
    setPrestepType(prestepType: PhysicsPrestepType): void;
    /**
     * Get the current prestep type of the body
     * @returns the type of prestep associated with the body and its instance index
     */
    getPrestepType(): PhysicsPrestepType;
    /**
     * Computes the mass properties of the physics object, based on the set of physics shapes this body uses.
     * This method is useful for computing the initial mass properties of a physics object, such as its mass,
     * inertia, and center of mass; these values are important for accurately simulating the physics of the
     * object in the physics engine, and computing values based on the shape will provide you with reasonable
     * initial values, which you can then customize.
     * @param instanceIndex - The index of the instance to compute the mass properties for.
     * @returns The mass properties of the object.
     */
    computeMassProperties(instanceIndex?: number): PhysicsMassProperties;
    /**
     * Sets the mass properties of the physics object.
     *
     * @param massProps - The mass properties to set.
     * @param instanceIndex - The index of the instance to set the mass properties for. If not defined, the mass properties will be set for all instances.
     *
     * This method is useful for setting the mass properties of a physics object, such as its mass,
     * inertia, and center of mass. This is important for accurately simulating the physics of the object in the physics engine.
     */
    setMassProperties(massProps: PhysicsMassProperties, instanceIndex?: number): void;
    /**
     * Retrieves the mass properties of the object.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the mass properties for.
     * @returns The mass properties of the object.
     *
     * This method is useful for physics simulations, as it allows the user to
     * retrieve the mass properties of the object, such as its mass, center of mass,
     * and moment of inertia. This information is necessary for accurate physics
     * simulations.
     */
    getMassProperties(instanceIndex?: number): PhysicsMassProperties;
    /**
     * Sets the linear damping of the physics body.
     *
     * @param damping - The linear damping value.
     * @param instanceIndex - If this body is instanced, the index of the instance to set the linear damping for.
     *
     * This method is useful for controlling the linear damping of the physics body,
     * which is the rate at which the body's velocity decreases over time. This is useful for simulating
     * the effects of air resistance or other forms of friction.
     */
    setLinearDamping(damping: number, instanceIndex?: number): void;
    /**
     * Gets the linear damping of the physics body.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the linear damping for.
     * @returns The linear damping of the physics body.
     *
     * This method is useful for retrieving the linear damping of the physics body, which is the amount of
     * resistance the body has to linear motion. This is useful for simulating realistic physics behavior
     * in a game.
     */
    getLinearDamping(instanceIndex?: number): number;
    /**
     * Sets the angular damping of the physics body.
     * @param damping The angular damping of the body.
     * @param instanceIndex - If this body is instanced, the index of the instance to set the angular damping for.
     *
     * This method is useful for controlling the angular velocity of a physics body.
     * By setting the damping, the body's angular velocity will be reduced over time, simulating the effect of friction.
     * This can be used to create realistic physical behavior in a physics engine.
     */
    setAngularDamping(damping: number, instanceIndex?: number): void;
    /**
     * Gets the angular damping of the physics body.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the angular damping for.
     *
     * @returns The angular damping of the physics body.
     *
     * This method is useful for getting the angular damping of the physics body,
     * which is the rate of reduction of the angular velocity over time.
     * This is important for simulating realistic physics behavior in a game.
     */
    getAngularDamping(instanceIndex?: number): number;
    /**
     * Sets the linear velocity of the physics object.
     * @param linVel - The linear velocity to set.
     * @param instanceIndex - If this body is instanced, the index of the instance to set the linear velocity for.
     *
     * This method is useful for setting the linear velocity of a physics object,
     * which is necessary for simulating realistic physics in a game engine.
     * By setting the linear velocity, the physics object will move in the direction and speed specified by the vector.
     * This allows for realistic physics simulations, such as simulating the motion of a ball rolling down a hill.
     */
    setLinearVelocity(linVel: Vector3, instanceIndex?: number): void;
    /**
     * Gets the linear velocity of the physics body and stores it in the given vector3.
     * @param linVel - The vector3 to store the linear velocity in.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the linear velocity for.
     *
     * This method is useful for getting the linear velocity of a physics body in a physics engine.
     * This can be used to determine the speed and direction of the body, which can be used to calculate the motion of the body.
     */
    getLinearVelocityToRef(linVel: Vector3, instanceIndex?: number): void;
    /**
     * Gets the linear velocity of the physics body as a new vector3.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the linear velocity for.
     * @returns The linear velocity of the physics body.
     *
     * This method is useful for getting the linear velocity of a physics body in a physics engine.
     * This can be used to determine the speed and direction of the body, which can be used to calculate the motion of the body.
     */
    getLinearVelocity(instanceIndex?: number): Vector3;
    /**
     * Sets the angular velocity of the physics object.
     * @param angVel - The angular velocity to set.
     * @param instanceIndex - If this body is instanced, the index of the instance to set the angular velocity for.
     *
     * This method is useful for setting the angular velocity of a physics object, which is necessary for
     * simulating realistic physics behavior. The angular velocity is used to determine the rate of rotation of the object,
     * which is important for simulating realistic motion.
     */
    setAngularVelocity(angVel: Vector3, instanceIndex?: number): void;
    /**
     * Gets the angular velocity of the physics body and stores it in the given vector3.
     * @param angVel - The vector3 to store the angular velocity in.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the angular velocity for.
     *
     * This method is useful for getting the angular velocity of a physics body, which can be used to determine the body's
     * rotational speed. This information can be used to create realistic physics simulations.
     */
    getAngularVelocityToRef(angVel: Vector3, instanceIndex?: number): void;
    /**
     * Gets the angular velocity of the physics body as a new vector3.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the angular velocity for.
     * @returns The angular velocity of the physics body.
     *
     * This method is useful for getting the angular velocity of a physics body, which can be used to determine the body's
     * rotational speed. This information can be used to create realistic physics simulations.
     */
    getAngularVelocity(instanceIndex?: number): Vector3;
    /**
     * Applies an impulse to the physics object.
     *
     * @param impulse The impulse vector.
     * @param location The location of the impulse.
     * @param instanceIndex For a instanced body, the instance to where the impulse should be applied. If not specified, the impulse is applied to all instances.
     *
     * This method is useful for applying an impulse to a physics object, which can be used to simulate physical forces such as gravity,
     * collisions, and explosions. This can be used to create realistic physics simulations in a game or other application.
     */
    applyImpulse(impulse: Vector3, location: Vector3, instanceIndex?: number): void;
    /**
     * Add torque to a physics body
     * @param angularImpulse The angular impulse vector.
     * @param instanceIndex For a instanced body, the instance to where the impulse should be applied. If not specified, the impulse is applied to all instances.
     */
    applyAngularImpulse(angularImpulse: Vector3, instanceIndex?: number): void;
    /**
     * Applies a torque to the physics body.
     *
     * @param torque The torque vector.
     * @param instanceIndex For a instanced body, the instance to where the torque should be applied. If not specified, the torque is applied to all instances.
     *
     * This method is useful for applying a torque to a physics body, which can be used to simulate rotational forces such as motors,
     * angular momentum, and rotational dynamics. This can be used to create realistic physics simulations in a game or other application.
     */
    applyTorque(torque: Vector3, instanceIndex?: number): void;
    /**
     * Applies a force to the physics object.
     *
     * @param force The force vector.
     * @param location The location of the force.
     * @param instanceIndex For a instanced body, the instance to where the force should be applied. If not specified, the force is applied to all instances.
     *
     * This method is useful for applying a force to a physics object, which can be used to simulate physical forces such as gravity,
     * collisions, and explosions. This can be used to create realistic physics simulations in a game or other application.
     */
    applyForce(force: Vector3, location: Vector3, instanceIndex?: number): void;
    /**
     * Retrieves the geometry of the body from the physics plugin.
     *
     * @returns The geometry of the body.
     *
     * This method is useful for retrieving the geometry of the body from the physics plugin, which can be used for various physics calculations.
     */
    getGeometry(): object;
    /**
     * Returns an observable that will be notified for when a collision starts or continues for this PhysicsBody
     * @returns Observable
     */
    getCollisionObservable(): Observable<IPhysicsCollisionEvent>;
    /**
     * Returns an observable that will be notified when the body has finished colliding with another body
     * @returns
     */
    getCollisionEndedObservable(): Observable<IBasePhysicsCollisionEvent>;
    /**
     * Enable or disable collision callback for this PhysicsBody.
     * @param enabled true if PhysicsBody's collision will rise a collision event and notifies the observable
     */
    setCollisionCallbackEnabled(enabled: boolean): void;
    /**
     * Enable or disable collision ended callback for this PhysicsBody.
     * @param enabled true if PhysicsBody's collision ended will rise a collision event and notifies the observable
     */
    setCollisionEndedCallbackEnabled(enabled: boolean): void;
    /**
     * Get the center of the object in world space.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the center for.
     * @returns geometric center of the associated mesh
     */
    getObjectCenterWorld(instanceIndex?: number): Vector3;
    /**
     * Get the center of the object in world space.
     * @param ref - The vector3 to store the result in.
     * @param instanceIndex - If this body is instanced, the index of the instance to get the center for.
     * @returns geometric center of the associated mesh
     */
    getObjectCenterWorldToRef(ref: Vector3, instanceIndex?: number): Vector3;
    /**
     * Adds a constraint to the physics engine.
     *
     * @param childBody - The body to which the constraint will be applied.
     * @param constraint - The constraint to be applied.
     * @param instanceIndex - If this body is instanced, the index of the instance to which the constraint will be applied. If not specified, no constraint will be applied.
     * @param childInstanceIndex - If the child body is instanced, the index of the instance to which the constraint will be applied. If not specified, no constraint will be applied.
     *
     */
    addConstraint(childBody: PhysicsBody, constraint: PhysicsConstraint, instanceIndex?: number, childInstanceIndex?: number): void;
    /**
     * Sync with a bone
     * @param bone The bone that the impostor will be synced to.
     * @param boneMesh The mesh that the bone is influencing.
     * @param jointPivot The pivot of the joint / bone in local space.
     * @param distToJoint Optional distance from the impostor to the joint.
     * @param adjustRotation Optional quaternion for adjusting the local rotation of the bone.
     * @param boneAxis Optional vector3 axis the bone is aligned with
     */
    syncWithBone(bone: Bone, boneMesh: AbstractMesh, jointPivot: Vector3, distToJoint?: number, adjustRotation?: Quaternion, boneAxis?: Vector3): void;
    /**
     * Executes a callback on the body or all of the instances of a body
     * @param callback the callback to execute
     */
    iterateOverAllInstances(callback: (body: PhysicsBody, instanceIndex?: number) => void): void;
    /**
     * Sets the gravity factor of the physics body
     * @param factor the gravity factor to set
     * @param instanceIndex the instance of the body to set, if undefined all instances will be set
     */
    setGravityFactor(factor: number, instanceIndex?: number): void;
    /**
     * Gets the gravity factor of the physics body
     * @param instanceIndex the instance of the body to get, if undefined the value of first instance will be returned
     * @returns the gravity factor
     */
    getGravityFactor(instanceIndex?: number): number;
    /**
     * Set the target transformation (position and rotation) of the body, such that the body will set its velocity to reach that target
     * @param position The target position
     * @param rotation The target rotation
     * @param instanceIndex The index of the instance in an instanced body
     */
    setTargetTransform(position: Vector3, rotation: Quaternion, instanceIndex?: number): void;
    /**
     * Returns if the body has been disposed.
     * @returns true if disposed, false otherwise.
     */
    get isDisposed(): boolean;
    /**
     * Disposes the body from the physics engine.
     *
     * This method is useful for cleaning up the physics engine when a body is no longer needed. Disposing the body will free up resources and prevent memory leaks.
     */
    dispose(): void;
}

/**
 * Determines how values from the PhysicsMaterial are combined when
 * two objects are in contact. When each PhysicsMaterial specifies
 * a different combine mode for some property, the combine mode which
 * is used will be selected based on their order in this enum - i.e.
 * a value later in this list will be preferentially used.
 */
declare const enum PhysicsMaterialCombineMode {
    /**
     * The final value will be the geometric mean of the two values:
     * sqrt( valueA *  valueB )
     */
    GEOMETRIC_MEAN = 0,
    /**
     * The final value will be the smaller of the two:
     * min( valueA , valueB )
     */
    MINIMUM = 1,
    MAXIMUM = 2,
    ARITHMETIC_MEAN = 3,
    /**
     * The final value will be the product of the two values:
     * valueA * valueB
     */
    MULTIPLY = 4
}
/**
 * Physics material class
 * Helps setting friction and restitution that are used to compute responding forces in collision response
 */
interface PhysicsMaterial {
    /**
     * Sets the friction used by this material
     *
     * The friction determines how much an object will slow down when it is in contact with another object.
     * This is important for simulating realistic physics, such as when an object slides across a surface.
     *
     * If not provided, a default value of 0.5 will be used.
     */
    friction?: number;
    /**
     * Sets the static friction used by this material.
     *
     * Static friction is the friction that must be overcome before a pair of objects can start sliding
     * relative to each other; for physically-realistic behaviour, it should be at least as high as the
     * normal friction value. If not provided, the friction value will be used
     */
    staticFriction?: number;
    /**
     * Sets the restitution of the physics material.
     *
     * The restitution is a factor which describes, the amount of energy that is retained after a collision,
     * which should be a number between 0 and 1..
     *
     * A restitution of 0 means that no energy is retained and the objects will not bounce off each other,
     * while a restitution of 1 means that all energy is retained and the objects will bounce.
     *
     * Note, though, due that due to the simulation implementation, an object with a restitution of 1 may
     * still lose energy over time.
     *
     * If not provided, a default value of 0 will be used.
     */
    restitution?: number;
    /**
     * Describes how two different friction values should be combined. See PhysicsMaterialCombineMode for
     * more details.
     *
     * If not provided, will use PhysicsMaterialCombineMode.MINIMUM
     */
    frictionCombine?: PhysicsMaterialCombineMode;
    /**
     * Describes how two different restitution values should be combined. See PhysicsMaterialCombineMode for
     * more details.
     *
     * If not provided, will use PhysicsMaterialCombineMode.MAXIMUM
     */
    restitutionCombine?: PhysicsMaterialCombineMode;
}

/**
 * Mesh representing the ground
 */
declare class GroundMesh extends Mesh {
    /** If octree should be generated */
    generateOctree: boolean;
    private _heightQuads;
    /** @internal */
    _subdivisionsX: number;
    /** @internal */
    _subdivisionsY: number;
    /** @internal */
    _width: number;
    /** @internal */
    _height: number;
    /** @internal */
    _minX: number;
    /** @internal */
    _maxX: number;
    /** @internal */
    _minZ: number;
    /** @internal */
    _maxZ: number;
    constructor(name: string, scene?: Scene);
    /**
     * "GroundMesh"
     * @returns "GroundMesh"
     */
    getClassName(): string;
    /**
     * The minimum of x and y subdivisions
     */
    get subdivisions(): number;
    /**
     * X subdivisions
     */
    get subdivisionsX(): number;
    /**
     * Y subdivisions
     */
    get subdivisionsY(): number;
    /**
     * This function will divide the mesh into submeshes and update an octree to help to select the right submeshes
     * for rendering, picking and collision computations. Please note that you must have a decent number of submeshes
     * to get performance improvements when using an octree.
     * @param chunksCount the number of submeshes the mesh will be divided into
     * @param octreeBlocksSize the maximum size of the octree blocks (Default: 32)
     */
    optimize(chunksCount: number, octreeBlocksSize?: number): void;
    /**
     * Returns a height (y) value in the World system :
     * the ground altitude at the coordinates (x, z) expressed in the World system.
     * @param x x coordinate
     * @param z z coordinate
     * @returns the ground y position if (x, z) are outside the ground surface.
     */
    getHeightAtCoordinates(x: number, z: number): number;
    /**
     * Returns a normalized vector (Vector3) orthogonal to the ground
     * at the ground coordinates (x, z) expressed in the World system.
     * @param x x coordinate
     * @param z z coordinate
     * @returns Vector3(0.0, 1.0, 0.0) if (x, z) are outside the ground surface.
     */
    getNormalAtCoordinates(x: number, z: number): Vector3;
    /**
     * Updates the Vector3 passed a reference with a normalized vector orthogonal to the ground
     * at the ground coordinates (x, z) expressed in the World system.
     * Doesn't update the reference Vector3 if (x, z) are outside the ground surface.
     * @param x x coordinate
     * @param z z coordinate
     * @param ref vector to store the result
     * @returns the GroundMesh.
     */
    getNormalAtCoordinatesToRef(x: number, z: number, ref: Vector3): GroundMesh;
    /**
     * Force the heights to be recomputed for getHeightAtCoordinates() or getNormalAtCoordinates()
     * if the ground has been updated.
     * This can be used in the render loop.
     * @returns the GroundMesh.
     */
    updateCoordinateHeights(): GroundMesh;
    private _getFacetAt;
    private _initHeightQuads;
    private _computeHeightQuads;
    /**
     * Serializes this ground mesh
     * @param serializationObject object to write serialization to
     */
    serialize(serializationObject: any): void;
    /**
     * Parses a serialized ground mesh
     * @param parsedMesh the serialized mesh
     * @param scene the scene to create the ground mesh in
     * @returns the created ground mesh
     */
    static Parse(parsedMesh: any, scene: Scene): GroundMesh;
}

/** How a specific axis can be constrained */
declare const enum PhysicsConstraintAxisLimitMode {
    FREE = 0,
    LIMITED = 1,
    LOCKED = 2
}
/** The constraint specific axis to use when setting Friction, `ConstraintAxisLimitMode`, max force, ... */
declare const enum PhysicsConstraintAxis {
    LINEAR_X = 0,
    LINEAR_Y = 1,
    LINEAR_Z = 2,
    ANGULAR_X = 3,
    ANGULAR_Y = 4,
    ANGULAR_Z = 5,
    LINEAR_DISTANCE = 6
}
/** Type of Constraint */
declare const enum PhysicsConstraintType {
    /**
     * A ball and socket constraint will attempt to line up the pivot
     * positions in each body, and have no restrictions on rotation
     */
    BALL_AND_SOCKET = 1,
    /**
     * A distance constraint will attempt to keep the pivot locations
     * within a specified distance.
     */
    DISTANCE = 2,
    /**
     * A hinge constraint will keep the pivot positions aligned as well
     * as two angular axes. The remaining angular axis will be free to rotate.
     */
    HINGE = 3,
    /**
     * A slider constraint allows bodies to translate along one axis and
     * rotate about the same axis. The remaining two axes are locked in
     * place
     */
    SLIDER = 4,
    /**
     * A lock constraint will attempt to keep the pivots completely lined
     * up between both bodies, allowing no relative movement.
     */
    LOCK = 5,
    PRISMATIC = 6,
    SIX_DOF = 7
}
/** Type of Shape */
declare const enum PhysicsShapeType {
    SPHERE = 0,
    CAPSULE = 1,
    CYLINDER = 2,
    BOX = 3,
    CONVEX_HULL = 4,
    CONTAINER = 5,
    MESH = 6,
    HEIGHTFIELD = 7
}
/** Optional motor which attempts to move a body at a specific velocity, or at a specific position */
declare const enum PhysicsConstraintMotorType {
    NONE = 0,
    VELOCITY = 1,
    POSITION = 2
}
declare const enum PhysicsEventType {
    COLLISION_STARTED = "COLLISION_STARTED",
    COLLISION_CONTINUED = "COLLISION_CONTINUED",
    COLLISION_FINISHED = "COLLISION_FINISHED",
    TRIGGER_ENTERED = "TRIGGER_ENTERED",
    TRIGGER_EXITED = "TRIGGER_EXITED"
}
/**
 * Base collision object
 */
interface IBasePhysicsCollisionEvent {
    /**
     * 1st physics body that collided
     */
    collider: PhysicsBody;
    /**
     * 2nd physics body that collided
     */
    collidedAgainst: PhysicsBody;
    /**
     * index in instances array for the collider
     */
    colliderIndex: number;
    /**
     * index in instances array for the collidedAgainst
     */
    collidedAgainstIndex: number;
    /**
     * Event type
     */
    type: PhysicsEventType;
}
/**
 * Collision object that is the parameter when notification for collision fires.
 */
interface IPhysicsCollisionEvent extends IBasePhysicsCollisionEvent {
    /**
     * World position where the collision occured
     */
    point: Nullable<Vector3>;
    /**
     * Penetration distance
     */
    distance: number;
    /**
     * Impulse value computed by the solver response
     */
    impulse: number;
    /**
     * Collision world normal direction
     */
    normal: Nullable<Vector3>;
}
/**
 * Parameters used to describe the Shape
 */
interface PhysicsShapeParameters {
    /**
     * Shape center position
     */
    center?: Vector3;
    /**
     * Radius for cylinder, shape and capsule
     */
    radius?: number;
    /**
     * First point position that defines the cylinder or capsule
     */
    pointA?: Vector3;
    /**
     * Second point position that defines the cylinder or capsule
     */
    pointB?: Vector3;
    /**
     * Shape orientation
     */
    rotation?: Quaternion;
    /**
     * Dimesion extention for the box
     */
    extents?: Vector3;
    /**
     * Mesh used for Mesh shape or convex hull. It can be different than the mesh the body is attached to.
     */
    mesh?: Mesh;
    /**
     * Use children hierarchy
     */
    includeChildMeshes?: boolean;
    /**
     * The size of the heightfield in the X axis
     */
    heightFieldSizeX?: number;
    /**
     * The size of the heightfield in the Z axis
     */
    heightFieldSizeZ?: number;
    /**
     * The number of samples along the X axis
     */
    numHeightFieldSamplesX?: number;
    /**
     * The number of samples along the Z axis
     */
    numHeightFieldSamplesZ?: number;
    /**
     * The data for the heightfield
     */
    heightFieldData?: Float32Array;
    /**
     * Ground mesh used for display
     */
    groundMesh?: GroundMesh;
}
/**
 * Parameters used to describe a Constraint
 */
interface PhysicsConstraintParameters {
    /**
     * Location of the constraint pivot in the space of first body
     */
    pivotA?: Vector3;
    /**
     * Location of the constraint pivot in the space of the second body
     */
    pivotB?: Vector3;
    /**
     * An axis in the space of the first body which determines how
     * distances/angles are measured for LINEAR_X/ANGULAR_X limits.
     */
    axisA?: Vector3;
    /**
     * An axis in the space of the second body which determines how
     * distances/angles are measured for LINEAR_X/ANGULAR_X limits.
     */
    axisB?: Vector3;
    /**
     * An axis in the space of the first body which determines how
     * distances/angles are measured for LINEAR_Y/ANGULAR_Y limits.
     */
    perpAxisA?: Vector3;
    /**
     * An axis in the space of the second body which determines how
     * distances/angles are measured for LINEAR_Y/ANGULAR_Y limits.
     */
    perpAxisB?: Vector3;
    /**
     * The maximum distance that can seperate the two pivots.
     * Only used for DISTANCE constraints
     */
    maxDistance?: number;
    /**
     * Determines if the connected bodies should collide. Generally,
     * it is preferable to set this to false, especially if the constraint
     * positions the bodies so that they overlap. Otherwise, the constraint
     * will "fight" the collision detection and may cause jitter.
     */
    collision?: boolean;
}
/**
 * Parameters used to describe mass and inertia of the Physics Body
 */
interface PhysicsMassProperties {
    /**
     * The center of mass, in local space. This is The
     * point the body will rotate around when applying
     * an angular velocity.
     *
     * If not provided, the physics engine will compute
     * an appropriate value.
     */
    centerOfMass?: Vector3;
    /**
     * The total mass of this object, in kilograms. This
     * affects how easy it is to move the body. A value
     * of zero will be used as an infinite mass.
     *
     * If not provided, the physics engine will compute
     * an appropriate value.
     */
    mass?: number;
    /**
     * The principal moments of inertia of this object
     * for a unit mass. This determines how easy it is
     * for the body to rotate. A value of zero on any
     * axis will be used as infinite interia about that
     * axis.
     *
     * If not provided, the physics engine will compute
     * an appropriate value.
     */
    inertia?: Vector3;
    /**
     * The rotation rotating from inertia major axis space
     * to parent space (i.e., the rotation which, when
     * applied to the 3x3 inertia tensor causes the inertia
     * tensor to become a diagonal matrix). This determines
     * how the values of inertia are aligned with the parent
     * object.
     *
     * If not provided, the physics engine will compute
     * an appropriate value.
     */
    inertiaOrientation?: Quaternion;
}
/**
 * Indicates how the body will behave.
 */
declare const enum PhysicsMotionType {
    STATIC = 0,
    ANIMATED = 1,
    DYNAMIC = 2
}
/**
 * Indicates how to handle position/rotation change of transform node attached to a physics body
 */
declare enum PhysicsPrestepType {
    DISABLED = 0,
    TELEPORT = 1,
    ACTION = 2
}
/**
 * Represents a pair of bodies connected by a constraint.
 */
type ConstrainedBodyPair = {
    parentBody: PhysicsBody;
    parentBodyIndex: number;
    childBody: PhysicsBody;
    childBodyIndex: number;
};
/** @internal */
interface IPhysicsEnginePluginV2 {
    /**
     * Physics plugin world instance
     */
    world: any;
    /**
     * Physics plugin name
     */
    name: string;
    /**
     * Collision observable
     */
    onCollisionObservable: Observable<IPhysicsCollisionEvent>;
    /**
     * Collision ended observable
     */
    onCollisionEndedObservable: Observable<IBasePhysicsCollisionEvent>;
    /**
     * Trigger observable
     */
    onTriggerCollisionObservable: Observable<IBasePhysicsCollisionEvent>;
    setGravity(gravity: Vector3): void;
    setTimeStep(timeStep: number): void;
    getTimeStep(): number;
    executeStep(delta: number, bodies: Array<PhysicsBody>): void;
    getPluginVersion(): number;
    setVelocityLimits(maxLinearVelocity: number, maxAngularVelocity: number): void;
    getMaxLinearVelocity(): number;
    getMaxAngularVelocity(): number;
    initBody(body: PhysicsBody, motionType: PhysicsMotionType, position: Vector3, orientation: Quaternion): void;
    initBodyInstances(body: PhysicsBody, motionType: PhysicsMotionType, mesh: Mesh): void;
    updateBodyInstances(body: PhysicsBody, mesh: Mesh): void;
    removeBody(body: PhysicsBody): void;
    sync(body: PhysicsBody): void;
    syncTransform(body: PhysicsBody, transformNode: TransformNode): void;
    setShape(body: PhysicsBody, shape: Nullable<PhysicsShape>): void;
    getShape(body: PhysicsBody): Nullable<PhysicsShape>;
    getShapeType(shape: PhysicsShape): PhysicsShapeType;
    setEventMask(body: PhysicsBody, eventMask: number, instanceIndex?: number): void;
    getEventMask(body: PhysicsBody, instanceIndex?: number): number;
    setMotionType(body: PhysicsBody, motionType: PhysicsMotionType, instanceIndex?: number): void;
    getMotionType(body: PhysicsBody, instanceIndex?: number): PhysicsMotionType;
    computeMassProperties(body: PhysicsBody, instanceIndex?: number): PhysicsMassProperties;
    setMassProperties(body: PhysicsBody, massProps: PhysicsMassProperties, instanceIndex?: number): void;
    getMassProperties(body: PhysicsBody, instanceIndex?: number): PhysicsMassProperties;
    setLinearDamping(body: PhysicsBody, damping: number, instanceIndex?: number): void;
    getLinearDamping(body: PhysicsBody, instanceIndex?: number): number;
    setAngularDamping(body: PhysicsBody, damping: number, instanceIndex?: number): void;
    getAngularDamping(body: PhysicsBody, instanceIndex?: number): number;
    setLinearVelocity(body: PhysicsBody, linVel: Vector3, instanceIndex?: number): void;
    getLinearVelocityToRef(body: PhysicsBody, linVel: Vector3, instanceIndex?: number): void;
    applyImpulse(body: PhysicsBody, impulse: Vector3, location: Vector3, instanceIndex?: number): void;
    applyAngularImpulse(body: PhysicsBody, angularImpulse: Vector3, instanceIndex?: number): void;
    applyForce(body: PhysicsBody, force: Vector3, location: Vector3, instanceIndex?: number): void;
    applyTorque(body: PhysicsBody, torque: Vector3, instanceIndex?: number): void;
    setAngularVelocity(body: PhysicsBody, angVel: Vector3, instanceIndex?: number): void;
    getAngularVelocityToRef(body: PhysicsBody, angVel: Vector3, instanceIndex?: number): void;
    getBodyGeometry(body: PhysicsBody): object;
    disposeBody(body: PhysicsBody): void;
    setCollisionCallbackEnabled(body: PhysicsBody, enabled: boolean, instanceIndex?: number): void;
    setCollisionEndedCallbackEnabled(body: PhysicsBody, enabled: boolean, instanceIndex?: number): void;
    addConstraint(body: PhysicsBody, childBody: PhysicsBody, constraint: PhysicsConstraint, instanceIndex?: number, childInstanceIndex?: number): void;
    getCollisionObservable(body: PhysicsBody, instanceIndex?: number): Observable<IPhysicsCollisionEvent>;
    getCollisionEndedObservable(body: PhysicsBody, instanceIndex?: number): Observable<IBasePhysicsCollisionEvent>;
    setGravityFactor(body: PhysicsBody, factor: number, instanceIndex?: number): void;
    getGravityFactor(body: PhysicsBody, instanceIndex?: number): number;
    setTargetTransform(body: PhysicsBody, position: Vector3, rotation: Quaternion, instanceIndex?: number): void;
    initShape(shape: PhysicsShape, type: PhysicsShapeType, options: PhysicsShapeParameters): void;
    setShapeFilterMembershipMask(shape: PhysicsShape, membershipMask: number): void;
    getShapeFilterMembershipMask(shape: PhysicsShape): number;
    setShapeFilterCollideMask(shape: PhysicsShape, collideMask: number): void;
    getShapeFilterCollideMask(shape: PhysicsShape): number;
    setMaterial(shape: PhysicsShape, material: PhysicsMaterial): void;
    getMaterial(shape: PhysicsShape): PhysicsMaterial;
    setDensity(shape: PhysicsShape, density: number): void;
    getDensity(shape: PhysicsShape): number;
    addChild(shape: PhysicsShape, newChild: PhysicsShape, translation?: Vector3, rotation?: Quaternion, scale?: Vector3): void;
    removeChild(shape: PhysicsShape, childIndex: number): void;
    getNumChildren(shape: PhysicsShape): number;
    getBoundingBox(shape: PhysicsShape): BoundingBox;
    getBodyBoundingBox(body: PhysicsBody): BoundingBox;
    disposeShape(shape: PhysicsShape): void;
    setTrigger(shape: PhysicsShape, isTrigger: boolean): void;
    initConstraint(constraint: PhysicsConstraint, body: PhysicsBody, childBody: PhysicsBody): void;
    setEnabled(constraint: PhysicsConstraint, isEnabled: boolean): void;
    getEnabled(constraint: PhysicsConstraint): boolean;
    setCollisionsEnabled(constraint: PhysicsConstraint, isEnabled: boolean): void;
    getCollisionsEnabled(constraint: PhysicsConstraint): boolean;
    setAxisFriction(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis, friction: number): void;
    getAxisFriction(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis): Nullable<number>;
    setAxisMode(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis, limitMode: PhysicsConstraintAxisLimitMode): void;
    getAxisMode(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis): Nullable<PhysicsConstraintAxisLimitMode>;
    setAxisMinLimit(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis, minLimit: number): void;
    getAxisMinLimit(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis): Nullable<number>;
    setAxisMaxLimit(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis, limit: number): void;
    getAxisMaxLimit(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis): Nullable<number>;
    setAxisMotorType(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis, motorType: PhysicsConstraintMotorType): void;
    getAxisMotorType(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis): Nullable<PhysicsConstraintMotorType>;
    setAxisMotorTarget(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis, target: number): void;
    getAxisMotorTarget(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis): Nullable<number>;
    setAxisMotorMaxForce(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis, maxForce: number): void;
    getAxisMotorMaxForce(constraint: PhysicsConstraint, axis: PhysicsConstraintAxis): Nullable<number>;
    disposeConstraint(constraint: PhysicsConstraint): void;
    getBodiesUsingConstraint(constraint: PhysicsConstraint): ConstrainedBodyPair[];
    raycast(from: Vector3, to: Vector3, result: PhysicsRaycastResult | Array<PhysicsRaycastResult>, query?: IRaycastQuery): void;
    dispose(): void;
}

/**
 * Options for creating a physics shape
 */
interface PhysicShapeOptions {
    /**
     * The type of the shape. This can be one of the following: SPHERE, BOX, CAPSULE, CYLINDER, CONVEX_HULL, MESH, HEIGHTFIELD, CONTAINER
     */
    type?: PhysicsShapeType;
    /**
     * The parameters of the shape. Varies depending of the shape type.
     */
    parameters?: PhysicsShapeParameters;
    /**
     * Reference to an already existing physics shape in the plugin.
     */
    pluginData?: any;
}
/**
 * PhysicsShape class.
 * This class is useful for creating a physics shape that can be used in a physics engine.
 * A Physic Shape determine how collision are computed. It must be attached to a body.
 */
declare class PhysicsShape {
    /**
     * V2 Physics plugin private data for single shape
     */
    _pluginData: any;
    /**
     * The V2 plugin used to create and manage this Physics Body
     */
    private _physicsPlugin;
    private _type;
    private _material;
    private _isTrigger;
    private _isDisposed;
    /**
     * Constructs a new physics shape.
     * @param options The options for the physics shape. These are:
     *  * type: The type of the shape. This can be one of the following: SPHERE, BOX, CAPSULE, CYLINDER, CONVEX_HULL, MESH, HEIGHTFIELD, CONTAINER
     *  * parameters: The parameters of the shape.
     *  * pluginData: The plugin data of the shape. This is used if you already have a reference to the object on the plugin side.
     * You need to specify either type or pluginData.
     * @param scene The scene the shape belongs to.
     *
     * This code is useful for creating a new physics shape with the given type, options, and scene.
     * It also checks that the physics engine and plugin version are correct.
     * If not, it throws an error. This ensures that the shape is created with the correct parameters and is compatible with the physics engine.
     */
    constructor(options: PhysicShapeOptions, scene: Scene);
    /**
     * Returns the string "PhysicsShape".
     * @returns "PhysicsShape"
     */
    getClassName(): string;
    /**
     * Returns the type of the physics shape.
     * @returns The type of the physics shape.
     */
    get type(): PhysicsShapeType;
    /**
     * Set the membership mask of a shape. This is a bitfield of arbitrary
     * "categories" to which the shape is a member. This is used in combination
     * with the collide mask to determine if this shape should collide with
     * another.
     *
     * @param membershipMask Bitfield of categories of this shape.
     */
    set filterMembershipMask(membershipMask: number);
    /**
     * Get the membership mask of a shape.
     * @returns Bitmask of categories which this shape is a member of.
     */
    get filterMembershipMask(): number;
    /**
     * Sets the collide mask of a shape. This is a bitfield of arbitrary
     * "categories" to which this shape collides with. Given two shapes,
     * the engine will check if the collide mask and membership overlap:
     * shapeA.filterMembershipMask & shapeB.filterCollideMask
     *
     * If this value is zero (i.e. shapeB only collides with categories
     * which shapeA is _not_ a member of) then the shapes will not collide.
     *
     * Note, the engine will also perform the same test with shapeA and
     * shapeB swapped; the shapes will not collide if either shape has
     * a collideMask which prevents collision with the other shape.
     *
     * @param collideMask Bitmask of categories this shape should collide with
     */
    set filterCollideMask(collideMask: number);
    /**
     *
     * @returns Bitmask of categories that this shape should collide with
     */
    get filterCollideMask(): number;
    /**
     *
     * @param material
     */
    set material(material: PhysicsMaterial);
    /**
     * Returns the material of the physics shape.
     * @returns The material of the physics shape.
     */
    get material(): PhysicsMaterial;
    /**
     * Sets the density of the physics shape.
     * @param density The density of the physics shape.
     */
    set density(density: number);
    /**
     * Returns the density of the physics shape.
     * @returns The density of the physics shape.
     */
    get density(): number;
    /**
     * Utility to add a child shape to this container,
     * automatically computing the relative transform between
     * the container shape and the child instance.
     *
     * @param parentTransform The transform node associated with this shape
     * @param newChild The new PhysicsShape to add
     * @param childTransform The transform node associated with the child shape
     */
    addChildFromParent(parentTransform: TransformNode, newChild: PhysicsShape, childTransform: TransformNode): void;
    /**
     * Adds a child shape to a container with an optional transform
     * @param newChild The new PhysicsShape to add
     * @param translation Optional position of the child shape relative to this shape
     * @param rotation Optional rotation of the child shape relative to this shape
     * @param scale Optional scale of the child shape relative to this shape
     */
    addChild(newChild: PhysicsShape, translation?: Vector3, rotation?: Quaternion, scale?: Vector3): void;
    /**
     * Removes a child shape from this shape.
     * @param childIndex The index of the child shape to remove
     */
    removeChild(childIndex: number): void;
    /**
     * Returns the number of children of a physics shape.
     * @returns The number of children of a physics shape.
     */
    getNumChildren(): number;
    /**
     * Returns the bounding box of the physics shape.
     * @returns The bounding box of the physics shape.
     */
    getBoundingBox(): BoundingBox;
    set isTrigger(isTrigger: boolean);
    get isTrigger(): boolean;
    /**
     * Dispose the shape and release its associated resources.
     */
    dispose(): void;
}

/**
 * Base class for results of casts.
 */
declare class CastingResult {
    private _hasHit;
    protected _hitNormal: Vector3;
    protected _hitPoint: Vector3;
    private _triangleIndex;
    /**
     * The Physics body that the query hit.
     */
    body?: PhysicsBody;
    /**
     * The body Index in case the Physics body is using instances
     */
    bodyIndex?: number;
    /**
     * The shape hit by the query.
     */
    shape?: PhysicsShape;
    /**
     * Gets the hit point.
     */
    get hitPoint(): Vector3;
    /**
     * Gets the hit normal.
     */
    get hitNormal(): Vector3;
    /**
     * Gets if there was a hit
     */
    get hasHit(): boolean;
    get triangleIndex(): number;
    /**
     * Sets the hit data
     * @param hitNormal defines the normal in world space
     * @param hitPoint defines the point in world space
     * @param triangleIndex defines the index of the triangle in case of mesh shape
     */
    setHitData(hitNormal: IXYZ, hitPoint: IXYZ, triangleIndex?: number): void;
    /**
     * Resets all the values to default
     */
    reset(): void;
}
/**
 * Interface for the size containing width and height
 */
interface IXYZ {
    /**
     * X
     */
    x: number;
    /**
     * Y
     */
    y: number;
    /**
     * Z
     */
    z: number;
}

/**
 * Interface for query parameters in the raycast function.
 * @see the "Collision Filtering" section in https://github.com/eoineoineoin/glTF/tree/MSFT_RigidBodies/extensions/2.0/Vendor/MSFT_collision_primitives
 */
interface IRaycastQuery {
    /** Membership mask */
    membership?: number;
    /** CollideWith mask */
    collideWith?: number;
    /** Should trigger collisions be considered in the query? */
    shouldHitTriggers?: boolean;
    /** Ignores the body passed if it is in the query */
    ignoreBody?: PhysicsBody;
}
/**
 * Holds the data for the raycast result
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
declare class PhysicsRaycastResult extends CastingResult {
    private _hitDistance;
    private _rayFromWorld;
    private _rayToWorld;
    /**
     * Gets the distance from the hit
     */
    get hitDistance(): number;
    /**
     * Gets the hit normal/direction in the world
     */
    get hitNormalWorld(): Vector3;
    /**
     * Gets the hit point in the world
     */
    get hitPointWorld(): Vector3;
    /**
     * Gets the ray "start point" of the ray in the world
     */
    get rayFromWorld(): Vector3;
    /**
     * Gets the ray "end point" of the ray in the world
     */
    get rayToWorld(): Vector3;
    /**
     * Sets the distance from the start point to the hit point
     * @param distance defines the distance to set
     */
    setHitDistance(distance: number): void;
    /**
     * Calculates the distance manually
     */
    calculateHitDistance(): void;
    /**
     * Resets all the values to default
     * @param from The from point on world space
     * @param to The to point on world space
     */
    reset(from?: Vector3, to?: Vector3): void;
}

/**
 * Interface used to describe a physics joint
 */
interface PhysicsImpostorJoint {
    /** Defines the main impostor to which the joint is linked */
    mainImpostor: PhysicsImpostor;
    /** Defines the impostor that is connected to the main impostor using this joint */
    connectedImpostor: PhysicsImpostor;
    /** Defines the joint itself */
    joint: PhysicsJoint;
}
/** @internal */
interface IPhysicsEnginePlugin {
    world: any;
    name: string;
    setGravity(gravity: Vector3): void;
    setTimeStep(timeStep: number): void;
    getTimeStep(): number;
    executeStep(delta: number, impostors: Array<PhysicsImpostor>): void;
    getPluginVersion(): number;
    applyImpulse(impostor: PhysicsImpostor, force: Vector3, contactPoint: Vector3): void;
    applyForce(impostor: PhysicsImpostor, force: Vector3, contactPoint: Vector3): void;
    generatePhysicsBody(impostor: PhysicsImpostor): void;
    removePhysicsBody(impostor: PhysicsImpostor): void;
    generateJoint(joint: PhysicsImpostorJoint): void;
    removeJoint(joint: PhysicsImpostorJoint): void;
    isSupported(): boolean;
    setTransformationFromPhysicsBody(impostor: PhysicsImpostor): void;
    setPhysicsBodyTransformation(impostor: PhysicsImpostor, newPosition: Vector3, newRotation: Quaternion): void;
    setLinearVelocity(impostor: PhysicsImpostor, velocity: Nullable<Vector3>): void;
    setAngularVelocity(impostor: PhysicsImpostor, velocity: Nullable<Vector3>): void;
    getLinearVelocity(impostor: PhysicsImpostor): Nullable<Vector3>;
    getAngularVelocity(impostor: PhysicsImpostor): Nullable<Vector3>;
    setBodyMass(impostor: PhysicsImpostor, mass: number): void;
    getBodyMass(impostor: PhysicsImpostor): number;
    getBodyFriction(impostor: PhysicsImpostor): number;
    setBodyFriction(impostor: PhysicsImpostor, friction: number): void;
    getBodyRestitution(impostor: PhysicsImpostor): number;
    setBodyRestitution(impostor: PhysicsImpostor, restitution: number): void;
    getBodyPressure?(impostor: PhysicsImpostor): number;
    setBodyPressure?(impostor: PhysicsImpostor, pressure: number): void;
    getBodyStiffness?(impostor: PhysicsImpostor): number;
    setBodyStiffness?(impostor: PhysicsImpostor, stiffness: number): void;
    getBodyVelocityIterations?(impostor: PhysicsImpostor): number;
    setBodyVelocityIterations?(impostor: PhysicsImpostor, velocityIterations: number): void;
    getBodyPositionIterations?(impostor: PhysicsImpostor): number;
    setBodyPositionIterations?(impostor: PhysicsImpostor, positionIterations: number): void;
    appendAnchor?(impostor: PhysicsImpostor, otherImpostor: PhysicsImpostor, width: number, height: number, influence: number, noCollisionBetweenLinkedBodies: boolean): void;
    appendHook?(impostor: PhysicsImpostor, otherImpostor: PhysicsImpostor, length: number, influence: number, noCollisionBetweenLinkedBodies: boolean): void;
    sleepBody(impostor: PhysicsImpostor): void;
    wakeUpBody(impostor: PhysicsImpostor): void;
    raycast(from: Vector3, to: Vector3): PhysicsRaycastResult;
    raycastToRef(from: Vector3, to: Vector3, result: PhysicsRaycastResult): void;
    updateDistanceJoint(joint: PhysicsJoint, maxDistance: number, minDistance?: number): void;
    setMotor(joint: IMotorEnabledJoint, speed: number, maxForce?: number, motorIndex?: number): void;
    setLimit(joint: IMotorEnabledJoint, upperLimit: number, lowerLimit?: number, motorIndex?: number): void;
    getRadius(impostor: PhysicsImpostor): number;
    getBoxSizeToRef(impostor: PhysicsImpostor, result: Vector3): void;
    syncMeshWithImpostor(mesh: AbstractMesh, impostor: PhysicsImpostor): void;
    dispose(): void;
}

/**
 * Interface for Physics-Joint data
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
interface PhysicsJointData {
    /**
     * The main pivot of the joint
     */
    mainPivot?: Vector3;
    /**
     * The connected pivot of the joint
     */
    connectedPivot?: Vector3;
    /**
     * The main axis of the joint
     */
    mainAxis?: Vector3;
    /**
     * The connected axis of the joint
     */
    connectedAxis?: Vector3;
    /**
     * The collision of the joint
     */
    collision?: boolean;
    /**
     * Native Oimo/Cannon/Energy data
     */
    nativeParams?: any;
}
/**
 * This is a holder class for the physics joint created by the physics plugin
 * It holds a set of functions to control the underlying joint
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
declare class PhysicsJoint {
    /**
     * The type of the physics joint
     */
    type: number;
    /**
     * The data for the physics joint
     */
    jointData: PhysicsJointData;
    private _physicsJoint;
    protected _physicsPlugin: IPhysicsEnginePlugin;
    /**
     * Initializes the physics joint
     * @param type The type of the physics joint
     * @param jointData The data for the physics joint
     */
    constructor(
    /**
     * The type of the physics joint
     */
    type: number, 
    /**
     * The data for the physics joint
     */
    jointData: PhysicsJointData);
    /**
     * Gets the physics joint
     */
    get physicsJoint(): any;
    /**
     * Sets the physics joint
     */
    set physicsJoint(newJoint: any);
    /**
     * Sets the physics plugin
     */
    set physicsPlugin(physicsPlugin: IPhysicsEnginePlugin);
    /**
     * Execute a function that is physics-plugin specific.
     * @param {Function} func the function that will be executed.
     *                        It accepts two parameters: the physics world and the physics joint
     */
    executeNativeFunction(func: (world: any, physicsJoint: any) => void): void;
    /**
     * Distance-Joint type
     */
    static DistanceJoint: number;
    /**
     * Hinge-Joint type
     */
    static HingeJoint: number;
    /**
     * Ball-and-Socket joint type
     */
    static BallAndSocketJoint: number;
    /**
     * Wheel-Joint type
     */
    static WheelJoint: number;
    /**
     * Slider-Joint type
     */
    static SliderJoint: number;
    /**
     * Prismatic-Joint type
     */
    static PrismaticJoint: number;
    /**
     * Universal-Joint type
     * ENERGY FTW! (compare with this - @see http://ode-wiki.org/wiki/index.php?title=Manual:_Joint_Types_and_Functions)
     */
    static UniversalJoint: number;
    /**
     * Hinge-Joint 2 type
     */
    static Hinge2Joint: number;
    /**
     * Point to Point Joint type.  Similar to a Ball-Joint.  Different in parameters
     */
    static PointToPointJoint: number;
    /**
     * Spring-Joint type
     */
    static SpringJoint: number;
    /**
     * Lock-Joint type
     */
    static LockJoint: number;
}
/**
 * Interface for a motor enabled joint
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
interface IMotorEnabledJoint {
    /**
     * Physics joint
     */
    physicsJoint: any;
    /**
     * Sets the motor of the motor-enabled joint
     * @param force The force of the motor
     * @param maxForce The maximum force of the motor
     * @param motorIndex The index of the motor
     */
    setMotor(force?: number, maxForce?: number, motorIndex?: number): void;
    /**
     * Sets the limit of the motor
     * @param upperLimit The upper limit of the motor
     * @param lowerLimit The lower limit of the motor
     * @param motorIndex The index of the motor
     */
    setLimit(upperLimit: number, lowerLimit?: number, motorIndex?: number): void;
}

/**
 * The interface for the physics imposter parameters
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
interface PhysicsImpostorParameters {
    /**
     * The mass of the physics imposter
     */
    mass: number;
    /**
     * The friction of the physics imposter
     */
    friction?: number;
    /**
     * The coefficient of restitution of the physics imposter
     */
    restitution?: number;
    /**
     * The native options of the physics imposter
     */
    nativeOptions?: any;
    /**
     * Specifies if the parent should be ignored
     */
    ignoreParent?: boolean;
    /**
     * Specifies if bi-directional transformations should be disabled
     */
    disableBidirectionalTransformation?: boolean;
    /**
     * The pressure inside the physics imposter, soft object only
     */
    pressure?: number;
    /**
     * The stiffness the physics imposter, soft object only
     */
    stiffness?: number;
    /**
     * The number of iterations used in maintaining consistent vertex velocities, soft object only
     */
    velocityIterations?: number;
    /**
     * The number of iterations used in maintaining consistent vertex positions, soft object only
     */
    positionIterations?: number;
    /**
     * The number used to fix points on a cloth (0, 1, 2, 4, 8) or rope (0, 1, 2) only
     * 0 None, 1, back left or top, 2, back right or bottom, 4, front left, 8, front right
     * Add to fix multiple points
     */
    fixedPoints?: number;
    /**
     * The collision margin around a soft object
     */
    margin?: number;
    /**
     * The collision margin around a soft object
     */
    damping?: number;
    /**
     * The path for a rope based on an extrusion
     */
    path?: any;
    /**
     * The shape of an extrusion used for a rope based on an extrusion
     */
    shape?: any;
}
/**
 * Interface for a physics-enabled object
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
interface IPhysicsEnabledObject {
    /**
     * The position of the physics-enabled object
     */
    position: Vector3;
    /**
     * The rotation of the physics-enabled object
     */
    rotationQuaternion: Nullable<Quaternion>;
    /**
     * The scale of the physics-enabled object
     */
    scaling: Vector3;
    /**
     * The rotation of the physics-enabled object
     */
    rotation?: Vector3;
    /**
     * The parent of the physics-enabled object
     */
    parent?: any;
    /**
     * The bounding info of the physics-enabled object
     * @returns The bounding info of the physics-enabled object
     */
    getBoundingInfo(): BoundingInfo;
    /**
     * Computes the world matrix
     * @param force Specifies if the world matrix should be computed by force
     * @returns A world matrix
     */
    computeWorldMatrix(force: boolean): Matrix;
    /**
     * Gets the world matrix
     * @returns A world matrix
     */
    getWorldMatrix?(): Matrix;
    /**
     * Gets the child meshes
     * @param directDescendantsOnly Specifies if only direct-descendants should be obtained
     * @returns An array of abstract meshes
     */
    getChildMeshes?(directDescendantsOnly?: boolean): Array<AbstractMesh>;
    /**
     * Gets the vertex data
     * @param kind The type of vertex data
     * @returns A nullable array of numbers, or a float32 array
     */
    getVerticesData(kind: string): Nullable<FloatArray>;
    /**
     * Gets the indices from the mesh
     * @returns A nullable array of index arrays
     */
    getIndices?(): Nullable<IndicesArray>;
    /**
     * Gets the scene from the mesh
     * @returns the indices array or null
     */
    getScene?(): Scene;
    /**
     * Gets the absolute position from the mesh
     * @returns the absolute position
     */
    getAbsolutePosition(): Vector3;
    /**
     * Gets the absolute pivot point from the mesh
     * @returns the absolute pivot point
     */
    getAbsolutePivotPoint(): Vector3;
    /**
     * Rotates the mesh
     * @param axis The axis of rotation
     * @param amount The amount of rotation
     * @param space The space of the rotation
     * @returns The rotation transform node
     */
    rotate(axis: Vector3, amount: number, space?: Space): TransformNode;
    /**
     * Translates the mesh
     * @param axis The axis of translation
     * @param distance The distance of translation
     * @param space The space of the translation
     * @returns The transform node
     */
    translate(axis: Vector3, distance: number, space?: Space): TransformNode;
    /**
     * Sets the absolute position of the mesh
     * @param absolutePosition The absolute position of the mesh
     * @returns The transform node
     */
    setAbsolutePosition(absolutePosition: Vector3): TransformNode;
    /**
     * Gets the class name of the mesh
     * @returns The class name
     */
    getClassName(): string;
}
/**
 * Represents a physics imposter
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
declare class PhysicsImpostor {
    /**
     * The physics-enabled object used as the physics imposter
     */
    object: IPhysicsEnabledObject;
    /**
     * The type of the physics imposter
     */
    type: number;
    private _options;
    private _scene?;
    /**
     * The default object size of the imposter
     */
    static DEFAULT_OBJECT_SIZE: Vector3;
    /**
     * The identity quaternion of the imposter
     */
    static IDENTITY_QUATERNION: Quaternion;
    /** @internal */
    _pluginData: any;
    private _physicsEngine;
    private _physicsBody;
    private _bodyUpdateRequired;
    private _onBeforePhysicsStepCallbacks;
    private _onAfterPhysicsStepCallbacks;
    /** @internal */
    _onPhysicsCollideCallbacks: Array<{
        callback: (collider: PhysicsImpostor, collidedAgainst: PhysicsImpostor, point: Nullable<Vector3>, distance: number, impulse: number, normal: Nullable<Vector3>) => void;
        otherImpostors: Array<PhysicsImpostor>;
    }>;
    private _deltaPosition;
    private _deltaRotation;
    private _deltaRotationConjugated;
    /** @internal */
    _isFromLine: boolean;
    private _parent;
    private _isDisposed;
    private static _TmpVecs;
    private static _TmpQuat;
    /**
     * Specifies if the physics imposter is disposed
     */
    get isDisposed(): boolean;
    /**
     * Gets the mass of the physics imposter
     */
    get mass(): number;
    set mass(value: number);
    /**
     * Gets the coefficient of friction
     */
    get friction(): number;
    /**
     * Sets the coefficient of friction
     */
    set friction(value: number);
    /**
     * Gets the coefficient of restitution
     */
    get restitution(): number;
    /**
     * Sets the coefficient of restitution
     */
    set restitution(value: number);
    /**
     * Gets the pressure of a soft body; only supported by the AmmoJSPlugin
     */
    get pressure(): number;
    /**
     * Sets the pressure of a soft body; only supported by the AmmoJSPlugin
     */
    set pressure(value: number);
    /**
     * Gets the stiffness of a soft body; only supported by the AmmoJSPlugin
     */
    get stiffness(): number;
    /**
     * Sets the stiffness of a soft body; only supported by the AmmoJSPlugin
     */
    set stiffness(value: number);
    /**
     * Gets the velocityIterations of a soft body; only supported by the AmmoJSPlugin
     */
    get velocityIterations(): number;
    /**
     * Sets the velocityIterations of a soft body; only supported by the AmmoJSPlugin
     */
    set velocityIterations(value: number);
    /**
     * Gets the positionIterations of a soft body; only supported by the AmmoJSPlugin
     */
    get positionIterations(): number;
    /**
     * Sets the positionIterations of a soft body; only supported by the AmmoJSPlugin
     */
    set positionIterations(value: number);
    /**
     * The unique id of the physics imposter
     * set by the physics engine when adding this impostor to the array
     */
    uniqueId: number;
    /**
     * @internal
     */
    soft: boolean;
    /**
     * @internal
     */
    segments: number;
    private _joints;
    /**
     * Initializes the physics imposter
     * @param object The physics-enabled object used as the physics imposter
     * @param type The type of the physics imposter. Types are available as static members of this class.
     * @param _options The options for the physics imposter
     * @param _scene The Babylon scene
     */
    constructor(
    /**
     * The physics-enabled object used as the physics imposter
     */
    object: IPhysicsEnabledObject, 
    /**
     * The type of the physics imposter
     */
    type: number, _options?: PhysicsImpostorParameters, _scene?: Scene | undefined);
    /**
     * This function will completely initialize this impostor.
     * It will create a new body - but only if this mesh has no parent.
     * If it has, this impostor will not be used other than to define the impostor
     * of the child mesh.
     * @internal
     */
    _init(): void;
    private _getPhysicsParent;
    /**
     * Should a new body be generated.
     * @returns boolean specifying if body initialization is required
     */
    isBodyInitRequired(): boolean;
    /**
     * Sets the updated scaling
     */
    setScalingUpdated(): void;
    /**
     * Force a regeneration of this or the parent's impostor's body.
     * Use with caution - This will remove all previously-instantiated joints.
     */
    forceUpdate(): void;
    /**
     * Gets the body that holds this impostor. Either its own, or its parent.
     */
    get physicsBody(): any;
    /**
     * Get the parent of the physics imposter
     * @returns Physics imposter or null
     */
    get parent(): Nullable<PhysicsImpostor>;
    /**
     * Sets the parent of the physics imposter
     */
    set parent(value: Nullable<PhysicsImpostor>);
    /**
     * Set the physics body. Used mainly by the physics engine/plugin
     */
    set physicsBody(physicsBody: any);
    /**
     * Resets the update flags
     */
    resetUpdateFlags(): void;
    /**
     * Gets the object extents
     * @returns the object extents
     */
    getObjectExtents(): Vector3;
    /**
     * Gets the object center
     * @returns The object center
     */
    getObjectCenter(): Vector3;
    /**
     * Get a specific parameter from the options parameters
     * @param paramName The object parameter name
     * @returns The object parameter
     */
    getParam(paramName: string): any;
    /**
     * Sets a specific parameter in the options given to the physics plugin
     * @param paramName The parameter name
     * @param value The value of the parameter
     */
    setParam(paramName: string, value: number): void;
    /**
     * Specifically change the body's mass. Won't recreate the physics body object
     * @param mass The mass of the physics imposter
     */
    setMass(mass: number): void;
    /**
     * Gets the linear velocity
     * @returns  linear velocity or null
     */
    getLinearVelocity(): Nullable<Vector3>;
    /**
     * Sets the linear velocity
     * @param velocity  linear velocity or null
     */
    setLinearVelocity(velocity: Nullable<Vector3>): void;
    /**
     * Gets the angular velocity
     * @returns angular velocity or null
     */
    getAngularVelocity(): Nullable<Vector3>;
    /**
     * Sets the angular velocity
     * @param velocity The velocity or null
     */
    setAngularVelocity(velocity: Nullable<Vector3>): void;
    /**
     * Execute a function with the physics plugin native code
     * Provide a function the will have two variables - the world object and the physics body object
     * @param func The function to execute with the physics plugin native code
     */
    executeNativeFunction(func: (world: any, physicsBody: any) => void): void;
    /**
     * Register a function that will be executed before the physics world is stepping forward
     * @param func The function to execute before the physics world is stepped forward
     */
    registerBeforePhysicsStep(func: (impostor: PhysicsImpostor) => void): void;
    /**
     * Unregister a function that will be executed before the physics world is stepping forward
     * @param func The function to execute before the physics world is stepped forward
     */
    unregisterBeforePhysicsStep(func: (impostor: PhysicsImpostor) => void): void;
    /**
     * Register a function that will be executed after the physics step
     * @param func The function to execute after physics step
     */
    registerAfterPhysicsStep(func: (impostor: PhysicsImpostor) => void): void;
    /**
     * Unregisters a function that will be executed after the physics step
     * @param func The function to execute after physics step
     */
    unregisterAfterPhysicsStep(func: (impostor: PhysicsImpostor) => void): void;
    /**
     * register a function that will be executed when this impostor collides against a different body
     * @param collideAgainst Physics imposter, or array of physics imposters to collide against
     * @param func Callback that is executed on collision
     */
    registerOnPhysicsCollide(collideAgainst: PhysicsImpostor | Array<PhysicsImpostor>, func: (collider: PhysicsImpostor, collidedAgainst: PhysicsImpostor, point: Nullable<Vector3>) => void): void;
    /**
     * Unregisters the physics imposter's collision callback
     * @param collideAgainst The physics object to collide against
     * @param func Callback to execute on collision
     */
    unregisterOnPhysicsCollide(collideAgainst: PhysicsImpostor | Array<PhysicsImpostor>, func: (collider: PhysicsImpostor, collidedAgainst: PhysicsImpostor | Array<PhysicsImpostor>, point: Nullable<Vector3>) => void): void;
    private _tmpQuat;
    private _tmpQuat2;
    /**
     * Get the parent rotation
     * @returns The parent rotation
     */
    getParentsRotation(): Quaternion;
    /**
     * this function is executed by the physics engine.
     */
    beforeStep: () => void;
    /**
     * this function is executed by the physics engine
     */
    afterStep: () => void;
    /**
     * Legacy collision detection event support
     */
    onCollideEvent: Nullable<(collider: PhysicsImpostor, collidedWith: PhysicsImpostor) => void>;
    /**
     *  define an onCollide function to call when this impostor collides against a different body
     * @param e collide event data
     */
    onCollide: (e: {
        body: any;
        point: Nullable<Vector3>;
        distance: number;
        impulse: number;
        normal: Nullable<Vector3>;
    }) => void;
    /**
     * Apply a force
     * @param force The force to apply
     * @param contactPoint The contact point for the force
     * @returns The physics imposter
     */
    applyForce(force: Vector3, contactPoint: Vector3): PhysicsImpostor;
    /**
     * Apply an impulse
     * @param force The impulse force
     * @param contactPoint The contact point for the impulse force
     * @returns The physics imposter
     */
    applyImpulse(force: Vector3, contactPoint: Vector3): PhysicsImpostor;
    /**
     * A help function to create a joint
     * @param otherImpostor A physics imposter used to create a joint
     * @param jointType The type of joint
     * @param jointData The data for the joint
     * @returns The physics imposter
     */
    createJoint(otherImpostor: PhysicsImpostor, jointType: number, jointData: PhysicsJointData): PhysicsImpostor;
    /**
     * Add a joint to this impostor with a different impostor
     * @param otherImpostor A physics imposter used to add a joint
     * @param joint The joint to add
     * @returns The physics imposter
     */
    addJoint(otherImpostor: PhysicsImpostor, joint: PhysicsJoint): PhysicsImpostor;
    /**
     * Add an anchor to a cloth impostor
     * @param otherImpostor rigid impostor to anchor to
     * @param width ratio across width from 0 to 1
     * @param height ratio up height from 0 to 1
     * @param influence the elasticity between cloth impostor and anchor from 0, very stretchy to 1, little stretch
     * @param noCollisionBetweenLinkedBodies when true collisions between cloth impostor and anchor are ignored; default false
     * @returns impostor the soft imposter
     */
    addAnchor(otherImpostor: PhysicsImpostor, width: number, height: number, influence: number, noCollisionBetweenLinkedBodies: boolean): PhysicsImpostor;
    /**
     * Add a hook to a rope impostor
     * @param otherImpostor rigid impostor to anchor to
     * @param length ratio across rope from 0 to 1
     * @param influence the elasticity between rope impostor and anchor from 0, very stretchy to 1, little stretch
     * @param noCollisionBetweenLinkedBodies when true collisions between soft impostor and anchor are ignored; default false
     * @returns impostor the rope imposter
     */
    addHook(otherImpostor: PhysicsImpostor, length: number, influence: number, noCollisionBetweenLinkedBodies: boolean): PhysicsImpostor;
    /**
     * Will keep this body still, in a sleep mode.
     * @returns the physics imposter
     */
    sleep(): PhysicsImpostor;
    /**
     * Wake the body up.
     * @returns The physics imposter
     */
    wakeUp(): PhysicsImpostor;
    /**
     * Clones the physics imposter
     * @param newObject The physics imposter clones to this physics-enabled object
     * @returns A nullable physics imposter
     */
    clone(newObject: IPhysicsEnabledObject): Nullable<PhysicsImpostor>;
    /**
     * Disposes the physics imposter
     */
    dispose(): void;
    /**
     * Sets the delta position
     * @param position The delta position amount
     */
    setDeltaPosition(position: Vector3): void;
    /**
     * Sets the delta rotation
     * @param rotation The delta rotation amount
     */
    setDeltaRotation(rotation: Quaternion): void;
    /**
     * Gets the box size of the physics imposter and stores the result in the input parameter
     * @param result Stores the box size
     * @returns The physics imposter
     */
    getBoxSizeToRef(result: Vector3): PhysicsImpostor;
    /**
     * Gets the radius of the physics imposter
     * @returns Radius of the physics imposter
     */
    getRadius(): number;
    /**
     * Sync a bone with this impostor
     * @param bone The bone to sync to the impostor.
     * @param boneMesh The mesh that the bone is influencing.
     * @param jointPivot The pivot of the joint / bone in local space.
     * @param distToJoint Optional distance from the impostor to the joint.
     * @param adjustRotation Optional quaternion for adjusting the local rotation of the bone.
     */
    syncBoneWithImpostor(bone: Bone, boneMesh: AbstractMesh, jointPivot: Vector3, distToJoint?: number, adjustRotation?: Quaternion): void;
    /**
     * Sync impostor to a bone
     * @param bone The bone that the impostor will be synced to.
     * @param boneMesh The mesh that the bone is influencing.
     * @param jointPivot The pivot of the joint / bone in local space.
     * @param distToJoint Optional distance from the impostor to the joint.
     * @param adjustRotation Optional quaternion for adjusting the local rotation of the bone.
     * @param boneAxis Optional vector3 axis the bone is aligned with
     */
    syncImpostorWithBone(bone: Bone, boneMesh: AbstractMesh, jointPivot: Vector3, distToJoint?: number, adjustRotation?: Quaternion, boneAxis?: Vector3): void;
    /**
     * No-Imposter type
     */
    static NoImpostor: number;
    /**
     * Sphere-Imposter type
     */
    static SphereImpostor: number;
    /**
     * Box-Imposter type
     */
    static BoxImpostor: number;
    /**
     * Plane-Imposter type
     */
    static PlaneImpostor: number;
    /**
     * Mesh-imposter type (Only available to objects with vertices data)
     */
    static MeshImpostor: number;
    /**
     * Capsule-Impostor type (Ammo.js plugin only)
     */
    static CapsuleImpostor: number;
    /**
     * Cylinder-Imposter type
     */
    static CylinderImpostor: number;
    /**
     * Particle-Imposter type
     */
    static ParticleImpostor: number;
    /**
     * Heightmap-Imposter type
     */
    static HeightmapImpostor: number;
    /**
     * ConvexHull-Impostor type (Ammo.js plugin only)
     */
    static ConvexHullImpostor: number;
    /**
     * Custom-Imposter type (Ammo.js plugin only)
     */
    static CustomImpostor: number;
    /**
     * Rope-Imposter type
     */
    static RopeImpostor: number;
    /**
     * Cloth-Imposter type
     */
    static ClothImpostor: number;
    /**
     * Softbody-Imposter type
     */
    static SoftbodyImpostor: number;
}

/**
 * Line mesh
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/param
 */
declare class LinesMesh extends Mesh {
    /**
     * If vertex color should be applied to the mesh
     */
    readonly useVertexColor?: boolean | undefined;
    /**
     * If vertex alpha should be applied to the mesh
     */
    readonly useVertexAlpha?: boolean | undefined;
    /**
     * Force all the LineMeshes to compile their default color material to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * Color of the line (Default: White)
     */
    color: Color3;
    /**
     * Alpha of the line (Default: 1)
     */
    alpha: number;
    /**
     * The intersection Threshold is the margin applied when intersection a segment of the LinesMesh with a Ray.
     * This margin is expressed in world space coordinates, so its value may vary.
     * Default value is 0.1
     */
    intersectionThreshold: number;
    private _isShaderMaterial;
    private _color4;
    /** Shader language used by the material */
    protected _shaderLanguage: ShaderLanguage;
    private _ownsMaterial;
    /**
     * Creates a new LinesMesh
     * @param name defines the name
     * @param scene defines the hosting scene
     * @param parent defines the parent mesh if any
     * @param source defines the optional source LinesMesh used to clone data from
     * @param doNotCloneChildren When cloning, skip cloning child meshes of source, default False.
     * When false, achieved by calling a clone(), also passing False.
     * This will make creation of children, recursive.
     * @param useVertexColor defines if this LinesMesh supports vertex color
     * @param useVertexAlpha defines if this LinesMesh supports vertex alpha
     * @param material material to use to draw the line. If not provided, will create a new one
     */
    constructor(name: string, scene?: Nullable<Scene>, parent?: Nullable<Node>, source?: Nullable<LinesMesh>, doNotCloneChildren?: boolean, 
    /**
     * If vertex color should be applied to the mesh
     */
    useVertexColor?: boolean | undefined, 
    /**
     * If vertex alpha should be applied to the mesh
     */
    useVertexAlpha?: boolean | undefined, material?: Material);
    /**
     * @returns the string "LineMesh"
     */
    getClassName(): string;
    /**
     * @internal
     */
    get material(): Nullable<Material>;
    /**
     * @internal
     */
    set material(value: Nullable<Material>);
    private _setInternalMaterial;
    /**
     * @internal
     */
    get checkCollisions(): boolean;
    set checkCollisions(value: boolean);
    /**
     * @internal
     */
    _bind(_subMesh: SubMesh, colorEffect: Effect): Mesh;
    /**
     * @internal
     */
    _draw(subMesh: SubMesh, fillMode: number, instancesCount?: number): Mesh;
    /**
     * Disposes of the line mesh (this disposes of the automatically created material if not instructed otherwise).
     * @param doNotRecurse If children should be disposed
     * @param disposeMaterialAndTextures This parameter is used to force disposing the material in case it is not the default one
     * @param doNotDisposeMaterial If the material should not be disposed (default: false, meaning the material might be disposed)
     */
    dispose(doNotRecurse?: boolean, disposeMaterialAndTextures?: boolean, doNotDisposeMaterial?: boolean): void;
    /**
     * Returns a new LineMesh object cloned from the current one.
     * @param name defines the cloned mesh name
     * @param newParent defines the new mesh parent
     * @param doNotCloneChildren if set to true, none of the mesh children are cloned (false by default)
     * @returns the new mesh
     */
    clone(name: string, newParent?: Nullable<Node> | MeshCreationOptions, doNotCloneChildren?: boolean): LinesMesh;
    /**
     * Creates a new InstancedLinesMesh object from the mesh model.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/copies/instances
     * @param name defines the name of the new instance
     * @returns a new InstancedLinesMesh
     */
    createInstance(name: string): InstancedLinesMesh;
    /**
     * Serializes this ground mesh
     * @param serializationObject object to write serialization to
     */
    serialize(serializationObject: any): void;
    /**
     * Parses a serialized ground mesh
     * @param parsedMesh the serialized mesh
     * @param scene the scene to create the ground mesh in
     * @returns the created ground mesh
     */
    static Parse(parsedMesh: any, scene: Scene): LinesMesh;
}
/**
 * Creates an instance based on a source LinesMesh
 */
declare class InstancedLinesMesh extends InstancedMesh {
    /**
     * The intersection Threshold is the margin applied when intersection a segment of the LinesMesh with a Ray.
     * This margin is expressed in world space coordinates, so its value may vary.
     * Initialized with the intersectionThreshold value of the source LinesMesh
     */
    intersectionThreshold: number;
    constructor(name: string, source: LinesMesh);
    /**
     * @returns the string "InstancedLinesMesh".
     */
    getClassName(): string;
}

/**
 * @internal
 **/
declare class _CreationDataStorage {
    closePath?: boolean;
    closeArray?: boolean;
    idx: number[];
    dashSize: number;
    gapSize: number;
    path3D: Path3D;
    pathArray: Vector3[][];
    arc: number;
    radius: number;
    cap: number;
    tessellation: number;
}
/**
 * @internal
 **/
interface IInstanceDataStorageRenderPassVisibleInstances {
    defaultRenderId: number;
    selfDefaultRenderId: number;
    intermediateDefaultRenderId: number;
    [renderId: number]: Nullable<Array<InstancedMesh>>;
}
/**
 * @internal
 **/
declare class _InstanceDataStorageRenderPass {
    visibleInstances: Nullable<IInstanceDataStorageRenderPassVisibleInstances>;
    batchCache: _InstancesBatch;
    batchCacheReplacementModeInFrozenMode: _InstancesBatch;
    instancesBufferSize: number;
    instancesBuffer: Nullable<Buffer$1>;
    instancesPreviousBuffer: Nullable<Buffer$1>;
    instancesData: Float32Array;
    instancesPreviousData: Float32Array;
    previousBatch: Nullable<_InstancesBatch>;
    previousRenderId: number;
}
/**
 * @internal
 **/
declare class _InstanceDataStorage {
    renderPasses: {
        [id: number]: _InstanceDataStorageRenderPass;
    };
    overridenInstanceCount: number;
    isFrozen: boolean;
    forceMatrixUpdates: boolean;
    hardwareInstancedRendering: boolean;
    manualUpdate: boolean;
    previousManualUpdate: boolean;
    masterMeshPreviousWorldMatrix: Nullable<Matrix>;
    engine: AbstractEngine;
}
/**
 * @internal
 **/
declare class _InstancesBatch {
    parent: _InstanceDataStorageRenderPass;
    mustReturn: boolean;
    visibleInstances: Nullable<InstancedMesh[]>[];
    renderSelf: boolean[];
    hardwareInstancedRendering: boolean[];
    constructor(parent: _InstanceDataStorageRenderPass);
}
/**
 * @internal
 **/
declare class _ThinInstanceDataStorage {
    instancesCount: number;
    matrixBuffer: Nullable<Buffer$1>;
    previousMatrixBuffer: Nullable<Buffer$1>;
    matrixBufferSize: number;
    matrixData: Nullable<Float32Array>;
    previousMatrixData: Nullable<Float32Array>;
    boundingVectors: Array<Vector3>;
    worldMatrices: Nullable<Matrix[]>;
    masterMeshPreviousWorldMatrix: Nullable<Matrix>;
}
/**
 * Options used to clone a mesh
 */
interface MeshCloneOptions {
    /** The parent of the mesh, if it has one */
    parent?: Nullable<Node>;
    /** Skips cloning child meshes of source (default: false. When false, achieved by calling a clone(), also passing False. This will make creation of children, recursive. */
    doNotCloneChildren?: boolean;
    /** Includes cloning mesh physics impostor (default: true) */
    clonePhysicsImpostor?: boolean;
    /** Includes cloning thin instances (default: false) */
    cloneThinInstances?: boolean;
}
/**
 * Options used to create a mesh
 */
interface MeshCreationOptions extends MeshCloneOptions {
    /** An optional Mesh from which the new mesh will be cloned from (geometry will be shared) */
    source?: Nullable<Mesh>;
}
/**
 * Class used to represent renderable models
 */
declare class Mesh extends AbstractMesh implements IGetSetVerticesData {
    /**
     * Mesh side orientation : usually the external or front surface
     */
    static readonly FRONTSIDE = 0;
    /**
     * Mesh side orientation : usually the internal or back surface
     */
    static readonly BACKSIDE = 1;
    /**
     * Mesh side orientation : both internal and external or front and back surfaces
     */
    static readonly DOUBLESIDE = 2;
    /**
     * Mesh side orientation : by default, `FRONTSIDE`
     */
    static readonly DEFAULTSIDE = 0;
    /**
     * Mesh cap setting : no cap
     */
    static readonly NO_CAP = 0;
    /**
     * Mesh cap setting : one cap at the beginning of the mesh
     */
    static readonly CAP_START = 1;
    /**
     * Mesh cap setting : one cap at the end of the mesh
     */
    static readonly CAP_END = 2;
    /**
     * Mesh cap setting : two caps, one at the beginning  and one at the end of the mesh
     */
    static readonly CAP_ALL = 3;
    /**
     * Mesh pattern setting : no flip or rotate
     */
    static readonly NO_FLIP = 0;
    /**
     * Mesh pattern setting : flip (reflect in y axis) alternate tiles on each row or column
     */
    static readonly FLIP_TILE = 1;
    /**
     * Mesh pattern setting : rotate (180degs) alternate tiles on each row or column
     */
    static readonly ROTATE_TILE = 2;
    /**
     * Mesh pattern setting : flip (reflect in y axis) all tiles on alternate rows
     */
    static readonly FLIP_ROW = 3;
    /**
     * Mesh pattern setting : rotate (180degs) all tiles on alternate rows
     */
    static readonly ROTATE_ROW = 4;
    /**
     * Mesh pattern setting : flip and rotate alternate tiles on each row or column
     */
    static readonly FLIP_N_ROTATE_TILE = 5;
    /**
     * Mesh pattern setting : rotate pattern and rotate
     */
    static readonly FLIP_N_ROTATE_ROW = 6;
    /**
     * Mesh tile positioning : part tiles same on left/right or top/bottom
     */
    static readonly CENTER = 0;
    /**
     * Mesh tile positioning : part tiles on left
     */
    static readonly LEFT = 1;
    /**
     * Mesh tile positioning : part tiles on right
     */
    static readonly RIGHT = 2;
    /**
     * Mesh tile positioning : part tiles on top
     */
    static readonly TOP = 3;
    /**
     * Mesh tile positioning : part tiles on bottom
     */
    static readonly BOTTOM = 4;
    /**
     * Indicates that the instanced meshes should be sorted from back to front before rendering if their material is transparent
     */
    static INSTANCEDMESH_SORT_TRANSPARENT: boolean;
    /**
     * Gets the default side orientation.
     * @param orientation the orientation to value to attempt to get
     * @returns the default orientation
     * @internal
     */
    static _GetDefaultSideOrientation(orientation?: number): number;
    private _internalMeshDataInfo;
    /**
     * Determines if the LOD levels are intended to be calculated using screen coverage (surface area ratio) instead of distance.
     */
    get useLODScreenCoverage(): boolean;
    set useLODScreenCoverage(value: boolean);
    /**
     * Will notify when the mesh is completely ready, including materials.
     * Observers added to this observable will be removed once triggered
     */
    onMeshReadyObservable: Observable<Mesh>;
    get computeBonesUsingShaders(): boolean;
    set computeBonesUsingShaders(value: boolean);
    /**
     * An event triggered before rendering the mesh
     */
    get onBeforeRenderObservable(): Observable<Mesh>;
    /**
     * An event triggered before binding the mesh
     */
    get onBeforeBindObservable(): Observable<Mesh>;
    /**
     * An event triggered after rendering the mesh
     */
    get onAfterRenderObservable(): Observable<Mesh>;
    /**
     * An event triggeredbetween rendering pass when using separateCullingPass = true
     */
    get onBetweenPassObservable(): Observable<SubMesh>;
    /**
     * An event triggered before drawing the mesh
     */
    get onBeforeDrawObservable(): Observable<Mesh>;
    private _onBeforeDrawObserver;
    /**
     * Sets a callback to call before drawing the mesh. It is recommended to use onBeforeDrawObservable instead
     */
    set onBeforeDraw(callback: () => void);
    get hasInstances(): boolean;
    get hasThinInstances(): boolean;
    /**
     * Gets the delay loading state of the mesh (when delay loading is turned on)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/importers/incrementalLoading
     */
    delayLoadState: number;
    /**
     * Gets the list of instances created from this mesh
     * it is not supposed to be modified manually.
     * Note also that the order of the InstancedMesh wihin the array is not significant and might change.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/copies/instances
     */
    instances: InstancedMesh[];
    /**
     * Gets the file containing delay loading data for this mesh
     */
    delayLoadingFile: string;
    /** @internal */
    _binaryInfo: any;
    /**
     * User defined function used to change how LOD level selection is done
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/LOD
     */
    onLODLevelSelection: (distance: number, mesh: Mesh, selectedLevel: Nullable<Mesh>) => void;
    /** @internal */
    _creationDataStorage: Nullable<_CreationDataStorage>;
    /** @internal */
    _geometry: Nullable<Geometry>;
    /** @internal */
    _delayInfo: Array<string>;
    /** @internal */
    _delayLoadingFunction: (any: any, mesh: Mesh) => void;
    /**
     * Gets or sets the forced number of instances to display.
     * If 0 (default value), the number of instances is not forced and depends on the draw type
     * (regular / instance / thin instances mesh)
     */
    get forcedInstanceCount(): number;
    set forcedInstanceCount(count: number);
    /** @internal */
    _instanceDataStorage: _InstanceDataStorage;
    /** @internal */
    _thinInstanceDataStorage: _ThinInstanceDataStorage;
    /** @internal */
    _shouldGenerateFlatShading: boolean;
    /** @internal */
    _originalBuilderSideOrientation: number;
    /**
     * Use this property to change the original side orientation defined at construction time
     * Material.sideOrientation will override this value if set
     * User will still be able to change the material sideOrientation afterwards if they really need it
     */
    get sideOrientation(): number;
    set sideOrientation(value: number);
    /** @internal */
    get _effectiveSideOrientation(): number;
    /**
     * @deprecated Please use sideOrientation instead.
     * @see https://doc.babylonjs.com/breaking-changes#7110
     */
    get overrideMaterialSideOrientation(): number;
    set overrideMaterialSideOrientation(value: number);
    /**
     * Use this property to override the Material's fillMode value
     */
    get overrideRenderingFillMode(): Nullable<number>;
    set overrideRenderingFillMode(fillMode: Nullable<number>);
    get material(): Nullable<Material>;
    set material(value: Nullable<Material>);
    /**
     * Gets or sets a boolean indicating whether to render ignoring the active camera's max z setting. (false by default)
     * You should not mix meshes that have this property set to true with meshes that have it set to false if they all write
     * to the depth buffer, because the z-values are not comparable in the two cases and you will get rendering artifacts if you do.
     * You can set the property to true for meshes that do not write to the depth buffer, or set the same value (either false or true) otherwise.
     * Note this will reduce performance when set to true.
     */
    ignoreCameraMaxZ: boolean;
    /**
     * Gets the source mesh (the one used to clone this one from)
     */
    get source(): Nullable<Mesh>;
    /**
     * Gets the list of clones of this mesh
     * The scene must have been constructed with useClonedMeshMap=true for this to work!
     * Note that useClonedMeshMap=true is the default setting
     */
    get cloneMeshMap(): Nullable<{
        [id: string]: Mesh | undefined;
    }>;
    /**
     * Gets or sets a boolean indicating that this mesh does not use index buffer
     */
    get isUnIndexed(): boolean;
    set isUnIndexed(value: boolean);
    /** Gets the array buffer used to store the instanced buffer used for instances' world matrices */
    get worldMatrixInstancedBuffer(): Float32Array;
    /** Gets the array buffer used to store the instanced buffer used for instances' previous world matrices */
    get previousWorldMatrixInstancedBuffer(): Float32Array;
    /** Gets or sets a boolean indicating that the update of the instance buffer of the world matrices is manual */
    get manualUpdateOfWorldMatrixInstancedBuffer(): boolean;
    set manualUpdateOfWorldMatrixInstancedBuffer(value: boolean);
    /** Gets or sets a boolean indicating that the update of the instance buffer of the world matrices is manual */
    get manualUpdateOfPreviousWorldMatrixInstancedBuffer(): boolean;
    set manualUpdateOfPreviousWorldMatrixInstancedBuffer(value: boolean);
    /** Gets or sets a boolean indicating that the update of the instance buffer of the world matrices must be performed in all cases (and notably even in frozen mode) */
    get forceWorldMatrixInstancedBufferUpdate(): boolean;
    set forceWorldMatrixInstancedBufferUpdate(value: boolean);
    protected _copySource(source: Mesh, doNotCloneChildren?: boolean, clonePhysicsImpostor?: boolean, cloneThinInstances?: boolean): void;
    /**
     * Constructor
     * @param name The value used by scene.getMeshByName() to do a lookup.
     * @param scene The scene to add this mesh to.
     * @param options Options used to create the mesh
     */
    constructor(name: string, scene?: Nullable<Scene>, options?: MeshCreationOptions);
    /**
     * Constructor
     * @param name The value used by scene.getMeshByName() to do a lookup.
     * @param scene The scene to add this mesh to.
     * @param parent The parent of this mesh, if it has one
     * @param source An optional Mesh from which geometry is shared, cloned.
     * @param doNotCloneChildren When cloning, skip cloning child meshes of source, default False.
     *                  When false, achieved by calling a clone(), also passing False.
     *                  This will make creation of children, recursive.
     * @param clonePhysicsImpostor When cloning, include cloning mesh physics impostor, default True.
     */
    constructor(name: string, scene?: Nullable<Scene>, parent?: Nullable<Node>, source?: Nullable<Mesh>, doNotCloneChildren?: boolean, clonePhysicsImpostor?: boolean);
    instantiateHierarchy(newParent?: Nullable<TransformNode>, options?: {
        doNotInstantiate: boolean | ((node: TransformNode) => boolean);
    }, onNewNodeCreated?: (source: TransformNode, clone: TransformNode) => void): Nullable<TransformNode>;
    /**
     * Gets the class name
     * @returns the string "Mesh".
     */
    getClassName(): string;
    /** @internal */
    get _isMesh(): boolean;
    /**
     * Returns a description of this mesh
     * @param fullDetails define if full details about this mesh must be used
     * @returns a descriptive string representing this mesh
     */
    toString(fullDetails?: boolean): string;
    /** @internal */
    _unBindEffect(): void;
    /**
     * Gets a boolean indicating if this mesh has LOD
     */
    get hasLODLevels(): boolean;
    /**
     * Gets the list of MeshLODLevel associated with the current mesh
     * @returns an array of MeshLODLevel
     */
    getLODLevels(): MeshLODLevel[];
    private _sortLODLevels;
    /**
     * Add a mesh as LOD level triggered at the given distance.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/LOD
     * @param distanceOrScreenCoverage Either distance from the center of the object to show this level or the screen coverage if `useScreenCoverage` is set to `true`.
     * If screen coverage, value is a fraction of the screen's total surface, between 0 and 1.
     * Example Playground for distance https://playground.babylonjs.com/#QE7KM#197
     * Example Playground for screen coverage https://playground.babylonjs.com/#QE7KM#196
     * @param mesh The mesh to be added as LOD level (can be null)
     * @returns This mesh (for chaining)
     */
    addLODLevel(distanceOrScreenCoverage: number, mesh: Nullable<Mesh>): Mesh;
    /**
     * Returns the LOD level mesh at the passed distance or null if not found.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/LOD
     * @param distance The distance from the center of the object to show this level
     * @returns a Mesh or `null`
     */
    getLODLevelAtDistance(distance: number): Nullable<Mesh>;
    /**
     * Remove a mesh from the LOD array
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/LOD
     * @param mesh defines the mesh to be removed
     * @returns This mesh (for chaining)
     */
    removeLODLevel(mesh: Nullable<Mesh>): Mesh;
    /**
     * Returns the registered LOD mesh distant from the parameter `camera` position if any, else returns the current mesh.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/LOD
     * @param camera defines the camera to use to compute distance
     * @param boundingSphere defines a custom bounding sphere to use instead of the one from this mesh
     * @returns This mesh (for chaining)
     */
    getLOD(camera: Camera, boundingSphere?: BoundingSphere): Nullable<AbstractMesh>;
    /**
     * Gets the mesh internal Geometry object
     */
    get geometry(): Nullable<Geometry>;
    /**
     * Returns the total number of vertices within the mesh geometry or zero if the mesh has no geometry.
     * @returns the total number of vertices
     */
    getTotalVertices(): number;
    /**
     * Returns the content of an associated vertex buffer
     * @param kind defines which buffer to read from (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @param copyWhenShared defines a boolean indicating that if the mesh geometry is shared among some other meshes, the returned array is a copy of the internal one
     * @param forceCopy defines a boolean forcing the copy of the buffer no matter what the value of copyWhenShared is
     * @param bypassInstanceData defines a boolean indicating that the function should not take into account the instance data (applies only if the mesh has instances). Default: false
     * @returns a FloatArray or null if the mesh has no geometry or no vertex buffer for this kind.
     */
    getVerticesData(kind: string, copyWhenShared?: boolean, forceCopy?: boolean, bypassInstanceData?: boolean): Nullable<FloatArray>;
    copyVerticesData(kind: string, vertexData: {
        [kind: string]: Float32Array;
    }): void;
    getVertexBuffer(kind: string, bypassInstanceData?: boolean): Nullable<VertexBuffer>;
    /**
     * Tests if a specific vertex buffer is associated with this mesh
     * @param kind defines which buffer to check (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.NormalKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @param bypassInstanceData defines a boolean indicating that the function should not take into account the instance data (applies only if the mesh has instances). Default: false
     * @returns a boolean
     */
    isVerticesDataPresent(kind: string, bypassInstanceData?: boolean): boolean;
    /**
     * Returns a boolean defining if the vertex data for the requested `kind` is updatable.
     * @param kind defines which buffer to check (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @param bypassInstanceData defines a boolean indicating that the function should not take into account the instance data (applies only if the mesh has instances). Default: false
     * @returns a boolean
     */
    isVertexBufferUpdatable(kind: string, bypassInstanceData?: boolean): boolean;
    /**
     * Returns a string which contains the list of existing `kinds` of Vertex Data associated with this mesh.
     * @param bypassInstanceData defines a boolean indicating that the function should not take into account the instance data (applies only if the mesh has instances). Default: false
     * @returns an array of strings
     */
    getVerticesDataKinds(bypassInstanceData?: boolean): string[];
    /**
     * Returns a positive integer : the total number of indices in this mesh geometry.
     * @returns the number of indices or zero if the mesh has no geometry.
     */
    getTotalIndices(): number;
    /**
     * Returns an array of integers or a typed array (Int32Array, Uint32Array, Uint16Array) populated with the mesh indices.
     * @param copyWhenShared If true (default false) and and if the mesh geometry is shared among some other meshes, the returned array is a copy of the internal one.
     * @param forceCopy defines a boolean indicating that the returned array must be cloned upon returning it
     * @returns the indices array or an empty array if the mesh has no geometry
     */
    getIndices(copyWhenShared?: boolean, forceCopy?: boolean): Nullable<IndicesArray>;
    get isBlocked(): boolean;
    /**
     * Determine if the current mesh is ready to be rendered
     * @param completeCheck defines if a complete check (including materials and lights) has to be done (false by default)
     * @param forceInstanceSupport will check if the mesh will be ready when used with instances (false by default)
     * @returns true if all associated assets are ready (material, textures, shaders)
     */
    isReady(completeCheck?: boolean, forceInstanceSupport?: boolean): boolean;
    /**
     * Gets a boolean indicating if the normals aren't to be recomputed on next mesh `positions` array update. This property is pertinent only for updatable parametric shapes.
     */
    get areNormalsFrozen(): boolean;
    /**
     * This function affects parametric shapes on vertex position update only : ribbons, tubes, etc. It has no effect at all on other shapes. It prevents the mesh normals from being recomputed on next `positions` array update.
     * @returns the current mesh
     */
    freezeNormals(): Mesh;
    /**
     * This function affects parametric shapes on vertex position update only : ribbons, tubes, etc. It has no effect at all on other shapes. It reactivates the mesh normals computation if it was previously frozen
     * @returns the current mesh
     */
    unfreezeNormals(): Mesh;
    /**
     * Sets a value overriding the instance count. Only applicable when custom instanced InterleavedVertexBuffer are used rather than InstancedMeshs
     */
    set overridenInstanceCount(count: number);
    /** @internal */
    _getInstanceDataStorage(): _InstanceDataStorageRenderPass;
    /** @internal */
    _preActivate(): Mesh;
    /**
     * @internal
     */
    _preActivateForIntermediateRendering(renderId: number): Mesh;
    /**
     * @internal
     */
    _registerInstanceForRenderId(instance: InstancedMesh, renderId: number): Mesh;
    protected _afterComputeWorldMatrix(): void;
    /** @internal */
    _postActivate(): void;
    /**
     * This method recomputes and sets a new BoundingInfo to the mesh unless it is locked.
     * This means the mesh underlying bounding box and sphere are recomputed.
     * @param applySkeletonOrOptions defines whether to apply the skeleton before computing the bounding info or a set of options
     * @param applyMorph defines whether to apply the morph target before computing the bounding info
     * @returns the current mesh
     */
    refreshBoundingInfo(applySkeletonOrOptions?: boolean | IMeshDataOptions, applyMorph?: boolean): Mesh;
    /**
     * @internal
     */
    _createGlobalSubMesh(force: boolean): Nullable<SubMesh>;
    /**
     * This function will subdivide the mesh into multiple submeshes
     * @param count defines the expected number of submeshes
     */
    subdivide(count: number): void;
    /**
     * Copy a FloatArray into a specific associated vertex buffer
     * @param kind defines which buffer to write to (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @param data defines the data source
     * @param updatable defines if the updated vertex buffer must be flagged as updatable
     * @param stride defines the data stride size (can be null)
     * @returns the current mesh
     */
    setVerticesData(kind: string, data: FloatArray, updatable?: boolean, stride?: number): AbstractMesh;
    /**
     * Delete a vertex buffer associated with this mesh
     * @param kind defines which buffer to delete (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     */
    removeVerticesData(kind: string): void;
    /**
     * Flags an associated vertex buffer as updatable
     * @param kind defines which buffer to use (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @param updatable defines if the updated vertex buffer must be flagged as updatable
     */
    markVerticesDataAsUpdatable(kind: string, updatable?: boolean): void;
    /**
     * Sets the mesh global Vertex Buffer
     * @param buffer defines the buffer to use
     * @param disposeExistingBuffer disposes the existing buffer, if any (default: true)
     * @param totalVertices defines the total number of vertices for position kind (could be null)
     * @returns the current mesh
     */
    setVerticesBuffer(buffer: VertexBuffer, disposeExistingBuffer?: boolean, totalVertices?: Nullable<number>): Mesh;
    /**
     * Update a specific associated vertex buffer
     * @param kind defines which buffer to write to (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @param data defines the data source
     * @param updateExtends defines if extends info of the mesh must be updated (can be null). This is mostly useful for "position" kind
     * @param makeItUnique defines if the geometry associated with the mesh must be cloned to make the change only for this mesh (and not all meshes associated with the same geometry)
     * @returns the current mesh
     */
    updateVerticesData(kind: string, data: FloatArray, updateExtends?: boolean, makeItUnique?: boolean): AbstractMesh;
    /**
     * This method updates the vertex positions of an updatable mesh according to the `positionFunction` returned values.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/dynamicMeshMorph#other-shapes-updatemeshpositions
     * @param positionFunction is a simple JS function what is passed the mesh `positions` array. It doesn't need to return anything
     * @param computeNormals is a boolean (default true) to enable/disable the mesh normal recomputation after the vertex position update
     * @returns the current mesh
     */
    updateMeshPositions(positionFunction: (data: FloatArray) => void, computeNormals?: boolean): Mesh;
    /**
     * Creates a un-shared specific occurence of the geometry for the mesh.
     * @returns the current mesh
     */
    makeGeometryUnique(): Mesh;
    /**
     * Sets the index buffer of this mesh.
     * @param indexBuffer Defines the index buffer to use for this mesh
     * @param totalVertices Defines the total number of vertices used by the buffer
     * @param totalIndices Defines the total number of indices in the index buffer
     * @param is32Bits Defines if the indices are 32 bits. If null (default), the value is guessed from the number of vertices
     */
    setIndexBuffer(indexBuffer: DataBuffer, totalVertices: number, totalIndices: number, is32Bits?: Nullable<boolean>): void;
    /**
     * Set the index buffer of this mesh
     * @param indices defines the source data
     * @param totalVertices defines the total number of vertices referenced by this index data (can be null)
     * @param updatable defines if the updated index buffer must be flagged as updatable (default is false)
     * @param dontForceSubMeshRecreation defines a boolean indicating that we don't want to force the recreation of sub-meshes if we don't have to (false by default)
     * @returns the current mesh
     */
    setIndices(indices: IndicesArray, totalVertices?: Nullable<number>, updatable?: boolean, dontForceSubMeshRecreation?: boolean): AbstractMesh;
    /**
     * Update the current index buffer
     * @param indices defines the source data
     * @param offset defines the offset in the index buffer where to store the new data (can be null)
     * @param gpuMemoryOnly defines a boolean indicating that only the GPU memory must be updated leaving the CPU version of the indices unchanged (false by default)
     * @returns the current mesh
     */
    updateIndices(indices: IndicesArray, offset?: number, gpuMemoryOnly?: boolean): AbstractMesh;
    /**
     * Invert the geometry to move from a right handed system to a left handed one.
     * @returns the current mesh
     */
    toLeftHanded(): Mesh;
    /**
     * @internal
     */
    _bind(subMesh: SubMesh, effect: Effect, fillMode: number, allowInstancedRendering?: boolean): Mesh;
    /**
     * @internal
     */
    _bindDirect(effect: Effect, indexToBind: Nullable<DataBuffer>, allowInstancedRendering?: boolean): Mesh;
    /**
     * @internal
     */
    _draw(subMesh: SubMesh, fillMode: number, instancesCount?: number): Mesh;
    /**
     * Registers for this mesh a javascript function called just before the rendering process
     * @param func defines the function to call before rendering this mesh
     * @returns the current mesh
     */
    registerBeforeRender(func: (mesh: AbstractMesh) => void): Mesh;
    /**
     * Disposes a previously registered javascript function called before the rendering
     * @param func defines the function to remove
     * @returns the current mesh
     */
    unregisterBeforeRender(func: (mesh: AbstractMesh) => void): Mesh;
    /**
     * Registers for this mesh a javascript function called just after the rendering is complete
     * @param func defines the function to call after rendering this mesh
     * @returns the current mesh
     */
    registerAfterRender(func: (mesh: AbstractMesh) => void): Mesh;
    /**
     * Disposes a previously registered javascript function called after the rendering.
     * @param func defines the function to remove
     * @returns the current mesh
     */
    unregisterAfterRender(func: (mesh: AbstractMesh) => void): Mesh;
    /**
     * @internal
     */
    _getInstancesRenderList(subMeshId: number, isReplacementMode?: boolean): _InstancesBatch;
    /**
     * This method will also draw the instances if fillMode and effect are passed
     * @internal
     */
    _updateInstancedBuffers(subMesh: SubMesh, batch: _InstancesBatch, currentInstancesBufferSize: number, engine: AbstractEngine, fillMode?: number, effect?: Effect): void;
    /**
     * @internal
     */
    _renderWithInstances(subMesh: SubMesh, fillMode: number, batch: _InstancesBatch, effect: Effect, engine: AbstractEngine): Mesh;
    /**
     * @internal
     */
    _renderWithThinInstances(subMesh: SubMesh, fillMode: number, effect: Effect, engine: AbstractEngine): void;
    /**
     * @internal
     */
    _processInstancedBuffers(visibleInstances: Nullable<InstancedMesh[]>, renderSelf: boolean): void;
    /**
     * @internal
     */
    _processRendering(renderingMesh: AbstractMesh, subMesh: SubMesh, effect: Effect, fillMode: number, batch: _InstancesBatch, hardwareInstancedRendering: boolean, onBeforeDraw: (isInstance: boolean, world: Matrix, effectiveMaterial?: Material) => void, effectiveMaterial?: Material): Mesh;
    /**
     * @internal
     */
    _rebuild(dispose?: boolean): void;
    /** @internal */
    _freeze(): void;
    /** @internal */
    _unFreeze(): void;
    /**
     * Triggers the draw call for the mesh (or a submesh), for a specific render pass id
     * @param renderPassId defines the render pass id to use to draw the mesh / submesh. If not provided, use the current renderPassId of the engine.
     * @param enableAlphaMode defines if alpha mode can be changed (default: false)
     * @param effectiveMeshReplacement defines an optional mesh used to provide info for the rendering (default: undefined)
     * @param subMesh defines the subMesh to render. If not provided, draw all mesh submeshes (default: undefined)
     * @param checkFrustumCulling defines if frustum culling must be checked (default: true). If you know the mesh is in the frustum (or if you don't care!), you can pass false to optimize.
     * @returns the current mesh
     */
    renderWithRenderPassId(renderPassId?: number, enableAlphaMode?: boolean, effectiveMeshReplacement?: AbstractMesh, subMesh?: SubMesh, checkFrustumCulling?: boolean): this;
    /**
     * Render a complete mesh by going through all submeshes
     * @returns the current mesh
     * @see [simple test](https://playground.babylonjs.com/#5SPY1V#2)
     * @see [perf test](https://playground.babylonjs.com/#5SPY1V#5)
     */
    directRender(): Mesh;
    /**
     * Triggers the draw call for the mesh. Usually, you don't need to call this method by your own because the mesh rendering is handled by the scene rendering manager
     * @param subMesh defines the subMesh to render
     * @param enableAlphaMode defines if alpha mode can be changed
     * @param effectiveMeshReplacement defines an optional mesh used to provide info for the rendering
     * @returns the current mesh
     */
    render(subMesh: SubMesh, enableAlphaMode: boolean, effectiveMeshReplacement?: AbstractMesh): Mesh;
    private _onBeforeDraw;
    /**
     *   Renormalize the mesh and patch it up if there are no weights
     *   Similar to normalization by adding the weights compute the reciprocal and multiply all elements, this wil ensure that everything adds to 1.
     *   However in the case of zero weights then we set just a single influence to 1.
     *   We check in the function for extra's present and if so we use the normalizeSkinWeightsWithExtras rather than the FourWeights version.
     */
    cleanMatrixWeights(): void;
    private _normalizeSkinFourWeights;
    private _normalizeSkinWeightsAndExtra;
    /**
     * ValidateSkinning is used to determine that a mesh has valid skinning data along with skin metrics, if missing weights,
     * or not normalized it is returned as invalid mesh the string can be used for console logs, or on screen messages to let
     * the user know there was an issue with importing the mesh
     * @returns a validation object with skinned, valid and report string
     */
    validateSkinning(): {
        skinned: boolean;
        valid: boolean;
        report: string;
    };
    /** @internal */
    _checkDelayState(): Mesh;
    private _queueLoad;
    /**
     * Returns `true` if the mesh is within the frustum defined by the passed array of planes.
     * A mesh is in the frustum if its bounding box intersects the frustum
     * @param frustumPlanes defines the frustum to test
     * @returns true if the mesh is in the frustum planes
     */
    isInFrustum(frustumPlanes: Plane[]): boolean;
    /**
     * Sets the mesh material by the material or multiMaterial `id` property
     * @param id is a string identifying the material or the multiMaterial
     * @returns the current mesh
     */
    setMaterialById(id: string): Mesh;
    /**
     * Returns as a new array populated with the mesh material and/or skeleton, if any.
     * @returns an array of IAnimatable
     */
    getAnimatables(): IAnimatable[];
    /**
     * Modifies the mesh geometry according to the passed transformation matrix.
     * This method returns nothing, but it really modifies the mesh even if it's originally not set as updatable.
     * The mesh normals are modified using the same transformation.
     * Note that, under the hood, this method sets a new VertexBuffer each call.
     * @param transform defines the transform matrix to use
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/center_origin/bakingTransforms
     * @returns the current mesh
     */
    bakeTransformIntoVertices(transform: DeepImmutable<Matrix>): Mesh;
    /**
     * Modifies the mesh geometry according to its own current World Matrix.
     * The mesh World Matrix is then reset.
     * This method returns nothing but really modifies the mesh even if it's originally not set as updatable.
     * Note that, under the hood, this method sets a new VertexBuffer each call.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/center_origin/bakingTransforms
     * @param bakeIndependentlyOfChildren indicates whether to preserve all child nodes' World Matrix during baking
     * @param forceUnique indicates whether to force the mesh geometry to be unique
     * @returns the current mesh
     */
    bakeCurrentTransformIntoVertices(bakeIndependentlyOfChildren?: boolean, forceUnique?: boolean): Mesh;
    /** @internal */
    get _positions(): Nullable<Vector3[]>;
    /** @internal */
    _resetPointsArrayCache(): Mesh;
    /** @internal */
    _generatePointsArray(): boolean;
    /**
     * Returns a new Mesh object generated from the current mesh properties.
     * This method must not get confused with createInstance()
     * @param name is a string, the name given to the new mesh
     * @param newParent can be any Node object (default `null`) or an instance of MeshCloneOptions. If the latter, doNotCloneChildren and clonePhysicsImpostor are unused.
     * @param doNotCloneChildren allows/denies the recursive cloning of the original mesh children if any (default `false`)
     * @param clonePhysicsImpostor allows/denies the cloning in the same time of the original mesh `body` used by the physics engine, if any (default `true`)
     * @returns a new mesh
     */
    clone(name?: string, newParent?: Nullable<Node> | MeshCloneOptions, doNotCloneChildren?: boolean, clonePhysicsImpostor?: boolean): Mesh;
    /**
     * Releases resources associated with this mesh.
     * @param doNotRecurse Set to true to not recurse into each children (recurse into each children by default)
     * @param disposeMaterialAndTextures Set to true to also dispose referenced materials and textures (false by default)
     */
    dispose(doNotRecurse?: boolean, disposeMaterialAndTextures?: boolean): void;
    /** @internal */
    _disposeInstanceSpecificData(): void;
    /** @internal */
    _disposeThinInstanceSpecificData(): void;
    /**
     * Modifies the mesh geometry according to a displacement map.
     * A displacement map is a colored image. Each pixel color value (actually a gradient computed from red, green, blue values) will give the displacement to apply to each mesh vertex.
     * The mesh must be set as updatable. Its internal geometry is directly modified, no new buffer are allocated.
     * @param url is a string, the URL from the image file is to be downloaded.
     * @param minHeight is the lower limit of the displacement.
     * @param maxHeight is the upper limit of the displacement.
     * @param onSuccess is an optional Javascript function to be called just after the mesh is modified. It is passed the modified mesh and must return nothing.
     * @param uvOffset is an optional vector2 used to offset UV.
     * @param uvScale is an optional vector2 used to scale UV.
     * @param forceUpdate defines whether or not to force an update of the generated buffers. This is useful to apply on a deserialized model for instance.
     * @param onError defines a callback called when an error occurs during the processing of the request.
     * @returns the Mesh.
     */
    applyDisplacementMap(url: string, minHeight: number, maxHeight: number, onSuccess?: (mesh: Mesh) => void, uvOffset?: Vector2, uvScale?: Vector2, forceUpdate?: boolean, onError?: (message?: string, exception?: any) => void): Mesh;
    /**
     * Modifies the mesh geometry according to a displacementMap buffer.
     * A displacement map is a colored image. Each pixel color value (actually a gradient computed from red, green, blue values) will give the displacement to apply to each mesh vertex.
     * The mesh must be set as updatable. Its internal geometry is directly modified, no new buffer are allocated.
     * @param buffer is a `Uint8Array` buffer containing series of `Uint8` lower than 255, the red, green, blue and alpha values of each successive pixel.
     * @param heightMapWidth is the width of the buffer image.
     * @param heightMapHeight is the height of the buffer image.
     * @param minHeight is the lower limit of the displacement.
     * @param maxHeight is the upper limit of the displacement.
     * @param uvOffset is an optional vector2 used to offset UV.
     * @param uvScale is an optional vector2 used to scale UV.
     * @param forceUpdate defines whether or not to force an update of the generated buffers. This is useful to apply on a deserialized model for instance.
     * @returns the Mesh.
     */
    applyDisplacementMapFromBuffer(buffer: Uint8Array, heightMapWidth: number, heightMapHeight: number, minHeight: number, maxHeight: number, uvOffset?: Vector2, uvScale?: Vector2, forceUpdate?: boolean): Mesh;
    private _getFlattenedNormals;
    private _convertToUnIndexedMesh;
    /**
     * Modify the mesh to get a flat shading rendering.
     * This means each mesh facet will then have its own normals. Usually new vertices are added in the mesh geometry to get this result.
     * Warning : the mesh is really modified even if not set originally as updatable and, under the hood, a new VertexBuffer is allocated.
     * @returns current mesh
     */
    convertToFlatShadedMesh(): Mesh;
    /**
     * This method removes all the mesh indices and add new vertices (duplication) in order to unfold facets into buffers.
     * In other words, more vertices, no more indices and a single bigger VBO.
     * The mesh is really modified even if not set originally as updatable. Under the hood, a new VertexBuffer is allocated.
     * @returns current mesh
     */
    convertToUnIndexedMesh(): Mesh;
    /**
     * Inverses facet orientations.
     * Warning : the mesh is really modified even if not set originally as updatable. A new VertexBuffer is created under the hood each call.
     * @param flipNormals will also inverts the normals
     * @returns current mesh
     */
    flipFaces(flipNormals?: boolean): Mesh;
    /**
     * Increase the number of facets and hence vertices in a mesh
     * Vertex normals are interpolated from existing vertex normals
     * Warning : the mesh is really modified even if not set originally as updatable. A new VertexBuffer is created under the hood each call.
     * @param numberPerEdge the number of new vertices to add to each edge of a facet, optional default 1
     */
    increaseVertices(numberPerEdge?: number): void;
    /**
     * Force adjacent facets to share vertices and remove any facets that have all vertices in a line
     * This will undo any application of covertToFlatShadedMesh
     * Warning : the mesh is really modified even if not set originally as updatable. A new VertexBuffer is created under the hood each call.
     */
    forceSharedVertices(): void;
    /**
     * @internal
     */
    static _instancedMeshFactory(name: string, mesh: Mesh): InstancedMesh;
    /**
     * @internal
     */
    static _PhysicsImpostorParser(scene: Scene, physicObject: IPhysicsEnabledObject, jsonObject: any): PhysicsImpostor;
    /**
     * Creates a new InstancedMesh object from the mesh model.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/copies/instances
     * @param name defines the name of the new instance
     * @returns a new InstancedMesh
     */
    createInstance(name: string): InstancedMesh;
    /**
     * Synchronises all the mesh instance submeshes to the current mesh submeshes, if any.
     * After this call, all the mesh instances have the same submeshes than the current mesh.
     * @returns the current mesh
     */
    synchronizeInstances(): Mesh;
    /**
     * Optimization of the mesh's indices, in case a mesh has duplicated vertices.
     * The function will only reorder the indices and will not remove unused vertices to avoid problems with submeshes.
     * This should be used together with the simplification to avoid disappearing triangles.
     * @param successCallback an optional success callback to be called after the optimization finished.
     * @returns the current mesh
     */
    optimizeIndices(successCallback?: (mesh?: Mesh) => void): Mesh;
    /**
     * Serialize current mesh
     * @param serializationObject defines the object which will receive the serialization data
     * @returns the serialized object
     */
    serialize(serializationObject?: any): any;
    /** @internal */
    _syncGeometryWithMorphTargetManager(): void;
    /**
     * @internal
     */
    static _GroundMeshParser: (parsedMesh: any, scene: Scene) => Mesh;
    /**
     * @internal
     */
    static _GoldbergMeshParser: (parsedMesh: any, scene: Scene) => GoldbergMesh;
    /**
     * @internal
     */
    static _LinesMeshParser: (parsedMesh: any, scene: Scene) => Mesh;
    /**
     * @internal
     */
    static _GreasedLineMeshParser: (parsedMesh: any, scene: Scene) => Mesh;
    /**
     * @internal
     */
    static _GreasedLineRibbonMeshParser: (parsedMesh: any, scene: Scene) => Mesh;
    /**
     * @internal
     */
    static _TrailMeshParser: (parsedMesh: any, scene: Scene) => Mesh;
    /**
     * Returns a new Mesh object parsed from the source provided.
     * @param parsedMesh is the source
     * @param scene defines the hosting scene
     * @param rootUrl is the root URL to prefix the `delayLoadingFile` property with
     * @returns a new Mesh
     */
    static Parse(parsedMesh: any, scene: Scene, rootUrl: string): Mesh;
    /**
     * Prepare internal position array for software CPU skinning
     * @returns original positions used for CPU skinning. Useful for integrating Morphing with skeletons in same mesh
     */
    setPositionsForCPUSkinning(): Nullable<Float32Array>;
    /**
     * Prepare internal normal array for software CPU skinning
     * @returns original normals used for CPU skinning. Useful for integrating Morphing with skeletons in same mesh.
     */
    setNormalsForCPUSkinning(): Nullable<Float32Array>;
    /**
     * Updates the vertex buffer by applying transformation from the bones
     * @param skeleton defines the skeleton to apply to current mesh
     * @returns the current mesh
     */
    applySkeleton(skeleton: Skeleton): Mesh;
    /**
     * Returns an object containing a min and max Vector3 which are the minimum and maximum vectors of each mesh bounding box from the passed array, in the world coordinates
     * @param meshes defines the list of meshes to scan
     * @returns an object `{min:` Vector3`, max:` Vector3`}`
     */
    static MinMax(meshes: AbstractMesh[]): {
        min: Vector3;
        max: Vector3;
    };
    /**
     * Returns the center of the `{min:` Vector3`, max:` Vector3`}` or the center of MinMax vector3 computed from a mesh array
     * @param meshesOrMinMaxVector could be an array of meshes or a `{min:` Vector3`, max:` Vector3`}` object
     * @returns a vector3
     */
    static Center(meshesOrMinMaxVector: {
        min: Vector3;
        max: Vector3;
    } | AbstractMesh[]): Vector3;
    /**
     * Merge the array of meshes into a single mesh for performance reasons.
     * @param meshes array of meshes with the vertices to merge. Entries cannot be empty meshes.
     * @param disposeSource when true (default), dispose of the vertices from the source meshes.
     * @param allow32BitsIndices when the sum of the vertices > 64k, this must be set to true.
     * @param meshSubclass (optional) can be set to a Mesh where the merged vertices will be inserted.
     * @param subdivideWithSubMeshes when true (false default), subdivide mesh into subMeshes.
     * @param multiMultiMaterials when true (false default), subdivide mesh into subMeshes with multiple materials, ignores subdivideWithSubMeshes.
     * @returns a new mesh
     */
    static MergeMeshes(meshes: Array<Mesh>, disposeSource?: boolean, allow32BitsIndices?: boolean, meshSubclass?: Mesh, subdivideWithSubMeshes?: boolean, multiMultiMaterials?: boolean): Nullable<Mesh>;
    /**
     * Merge the array of meshes into a single mesh for performance reasons.
     * @param meshes array of meshes with the vertices to merge. Entries cannot be empty meshes.
     * @param disposeSource when true (default), dispose of the vertices from the source meshes.
     * @param allow32BitsIndices when the sum of the vertices > 64k, this must be set to true.
     * @param meshSubclass (optional) can be set to a Mesh where the merged vertices will be inserted.
     * @param subdivideWithSubMeshes when true (false default), subdivide mesh into subMeshes.
     * @param multiMultiMaterials when true (false default), subdivide mesh into subMeshes with multiple materials, ignores subdivideWithSubMeshes.
     * @returns a new mesh
     */
    static MergeMeshesAsync(meshes: Array<Mesh>, disposeSource?: boolean, allow32BitsIndices?: boolean, meshSubclass?: Mesh, subdivideWithSubMeshes?: boolean, multiMultiMaterials?: boolean): Promise<any>;
    private static _MergeMeshesCoroutine;
    /**
     * @internal
     */
    addInstance(instance: InstancedMesh): void;
    /**
     * @internal
     */
    removeInstance(instance: InstancedMesh): void;
    /** @internal */
    _shouldConvertRHS(): boolean;
    /** @internal */
    _getRenderingFillMode(fillMode: number): number;
    /**
     * Sets the mesh material by the material or multiMaterial `id` property
     * @param id is a string identifying the material or the multiMaterial
     * @returns the current mesh
     * @deprecated Please use MeshBuilder instead Please use setMaterialById instead
     */
    setMaterialByID(id: string): Mesh;
    /**
     * Creates a ribbon mesh.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/param
     * @param name defines the name of the mesh to create
     * @param pathArray is a required array of paths, what are each an array of successive Vector3. The pathArray parameter depicts the ribbon geometry.
     * @param closeArray creates a seam between the first and the last paths of the path array (default is false)
     * @param closePath creates a seam between the first and the last points of each path of the path array
     * @param offset is taken in account only if the `pathArray` is containing a single path
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @param instance defines an instance of an existing Ribbon object to be updated with the passed `pathArray` parameter (https://doc.babylonjs.com/how_to/How_to_dynamically_morph_a_mesh#ribbon)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateRibbon(name: string, pathArray: Vector3[][], closeArray: boolean, closePath: boolean, offset: number, scene?: Scene, updatable?: boolean, sideOrientation?: number, instance?: Mesh): Mesh;
    /**
     * Creates a plane polygonal mesh.  By default, this is a disc.
     * @param name defines the name of the mesh to create
     * @param radius sets the radius size (float) of the polygon (default 0.5)
     * @param tessellation sets the number of polygon sides (positive integer, default 64). So a tessellation valued to 3 will build a triangle, to 4 a square, etc
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateDisc(name: string, radius: number, tessellation: number, scene: Nullable<Scene>, updatable?: boolean, sideOrientation?: number): Mesh;
    /**
     * Creates a box mesh.
     * @param name defines the name of the mesh to create
     * @param size sets the size (float) of each box side (default 1)
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateBox(name: string, size: number, scene: Nullable<Scene>, updatable?: boolean, sideOrientation?: number): Mesh;
    /**
     * Creates a sphere mesh.
     * @param name defines the name of the mesh to create
     * @param segments sets the sphere number of horizontal stripes (positive integer, default 32)
     * @param diameter sets the diameter size (float) of the sphere (default 1)
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateSphere(name: string, segments: number, diameter: number, scene?: Scene, updatable?: boolean, sideOrientation?: number): Mesh;
    /**
     * Creates a hemisphere mesh.
     * @param name defines the name of the mesh to create
     * @param segments sets the sphere number of horizontal stripes (positive integer, default 32)
     * @param diameter sets the diameter size (float) of the sphere (default 1)
     * @param scene defines the hosting scene
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateHemisphere(name: string, segments: number, diameter: number, scene?: Scene): Mesh;
    /**
     * Creates a cylinder or a cone mesh.
     * @param name defines the name of the mesh to create
     * @param height sets the height size (float) of the cylinder/cone (float, default 2)
     * @param diameterTop set the top cap diameter (floats, default 1)
     * @param diameterBottom set the bottom cap diameter (floats, default 1). This value can't be zero
     * @param tessellation sets the number of cylinder sides (positive integer, default 24). Set it to 3 to get a prism for instance
     * @param subdivisions sets the number of rings along the cylinder height (positive integer, default 1)
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateCylinder(name: string, height: number, diameterTop: number, diameterBottom: number, tessellation: number, subdivisions: any, scene?: Scene, updatable?: any, sideOrientation?: number): Mesh;
    /**
     * Creates a torus mesh.
     * @param name defines the name of the mesh to create
     * @param diameter sets the diameter size (float) of the torus (default 1)
     * @param thickness sets the diameter size of the tube of the torus (float, default 0.5)
     * @param tessellation sets the number of torus sides (positive integer, default 16)
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateTorus(name: string, diameter: number, thickness: number, tessellation: number, scene?: Scene, updatable?: boolean, sideOrientation?: number): Mesh;
    /**
     * Creates a torus knot mesh.
     * @param name defines the name of the mesh to create
     * @param radius sets the global radius size (float) of the torus knot (default 2)
     * @param tube sets the diameter size of the tube of the torus (float, default 0.5)
     * @param radialSegments sets the number of sides on each tube segments (positive integer, default 32)
     * @param tubularSegments sets the number of tubes to decompose the knot into (positive integer, default 32)
     * @param p the number of windings on X axis (positive integers, default 2)
     * @param q the number of windings on Y axis (positive integers, default 3)
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateTorusKnot(name: string, radius: number, tube: number, radialSegments: number, tubularSegments: number, p: number, q: number, scene?: Scene, updatable?: boolean, sideOrientation?: number): Mesh;
    /**
     * Creates a line mesh..
     * @param name defines the name of the mesh to create
     * @param points is an array successive Vector3
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param instance is an instance of an existing LineMesh object to be updated with the passed `points` parameter (https://doc.babylonjs.com/how_to/How_to_dynamically_morph_a_mesh#lines-and-dashedlines).
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateLines(name: string, points: Vector3[], scene: Nullable<Scene>, updatable: boolean, instance?: Nullable<LinesMesh>): LinesMesh;
    /**
     * Creates a dashed line mesh.
     * @param name defines the name of the mesh to create
     * @param points is an array successive Vector3
     * @param dashSize is the size of the dashes relatively the dash number (positive float, default 3)
     * @param gapSize is the size of the gap between two successive dashes relatively the dash number (positive float, default 1)
     * @param dashNb is the intended total number of dashes (positive integer, default 200)
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param instance is an instance of an existing LineMesh object to be updated with the passed `points` parameter (https://doc.babylonjs.com/how_to/How_to_dynamically_morph_a_mesh#lines-and-dashedlines)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateDashedLines(name: string, points: Vector3[], dashSize: number, gapSize: number, dashNb: number, scene: Nullable<Scene>, updatable?: boolean, instance?: LinesMesh): LinesMesh;
    /**
     * Creates a polygon mesh.Please consider using the same method from the MeshBuilder class instead
     * The polygon's shape will depend on the input parameters and is constructed parallel to a ground mesh.
     * The parameter `shape` is a required array of successive Vector3 representing the corners of the polygon in th XoZ plane, that is y = 0 for all vectors.
     * You can set the mesh side orientation with the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * The mesh can be set to updatable with the boolean parameter `updatable` (default false) if its internal geometry is supposed to change once created.
     * Remember you can only change the shape positions, not their number when updating a polygon.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/param#non-regular-polygon
     * @param name defines the name of the mesh to create
     * @param shape is a required array of successive Vector3 representing the corners of the polygon in th XoZ plane, that is y = 0 for all vectors
     * @param scene defines the hosting scene
     * @param holes is a required array of arrays of successive Vector3 used to defines holes in the polygon
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @param earcutInjection can be used to inject your own earcut reference
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreatePolygon(name: string, shape: Vector3[], scene: Scene, holes?: Vector3[][], updatable?: boolean, sideOrientation?: number, earcutInjection?: any): Mesh;
    /**
     * Creates an extruded polygon mesh, with depth in the Y direction..
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/param#extruded-non-regular-polygon
     * @param name defines the name of the mesh to create
     * @param shape is a required array of successive Vector3 representing the corners of the polygon in th XoZ plane, that is y = 0 for all vectors
     * @param depth defines the height of extrusion
     * @param scene defines the hosting scene
     * @param holes is a required array of arrays of successive Vector3 used to defines holes in the polygon
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @param earcutInjection can be used to inject your own earcut reference
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static ExtrudePolygon(name: string, shape: Vector3[], depth: number, scene: Scene, holes?: Vector3[][], updatable?: boolean, sideOrientation?: number, earcutInjection?: any): Mesh;
    /**
     * Creates an extruded shape mesh.
     * The extrusion is a parametric shape. It has no predefined shape. Its final shape will depend on the input parameters.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/param
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/param#extruded-shapes
     * @param name defines the name of the mesh to create
     * @param shape is a required array of successive Vector3. This array depicts the shape to be extruded in its local space : the shape must be designed in the xOy plane and will be extruded along the Z axis
     * @param path is a required array of successive Vector3. This is the axis curve the shape is extruded along
     * @param scale is the value to scale the shape
     * @param rotation is the angle value to rotate the shape each step (each path point), from the former step (so rotation added each step) along the curve
     * @param cap sets the way the extruded shape is capped. Possible values : Mesh.NO_CAP (default), Mesh.CAP_START, Mesh.CAP_END, Mesh.CAP_ALL
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @param instance is an instance of an existing ExtrudedShape object to be updated with the passed `shape`, `path`, `scale` or `rotation` parameters (https://doc.babylonjs.com/how_to/How_to_dynamically_morph_a_mesh#extruded-shape)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static ExtrudeShape(name: string, shape: Vector3[], path: Vector3[], scale: number, rotation: number, cap: number, scene: Nullable<Scene>, updatable?: boolean, sideOrientation?: number, instance?: Mesh): Mesh;
    /**
     * Creates an custom extruded shape mesh.
     * The custom extrusion is a parametric shape.
     * It has no predefined shape. Its final shape will depend on the input parameters.
     *
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/param#extruded-shapes
     * @param name defines the name of the mesh to create
     * @param shape is a required array of successive Vector3. This array depicts the shape to be extruded in its local space : the shape must be designed in the xOy plane and will be extruded along the Z axis
     * @param path is a required array of successive Vector3. This is the axis curve the shape is extruded along
     * @param scaleFunction is a custom Javascript function called on each path point
     * @param rotationFunction is a custom Javascript function called on each path point
     * @param ribbonCloseArray forces the extrusion underlying ribbon to close all the paths in its `pathArray`
     * @param ribbonClosePath forces the extrusion underlying ribbon to close its `pathArray`
     * @param cap sets the way the extruded shape is capped. Possible values : Mesh.NO_CAP (default), Mesh.CAP_START, Mesh.CAP_END, Mesh.CAP_ALL
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @param instance is an instance of an existing ExtrudedShape object to be updated with the passed `shape`, `path`, `scale` or `rotation` parameters (https://doc.babylonjs.com/features/featuresDeepDive/mesh/dynamicMeshMorph#extruded-shape)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static ExtrudeShapeCustom(name: string, shape: Vector3[], path: Vector3[], scaleFunction: Nullable<{
        (i: number, distance: number): number;
    }>, rotationFunction: Nullable<{
        (i: number, distance: number): number;
    }>, ribbonCloseArray: boolean, ribbonClosePath: boolean, cap: number, scene: Scene, updatable?: boolean, sideOrientation?: number, instance?: Mesh): Mesh;
    /**
     * Creates lathe mesh.
     * The lathe is a shape with a symmetry axis : a 2D model shape is rotated around this axis to design the lathe.
     * @param name defines the name of the mesh to create
     * @param shape is a required array of successive Vector3. This array depicts the shape to be rotated in its local space : the shape must be designed in the xOy plane and will be rotated around the Y axis. It's usually a 2D shape, so the Vector3 z coordinates are often set to zero
     * @param radius is the radius value of the lathe
     * @param tessellation is the side number of the lathe.
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateLathe(name: string, shape: Vector3[], radius: number, tessellation: number, scene: Scene, updatable?: boolean, sideOrientation?: number): Mesh;
    /**
     * Creates a plane mesh.
     * @param name defines the name of the mesh to create
     * @param size sets the size (float) of both sides of the plane at once (default 1)
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreatePlane(name: string, size: number, scene: Scene, updatable?: boolean, sideOrientation?: number): Mesh;
    /**
     * Creates a ground mesh.
     * @param name defines the name of the mesh to create
     * @param width set the width of the ground
     * @param height set the height of the ground
     * @param subdivisions sets the number of subdivisions per side
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateGround(name: string, width: number, height: number, subdivisions: number, scene?: Scene, updatable?: boolean): Mesh;
    /**
     * Creates a tiled ground mesh.
     * @param name defines the name of the mesh to create
     * @param xmin set the ground minimum X coordinate
     * @param zmin set the ground minimum Y coordinate
     * @param xmax set the ground maximum X coordinate
     * @param zmax set the ground maximum Z coordinate
     * @param subdivisions is an object `{w: positive integer, h: positive integer}` (default `{w: 6, h: 6}`). `w` and `h` are the numbers of subdivisions on the ground width and height. Each subdivision is called a tile
     * @param precision is an object `{w: positive integer, h: positive integer}` (default `{w: 2, h: 2}`). `w` and `h` are the numbers of subdivisions on the ground width and height of each tile
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateTiledGround(name: string, xmin: number, zmin: number, xmax: number, zmax: number, subdivisions: {
        w: number;
        h: number;
    }, precision: {
        w: number;
        h: number;
    }, scene: Scene, updatable?: boolean): Mesh;
    /**
     * Creates a ground mesh from a height map.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set/height_map
     * @param name defines the name of the mesh to create
     * @param url sets the URL of the height map image resource
     * @param width set the ground width size
     * @param height set the ground height size
     * @param subdivisions sets the number of subdivision per side
     * @param minHeight is the minimum altitude on the ground
     * @param maxHeight is the maximum altitude on the ground
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param onReady  is a callback function that will be called  once the mesh is built (the height map download can last some time)
     * @param alphaFilter will filter any data where the alpha channel is below this value, defaults 0 (all data visible)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateGroundFromHeightMap(name: string, url: string, width: number, height: number, subdivisions: number, minHeight: number, maxHeight: number, scene: Scene, updatable?: boolean, onReady?: (mesh: GroundMesh) => void, alphaFilter?: number): GroundMesh;
    /**
     * Creates a tube mesh.
     * The tube is a parametric shape.
     * It has no predefined shape. Its final shape will depend on the input parameters.
     *
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/param
     * @param name defines the name of the mesh to create
     * @param path is a required array of successive Vector3. It is the curve used as the axis of the tube
     * @param radius sets the tube radius size
     * @param tessellation is the number of sides on the tubular surface
     * @param radiusFunction is a custom function. If it is not null, it overrides the parameter `radius`. This function is called on each point of the tube path and is passed the index `i` of the i-th point and the distance of this point from the first point of the path
     * @param cap sets the way the extruded shape is capped. Possible values : Mesh.NO_CAP (default), Mesh.CAP_START, Mesh.CAP_END, Mesh.CAP_ALL
     * @param scene defines the hosting scene
     * @param updatable defines if the mesh must be flagged as updatable
     * @param sideOrientation defines the mesh side orientation (https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation)
     * @param instance is an instance of an existing Tube object to be updated with the passed `pathArray` parameter (https://doc.babylonjs.com/how_to/How_to_dynamically_morph_a_mesh#tube)
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateTube(name: string, path: Vector3[], radius: number, tessellation: number, radiusFunction: {
        (i: number, distance: number): number;
    }, cap: number, scene: Scene, updatable?: boolean, sideOrientation?: number, instance?: Mesh): Mesh;
    /**
     * Creates a polyhedron mesh.
     *.
     * * The parameter `type` (positive integer, max 14, default 0) sets the polyhedron type to build among the 15 embedded types. Please refer to the type sheet in the tutorial to choose the wanted type
     * * The parameter `size` (positive float, default 1) sets the polygon size
     * * You can overwrite the `size` on each dimension bu using the parameters `sizeX`, `sizeY` or `sizeZ` (positive floats, default to `size` value)
     * * You can build other polyhedron types than the 15 embbeded ones by setting the parameter `custom` (`polyhedronObject`, default null). If you set the parameter `custom`, this overwrittes the parameter `type`
     * * A `polyhedronObject` is a formatted javascript object. You'll find a full file with pre-set polyhedra here : https://github.com/BabylonJS/Extensions/tree/master/Polyhedron
     * * You can set the color and the UV of each side of the polyhedron with the parameters `faceColors` (Color4, default `(1, 1, 1, 1)`) and faceUV (Vector4, default `(0, 0, 1, 1)`)
     * * To understand how to set `faceUV` or `faceColors`, please read this by considering the right number of faces of your polyhedron, instead of only 6 for the box : https://doc.babylonjs.com/features/featuresDeepDive/materials/using/texturePerBoxFace
     * * The parameter `flat` (boolean, default true). If set to false, it gives the polyhedron a single global face, so less vertices and shared normals. In this case, `faceColors` and `faceUV` are ignored
     * * You can also set the mesh side orientation with the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * If you create a double-sided mesh, you can choose what parts of the texture image to crop and stick respectively on the front and the back sides with the parameters `frontUVs` and `backUVs` (Vector4). Detail here : https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation
     * * The mesh can be set to updatable with the boolean parameter `updatable` (default false) if its internal geometry is supposed to change once created
     * @param name defines the name of the mesh to create
     * @param options defines the options used to create the mesh
     * @param scene defines the hosting scene
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreatePolyhedron(name: string, options: {
        type?: number;
        size?: number;
        sizeX?: number;
        sizeY?: number;
        sizeZ?: number;
        custom?: any;
        faceUV?: Vector4[];
        faceColors?: Color4[];
        updatable?: boolean;
        sideOrientation?: number;
    }, scene: Scene): Mesh;
    /**
     * Creates a sphere based upon an icosahedron with 20 triangular faces which can be subdivided
     * * The parameter `radius` sets the radius size (float) of the icosphere (default 1)
     * * You can set some different icosphere dimensions, for instance to build an ellipsoid, by using the parameters `radiusX`, `radiusY` and `radiusZ` (all by default have the same value than `radius`)
     * * The parameter `subdivisions` sets the number of subdivisions (positive integer, default 4). The more subdivisions, the more faces on the icosphere whatever its size
     * * The parameter `flat` (boolean, default true) gives each side its own normals. Set it to false to get a smooth continuous light reflection on the surface
     * * You can also set the mesh side orientation with the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * If you create a double-sided mesh, you can choose what parts of the texture image to crop and stick respectively on the front and the back sides with the parameters `frontUVs` and `backUVs` (Vector4). Detail here : https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/set#side-orientation
     * * The mesh can be set to updatable with the boolean parameter `updatable` (default false) if its internal geometry is supposed to change once created
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/creation/polyhedra#icosphere
     * @param name defines the name of the mesh
     * @param options defines the options used to create the mesh
     * @param scene defines the hosting scene
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateIcoSphere(name: string, options: {
        radius?: number;
        flat?: boolean;
        subdivisions?: number;
        sideOrientation?: number;
        updatable?: boolean;
    }, scene: Scene): Mesh;
    /**
     * Creates a decal mesh.
     *.
     * A decal is a mesh usually applied as a model onto the surface of another mesh
     * @param name  defines the name of the mesh
     * @param sourceMesh defines the mesh receiving the decal
     * @param position sets the position of the decal in world coordinates
     * @param normal sets the normal of the mesh where the decal is applied onto in world coordinates
     * @param size sets the decal scaling
     * @param angle sets the angle to rotate the decal
     * @returns a new Mesh
     * @deprecated Please use MeshBuilder instead
     */
    static CreateDecal(name: string, sourceMesh: AbstractMesh, position: Vector3, normal: Vector3, size: Vector3, angle: number): Mesh;
    /** Creates a Capsule Mesh
     * @param name defines the name of the mesh.
     * @param options the constructors options used to shape the mesh.
     * @param scene defines the scene the mesh is scoped to.
     * @returns the capsule mesh
     * @see https://doc.babylonjs.com/how_to/capsule_shape
     * @deprecated Please use MeshBuilder instead
     */
    static CreateCapsule(name: string, options: ICreateCapsuleOptions, scene: Scene): Mesh;
    /**
     * Extends a mesh to a Goldberg mesh
     * Warning  the mesh to convert MUST be an import of a perviously exported Goldberg mesh
     * @param mesh the mesh to convert
     * @returns the extended mesh
     * @deprecated Please use ExtendMeshToGoldberg instead
     */
    static ExtendToGoldberg(mesh: Mesh): Mesh;
}

/**
 * The options Interface for creating a Capsule Mesh
 */
interface ICreateCapsuleOptions {
    /** The Orientation of the capsule.  Default : Vector3.Up() */
    orientation?: Vector3;
    /** Number of sub segments on the tube section of the capsule running parallel to orientation. */
    subdivisions?: number;
    /** Number of cylindrical segments on the capsule. */
    tessellation?: number;
    /** Height or Length of the capsule. */
    height?: number;
    /** Radius of the capsule. */
    radius?: number;
    /** Number of sub segments on the cap sections of the capsule running parallel to orientation. */
    capSubdivisions?: number;
    /** Overwrite for the top radius. */
    radiusTop?: number;
    /** Overwrite for the bottom radius. */
    radiusBottom?: number;
    /** Overwrite for the top capSubdivisions. */
    topCapSubdivisions?: number;
    /** Overwrite for the bottom capSubdivisions. */
    bottomCapSubdivisions?: number;
    /** Internal geometry is supposed to change once created. */
    updatable?: boolean;
}

/**
 * Define an interface for all classes that will get and set the data on vertices
 */
interface IGetSetVerticesData {
    /**
     * Gets a boolean indicating if specific vertex data is present
     * @param kind defines the vertex data kind to use
     * @returns true is data kind is present
     */
    isVerticesDataPresent(kind: string): boolean;
    /**
     * Gets a specific vertex data attached to this geometry. Float data is constructed if the vertex buffer data cannot be returned directly.
     * @param kind defines the data kind (Position, normal, etc...)
     * @param copyWhenShared defines if the returned array must be cloned upon returning it if the current geometry is shared between multiple meshes
     * @param forceCopy defines a boolean indicating that the returned array must be cloned upon returning it
     * @returns a float array containing vertex data
     */
    getVerticesData(kind: string, copyWhenShared?: boolean, forceCopy?: boolean): Nullable<FloatArray>;
    /**
     * Returns an array of integers or a typed array (Int32Array, Uint32Array, Uint16Array) populated with the mesh indices.
     * @param copyWhenShared If true (default false) and and if the mesh geometry is shared among some other meshes, the returned array is a copy of the internal one.
     * @param forceCopy defines a boolean indicating that the returned array must be cloned upon returning it
     * @returns the indices array or an empty array if the mesh has no geometry
     */
    getIndices(copyWhenShared?: boolean, forceCopy?: boolean): Nullable<IndicesArray>;
    /**
     * Set specific vertex data
     * @param kind defines the data kind (Position, normal, etc...)
     * @param data defines the vertex data to use
     * @param updatable defines if the vertex must be flagged as updatable (false as default)
     * @param stride defines the stride to use (0 by default). This value is deduced from the kind value if not specified
     */
    setVerticesData(kind: string, data: FloatArray, updatable: boolean, stride?: number): void;
    /**
     * Update a specific associated vertex buffer
     * @param kind defines which buffer to write to (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @param data defines the data source
     * @param updateExtends defines if extends info of the mesh must be updated (can be null). This is mostly useful for "position" kind
     * @param makeItUnique defines if the geometry associated with the mesh must be cloned to make the change only for this mesh (and not all meshes associated with the same geometry)
     */
    updateVerticesData(kind: string, data: FloatArray, updateExtends?: boolean, makeItUnique?: boolean): void;
    /**
     * Creates a new index buffer
     * @param indices defines the indices to store in the index buffer
     * @param totalVertices defines the total number of vertices (could be null)
     * @param updatable defines if the index buffer must be flagged as updatable (false by default)
     */
    setIndices(indices: IndicesArray, totalVertices: Nullable<number>, updatable?: boolean): void;
}
/** Class used to attach material info to sub section of a vertex data class */
declare class VertexDataMaterialInfo {
    /** Defines the material index to use */
    materialIndex: number;
    /** Defines vertex index start*/
    verticesStart: number;
    /** Defines vertices count */
    verticesCount: number;
    /** Defines index start */
    indexStart: number;
    /** Defines indices count */
    indexCount: number;
}
/**
 * Interface used to define a object like a vertex data structure
 */
interface IVertexDataLike {
    /**
     * An array of the x, y, z position of each vertex  [...., x, y, z, .....]
     */
    positions: Nullable<FloatArray>;
    /**
     * An array of the x, y, z normal vector of each vertex  [...., x, y, z, .....]
     */
    normals?: Nullable<FloatArray>;
    /**
     * An array of the x, y, z, w tangent vector of each vertex  [...., x, y, z, w, .....]
     */
    tangents?: Nullable<FloatArray>;
    /**
     * An array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs?: Nullable<FloatArray>;
    /**
     * A second array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs2?: Nullable<FloatArray>;
    /**
     * A third array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs3?: Nullable<FloatArray>;
    /**
     * A fourth array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs4?: Nullable<FloatArray>;
    /**
     * A fifth array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs5?: Nullable<FloatArray>;
    /**
     * A sixth array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs6?: Nullable<FloatArray>;
    /**
     * An array of the r, g, b, a, color of each vertex  [...., r, g, b, a, .....]
     */
    colors?: Nullable<FloatArray>;
    /**
     * An array containing the list of indices to the array of matrices produced by bones, each vertex have up to 4 indices (8 if the matricesIndicesExtra is set).
     */
    matricesIndices?: Nullable<FloatArray>;
    /**
     * An array containing the list of weights defining the weight of each indexed matrix in the final computation
     */
    matricesWeights?: Nullable<FloatArray>;
    /**
     * An array extending the number of possible indices
     */
    matricesIndicesExtra?: Nullable<FloatArray>;
    /**
     * An array extending the number of possible weights when the number of indices is extended
     */
    matricesWeightsExtra?: Nullable<FloatArray>;
    /**
     * An array of i, j, k the three vertex indices required for each triangular facet  [...., i, j, k .....]
     */
    indices?: Nullable<IndicesArray>;
}
/**
 * This class contains the various kinds of data on every vertex of a mesh used in determining its shape and appearance
 */
declare class VertexData implements IVertexDataLike {
    /**
     * Mesh side orientation : usually the external or front surface
     */
    static readonly FRONTSIDE = 0;
    /**
     * Mesh side orientation : usually the internal or back surface
     */
    static readonly BACKSIDE = 1;
    /**
     * Mesh side orientation : both internal and external or front and back surfaces
     */
    static readonly DOUBLESIDE = 2;
    /**
     * Mesh side orientation : by default, `FRONTSIDE`
     */
    static readonly DEFAULTSIDE = 0;
    private static _UniqueIdGenerator;
    /**
     * An array of the x, y, z position of each vertex  [...., x, y, z, .....]
     */
    positions: Nullable<FloatArray>;
    /**
     * An array of the x, y, z normal vector of each vertex  [...., x, y, z, .....]
     */
    normals: Nullable<FloatArray>;
    /**
     * An array of the x, y, z, w tangent vector of each vertex  [...., x, y, z, w, .....]
     */
    tangents: Nullable<FloatArray>;
    /**
     * An array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs: Nullable<FloatArray>;
    /**
     * A second array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs2: Nullable<FloatArray>;
    /**
     * A third array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs3: Nullable<FloatArray>;
    /**
     * A fourth array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs4: Nullable<FloatArray>;
    /**
     * A fifth array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs5: Nullable<FloatArray>;
    /**
     * A sixth array of u,v which maps a texture image onto each vertex  [...., u, v, .....]
     */
    uvs6: Nullable<FloatArray>;
    /**
     * An array of the r, g, b, a, color of each vertex  [...., r, g, b, a, .....]
     */
    colors: Nullable<FloatArray>;
    /**
     * An array containing the list of indices to the array of matrices produced by bones, each vertex have up to 4 indices (8 if the matricesIndicesExtra is set).
     */
    matricesIndices: Nullable<FloatArray>;
    /**
     * An array containing the list of weights defining the weight of each indexed matrix in the final computation
     */
    matricesWeights: Nullable<FloatArray>;
    /**
     * An array extending the number of possible indices
     */
    matricesIndicesExtra: Nullable<FloatArray>;
    /**
     * An array extending the number of possible weights when the number of indices is extended
     */
    matricesWeightsExtra: Nullable<FloatArray>;
    /**
     * An array of i, j, k the three vertex indices required for each triangular facet  [...., i, j, k .....]
     */
    indices: Nullable<IndicesArray>;
    /**
     * An array defining material association for sub sections of the vertex data
     */
    materialInfos: Nullable<Array<VertexDataMaterialInfo>>;
    /**
     * Gets the unique ID of this vertex Data
     */
    uniqueId: number;
    /**
     * Metadata used to store contextual values
     */
    metadata: any;
    /**
     * Gets or sets a value indicating that the mesh must be flagged with hasVertexAlpha = true
     */
    hasVertexAlpha: boolean;
    /**
     * Creates a new VertexData
     */
    constructor();
    /**
     * Uses the passed data array to set the set the values for the specified kind of data
     * @param data a linear array of floating numbers
     * @param kind the type of data that is being set, eg positions, colors etc
     */
    set(data: FloatArray, kind: string): void;
    /**
     * Associates the vertexData to the passed Mesh.
     * Sets it as updatable or not (default `false`)
     * @param mesh the mesh the vertexData is applied to
     * @param updatable when used and having the value true allows new data to update the vertexData
     * @returns the VertexData
     */
    applyToMesh(mesh: Mesh, updatable?: boolean): VertexData;
    /**
     * Associates the vertexData to the passed Geometry.
     * Sets it as updatable or not (default `false`)
     * @param geometry the geometry the vertexData is applied to
     * @param updatable when used and having the value true allows new data to update the vertexData
     * @returns VertexData
     */
    applyToGeometry(geometry: Geometry, updatable?: boolean): VertexData;
    /**
     * Updates the associated mesh
     * @param mesh the mesh to be updated
     * @returns VertexData
     */
    updateMesh(mesh: Mesh): VertexData;
    /**
     * Updates the associated geometry
     * @param geometry the geometry to be updated
     * @returns VertexData.
     */
    updateGeometry(geometry: Geometry): VertexData;
    private readonly _applyTo;
    /**
     * @internal
     */
    _applyToCoroutine(meshOrGeometry: IGetSetVerticesData, updatable: boolean | undefined, isAsync: boolean): Coroutine<VertexData>;
    private _update;
    private static _TransformVector3Coordinates;
    private static _TransformVector3Normals;
    private static _TransformVector4Normals;
    private static _FlipFaces;
    /**
     * Transforms each position and each normal of the vertexData according to the passed Matrix
     * @param matrix the transforming matrix
     * @returns the VertexData
     */
    transform(matrix: Matrix): VertexData;
    /**
     * Generates an array of vertex data where each vertex data only has one material info
     * @returns An array of VertexData
     */
    splitBasedOnMaterialID(): VertexData[];
    /**
     * Merges the passed VertexData into the current one
     * @param others the VertexData to be merged into the current one
     * @param use32BitsIndices defines a boolean indicating if indices must be store in a 32 bits array
     * @param forceCloneIndices defines a boolean indicating if indices are forced to be cloned
     * @param mergeMaterialIds defines a boolean indicating if we need to merge the material infos
     * @param enableCompletion defines a boolean indicating if the vertex data should be completed to be compatible
     * @returns the modified VertexData
     */
    merge(others: VertexData | VertexData[], use32BitsIndices?: boolean, forceCloneIndices?: boolean, mergeMaterialIds?: boolean, enableCompletion?: boolean): VertexData;
    /**
     * @internal
     */
    _mergeCoroutine(transform: Matrix | undefined, vertexDatas: {
        vertexData: VertexData;
        transform?: Matrix;
    }[], use32BitsIndices: boolean | undefined, isAsync: boolean, forceCloneIndices: boolean, mergeMaterialIds?: boolean, enableCompletion?: boolean): Coroutine<VertexData>;
    private static _MergeElement;
    private _validate;
    /**
     * Clone the current vertex data
     * @returns a copy of the current data
     */
    clone(): VertexData;
    /**
     * Serializes the VertexData
     * @returns a serialized object
     */
    serialize(): any;
    /**
     * Extracts the vertexData from a mesh
     * @param mesh the mesh from which to extract the VertexData
     * @param copyWhenShared defines if the VertexData must be cloned when shared between multiple meshes, optional, default false
     * @param forceCopy indicating that the VertexData must be cloned, optional, default false
     * @returns the object VertexData associated to the passed mesh
     */
    static ExtractFromMesh(mesh: Mesh, copyWhenShared?: boolean, forceCopy?: boolean): VertexData;
    /**
     * Extracts the vertexData from the geometry
     * @param geometry the geometry from which to extract the VertexData
     * @param copyWhenShared defines if the VertexData must be cloned when the geometry is shared between multiple meshes, optional, default false
     * @param forceCopy indicating that the VertexData must be cloned, optional, default false
     * @returns the object VertexData associated to the passed mesh
     */
    static ExtractFromGeometry(geometry: Geometry, copyWhenShared?: boolean, forceCopy?: boolean): VertexData;
    private static _ExtractFrom;
    /**
     * Creates the VertexData for a Ribbon
     * @param options an object used to set the following optional parameters for the ribbon, required but can be empty
     * * pathArray array of paths, each of which an array of successive Vector3
     * * closeArray creates a seam between the first and the last paths of the pathArray, optional, default false
     * * closePath creates a seam between the first and the last points of each path of the path array, optional, default false
     * * offset a positive integer, only used when pathArray contains a single path (offset = 10 means the point 1 is joined to the point 11), default rounded half size of the pathArray length
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * * invertUV swaps in the U and V coordinates when applying a texture, optional, default false
     * * uvs a linear array, of length 2 * number of vertices, of custom UV values, optional
     * * colors a linear array, of length 4 * number of vertices, of custom color values, optional
     * @returns the VertexData of the ribbon
     * @deprecated use CreateRibbonVertexData instead
     */
    static CreateRibbon(options: {
        pathArray: Vector3[][];
        closeArray?: boolean;
        closePath?: boolean;
        offset?: number;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
        invertUV?: boolean;
        uvs?: Vector2[];
        colors?: Color4[];
    }): VertexData;
    /**
     * Creates the VertexData for a box
     * @param options an object used to set the following optional parameters for the box, required but can be empty
     * * size sets the width, height and depth of the box to the value of size, optional default 1
     * * width sets the width (x direction) of the box, overwrites the width set by size, optional, default size
     * * height sets the height (y direction) of the box, overwrites the height set by size, optional, default size
     * * depth sets the depth (z direction) of the box, overwrites the depth set by size, optional, default size
     * * faceUV an array of 6 Vector4 elements used to set different images to each box side
     * * faceColors an array of 6 Color3 elements used to set different colors to each box side
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the box
     * @deprecated Please use CreateBoxVertexData from the BoxBuilder file instead
     */
    static CreateBox(options: {
        size?: number;
        width?: number;
        height?: number;
        depth?: number;
        faceUV?: Vector4[];
        faceColors?: Color4[];
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData for a tiled box
     * @param options an object used to set the following optional parameters for the box, required but can be empty
     * * faceTiles sets the pattern, tile size and number of tiles for a face
     * * faceUV an array of 6 Vector4 elements used to set different images to each box side
     * * faceColors an array of 6 Color3 elements used to set different colors to each box side
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * @param options.pattern
     * @param options.width
     * @param options.height
     * @param options.depth
     * @param options.tileSize
     * @param options.tileWidth
     * @param options.tileHeight
     * @param options.alignHorizontal
     * @param options.alignVertical
     * @param options.faceUV
     * @param options.faceColors
     * @param options.sideOrientation
     * @returns the VertexData of the box
     * @deprecated Please use CreateTiledBoxVertexData instead
     */
    static CreateTiledBox(options: {
        pattern?: number;
        width?: number;
        height?: number;
        depth?: number;
        tileSize?: number;
        tileWidth?: number;
        tileHeight?: number;
        alignHorizontal?: number;
        alignVertical?: number;
        faceUV?: Vector4[];
        faceColors?: Color4[];
        sideOrientation?: number;
    }): VertexData;
    /**
     * Creates the VertexData for a tiled plane
     * @param options an object used to set the following optional parameters for the box, required but can be empty
     * * pattern a limited pattern arrangement depending on the number
     * * tileSize sets the width, height and depth of the tile to the value of size, optional default 1
     * * tileWidth sets the width (x direction) of the tile, overwrites the width set by size, optional, default size
     * * tileHeight sets the height (y direction) of the tile, overwrites the height set by size, optional, default size
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the tiled plane
     * @deprecated use CreateTiledPlaneVertexData instead
     */
    static CreateTiledPlane(options: {
        pattern?: number;
        tileSize?: number;
        tileWidth?: number;
        tileHeight?: number;
        size?: number;
        width?: number;
        height?: number;
        alignHorizontal?: number;
        alignVertical?: number;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData for an ellipsoid, defaults to a sphere
     * @param options an object used to set the following optional parameters for the box, required but can be empty
     * * segments sets the number of horizontal strips optional, default 32
     * * diameter sets the axes dimensions, diameterX, diameterY and diameterZ to the value of diameter, optional default 1
     * * diameterX sets the diameterX (x direction) of the ellipsoid, overwrites the diameterX set by diameter, optional, default diameter
     * * diameterY sets the diameterY (y direction) of the ellipsoid, overwrites the diameterY set by diameter, optional, default diameter
     * * diameterZ sets the diameterZ (z direction) of the ellipsoid, overwrites the diameterZ set by diameter, optional, default diameter
     * * arc a number from 0 to 1, to create an unclosed ellipsoid based on the fraction of the circumference (latitude) given by the arc value, optional, default 1
     * * slice a number from 0 to 1, to create an unclosed ellipsoid based on the fraction of the height (latitude) given by the arc value, optional, default 1
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the ellipsoid
     * @deprecated use CreateSphereVertexData instead
     */
    static CreateSphere(options: {
        segments?: number;
        diameter?: number;
        diameterX?: number;
        diameterY?: number;
        diameterZ?: number;
        arc?: number;
        slice?: number;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData for a cylinder, cone or prism
     * @param options an object used to set the following optional parameters for the box, required but can be empty
     * * height sets the height (y direction) of the cylinder, optional, default 2
     * * diameterTop sets the diameter of the top of the cone, overwrites diameter,  optional, default diameter
     * * diameterBottom sets the diameter of the bottom of the cone, overwrites diameter,  optional, default diameter
     * * diameter sets the diameter of the top and bottom of the cone, optional default 1
     * * tessellation the number of prism sides, 3 for a triangular prism, optional, default 24
     * * subdivisions` the number of rings along the cylinder height, optional, default 1
     * * arc a number from 0 to 1, to create an unclosed cylinder based on the fraction of the circumference given by the arc value, optional, default 1
     * * faceColors an array of Color3 elements used to set different colors to the top, rings and bottom respectively
     * * faceUV an array of Vector4 elements used to set different images to the top, rings and bottom respectively
     * * hasRings when true makes each subdivision independently treated as a face for faceUV and faceColors, optional, default false
     * * enclose when true closes an open cylinder by adding extra flat faces between the height axis and vertical edges, think cut cake
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the cylinder, cone or prism
     * @deprecated please use CreateCylinderVertexData instead
     */
    static CreateCylinder(options: {
        height?: number;
        diameterTop?: number;
        diameterBottom?: number;
        diameter?: number;
        tessellation?: number;
        subdivisions?: number;
        arc?: number;
        faceColors?: Color4[];
        faceUV?: Vector4[];
        hasRings?: boolean;
        enclose?: boolean;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData for a torus
     * @param options an object used to set the following optional parameters for the box, required but can be empty
     * * diameter the diameter of the torus, optional default 1
     * * thickness the diameter of the tube forming the torus, optional default 0.5
     * * tessellation the number of prism sides, 3 for a triangular prism, optional, default 24
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the torus
     * @deprecated use CreateTorusVertexData instead
     */
    static CreateTorus(options: {
        diameter?: number;
        thickness?: number;
        tessellation?: number;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData of the LineSystem
     * @param options an object used to set the following optional parameters for the LineSystem, required but can be empty
     *  - lines an array of lines, each line being an array of successive Vector3
     *  - colors an array of line colors, each of the line colors being an array of successive Color4, one per line point
     * @returns the VertexData of the LineSystem
     * @deprecated use CreateLineSystemVertexData instead
     */
    static CreateLineSystem(options: {
        lines: Vector3[][];
        colors?: Nullable<Color4[][]>;
    }): VertexData;
    /**
     * Create the VertexData for a DashedLines
     * @param options an object used to set the following optional parameters for the DashedLines, required but can be empty
     *  - points an array successive Vector3
     *  - dashSize the size of the dashes relative to the dash number, optional, default 3
     *  - gapSize the size of the gap between two successive dashes relative to the dash number, optional, default 1
     *  - dashNb the intended total number of dashes, optional, default 200
     * @returns the VertexData for the DashedLines
     * @deprecated use CreateDashedLinesVertexData instead
     */
    static CreateDashedLines(options: {
        points: Vector3[];
        dashSize?: number;
        gapSize?: number;
        dashNb?: number;
    }): VertexData;
    /**
     * Creates the VertexData for a Ground
     * @param options an object used to set the following optional parameters for the Ground, required but can be empty
     *  - width the width (x direction) of the ground, optional, default 1
     *  - height the height (z direction) of the ground, optional, default 1
     *  - subdivisions the number of subdivisions per side, optional, default 1
     * @returns the VertexData of the Ground
     * @deprecated Please use CreateGroundVertexData instead
     */
    static CreateGround(options: {
        width?: number;
        height?: number;
        subdivisions?: number;
        subdivisionsX?: number;
        subdivisionsY?: number;
    }): VertexData;
    /**
     * Creates the VertexData for a TiledGround by subdividing the ground into tiles
     * @param options an object used to set the following optional parameters for the Ground, required but can be empty
     * * xmin the ground minimum X coordinate, optional, default -1
     * * zmin the ground minimum Z coordinate, optional, default -1
     * * xmax the ground maximum X coordinate, optional, default 1
     * * zmax the ground maximum Z coordinate, optional, default 1
     * * subdivisions a javascript object {w: positive integer, h: positive integer}, `w` and `h` are the numbers of subdivisions on the ground width and height creating 'tiles', default {w: 6, h: 6}
     * * precision a javascript object {w: positive integer, h: positive integer}, `w` and `h` are the numbers of subdivisions on the tile width and height, default {w: 2, h: 2}
     * @returns the VertexData of the TiledGround
     * @deprecated use CreateTiledGroundVertexData instead
     */
    static CreateTiledGround(options: {
        xmin: number;
        zmin: number;
        xmax: number;
        zmax: number;
        subdivisions?: {
            w: number;
            h: number;
        };
        precision?: {
            w: number;
            h: number;
        };
    }): VertexData;
    /**
     * Creates the VertexData of the Ground designed from a heightmap
     * @param options an object used to set the following parameters for the Ground, required and provided by CreateGroundFromHeightMap
     * * width the width (x direction) of the ground
     * * height the height (z direction) of the ground
     * * subdivisions the number of subdivisions per side
     * * minHeight the minimum altitude on the ground, optional, default 0
     * * maxHeight the maximum altitude on the ground, optional default 1
     * * colorFilter the filter to apply to the image pixel colors to compute the height, optional Color3, default (0.3, 0.59, 0.11)
     * * buffer the array holding the image color data
     * * bufferWidth the width of image
     * * bufferHeight the height of image
     * * alphaFilter Remove any data where the alpha channel is below this value, defaults 0 (all data visible)
     * @returns the VertexData of the Ground designed from a heightmap
     * @deprecated use CreateGroundFromHeightMapVertexData instead
     */
    static CreateGroundFromHeightMap(options: {
        width: number;
        height: number;
        subdivisions: number;
        minHeight: number;
        maxHeight: number;
        colorFilter: Color3;
        buffer: Uint8Array;
        bufferWidth: number;
        bufferHeight: number;
        alphaFilter: number;
    }): VertexData;
    /**
     * Creates the VertexData for a Plane
     * @param options an object used to set the following optional parameters for the plane, required but can be empty
     * * size sets the width and height of the plane to the value of size, optional default 1
     * * width sets the width (x direction) of the plane, overwrites the width set by size, optional, default size
     * * height sets the height (y direction) of the plane, overwrites the height set by size, optional, default size
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the box
     * @deprecated use CreatePlaneVertexData instead
     */
    static CreatePlane(options: {
        size?: number;
        width?: number;
        height?: number;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData of the Disc or regular Polygon
     * @param options an object used to set the following optional parameters for the disc, required but can be empty
     * * radius the radius of the disc, optional default 0.5
     * * tessellation the number of polygon sides, optional, default 64
     * * arc a number from 0 to 1, to create an unclosed polygon based on the fraction of the circumference given by the arc value, optional, default 1
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the box
     * @deprecated use CreateDiscVertexData instead
     */
    static CreateDisc(options: {
        radius?: number;
        tessellation?: number;
        arc?: number;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData for an irregular Polygon in the XoZ plane using a mesh built by polygonTriangulation.build()
     * All parameters are provided by CreatePolygon as needed
     * @param polygon a mesh built from polygonTriangulation.build()
     * @param sideOrientation takes the values Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * @param fUV an array of Vector4 elements used to set different images to the top, rings and bottom respectively
     * @param fColors an array of Color3 elements used to set different colors to the top, rings and bottom respectively
     * @param frontUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * @param backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @param wrap a boolean, default false, when true and fUVs used texture is wrapped around all sides, when false texture is applied side
     * @returns the VertexData of the Polygon
     * @deprecated use CreatePolygonVertexData instead
     */
    static CreatePolygon(polygon: Mesh, sideOrientation: number, fUV?: Vector4[], fColors?: Color4[], frontUVs?: Vector4, backUVs?: Vector4, wrap?: boolean): VertexData;
    /**
     * Creates the VertexData of the IcoSphere
     * @param options an object used to set the following optional parameters for the IcoSphere, required but can be empty
     * * radius the radius of the IcoSphere, optional default 1
     * * radiusX allows stretching in the x direction, optional, default radius
     * * radiusY allows stretching in the y direction, optional, default radius
     * * radiusZ allows stretching in the z direction, optional, default radius
     * * flat when true creates a flat shaded mesh, optional, default true
     * * subdivisions increasing the subdivisions increases the number of faces, optional, default 4
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the IcoSphere
     * @deprecated use CreateIcoSphereVertexData instead
     */
    static CreateIcoSphere(options: {
        radius?: number;
        radiusX?: number;
        radiusY?: number;
        radiusZ?: number;
        flat?: boolean;
        subdivisions?: number;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData for a Polyhedron
     * @param options an object used to set the following optional parameters for the polyhedron, required but can be empty
     * * type provided types are:
     *  * 0 : Tetrahedron, 1 : Octahedron, 2 : Dodecahedron, 3 : Icosahedron, 4 : Rhombicuboctahedron, 5 : Triangular Prism, 6 : Pentagonal Prism, 7 : Hexagonal Prism, 8 : Square Pyramid (J1)
     *  * 9 : Pentagonal Pyramid (J2), 10 : Triangular Dipyramid (J12), 11 : Pentagonal Dipyramid (J13), 12 : Elongated Square Dipyramid (J15), 13 : Elongated Pentagonal Dipyramid (J16), 14 : Elongated Pentagonal Cupola (J20)
     * * size the size of the IcoSphere, optional default 1
     * * sizeX allows stretching in the x direction, optional, default size
     * * sizeY allows stretching in the y direction, optional, default size
     * * sizeZ allows stretching in the z direction, optional, default size
     * * custom a number that overwrites the type to create from an extended set of polyhedron from https://www.babylonjs-playground.com/#21QRSK#15 with minimised editor
     * * faceUV an array of Vector4 elements used to set different images to the top, rings and bottom respectively
     * * faceColors an array of Color3 elements used to set different colors to the top, rings and bottom respectively
     * * flat when true creates a flat shaded mesh, optional, default true
     * * subdivisions increasing the subdivisions increases the number of faces, optional, default 4
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the Polyhedron
     * @deprecated use CreatePolyhedronVertexData instead
     */
    static CreatePolyhedron(options: {
        type?: number;
        size?: number;
        sizeX?: number;
        sizeY?: number;
        sizeZ?: number;
        custom?: any;
        faceUV?: Vector4[];
        faceColors?: Color4[];
        flat?: boolean;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Creates the VertexData for a Capsule, inspired from https://github.com/maximeq/three-js-capsule-geometry/blob/master/src/CapsuleBufferGeometry.js
     * @param options an object used to set the following optional parameters for the capsule, required but can be empty
     * @returns the VertexData of the Capsule
     * @deprecated Please use CreateCapsuleVertexData from the capsuleBuilder file instead
     */
    static CreateCapsule(options?: ICreateCapsuleOptions): VertexData;
    /**
     * Creates the VertexData for a TorusKnot
     * @param options an object used to set the following optional parameters for the TorusKnot, required but can be empty
     * * radius the radius of the torus knot, optional, default 2
     * * tube the thickness of the tube, optional, default 0.5
     * * radialSegments the number of sides on each tube segments, optional, default 32
     * * tubularSegments the number of tubes to decompose the knot into, optional, default 32
     * * p the number of windings around the z axis, optional,  default 2
     * * q the number of windings around the x axis, optional,  default 3
     * * sideOrientation optional and takes the values : Mesh.FRONTSIDE (default), Mesh.BACKSIDE or Mesh.DOUBLESIDE
     * * frontUvs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the front side, optional, default vector4 (0, 0, 1, 1)
     * * backUVs only usable when you create a double-sided mesh, used to choose what parts of the texture image to crop and apply on the back side, optional, default vector4 (0, 0, 1, 1)
     * @returns the VertexData of the Torus Knot
     * @deprecated use CreateTorusKnotVertexData instead
     */
    static CreateTorusKnot(options: {
        radius?: number;
        tube?: number;
        radialSegments?: number;
        tubularSegments?: number;
        p?: number;
        q?: number;
        sideOrientation?: number;
        frontUVs?: Vector4;
        backUVs?: Vector4;
    }): VertexData;
    /**
     * Compute normals for given positions and indices
     * @param positions an array of vertex positions, [...., x, y, z, ......]
     * @param indices an array of indices in groups of three for each triangular facet, [...., i, j, k, ......]
     * @param normals an array of vertex normals, [...., x, y, z, ......]
     * @param options an object used to set the following optional parameters for the TorusKnot, optional
     * * facetNormals : optional array of facet normals (vector3)
     * * facetPositions : optional array of facet positions (vector3)
     * * facetPartitioning : optional partitioning array. facetPositions is required for facetPartitioning computation
     * * ratio : optional partitioning ratio / bounding box, required for facetPartitioning computation
     * * bInfo : optional bounding info, required for facetPartitioning computation
     * * bbSize : optional bounding box size data, required for facetPartitioning computation
     * * subDiv : optional partitioning data about subdivisions on  each axis (int), required for facetPartitioning computation
     * * useRightHandedSystem: optional boolean to for right handed system computation
     * * depthSort : optional boolean to enable the facet depth sort computation
     * * distanceTo : optional Vector3 to compute the facet depth from this location
     * * depthSortedFacets : optional array of depthSortedFacets to store the facet distances from the reference location
     */
    static ComputeNormals(positions: any, indices: any, normals: any, options?: {
        facetNormals?: any;
        facetPositions?: any;
        facetPartitioning?: any;
        ratio?: number;
        bInfo?: any;
        bbSize?: Vector3;
        subDiv?: any;
        useRightHandedSystem?: boolean;
        depthSort?: boolean;
        distanceTo?: Vector3;
        depthSortedFacets?: any;
    }): void;
    /**
     * @internal
     */
    static _ComputeSides(sideOrientation: number, positions: FloatArray, indices: FloatArray | IndicesArray, normals: FloatArray, uvs: FloatArray, frontUVs?: Vector4, backUVs?: Vector4): void;
    /**
     * Creates a VertexData from serialized data
     * @param parsedVertexData the parsed data from an imported file
     * @returns a VertexData
     */
    static Parse(parsedVertexData: any): VertexData;
    /**
     * Applies VertexData created from the imported parameters to the geometry
     * @param parsedVertexData the parsed data from an imported file
     * @param geometry the geometry to apply the VertexData to
     */
    static ImportVertexData(parsedVertexData: any, geometry: Geometry): void;
}

/**
 * Interface for baked vertex animation texture, see BakedVertexAnimationManager
 * @since 5.0
 */
interface IBakedVertexAnimationManager {
    /**
     * The vertex animation texture
     */
    texture: Nullable<BaseTexture>;
    /**
     * Gets or sets a boolean indicating if the edgesRenderer is active
     */
    isEnabled: boolean;
    /**
     * The animation parameters for the mesh. See setAnimationParameters()
     */
    animationParameters: Vector4;
    /**
     * The time counter, to pick the correct animation frame.
     */
    time: number;
    /**
     * Binds to the effect.
     * @param effect The effect to bind to.
     * @param useInstances True when it's an instance.
     */
    bind(effect: Effect, useInstances: boolean): void;
    /**
     * Sets animation parameters.
     * @param startFrame The first frame of the animation.
     * @param endFrame The last frame of the animation.
     * @param offset The offset when starting the animation.
     * @param speedFramesPerSecond The frame rate.
     */
    setAnimationParameters(startFrame: number, endFrame: number, offset: number, speedFramesPerSecond: number): void;
    /**
     * Disposes the resources of the manager.
     * @param forceDisposeTextures - Forces the disposal of all textures.
     */
    dispose(forceDisposeTextures?: boolean): void;
    /**
     * Get the current class name useful for serialization or dynamic coding.
     * @returns "BakedVertexAnimationManager"
     */
    getClassName(): string;
}

/**
 * A target camera takes a mesh or position as a target and continues to look at it while it moves.
 * This is the base of the follow, arc rotate cameras and Free camera
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras
 */
declare class TargetCamera extends Camera {
    private static _RigCamTransformMatrix;
    private static _TargetTransformMatrix;
    private static _TargetFocalPoint;
    /**
     * Define the current direction the camera is moving to
     */
    cameraDirection: Vector3;
    /**
     * Define the current rotation the camera is rotating to
     */
    cameraRotation: Vector2;
    /**
     * When set, the up vector of the camera will be updated by the rotation of the camera
     */
    updateUpVectorFromRotation: boolean;
    /**
     * Define the current rotation of the camera
     */
    rotation: Vector3;
    /**
     * Define the current rotation of the camera as a quaternion to prevent Gimbal lock
     */
    rotationQuaternion: Nullable<Quaternion>;
    /**
     * Define the current speed of the camera
     */
    speed: number;
    /**
     * Add constraint to the camera to prevent it to move freely in all directions and
     * around all axis.
     */
    noRotationConstraint: boolean;
    /**
     * Reverses mouselook direction to 'natural' panning as opposed to traditional direct
     * panning
     */
    invertRotation: boolean;
    /**
     * Speed multiplier for inverse camera panning
     */
    inverseRotationSpeed: number;
    /**
     * @internal
     * @experimental
     * Can be used to change clamping behavior for inertia. Hook into onBeforeRenderObservable to change the value per-frame
     */
    _panningEpsilon: number;
    /**
     * @internal
     * @experimental
     * Can be used to change clamping behavior for inertia. Hook into onBeforeRenderObservable to change the value per-frame
     */
    _rotationEpsilon: number;
    /**
     * Define the current target of the camera as an object or a position.
     * Please note that locking a target will disable panning.
     */
    lockedTarget: any;
    protected readonly _currentTarget: Vector3;
    protected _initialFocalDistance: number;
    protected readonly _viewMatrix: Matrix;
    /** @internal */
    readonly _cameraTransformMatrix: Matrix;
    /** @internal */
    readonly _cameraRotationMatrix: Matrix;
    protected readonly _referencePoint: Vector3;
    protected readonly _transformedReferencePoint: Vector3;
    protected readonly _deferredPositionUpdate: Vector3;
    protected readonly _deferredRotationQuaternionUpdate: Quaternion;
    protected readonly _deferredRotationUpdate: Vector3;
    protected _deferredUpdated: boolean;
    protected _deferOnly: boolean;
    /** @internal */
    _reset: () => void;
    /**
     * Instantiates a target camera that takes a mesh or position as a target and continues to look at it while it moves.
     * This is the base of the follow, arc rotate cameras and Free camera
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras
     * @param name Defines the name of the camera in the scene
     * @param position Defines the start position of the camera in the scene
     * @param scene Defines the scene the camera belongs to
     * @param setActiveOnSceneIfNoneActive Defines whether the camera should be marked as active if not other active cameras have been defined
     */
    constructor(name: string, position: Vector3, scene?: Scene, setActiveOnSceneIfNoneActive?: boolean);
    /**
     * Gets the position in front of the camera at a given distance.
     * @param distance The distance from the camera we want the position to be
     * @returns the position
     */
    getFrontPosition(distance: number): Vector3;
    /** @internal */
    _getLockedTargetPosition(): Nullable<Vector3>;
    private _storedPosition;
    private _storedRotation;
    private _storedRotationQuaternion;
    /**
     * Store current camera state of the camera (fov, position, rotation, etc..)
     * @returns the camera
     */
    storeState(): Camera;
    /**
     * Restored camera state. You must call storeState() first
     * @returns whether it was successful or not
     * @internal
     */
    _restoreStateValues(): boolean;
    /** @internal */
    _initCache(): void;
    /**
     * @internal
     */
    _updateCache(ignoreParentClass?: boolean): void;
    /** @internal */
    _isSynchronizedViewMatrix(): boolean;
    /** @internal */
    _computeLocalCameraSpeed(): number;
    /**
     * Defines the target the camera should look at.
     * @param target Defines the new target as a Vector
     */
    setTarget(target: Vector3): void;
    /**
     * Defines the target point of the camera.
     * The camera looks towards it form the radius distance.
     */
    get target(): Vector3;
    set target(value: Vector3);
    /**
     * Return the current target position of the camera. This value is expressed in local space.
     * @returns the target position
     */
    getTarget(): Vector3;
    /** @internal */
    _decideIfNeedsToMove(): boolean;
    /** @internal */
    _updatePosition(): void;
    /** @internal */
    _checkInputs(): void;
    protected _updateCameraRotationMatrix(): void;
    /**
     * Update the up vector to apply the rotation of the camera (So if you changed the camera rotation.z this will let you update the up vector as well)
     * @returns the current camera
     */
    private _rotateUpVectorWithCameraRotationMatrix;
    private _cachedRotationZ;
    private _cachedQuaternionRotationZ;
    /** @internal */
    _getViewMatrix(): Matrix;
    protected _computeViewMatrix(position: Vector3, target: Vector3, up: Vector3): void;
    /**
     * @internal
     */
    createRigCamera(name: string, cameraIndex: number): Nullable<Camera>;
    /**
     * @internal
     */
    _updateRigCameras(): void;
    private _getRigCamPositionAndTarget;
    /**
     * Gets the current object class name.
     * @returns the class name
     */
    getClassName(): string;
}

/**
 * The SPS is a single updatable mesh. The solid particles are simply separate parts or faces of this big mesh.
 *As it is just a mesh, the SPS has all the same properties than any other BJS mesh : not more, not less. It can be scaled, rotated, translated, enlighted, textured, moved, etc.

 * The SPS is also a particle system. It provides some methods to manage the particles.
 * However it is behavior agnostic. This means it has no emitter, no particle physics, no particle recycler. You have to implement your own behavior.
 *
 * Full documentation here : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/sps_intro
 */
declare class SolidParticleSystem implements IDisposable {
    /**
     *  The SPS array of Solid Particle objects. Just access each particle as with any classic array.
     *  Example : var p = SPS.particles[i];
     */
    particles: SolidParticle[];
    /**
     * The SPS total number of particles. Read only. Use SPS.counter instead if you need to set your own value.
     */
    nbParticles: number;
    /**
     * If the particles must ever face the camera (default false). Useful for planar particles.
     */
    billboard: boolean;
    /**
     * Recompute normals when adding a shape
     */
    recomputeNormals: boolean;
    /**
     * This a counter ofr your own usage. It's not set by any SPS functions.
     */
    counter: number;
    /**
     * The SPS name. This name is also given to the underlying mesh.
     */
    name: string;
    /**
     * The SPS mesh. It's a standard BJS Mesh, so all the methods from the Mesh class are available.
     */
    mesh: Mesh;
    /**
     * This empty object is intended to store some SPS specific or temporary values in order to lower the Garbage Collector activity.
     * Please read : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/optimize_sps#limit-garbage-collection
     */
    vars: any;
    /**
     * This array is populated when the SPS is set as 'pickable'.
     * Each key of this array is a `faceId` value that you can get from a pickResult object.
     * Each element of this array is an object `{idx: int, faceId: int}`.
     * `idx` is the picked particle index in the `SPS.particles` array
     * `faceId` is the picked face index counted within this particle.
     * This array is the first element of the pickedBySubMesh array : sps.pickBySubMesh[0].
     * It's not pertinent to use it when using a SPS with the support for MultiMaterial enabled.
     * Use the method SPS.pickedParticle(pickingInfo) instead.
     * Please read : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/picking_sps
     */
    pickedParticles: {
        idx: number;
        faceId: number;
    }[];
    /**
     * This array is populated when the SPS is set as 'pickable'
     * Each key of this array is a submesh index.
     * Each element of this array is a second array defined like this :
     * Each key of this second array is a `faceId` value that you can get from a pickResult object.
     * Each element of this second array is an object `{idx: int, faceId: int}`.
     * `idx` is the picked particle index in the `SPS.particles` array
     * `faceId` is the picked face index counted within this particle.
     * It's better to use the method SPS.pickedParticle(pickingInfo) rather than using directly this array.
     * Please read : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/picking_sps
     */
    pickedBySubMesh: {
        idx: number;
        faceId: number;
    }[][];
    /**
     * This array is populated when `enableDepthSort` is set to true.
     * Each element of this array is an instance of the class DepthSortedParticle.
     */
    depthSortedParticles: DepthSortedParticle[];
    /**
     * If the particle intersection must be computed only with the bounding sphere (no bounding box computation, so faster). (Internal use only)
     * @internal
     */
    _bSphereOnly: boolean;
    /**
     * A number to multiply the bounding sphere radius by in order to reduce it for instance. (Internal use only)
     * @internal
     */
    _bSphereRadiusFactor: number;
    protected _scene: Scene;
    protected _positions: number[];
    protected _indices: number[];
    protected _normals: number[];
    protected _colors: number[];
    protected _uvs: number[];
    protected _indices32: IndicesArray;
    protected _positions32: Float32Array;
    protected _normals32: Float32Array;
    protected _fixedNormal32: Float32Array;
    protected _colors32: Float32Array;
    protected _uvs32: Float32Array;
    protected _index: number;
    protected _updatable: boolean;
    protected _pickable: boolean;
    protected _isVisibilityBoxLocked: boolean;
    protected _alwaysVisible: boolean;
    protected _depthSort: boolean;
    protected _expandable: boolean;
    protected _shapeCounter: number;
    protected _copy: SolidParticle;
    protected _color: Color4;
    protected _computeParticleColor: boolean;
    protected _computeParticleTexture: boolean;
    protected _computeParticleRotation: boolean;
    protected _computeParticleVertex: boolean;
    protected _computeBoundingBox: boolean;
    protected _autoFixFaceOrientation: boolean;
    protected _depthSortParticles: boolean;
    protected _camera: TargetCamera;
    protected _mustUnrotateFixedNormals: boolean;
    protected _particlesIntersect: boolean;
    protected _needs32Bits: boolean;
    protected _isNotBuilt: boolean;
    protected _lastParticleId: number;
    protected _idxOfId: number[];
    protected _multimaterialEnabled: boolean;
    protected _useModelMaterial: boolean;
    protected _indicesByMaterial: number[];
    protected _materialIndexes: number[];
    protected _depthSortFunction: (p1: DepthSortedParticle, p2: DepthSortedParticle) => number;
    protected _materialSortFunction: (p1: DepthSortedParticle, p2: DepthSortedParticle) => number;
    protected _materials: Material[];
    protected _multimaterial: MultiMaterial;
    protected _materialIndexesById: any;
    protected _defaultMaterial: Material;
    protected _autoUpdateSubMeshes: boolean;
    protected _tmpVertex: SolidParticleVertex;
    protected _recomputeInvisibles: boolean;
    protected _started: boolean;
    protected _stopped: boolean;
    protected _onBeforeRenderObserver: Nullable<Observer<Scene>>;
    /**
     * The overall motion speed (0.01 is default update speed, faster updates = faster animation)
     */
    updateSpeed: number;
    /** @internal */
    protected _scaledUpdateSpeed: number;
    /**
     * Creates a SPS (Solid Particle System) object.
     * @param name (String) is the SPS name, this will be the underlying mesh name.
     * @param scene (Scene) is the scene in which the SPS is added.
     * @param options defines the options of the sps e.g.
     * * updatable (optional boolean, default true) : if the SPS must be updatable or immutable.
     * * isPickable (optional boolean, default false) : if the solid particles must be pickable.
     * * enableDepthSort (optional boolean, default false) : if the solid particles must be sorted in the geometry according to their distance to the camera.
     * * useModelMaterial (optional boolean, default false) : if the model materials must be used to create the SPS multimaterial. This enables the multimaterial supports of the SPS.
     * * enableMultiMaterial (optional boolean, default false) : if the solid particles can be given different materials.
     * * expandable (optional boolean, default false) : if particles can still be added after the initial SPS mesh creation.
     * * particleIntersection (optional boolean, default false) : if the solid particle intersections must be computed.
     * * boundingSphereOnly (optional boolean, default false) : if the particle intersection must be computed only with the bounding sphere (no bounding box computation, so faster).
     * * bSphereRadiusFactor (optional float, default 1.0) : a number to multiply the bounding sphere radius by in order to reduce it for instance.
     * * computeBoundingBox (optional boolean, default false): if the bounding box of the entire SPS will be computed (for occlusion detection, for example). If it is false, the bounding box will be the bounding box of the first particle.
     * * autoFixFaceOrientation (optional boolean, default false): if the particle face orientations will be flipped for transformations that change orientation (scale (-1, 1, 1), for example)
     * * camera (optional Camera) : the camera to use with the particule system. If not provided, use the scene active camera.
     * @param options.updatable
     * @param options.isPickable
     * @param options.enableDepthSort
     * @param options.particleIntersection
     * @param options.boundingSphereOnly
     * @param options.bSphereRadiusFactor
     * @param options.expandable
     * @param options.useModelMaterial
     * @param options.enableMultiMaterial
     * @param options.computeBoundingBox
     * @param options.autoFixFaceOrientation
     * @param options.camera
     * @example bSphereRadiusFactor = 1.0 / Math.sqrt(3.0) => the bounding sphere exactly matches a spherical mesh.
     */
    constructor(name: string, scene: Scene, options?: {
        updatable?: boolean;
        isPickable?: boolean;
        enableDepthSort?: boolean;
        particleIntersection?: boolean;
        boundingSphereOnly?: boolean;
        bSphereRadiusFactor?: number;
        expandable?: boolean;
        useModelMaterial?: boolean;
        enableMultiMaterial?: boolean;
        computeBoundingBox?: boolean;
        autoFixFaceOrientation?: boolean;
        camera?: TargetCamera;
    });
    /**
     * Builds the SPS underlying mesh. Returns a standard Mesh.
     * If no model shape was added to the SPS, the returned mesh is just a single triangular plane.
     * @returns the created mesh
     */
    buildMesh(): Mesh;
    private _getUVKind;
    /**
     * Digests the mesh and generates as many solid particles in the system as wanted. Returns the SPS.
     * These particles will have the same geometry than the mesh parts and will be positioned at the same localisation than the mesh original places.
     * Thus the particles generated from `digest()` have their property `position` set yet.
     * @param mesh ( Mesh ) is the mesh to be digested
     * @param options {facetNb} (optional integer, default 1) is the number of mesh facets per particle, this parameter is overridden by the parameter `number` if any
     * {delta} (optional integer, default 0) is the random extra number of facets per particle , each particle will have between `facetNb` and `facetNb + delta` facets
     * {number} (optional positive integer) is the wanted number of particles : each particle is built with `mesh_total_facets / number` facets
     * {storage} (optional existing array) is an array where the particles will be stored for a further use instead of being inserted in the SPS.
     * {uvKind} (optional positive integer, default 0) is the kind of UV to read from. Use -1 to deduce it from the diffuse/albedo texture (if any) of the mesh material
     * @param options.facetNb
     * @param options.number
     * @param options.delta
     * @param options.storage
     * @param options.uvKind
     * @returns the current SPS
     */
    digest(mesh: Mesh, options?: {
        facetNb?: number;
        number?: number;
        delta?: number;
        storage?: [];
        uvKind?: number;
    }): SolidParticleSystem;
    /**
     * Unrotate the fixed normals in case the mesh was built with pre-rotated particles, ex : use of positionFunction in addShape()
     * @internal
     */
    protected _unrotateFixedNormals(): void;
    /**
     * Resets the temporary working copy particle
     * @internal
     */
    protected _resetCopy(): void;
    /**
     * Inserts the shape model geometry in the global SPS mesh by updating the positions, indices, normals, colors, uvs arrays
     * @param p the current index in the positions array to be updated
     * @param ind the current index in the indices array
     * @param shape a Vector3 array, the shape geometry
     * @param positions the positions array to be updated
     * @param meshInd the shape indices array
     * @param indices the indices array to be updated
     * @param meshUV the shape uv array
     * @param uvs the uv array to be updated
     * @param meshCol the shape color array
     * @param colors the color array to be updated
     * @param meshNor the shape normals array
     * @param normals the normals array to be updated
     * @param idx the particle index
     * @param idxInShape the particle index in its shape
     * @param options the addShape() method  passed options
     * @param model
     * @model the particle model
     * @internal
     */
    protected _meshBuilder(p: number, ind: number, shape: Vector3[], positions: number[], meshInd: IndicesArray, indices: number[], meshUV: FloatArray, uvs: number[], meshCol: FloatArray, colors: number[], meshNor: FloatArray, normals: number[], idx: number, idxInShape: number, options: any, model: ModelShape): SolidParticle;
    /**
     * Returns a shape Vector3 array from positions float array
     * @param positions float array
     * @returns a vector3 array
     * @internal
     */
    protected _posToShape(positions: FloatArray): Vector3[];
    /**
     * Returns a shapeUV array from a float uvs (array deep copy)
     * @param uvs as a float array
     * @returns a shapeUV array
     * @internal
     */
    protected _uvsToShapeUV(uvs: FloatArray): number[];
    /**
     * Adds a new particle object in the particles array
     * @param idx particle index in particles array
     * @param id particle id
     * @param idxpos positionIndex : the starting index of the particle vertices in the SPS "positions" array
     * @param idxind indiceIndex : he starting index of the particle indices in the SPS "indices" array
     * @param model particle ModelShape object
     * @param shapeId model shape identifier
     * @param idxInShape index of the particle in the current model
     * @param bInfo model bounding info object
     * @param storage target storage array, if any
     * @internal
     */
    protected _addParticle(idx: number, id: number, idxpos: number, idxind: number, model: ModelShape, shapeId: number, idxInShape: number, bInfo?: Nullable<BoundingInfo>, storage?: Nullable<[]>): SolidParticle;
    /**
     * Adds some particles to the SPS from the model shape. Returns the shape id.
     * Please read the doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/immutable_sps
     * @param mesh is any Mesh object that will be used as a model for the solid particles. If the mesh does not have vertex normals, it will turn on the recomputeNormals attribute.
     * @param nb (positive integer) the number of particles to be created from this model
     * @param options {positionFunction} is an optional javascript function to called for each particle on SPS creation.
     * {vertexFunction} is an optional javascript function to called for each vertex of each particle on SPS creation
     * {storage} (optional existing array) is an array where the particles will be stored for a further use instead of being inserted in the SPS.
     * @param options.positionFunction
     * @param options.vertexFunction
     * @param options.storage
     * @returns the number of shapes in the system
     */
    addShape(mesh: AbstractMesh, nb: number, options?: {
        positionFunction?: any;
        vertexFunction?: any;
        storage?: [];
    }): number;
    /**
     * Rebuilds a particle back to its just built status : if needed, recomputes the custom positions and vertices
     * @internal
     */
    protected _rebuildParticle(particle: SolidParticle, reset?: boolean): void;
    /**
     * Rebuilds the whole mesh and updates the VBO : custom positions and vertices are recomputed if needed.
     * @param reset boolean, default false : if the particles must be reset at position and rotation zero, scaling 1, color white, initial UVs and not parented.
     * @returns the SPS.
     */
    rebuildMesh(reset?: boolean): SolidParticleSystem;
    /** Removes the particles from the start-th to the end-th included from an expandable SPS (required).
     *  Returns an array with the removed particles.
     *  If the number of particles to remove is lower than zero or greater than the global remaining particle number, then an empty array is returned.
     *  The SPS can't be empty so at least one particle needs to remain in place.
     *  Under the hood, the VertexData array, so the VBO buffer, is recreated each call.
     * @param start index of the first particle to remove
     * @param end index of the last particle to remove (included)
     * @returns an array populated with the removed particles
     */
    removeParticles(start: number, end: number): SolidParticle[];
    /**
     * Inserts some pre-created particles in the solid particle system so that they can be managed by setParticles().
     * @param solidParticleArray an array populated with Solid Particles objects
     * @returns the SPS
     */
    insertParticlesFromArray(solidParticleArray: SolidParticle[]): SolidParticleSystem;
    /**
     * Creates a new particle and modifies the SPS mesh geometry :
     * - calls _meshBuilder() to increase the SPS mesh geometry step by step
     * - calls _addParticle() to populate the particle array
     * factorized code from addShape() and insertParticlesFromArray()
     * @param idx particle index in the particles array
     * @param i particle index in its shape
     * @param modelShape particle ModelShape object
     * @param shape shape vertex array
     * @param meshInd shape indices array
     * @param meshUV shape uv array
     * @param meshCol shape color array
     * @param meshNor shape normals array
     * @param bbInfo shape bounding info
     * @param storage target particle storage
     * @param options
     * @options addShape() passed options
     * @internal
     */
    protected _insertNewParticle(idx: number, i: number, modelShape: ModelShape, shape: Vector3[], meshInd: IndicesArray, meshUV: FloatArray, meshCol: FloatArray, meshNor: FloatArray, bbInfo: Nullable<BoundingInfo>, storage: Nullable<[]>, options: any): Nullable<SolidParticle>;
    /**
     *  Sets all the particles : this method actually really updates the mesh according to the particle positions, rotations, colors, textures, etc.
     *  This method calls `updateParticle()` for each particle of the SPS.
     *  For an animated SPS, it is usually called within the render loop.
     * This methods does nothing if called on a non updatable or not yet built SPS. Example : buildMesh() not called after having added or removed particles from an expandable SPS.
     * @param start The particle index in the particle array where to start to compute the particle property values _(default 0)_
     * @param end The particle index in the particle array where to stop to compute the particle property values _(default nbParticle - 1)_
     * @param update If the mesh must be finally updated on this call after all the particle computations _(default true)_
     * @returns the SPS.
     */
    setParticles(start?: number, end?: number, update?: boolean): SolidParticleSystem;
    /**
     * Disposes the SPS.
     */
    dispose(): void;
    /** Returns an object {idx: number faceId: number} for the picked particle from the passed pickingInfo object.
     * idx is the particle index in the SPS
     * faceId is the picked face index counted within this particle.
     * Returns null if the pickInfo can't identify a picked particle.
     * @param pickingInfo (PickingInfo object)
     * @returns {idx: number, faceId: number} or null
     */
    pickedParticle(pickingInfo: PickingInfo): Nullable<{
        idx: number;
        faceId: number;
    }>;
    /**
     * Returns a SolidParticle object from its identifier : particle.id
     * @param id (integer) the particle Id
     * @returns the searched particle or null if not found in the SPS.
     */
    getParticleById(id: number): Nullable<SolidParticle>;
    /**
     * Returns a new array populated with the particles having the passed shapeId.
     * @param shapeId (integer) the shape identifier
     * @returns a new solid particle array
     */
    getParticlesByShapeId(shapeId: number): SolidParticle[];
    /**
     * Populates the passed array "ref" with the particles having the passed shapeId.
     * @param shapeId the shape identifier
     * @param ref array to populate
     * @returns the SPS
     */
    getParticlesByShapeIdToRef(shapeId: number, ref: SolidParticle[]): SolidParticleSystem;
    /**
     * Computes the required SubMeshes according the materials assigned to the particles.
     * @returns the solid particle system.
     * Does nothing if called before the SPS mesh is built.
     */
    computeSubMeshes(): SolidParticleSystem;
    /**
     * Sorts the solid particles by material when MultiMaterial is enabled.
     * Updates the indices32 array.
     * Updates the indicesByMaterial array.
     * Updates the mesh indices array.
     * @returns the SPS
     * @internal
     */
    protected _sortParticlesByMaterial(): SolidParticleSystem;
    /**
     * Sets the material indexes by id materialIndexesById[id] = materialIndex
     * @internal
     */
    protected _setMaterialIndexesById(): void;
    /**
     * Returns an array with unique values of Materials from the passed array
     * @param array the material array to be checked and filtered
     * @internal
     */
    protected _filterUniqueMaterialId(array: Material[]): Material[];
    /**
     * Sets a new Standard Material as _defaultMaterial if not already set.
     * @internal
     */
    protected _setDefaultMaterial(): Material;
    /**
     * Visibility helper : Recomputes the visible size according to the mesh bounding box
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/sps_visibility
     * @returns the SPS.
     */
    refreshVisibleSize(): SolidParticleSystem;
    /**
     * Visibility helper : Sets the size of a visibility box, this sets the underlying mesh bounding box.
     * @param size the size (float) of the visibility box
     * note : this doesn't lock the SPS mesh bounding box.
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/sps_visibility
     */
    setVisibilityBox(size: number): void;
    /**
     * Gets whether the SPS as always visible or not
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/sps_visibility
     */
    get isAlwaysVisible(): boolean;
    /**
     * Sets the SPS as always visible or not
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/sps_visibility
     */
    set isAlwaysVisible(val: boolean);
    /**
     * Sets the SPS visibility box as locked or not. This enables/disables the underlying mesh bounding box updates.
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/sps_visibility
     */
    set isVisibilityBoxLocked(val: boolean);
    /**
     * Gets if the SPS visibility box as locked or not. This enables/disables the underlying mesh bounding box updates.
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/sps_visibility
     */
    get isVisibilityBoxLocked(): boolean;
    /**
     * Tells to `setParticles()` to compute the particle rotations or not.
     * Default value : true. The SPS is faster when it's set to false.
     * Note : the particle rotations aren't stored values, so setting `computeParticleRotation` to false will prevents the particle to rotate.
     */
    set computeParticleRotation(val: boolean);
    /**
     * Tells to `setParticles()` to compute the particle colors or not.
     * Default value : true. The SPS is faster when it's set to false.
     * Note : the particle colors are stored values, so setting `computeParticleColor` to false will keep yet the last colors set.
     */
    set computeParticleColor(val: boolean);
    set computeParticleTexture(val: boolean);
    /**
     * Tells to `setParticles()` to call the vertex function for each vertex of each particle, or not.
     * Default value : false. The SPS is faster when it's set to false.
     * Note : the particle custom vertex positions aren't stored values.
     */
    set computeParticleVertex(val: boolean);
    /**
     * Tells to `setParticles()` to compute or not the mesh bounding box when computing the particle positions.
     */
    set computeBoundingBox(val: boolean);
    /**
     * Tells to `setParticles()` to sort or not the distance between each particle and the camera.
     * Skipped when `enableDepthSort` is set to `false` (default) at construction time.
     * Default : `true`
     */
    set depthSortParticles(val: boolean);
    /**
     * Gets if `setParticles()` computes the particle rotations or not.
     * Default value : true. The SPS is faster when it's set to false.
     * Note : the particle rotations aren't stored values, so setting `computeParticleRotation` to false will prevents the particle to rotate.
     */
    get computeParticleRotation(): boolean;
    /**
     * Gets if `setParticles()` computes the particle colors or not.
     * Default value : true. The SPS is faster when it's set to false.
     * Note : the particle colors are stored values, so setting `computeParticleColor` to false will keep yet the last colors set.
     */
    get computeParticleColor(): boolean;
    /**
     * Gets if `setParticles()` computes the particle textures or not.
     * Default value : true. The SPS is faster when it's set to false.
     * Note : the particle textures are stored values, so setting `computeParticleTexture` to false will keep yet the last colors set.
     */
    get computeParticleTexture(): boolean;
    /**
     * Gets if `setParticles()` calls the vertex function for each vertex of each particle, or not.
     * Default value : false. The SPS is faster when it's set to false.
     * Note : the particle custom vertex positions aren't stored values.
     */
    get computeParticleVertex(): boolean;
    /**
     * Gets if `setParticles()` computes or not the mesh bounding box when computing the particle positions.
     */
    get computeBoundingBox(): boolean;
    /**
     * Gets if `setParticles()` sorts or not the distance between each particle and the camera.
     * Skipped when `enableDepthSort` is set to `false` (default) at construction time.
     * Default : `true`
     */
    get depthSortParticles(): boolean;
    /**
     * Gets if the SPS is created as expandable at construction time.
     * Default : `false`
     */
    get expandable(): boolean;
    /**
     * Gets if the SPS supports the Multi Materials
     */
    get multimaterialEnabled(): boolean;
    /**
     * Gets if the SPS uses the model materials for its own multimaterial.
     */
    get useModelMaterial(): boolean;
    /**
     * The SPS used material array.
     */
    get materials(): Material[];
    /**
     * Sets the SPS MultiMaterial from the passed materials.
     * Note : the passed array is internally copied and not used then by reference.
     * @param materials an array of material objects. This array indexes are the materialIndex values of the particles.
     */
    setMultiMaterial(materials: Material[]): void;
    /**
     * The SPS computed multimaterial object
     */
    get multimaterial(): MultiMaterial;
    set multimaterial(mm: MultiMaterial);
    /**
     * If the subMeshes must be updated on the next call to setParticles()
     */
    get autoUpdateSubMeshes(): boolean;
    set autoUpdateSubMeshes(val: boolean);
    /**
     * This function does nothing. It may be overwritten to set all the particle first values.
     * The SPS doesn't call this function, you may have to call it by your own.
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/manage_sps_particles
     */
    initParticles(): void;
    /**
     * This function does nothing. It may be overwritten to recycle a particle.
     * The SPS doesn't call this function, you may have to call it by your own.
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/manage_sps_particles
     * @param particle The particle to recycle
     * @returns the recycled particle
     */
    recycleParticle(particle: SolidParticle): SolidParticle;
    /**
     * Updates a particle : this function should  be overwritten by the user.
     * It is called on each particle by `setParticles()`. This is the place to code each particle behavior.
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/manage_sps_particles
     * @example : just set a particle position or velocity and recycle conditions
     * @param particle The particle to update
     * @returns the updated particle
     */
    updateParticle(particle: SolidParticle): SolidParticle;
    /**
     * Updates a vertex of a particle : it can be overwritten by the user.
     * This will be called on each vertex particle by `setParticles()` if `computeParticleVertex` is set to true only.
     * @param particle the current particle
     * @param vertex the current vertex of the current particle : a SolidParticleVertex object
     * @param pt the index of the current vertex in the particle shape
     * doc : https://doc.babylonjs.com/features/featuresDeepDive/particles/solid_particle_system/sps_vertices
     * @example : just set a vertex particle position or color
     * @returns the sps
     */
    updateParticleVertex(particle: SolidParticle, vertex: SolidParticleVertex, pt: number): SolidParticleSystem;
    /**
     * This will be called before any other treatment by `setParticles()` and will be passed three parameters.
     * This does nothing and may be overwritten by the user.
     * @param start the particle index in the particle array where to stop to iterate, same than the value passed to setParticle()
     * @param stop the particle index in the particle array where to stop to iterate, same than the value passed to setParticle()
     * @param update the boolean update value actually passed to setParticles()
     */
    beforeUpdateParticles(start?: number, stop?: number, update?: boolean): void;
    /**
     * This will be called  by `setParticles()` after all the other treatments and just before the actual mesh update.
     * This will be passed three parameters.
     * This does nothing and may be overwritten by the user.
     * @param start the particle index in the particle array where to stop to iterate, same than the value passed to setParticle()
     * @param stop the particle index in the particle array where to stop to iterate, same than the value passed to setParticle()
     * @param update the boolean update value actually passed to setParticles()
     */
    afterUpdateParticles(start?: number, stop?: number, update?: boolean): void;
    /**
     * Starts the particle system and begins to emit.
     * This will call buildMesh(), initParticles(), setParticles() and register the update loop.
     * @param delay defines the delay in milliseconds before starting the system (0 by default)
     */
    start(delay?: number): void;
    /**
     * Stops the particle system.
     */
    stop(): void;
    /**
     * Gets if the particle system is started
     */
    get started(): boolean;
    /**
     * Gets if the particle system is stopped
     */
    get stopped(): boolean;
}

/**
 * Represents one particle of a solid particle system.
 */
declare class SolidParticle {
    /**
     * particle global index
     */
    idx: number;
    /**
     * particle identifier
     */
    id: number;
    /**
     * The color of the particle
     */
    color: Nullable<Color4>;
    /**
     * The world space position of the particle.
     */
    position: Vector3;
    /**
     * The world space rotation of the particle. (Not use if rotationQuaternion is set)
     */
    rotation: Vector3;
    /**
     * The world space rotation quaternion of the particle.
     */
    rotationQuaternion: Nullable<Quaternion>;
    /**
     * The scaling of the particle.
     */
    scaling: Vector3;
    /**
     * The uvs of the particle.
     */
    uvs: Vector4;
    /**
     * The current speed of the particle.
     */
    velocity: Vector3;
    /**
     * The pivot point in the particle local space.
     */
    pivot: Vector3;
    /**
     * Must the particle be translated from its pivot point in its local space ?
     * In this case, the pivot point is set at the origin of the particle local space and the particle is translated.
     * Default : false
     */
    translateFromPivot: boolean;
    /**
     * Is the particle active or not ?
     */
    alive: boolean;
    /**
     * Is the particle visible or not ?
     */
    isVisible: boolean;
    /**
     * Defines how long will the life of the particle be.
     * Set to Infinity for particles that should never die (default behavior for SolidParticleSystem).
     */
    lifeTime: number;
    /**
     * The current age of the particle.
     */
    age: number;
    /**
     * Index of this particle in the global "positions" array (Internal use)
     * @internal
     */
    _pos: number;
    /**
     * @internal Index of this particle in the global "indices" array (Internal use)
     */
    _ind: number;
    /**
     * @internal ModelShape of this particle (Internal use)
     */
    _model: ModelShape;
    /**
     * ModelShape id of this particle
     */
    shapeId: number;
    /**
     * Index of the particle in its shape id
     */
    idxInShape: number;
    /**
     * @internal Reference to the shape model BoundingInfo object (Internal use)
     */
    _modelBoundingInfo: BoundingInfo;
    private _boundingInfo;
    /**
     * @internal Reference to the SPS what the particle belongs to (Internal use)
     */
    _sps: SolidParticleSystem;
    /**
     * @internal Still set as invisible in order to skip useless computations (Internal use)
     */
    _stillInvisible: boolean;
    /**
     * @internal Last computed particle rotation matrix
     */
    _rotationMatrix: number[];
    /**
     * Parent particle Id, if any.
     * Default null.
     */
    parentId: Nullable<number>;
    /**
     * The particle material identifier (integer) when MultiMaterials are enabled in the SPS.
     */
    materialIndex: Nullable<number>;
    /**
     * Custom object or properties.
     */
    props: Nullable<any>;
    /**
     * The culling strategy to use to check whether the solid particle must be culled or not when using isInFrustum().
     * The possible values are :
     * - AbstractMesh.CULLINGSTRATEGY_STANDARD
     * - AbstractMesh.CULLINGSTRATEGY_BOUNDINGSPHERE_ONLY
     * - AbstractMesh.CULLINGSTRATEGY_OPTIMISTIC_INCLUSION
     * - AbstractMesh.CULLINGSTRATEGY_OPTIMISTIC_INCLUSION_THEN_BSPHERE_ONLY
     * The default value for solid particles is AbstractMesh.CULLINGSTRATEGY_BOUNDINGSPHERE_ONLY
     * Please read each static variable documentation in the class AbstractMesh to get details about the culling process.
     * */
    cullingStrategy: number;
    /**
     * @internal Internal global position in the SPS.
     */
    _globalPosition: Vector3;
    /**
     * Particle BoundingInfo object
     * @returns a BoundingInfo
     */
    getBoundingInfo(): BoundingInfo;
    /**
     * Returns true if there is already a bounding info
     */
    get hasBoundingInfo(): boolean;
    /**
     * Creates a Solid Particle object.
     * Don't create particles manually, use instead the Solid Particle System internal tools like _addParticle()
     * @param particleIndex (integer) is the particle index in the Solid Particle System pool.
     * @param particleId (integer) is the particle identifier. Unless some particles are removed from the SPS, it's the same value than the particle idx.
     * @param positionIndex (integer) is the starting index of the particle vertices in the SPS "positions" array.
     * @param indiceIndex (integer) is the starting index of the particle indices in the SPS "indices" array.
     * @param model (ModelShape) is a reference to the model shape on what the particle is designed.
     * @param shapeId (integer) is the model shape identifier in the SPS.
     * @param idxInShape (integer) is the index of the particle in the current model (ex: the 10th box of addShape(box, 30))
     * @param sps defines the sps it is associated to
     * @param modelBoundingInfo is the reference to the model BoundingInfo used for intersection computations.
     * @param materialIndex is the particle material identifier (integer) when the MultiMaterials are enabled in the SPS.
     */
    constructor(particleIndex: number, particleId: number, positionIndex: number, indiceIndex: number, model: Nullable<ModelShape>, shapeId: number, idxInShape: number, sps: SolidParticleSystem, modelBoundingInfo?: Nullable<BoundingInfo>, materialIndex?: Nullable<number>);
    /**
     * Copies the particle property values into the existing target : position, rotation, scaling, uvs, colors, pivot, parent, visibility, alive
     * @param target the particle target
     * @returns the current particle
     */
    copyToRef(target: SolidParticle): SolidParticle;
    /**
     * Legacy support, changed scale to scaling
     */
    get scale(): Vector3;
    /**
     * Legacy support, changed scale to scaling
     */
    set scale(scale: Vector3);
    /**
     * Legacy support, changed quaternion to rotationQuaternion
     */
    get quaternion(): Nullable<Quaternion>;
    /**
     * Legacy support, changed quaternion to rotationQuaternion
     */
    set quaternion(q: Nullable<Quaternion>);
    /**
     * Returns a boolean. True if the particle intersects another particle or another mesh, else false.
     * The intersection is computed on the particle bounding sphere and Axis Aligned Bounding Box (AABB)
     * @param target is the object (solid particle or mesh) what the intersection is computed against.
     * @returns true if it intersects
     */
    intersectsMesh(target: Mesh | SolidParticle): boolean;
    /**
     * Returns `true` if the solid particle is within the frustum defined by the passed array of planes.
     * A particle is in the frustum if its bounding box intersects the frustum
     * @param frustumPlanes defines the frustum to test
     * @returns true if the particle is in the frustum planes
     */
    isInFrustum(frustumPlanes: Plane[]): boolean;
    /**
     * get the rotation matrix of the particle
     * @internal
     */
    getRotationMatrix(m: Matrix): void;
}
/**
 * Represents the shape of the model used by one particle of a solid particle system.
 * SPS internal tool, don't use it manually.
 */
declare class ModelShape {
    /**
     * Get or set the shapeId
     * @deprecated Please use shapeId instead
     */
    get shapeID(): number;
    set shapeID(shapeID: number);
    /**
     * The shape id
     * @internal
     */
    shapeId: number;
    /**
     * flat array of model positions (internal use)
     * @internal
     */
    _shape: Vector3[];
    /**
     * flat array of model UVs (internal use)
     * @internal
     */
    _shapeUV: number[];
    /**
     * color array of the model
     * @internal
     */
    _shapeColors: number[];
    /**
     * indices array of the model
     * @internal
     */
    _indices: number[];
    /**
     * normals array of the model
     * @internal
     */
    _normals: number[];
    /**
     * length of the shape in the model indices array (internal use)
     * @internal
     */
    _indicesLength: number;
    /**
     * Custom position function (internal use)
     * @internal
     */
    _positionFunction: Nullable<(particle: SolidParticle, i: number, s: number) => void>;
    /**
     * Custom vertex function (internal use)
     * @internal
     */
    _vertexFunction: Nullable<(particle: SolidParticle, vertex: Vector3, i: number) => void>;
    /**
     * Model material (internal use)
     * @internal
     */
    _material: Nullable<Material>;
    /**
     * Creates a ModelShape object. This is an internal simplified reference to a mesh used as for a model to replicate particles from by the SPS.
     * SPS internal tool, don't use it manually.
     * @internal
     */
    constructor(id: number, shape: Vector3[], indices: number[], normals: number[], colors: number[], shapeUV: number[], posFunction: Nullable<(particle: SolidParticle, i: number, s: number) => void>, vtxFunction: Nullable<(particle: SolidParticle, vertex: Vector3, i: number) => void>, material: Nullable<Material>);
}
/**
 * Represents a Depth Sorted Particle in the solid particle system.
 * @internal
 */
declare class DepthSortedParticle {
    /**
     * Particle index
     */
    idx: number;
    /**
     * Index of the particle in the "indices" array
     */
    ind: number;
    /**
     * Length of the particle shape in the "indices" array
     */
    indicesLength: number;
    /**
     * Squared distance from the particle to the camera
     */
    sqDistance: number;
    /**
     * Material index when used with MultiMaterials
     */
    materialIndex: number;
    /**
     * Creates a new sorted particle
     * @param idx
     * @param ind
     * @param indLength
     * @param materialIndex
     */
    constructor(idx: number, ind: number, indLength: number, materialIndex: number);
}
/**
 * Represents a solid particle vertex
 */
declare class SolidParticleVertex {
    /**
     * Vertex position
     */
    position: Vector3;
    /**
     * Vertex color
     */
    color: Color4;
    /**
     * Vertex UV
     */
    uv: Vector2;
    /**
     * Creates a new solid particle vertex
     */
    constructor();
    /** Vertex x coordinate */
    get x(): number;
    set x(val: number);
    /** Vertex y coordinate */
    get y(): number;
    set y(val: number);
    /** Vertex z coordinate */
    get z(): number;
    set z(val: number);
}

/**
 * @internal
 */
declare class _MeshCollisionData {
    _checkCollisions: boolean;
    _collisionMask: number;
    _collisionGroup: number;
    _surroundingMeshes: Nullable<AbstractMesh[]>;
    _collider: Nullable<Collider>;
    _oldPositionForCollisions: Vector3;
    _diffPositionForCollisions: Vector3;
    _onCollideObserver: Nullable<Observer<AbstractMesh>>;
    _onCollisionPositionChangeObserver: Nullable<Observer<Vector3>>;
    _collisionResponse: boolean;
}

/**
 * Opaque cache when computing data about a mesh
 */
interface IMeshDataCache {
    /** @internal */
    _outputData?: Float32Array;
    /** @internal */
    _vertexData?: {
        [kind: string]: Float32Array;
    };
}
/**
 * Options when computing data about a mesh
 */
interface IMeshDataOptions {
    /** Apply skeleton when computing the bounding info. Defaults to false. */
    applySkeleton?: boolean;
    /** Apply morph when computing the bounding info. Defaults to false. */
    applyMorph?: boolean;
    /** Update the cached positions stored as a Vector3 array. Defaults to true. */
    updatePositionsArray?: boolean;
    /**
     * Cache to avoid redundant allocations and computations when computing the bounding info multiple times. Pass in
     * an initial empty object and continue with subsequent calls using the same object. Caching is disabled by default.
     */
    cache?: IMeshDataCache;
}
/** @internal */
declare class _FacetDataStorage {
    facetPositions: Vector3[];
    facetNormals: Vector3[];
    facetPartitioning: number[][];
    facetNb: number;
    partitioningSubdivisions: number;
    partitioningBBoxRatio: number;
    facetDataEnabled: boolean;
    facetParameters: any;
    bbSize: Vector3;
    subDiv: {
        max: number;
        X: number;
        Y: number;
        Z: number;
    };
    facetDepthSort: boolean;
    facetDepthSortEnabled: boolean;
    depthSortedIndices: IndicesArray;
    depthSortedFacets: {
        ind: number;
        sqDistance: number;
    }[];
    facetDepthSortFunction: (f1: {
        ind: number;
        sqDistance: number;
    }, f2: {
        ind: number;
        sqDistance: number;
    }) => number;
    facetDepthSortFrom: Vector3;
    facetDepthSortOrigin: Vector3;
    invertedMatrix: Matrix;
}
/**
 * @internal
 **/
declare class _InternalAbstractMeshDataInfo {
    _hasVertexAlpha: boolean;
    _useVertexColors: boolean;
    _numBoneInfluencers: number;
    _applyFog: boolean;
    _receiveShadows: boolean;
    _facetData: _FacetDataStorage;
    _visibility: number;
    _skeleton: Nullable<Skeleton>;
    _layerMask: number;
    _computeBonesUsingShaders: boolean;
    _isActive: boolean;
    _onlyForInstances: boolean;
    _isActiveIntermediate: boolean;
    _onlyForInstancesIntermediate: boolean;
    _actAsRegularMesh: boolean;
    _currentLOD: Map<Camera, [Nullable<AbstractMesh>, number]>;
    _collisionRetryCount: number;
    _morphTargetManager: Nullable<MorphTargetManager>;
    _renderingGroupId: number;
    _bakedVertexAnimationManager: Nullable<IBakedVertexAnimationManager>;
    _material: Nullable<Material>;
    _materialForRenderPass: Array<Material | undefined>;
    _positions: Nullable<Vector3[]>;
    _pointerOverDisableMeshTesting: boolean;
    _meshCollisionData: _MeshCollisionData;
    _enableDistantPicking: boolean;
    /** @internal
     * Bounding info that is unnafected by the addition of thin instances
     */
    _rawBoundingInfo: Nullable<BoundingInfo>;
    /** @internal
     * This value will indicate us that at some point, the mesh was specifically used with the opposite winding order
     * We use that as a clue to force the material to sideOrientation = null
     */
    _sideOrientationHint: boolean;
    /**
     * Used in frame graph mode only, to know which meshes to update when in frozen mode
     */
    _wasActiveLastFrame: boolean;
}
/**
 * Class used to store all common mesh properties
 */
declare abstract class AbstractMesh extends TransformNode implements IDisposable, ICullable, IGetSetVerticesData {
    /** No occlusion */
    static OCCLUSION_TYPE_NONE: number;
    /** Occlusion set to optimistic */
    static OCCLUSION_TYPE_OPTIMISTIC: number;
    /** Occlusion set to strict */
    static OCCLUSION_TYPE_STRICT: number;
    /** Use an accurate occlusion algorithm */
    static OCCLUSION_ALGORITHM_TYPE_ACCURATE: number;
    /** Use a conservative occlusion algorithm */
    static OCCLUSION_ALGORITHM_TYPE_CONSERVATIVE: number;
    /** Default culling strategy : this is an exclusion test and it's the more accurate.
     *  Test order :
     *  Is the bounding sphere outside the frustum ?
     *  If not, are the bounding box vertices outside the frustum ?
     *  It not, then the cullable object is in the frustum.
     */
    static readonly CULLINGSTRATEGY_STANDARD = 0;
    /** Culling strategy : Bounding Sphere Only.
     *  This is an exclusion test. It's faster than the standard strategy because the bounding box is not tested.
     *  It's also less accurate than the standard because some not visible objects can still be selected.
     *  Test : is the bounding sphere outside the frustum ?
     *  If not, then the cullable object is in the frustum.
     */
    static readonly CULLINGSTRATEGY_BOUNDINGSPHERE_ONLY = 1;
    /** Culling strategy : Optimistic Inclusion.
     *  This in an inclusion test first, then the standard exclusion test.
     *  This can be faster when a cullable object is expected to be almost always in the camera frustum.
     *  This could also be a little slower than the standard test when the tested object center is not the frustum but one of its bounding box vertex is still inside.
     *  Anyway, it's as accurate as the standard strategy.
     *  Test :
     *  Is the cullable object bounding sphere center in the frustum ?
     *  If not, apply the default culling strategy.
     */
    static readonly CULLINGSTRATEGY_OPTIMISTIC_INCLUSION = 2;
    /** Culling strategy : Optimistic Inclusion then Bounding Sphere Only.
     *  This in an inclusion test first, then the bounding sphere only exclusion test.
     *  This can be the fastest test when a cullable object is expected to be almost always in the camera frustum.
     *  This could also be a little slower than the BoundingSphereOnly strategy when the tested object center is not in the frustum but its bounding sphere still intersects it.
     *  It's less accurate than the standard strategy and as accurate as the BoundingSphereOnly strategy.
     *  Test :
     *  Is the cullable object bounding sphere center in the frustum ?
     *  If not, apply the Bounding Sphere Only strategy. No Bounding Box is tested here.
     */
    static readonly CULLINGSTRATEGY_OPTIMISTIC_INCLUSION_THEN_BSPHERE_ONLY = 3;
    /**
     * No billboard
     */
    static get BILLBOARDMODE_NONE(): number;
    /** Billboard on X axis */
    static get BILLBOARDMODE_X(): number;
    /** Billboard on Y axis */
    static get BILLBOARDMODE_Y(): number;
    /** Billboard on Z axis */
    static get BILLBOARDMODE_Z(): number;
    /** Billboard on all axes */
    static get BILLBOARDMODE_ALL(): number;
    /** Billboard on using position instead of orientation */
    static get BILLBOARDMODE_USE_POSITION(): number;
    /** @internal */
    _internalAbstractMeshDataInfo: _InternalAbstractMeshDataInfo;
    /** @internal */
    _waitingMaterialId: Nullable<string>;
    /** @internal */
    _waitingMorphTargetManagerId: Nullable<number>;
    /**
     * The culling strategy to use to check whether the mesh must be rendered or not.
     * This value can be changed at any time and will be used on the next render mesh selection.
     * The possible values are :
     * - AbstractMesh.CULLINGSTRATEGY_STANDARD
     * - AbstractMesh.CULLINGSTRATEGY_BOUNDINGSPHERE_ONLY
     * - AbstractMesh.CULLINGSTRATEGY_OPTIMISTIC_INCLUSION
     * - AbstractMesh.CULLINGSTRATEGY_OPTIMISTIC_INCLUSION_THEN_BSPHERE_ONLY
     * Please read each static variable documentation to get details about the culling process.
     * */
    cullingStrategy: number;
    /**
     * Gets the number of facets in the mesh
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData#what-is-a-mesh-facet
     */
    get facetNb(): number;
    /**
     * Gets or set the number (integer) of subdivisions per axis in the partitioning space
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData#tweaking-the-partitioning
     */
    get partitioningSubdivisions(): number;
    set partitioningSubdivisions(nb: number);
    /**
     * The ratio (float) to apply to the bounding box size to set to the partitioning space.
     * Ex : 1.01 (default) the partitioning space is 1% bigger than the bounding box
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData#tweaking-the-partitioning
     */
    get partitioningBBoxRatio(): number;
    set partitioningBBoxRatio(ratio: number);
    /**
     * Gets or sets a boolean indicating that the facets must be depth sorted on next call to `updateFacetData()`.
     * Works only for updatable meshes.
     * Doesn't work with multi-materials
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData#facet-depth-sort
     */
    get mustDepthSortFacets(): boolean;
    set mustDepthSortFacets(sort: boolean);
    /**
     * The location (Vector3) where the facet depth sort must be computed from.
     * By default, the active camera position.
     * Used only when facet depth sort is enabled
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData#facet-depth-sort
     */
    get facetDepthSortFrom(): Vector3;
    set facetDepthSortFrom(location: Vector3);
    /** number of collision detection tries. Change this value if not all collisions are detected and handled properly */
    get collisionRetryCount(): number;
    set collisionRetryCount(retryCount: number);
    /**
     * gets a boolean indicating if facetData is enabled
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData#what-is-a-mesh-facet
     */
    get isFacetDataEnabled(): boolean;
    /**
     * Gets or sets the morph target manager
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/morphTargets
     */
    get morphTargetManager(): Nullable<MorphTargetManager>;
    set morphTargetManager(value: Nullable<MorphTargetManager>);
    /**
     * Gets or sets the baked vertex animation manager
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/baked_texture_animations
     */
    get bakedVertexAnimationManager(): Nullable<IBakedVertexAnimationManager>;
    set bakedVertexAnimationManager(value: Nullable<IBakedVertexAnimationManager>);
    /** @internal */
    _syncGeometryWithMorphTargetManager(): void;
    /**
     * @internal
     */
    _updateNonUniformScalingState(value: boolean): boolean;
    /** @internal */
    get rawBoundingInfo(): Nullable<BoundingInfo>;
    set rawBoundingInfo(boundingInfo: Nullable<BoundingInfo>);
    /**
     * An event triggered when this mesh collides with another one
     */
    onCollideObservable: Observable<AbstractMesh>;
    /** Set a function to call when this mesh collides with another one */
    set onCollide(callback: (collidedMesh?: AbstractMesh) => void);
    /**
     * An event triggered when the collision's position changes
     */
    onCollisionPositionChangeObservable: Observable<Vector3>;
    /** Set a function to call when the collision's position changes */
    set onCollisionPositionChange(callback: () => void);
    /**
     * An event triggered when material is changed
     */
    onMaterialChangedObservable: Observable<AbstractMesh>;
    /**
     * Gets or sets the orientation for POV movement & rotation
     */
    definedFacingForward: boolean;
    /** @internal */
    _occlusionQuery: Nullable<WebGLQuery | number>;
    /** @internal */
    _renderingGroup: Nullable<RenderingGroup>;
    /**
     * Gets or sets mesh visibility between 0 and 1 (default is 1)
     */
    get visibility(): number;
    /**
     * Gets or sets mesh visibility between 0 and 1 (default is 1)
     */
    set visibility(value: number);
    /** Gets or sets the alpha index used to sort transparent meshes
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/advanced/transparent_rendering#alpha-index
     */
    alphaIndex: number;
    /**
     * Gets or sets a boolean indicating if the mesh can be picked (by scene.pick for instance or through actions). Default is true
     */
    isPickable: boolean;
    /**
     * Gets or sets a boolean indicating if the mesh can be near picked (touched by the XR controller or hands). Default is false
     */
    isNearPickable: boolean;
    /**
     * Gets or sets a boolean indicating if the mesh can be grabbed. Default is false.
     * Setting this to true, while using the XR near interaction feature, will trigger a pointer event when the mesh is grabbed.
     * Grabbing means that the controller is using the squeeze or main trigger button to grab the mesh.
     * This is different from nearPickable which only triggers the event when the mesh is touched by the controller
     */
    isNearGrabbable: boolean;
    /** Gets or sets a boolean indicating that bounding boxes of subMeshes must be rendered as well (false by default) */
    showSubMeshesBoundingBox: boolean;
    /** Gets or sets a boolean indicating if the mesh must be considered as a ray blocker for lens flares (false by default)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/lenseFlare
     */
    isBlocker: boolean;
    /**
     * Gets or sets a boolean indicating that pointer move events must be supported on this mesh (false by default)
     */
    enablePointerMoveEvents: boolean;
    /**
     * Gets or sets the property which disables the test that is checking that the mesh under the pointer is the same than the previous time we tested for it (default: false).
     * Set this property to true if you want thin instances picking to be reported accurately when moving over the mesh.
     * Note that setting this property to true will incur some performance penalties when dealing with pointer events for this mesh so use it sparingly.
     */
    get pointerOverDisableMeshTesting(): boolean;
    set pointerOverDisableMeshTesting(disable: boolean);
    /**
     * Specifies the rendering group id for this mesh (0 by default)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/advanced/transparent_rendering#rendering-groups
     */
    get renderingGroupId(): number;
    set renderingGroupId(value: number);
    /** Gets or sets current material */
    get material(): Nullable<Material>;
    set material(value: Nullable<Material>);
    /** @internal */
    protected _setMaterial(value: Nullable<Material>): void;
    /**
     * Gets the material used to render the mesh in a specific render pass
     * @param renderPassId render pass id
     * @returns material used for the render pass. If no specific material is used for this render pass, undefined is returned (meaning mesh.material is used for this pass)
     */
    getMaterialForRenderPass(renderPassId: number): Material | undefined;
    /**
     * Sets the material to be used to render the mesh in a specific render pass
     * @param renderPassId render pass id
     * @param material material to use for this render pass. If undefined is passed, no specific material will be used for this render pass but the regular material will be used instead (mesh.material)
     */
    setMaterialForRenderPass(renderPassId: number, material?: Material): void;
    /**
     * Gets or sets a boolean indicating that this mesh can receive realtime shadows
     * @see https://doc.babylonjs.com/features/featuresDeepDive/lights/shadows
     */
    get receiveShadows(): boolean;
    set receiveShadows(value: boolean);
    /** Defines color to use when rendering outline */
    outlineColor: Color3;
    /** Define width to use when rendering outline */
    outlineWidth: number;
    /** Defines color to use when rendering overlay */
    overlayColor: Color3;
    /** Defines alpha to use when rendering overlay */
    overlayAlpha: number;
    /**
     * Gets or sets a boolean indicating that this mesh needs to use vertex alpha data to render.
     * This property is misnamed and should be `useVertexAlpha`. Note that the mesh will be rendered
     * with alpha blending when this flag is set even if vertex alpha data is missing from the geometry.
     */
    get hasVertexAlpha(): boolean;
    set hasVertexAlpha(value: boolean);
    /** Gets or sets a boolean indicating that this mesh needs to use vertex color data to render (if this kind of vertex data is available in the geometry) */
    get useVertexColors(): boolean;
    set useVertexColors(value: boolean);
    /**
     * Gets or sets a boolean indicating that bone animations must be computed by the GPU (true by default)
     */
    get computeBonesUsingShaders(): boolean;
    set computeBonesUsingShaders(value: boolean);
    /** Gets or sets the number of allowed bone influences per vertex (4 by default) */
    get numBoneInfluencers(): number;
    set numBoneInfluencers(value: number);
    /** Gets or sets a boolean indicating that this mesh will allow fog to be rendered on it (true by default) */
    get applyFog(): boolean;
    set applyFog(value: boolean);
    /** When enabled, decompose picking matrices for better precision with large values for mesh position and scling */
    get enableDistantPicking(): boolean;
    set enableDistantPicking(value: boolean);
    /** Gets or sets a boolean indicating that internal octree (if available) can be used to boost submeshes selection (true by default) */
    useOctreeForRenderingSelection: boolean;
    /** Gets or sets a boolean indicating that internal octree (if available) can be used to boost submeshes picking (true by default) */
    useOctreeForPicking: boolean;
    /** Gets or sets a boolean indicating that internal octree (if available) can be used to boost submeshes collision (true by default) */
    useOctreeForCollisions: boolean;
    /**
     * Gets or sets the current layer mask (default is 0x0FFFFFFF)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/layerMasksAndMultiCam
     */
    get layerMask(): number;
    set layerMask(value: number);
    /**
     * True if the mesh must be rendered in any case (this will shortcut the frustum clipping phase)
     */
    alwaysSelectAsActiveMesh: boolean;
    /**
     * Gets or sets a boolean indicating that the bounding info does not need to be kept in sync (for performance reason)
     */
    doNotSyncBoundingInfo: boolean;
    /**
     * Gets or sets the current action manager
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions
     */
    actionManager: Nullable<AbstractActionManager>;
    /**
     * Gets or sets the ellipsoid used to impersonate this mesh when using collision engine (default is (0.5, 1, 0.5))
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_collisions
     */
    ellipsoid: Vector3;
    /**
     * Gets or sets the ellipsoid offset used to impersonate this mesh when using collision engine (default is (0, 0, 0))
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_collisions
     */
    ellipsoidOffset: Vector3;
    /**
     * Gets or sets a collision mask used to mask collisions (default is -1).
     * A collision between A and B will happen if A.collisionGroup & b.collisionMask !== 0
     */
    get collisionMask(): number;
    set collisionMask(mask: number);
    /**
     * Gets or sets a collision response flag (default is true).
     * when collisionResponse is false, events are still triggered but colliding entity has no response
     * This helps creating trigger volume when user wants collision feedback events but not position/velocity
     * to respond to the collision.
     */
    get collisionResponse(): boolean;
    set collisionResponse(response: boolean);
    /**
     * Gets or sets the current collision group mask (-1 by default).
     * A collision between A and B will happen if A.collisionGroup & b.collisionMask !== 0
     */
    get collisionGroup(): number;
    set collisionGroup(mask: number);
    /**
     * Gets or sets current surrounding meshes (null by default).
     *
     * By default collision detection is tested against every mesh in the scene.
     * It is possible to set surroundingMeshes to a defined list of meshes and then only these specified
     * meshes will be tested for the collision.
     *
     * Note: if set to an empty array no collision will happen when this mesh is moved.
     */
    get surroundingMeshes(): Nullable<AbstractMesh[]>;
    set surroundingMeshes(meshes: Nullable<AbstractMesh[]>);
    /**
     * Defines edge width used when edgesRenderer is enabled
     * @see https://www.babylonjs-playground.com/#10OJSG#13
     */
    edgesWidth: number;
    /**
     * Defines edge color used when edgesRenderer is enabled
     * @see https://www.babylonjs-playground.com/#10OJSG#13
     */
    edgesColor: Color4;
    /** @internal */
    _edgesRenderer: Nullable<IEdgesRenderer>;
    /** @internal */
    _masterMesh: Nullable<AbstractMesh>;
    protected _boundingInfo: Nullable<BoundingInfo>;
    protected _boundingInfoIsDirty: boolean;
    /** @internal */
    _renderId: number;
    /**
     * Gets or sets the list of subMeshes
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/multiMaterials
     */
    subMeshes: SubMesh[];
    /** @internal */
    _intersectionsInProgress: AbstractMesh[];
    /** @internal */
    _unIndexed: boolean;
    /** @internal */
    _lightSources: Light[];
    /** Gets the list of lights affecting that mesh */
    get lightSources(): Light[];
    /** @internal */
    abstract get _positions(): Nullable<Vector3[]>;
    /** @internal */
    _waitingData: {
        lods: Nullable<any>;
        actions: Nullable<any>;
        freezeWorldMatrix: Nullable<boolean>;
    };
    /** @internal */
    _bonesTransformMatrices: Nullable<Float32Array>;
    /** @internal */
    _transformMatrixTexture: Nullable<RawTexture>;
    /**
     * Gets or sets a skeleton to apply skinning transformations
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/bonesSkeletons
     */
    set skeleton(value: Nullable<Skeleton>);
    get skeleton(): Nullable<Skeleton>;
    /**
     * An event triggered when the mesh is rebuilt.
     */
    onRebuildObservable: Observable<AbstractMesh>;
    /**
     * The current mesh uniform buffer.
     * @internal Internal use only.
     */
    _uniformBuffer: UniformBuffer;
    /**
     * Creates a new AbstractMesh
     * @param name defines the name of the mesh
     * @param scene defines the hosting scene
     */
    constructor(name: string, scene?: Nullable<Scene>);
    protected _buildUniformLayout(): void;
    /**
     * Transfer the mesh values to its UBO.
     * @param world The world matrix associated with the mesh
     */
    transferToEffect(world: Matrix): void;
    /**
     * Gets the mesh uniform buffer.
     * @returns the uniform buffer of the mesh.
     */
    getMeshUniformBuffer(): UniformBuffer;
    /**
     * Returns the string "AbstractMesh"
     * @returns "AbstractMesh"
     */
    getClassName(): string;
    /**
     * Gets a string representation of the current mesh
     * @param fullDetails defines a boolean indicating if full details must be included
     * @returns a string representation of the current mesh
     */
    toString(fullDetails?: boolean): string;
    /**
     * @internal
     */
    protected _getEffectiveParent(): Nullable<Node>;
    /**
     * @internal
     */
    _getActionManagerForTrigger(trigger?: number, initialCall?: boolean): Nullable<AbstractActionManager>;
    /**
     * @internal
     */
    _rebuild(dispose?: boolean): void;
    /** @internal */
    _resyncLightSources(): void;
    /**
     * @internal
     */
    _resyncLightSource(light: Light): void;
    /** @internal */
    _unBindEffect(): void;
    /**
     * @internal
     */
    _removeLightSource(light: Light, dispose: boolean): void;
    private _markSubMeshesAsDirty;
    /**
     * @internal
     */
    _markSubMeshesAsLightDirty(dispose?: boolean): void;
    /** @internal */
    _markSubMeshesAsAttributesDirty(): void;
    /** @internal */
    _markSubMeshesAsMiscDirty(): void;
    /**
     * Flag the AbstractMesh as dirty (Forcing it to update everything)
     * @param property if set to "rotation" the objects rotationQuaternion will be set to null
     * @returns this AbstractMesh
     */
    markAsDirty(property?: string): AbstractMesh;
    /**
     * Resets the draw wrappers cache for all submeshes of this abstract mesh
     * @param passId If provided, releases only the draw wrapper corresponding to this render pass id
     * @param immediate If true, the effect will be released immediately, otherwise it will be released at the next frame
     */
    resetDrawCache(passId?: number, immediate?: boolean): void;
    /**
     * Returns true if the mesh is blocked. Implemented by child classes
     */
    get isBlocked(): boolean;
    /**
     * Returns the mesh itself by default. Implemented by child classes
     * @param camera defines the camera to use to pick the right LOD level
     * @returns the currentAbstractMesh
     */
    getLOD(camera: Camera): Nullable<AbstractMesh>;
    /**
     * The mesh's internal Geometry object. Implemented by child classes.
     */
    abstract get geometry(): Nullable<Geometry>;
    /**
     * Returns 0 by default. Implemented by child classes
     * @returns an integer
     */
    getTotalVertices(): number;
    /**
     * Returns a positive integer : the total number of indices in this mesh geometry.
     * @returns the number of indices or zero if the mesh has no geometry.
     */
    getTotalIndices(): number;
    /**
     * Returns null by default. Implemented by child classes
     * @returns null
     */
    getIndices(): Nullable<IndicesArray>;
    /**
     * Returns the array of the requested vertex data kind. Implemented by child classes
     * @param kind defines the vertex data kind to use
     * @returns null
     */
    getVerticesData(kind: string): Nullable<FloatArray>;
    /**
     * Copies the requested vertex data kind into the given vertex data map. Float data is constructed if the map doesn't have the data.
     * @param kind defines the vertex data kind to use
     * @param vertexData defines the map that stores the resulting data
     */
    abstract copyVerticesData(kind: string, vertexData: {
        [kind: string]: Float32Array;
    }): void;
    /**
     * Returns the mesh VertexBuffer object from the requested `kind`
     * @param kind defines which buffer to read from (positions, indices, normals, etc). Possible `kind` values :
     * - VertexBuffer.PositionKind
     * - VertexBuffer.NormalKind
     * - VertexBuffer.UVKind
     * - VertexBuffer.UV2Kind
     * - VertexBuffer.UV3Kind
     * - VertexBuffer.UV4Kind
     * - VertexBuffer.UV5Kind
     * - VertexBuffer.UV6Kind
     * - VertexBuffer.ColorKind
     * - VertexBuffer.MatricesIndicesKind
     * - VertexBuffer.MatricesIndicesExtraKind
     * - VertexBuffer.MatricesWeightsKind
     * - VertexBuffer.MatricesWeightsExtraKind
     * @param bypassInstanceData defines a boolean indicating that the function should not take into account the instance data (applies only if the mesh has instances). Default: false
     * @returns a FloatArray or null if the mesh has no vertex buffer for this kind.
     */
    abstract getVertexBuffer(kind: string, bypassInstanceData?: boolean): Nullable<VertexBuffer>;
    /**
     * Sets the vertex data of the mesh geometry for the requested `kind`.
     * If the mesh has no geometry, a new Geometry object is set to the mesh and then passed this vertex data.
     * Note that a new underlying VertexBuffer object is created each call.
     * If the `kind` is the `PositionKind`, the mesh BoundingInfo is renewed, so the bounding box and sphere, and the mesh World Matrix is recomputed.
     * @param kind defines vertex data kind:
     * * VertexBuffer.PositionKind
     * * VertexBuffer.UVKind
     * * VertexBuffer.UV2Kind
     * * VertexBuffer.UV3Kind
     * * VertexBuffer.UV4Kind
     * * VertexBuffer.UV5Kind
     * * VertexBuffer.UV6Kind
     * * VertexBuffer.ColorKind
     * * VertexBuffer.MatricesIndicesKind
     * * VertexBuffer.MatricesIndicesExtraKind
     * * VertexBuffer.MatricesWeightsKind
     * * VertexBuffer.MatricesWeightsExtraKind
     * @param data defines the data source
     * @param updatable defines if the data must be flagged as updatable (or static)
     * @param stride defines the vertex stride (size of an entire vertex). Can be null and in this case will be deduced from vertex data kind
     * @returns the current mesh
     */
    setVerticesData(kind: string, data: FloatArray, updatable?: boolean, stride?: number): AbstractMesh;
    /**
     * Updates the existing vertex data of the mesh geometry for the requested `kind`.
     * If the mesh has no geometry, it is simply returned as it is.
     * @param kind defines vertex data kind:
     * * VertexBuffer.PositionKind
     * * VertexBuffer.UVKind
     * * VertexBuffer.UV2Kind
     * * VertexBuffer.UV3Kind
     * * VertexBuffer.UV4Kind
     * * VertexBuffer.UV5Kind
     * * VertexBuffer.UV6Kind
     * * VertexBuffer.ColorKind
     * * VertexBuffer.MatricesIndicesKind
     * * VertexBuffer.MatricesIndicesExtraKind
     * * VertexBuffer.MatricesWeightsKind
     * * VertexBuffer.MatricesWeightsExtraKind
     * @param data defines the data source
     * @param updateExtends If `kind` is `PositionKind` and if `updateExtends` is true, the mesh BoundingInfo is renewed, so the bounding box and sphere, and the mesh World Matrix is recomputed
     * @param makeItUnique If true, a new global geometry is created from this data and is set to the mesh
     * @returns the current mesh
     */
    updateVerticesData(kind: string, data: FloatArray, updateExtends?: boolean, makeItUnique?: boolean): AbstractMesh;
    /**
     * Sets the mesh indices,
     * If the mesh has no geometry, a new Geometry object is created and set to the mesh.
     * @param indices Expects an array populated with integers or a typed array (Int32Array, Uint32Array, Uint16Array)
     * @param totalVertices Defines the total number of vertices
     * @returns the current mesh
     */
    setIndices(indices: IndicesArray, totalVertices: Nullable<number>): AbstractMesh;
    /**
     * Gets a boolean indicating if specific vertex data is present
     * @param kind defines the vertex data kind to use
     * @returns true is data kind is present
     */
    isVerticesDataPresent(kind: string): boolean;
    /**
     * Returns the mesh BoundingInfo object or creates a new one and returns if it was undefined.
     * Note that it returns a shallow bounding of the mesh (i.e. it does not include children).
     * However, if the mesh contains thin instances, it will be expanded to include them. If you want the "raw" bounding data instead, then use `getRawBoundingInfo()`.
     * To get the full bounding of all children, call `getHierarchyBoundingVectors` instead.
     * @returns a BoundingInfo
     */
    getBoundingInfo(): BoundingInfo;
    /**
     * Returns the bounding info unnafected by instance data.
     * @returns the bounding info of the mesh unaffected by instance data.
     */
    getRawBoundingInfo(): BoundingInfo;
    /**
     * Overwrite the current bounding info
     * @param boundingInfo defines the new bounding info
     * @returns the current mesh
     */
    setBoundingInfo(boundingInfo: BoundingInfo): AbstractMesh;
    /**
     * Returns true if there is already a bounding info
     */
    get hasBoundingInfo(): boolean;
    /**
     * Creates a new bounding info for the mesh
     * @param minimum min vector of the bounding box/sphere
     * @param maximum max vector of the bounding box/sphere
     * @param worldMatrix defines the new world matrix
     * @returns the new bounding info
     */
    buildBoundingInfo(minimum: DeepImmutable<Vector3>, maximum: DeepImmutable<Vector3>, worldMatrix?: DeepImmutable<Matrix>): BoundingInfo;
    /**
     * Uniformly scales the mesh to fit inside of a unit cube (1 X 1 X 1 units)
     * @param includeDescendants Use the hierarchy's bounding box instead of the mesh's bounding box. Default is false
     * @param ignoreRotation ignore rotation when computing the scale (ie. object will be axis aligned). Default is false
     * @param predicate predicate that is passed in to getHierarchyBoundingVectors when selecting which object should be included when scaling
     * @returns the current mesh
     */
    normalizeToUnitCube(includeDescendants?: boolean, ignoreRotation?: boolean, predicate?: Nullable<(node: AbstractMesh) => boolean>): AbstractMesh;
    /** Gets a boolean indicating if this mesh has skinning data and an attached skeleton */
    get useBones(): boolean;
    /** @internal */
    _preActivate(): void;
    /**
     * @internal
     */
    _preActivateForIntermediateRendering(renderId: number): void;
    /**
     * @internal
     */
    _activate(renderId: number, intermediateRendering: boolean): boolean;
    /** @internal */
    _postActivate(): void;
    /** @internal */
    _freeze(): void;
    /** @internal */
    _unFreeze(): void;
    /**
     * Gets the current world matrix
     * @returns a Matrix
     */
    getWorldMatrix(): Matrix;
    /** @internal */
    _getWorldMatrixDeterminant(): number;
    /**
     * Gets a boolean indicating if this mesh is an instance or a regular mesh
     */
    get isAnInstance(): boolean;
    /**
     * Gets a boolean indicating if this mesh has instances
     */
    get hasInstances(): boolean;
    /**
     * Gets a boolean indicating if this mesh has thin instances
     */
    get hasThinInstances(): boolean;
    /**
     * Perform relative position change from the point of view of behind the front of the mesh.
     * This is performed taking into account the meshes current rotation, so you do not have to care.
     * Supports definition of mesh facing forward or backward {@link definedFacingForwardSearch | See definedFacingForwardSearch }.
     * @param amountRight defines the distance on the right axis
     * @param amountUp defines the distance on the up axis
     * @param amountForward defines the distance on the forward axis
     * @returns the current mesh
     */
    movePOV(amountRight: number, amountUp: number, amountForward: number): AbstractMesh;
    /**
     * Calculate relative position change from the point of view of behind the front of the mesh.
     * This is performed taking into account the meshes current rotation, so you do not have to care.
     * Supports definition of mesh facing forward or backward {@link definedFacingForwardSearch | See definedFacingForwardSearch }.
     * @param amountRight defines the distance on the right axis
     * @param amountUp defines the distance on the up axis
     * @param amountForward defines the distance on the forward axis
     * @returns the new displacement vector
     */
    calcMovePOV(amountRight: number, amountUp: number, amountForward: number): Vector3;
    /**
     * Perform relative rotation change from the point of view of behind the front of the mesh.
     * Supports definition of mesh facing forward or backward {@link definedFacingForwardSearch | See definedFacingForwardSearch }.
     * @param flipBack defines the flip
     * @param twirlClockwise defines the twirl
     * @param tiltRight defines the tilt
     * @returns the current mesh
     */
    rotatePOV(flipBack: number, twirlClockwise: number, tiltRight: number): AbstractMesh;
    /**
     * Calculate relative rotation change from the point of view of behind the front of the mesh.
     * Supports definition of mesh facing forward or backward {@link definedFacingForwardSearch | See definedFacingForwardSearch }.
     * @param flipBack defines the flip
     * @param twirlClockwise defines the twirl
     * @param tiltRight defines the tilt
     * @returns the new rotation vector
     */
    calcRotatePOV(flipBack: number, twirlClockwise: number, tiltRight: number): Vector3;
    /**
     * This method recomputes and sets a new BoundingInfo to the mesh unless it is locked.
     * This means the mesh underlying bounding box and sphere are recomputed.
     * @param options defines a set of options for computing the bounding info
     * @returns the current mesh
     */
    abstract refreshBoundingInfo(options: IMeshDataOptions): AbstractMesh;
    /**
     * This method recomputes and sets a new BoundingInfo to the mesh unless it is locked.
     * This means the mesh underlying bounding box and sphere are recomputed.
     * @param applySkeletonOrOptions defines whether to apply the skeleton before computing the bounding info or a set of options
     * @param applyMorph defines whether to apply the morph target before computing the bounding info
     * @returns the current mesh
     */
    abstract refreshBoundingInfo(applySkeletonOrOptions: boolean | IMeshDataOptions, applyMorph: boolean): AbstractMesh;
    /**
     * @internal
     */
    _refreshBoundingInfo(data: Nullable<FloatArray>, bias: Nullable<Vector2>): void;
    /**
     * @internal
     */
    _refreshBoundingInfoDirect(extend: {
        minimum: Vector3;
        maximum: Vector3;
    }): void;
    private static _ApplySkeleton;
    /** @internal */
    _getData(options: IMeshDataOptions, data: Nullable<FloatArray>, kind?: string): Nullable<FloatArray>;
    /**
     * Get the normals vertex data and optionally apply skeleton and morphing.
     * @param applySkeleton defines whether to apply the skeleton
     * @param applyMorph  defines whether to apply the morph target
     * @returns the normals data
     */
    getNormalsData(applySkeleton?: boolean, applyMorph?: boolean): Nullable<FloatArray>;
    /**
     * Get the position vertex data and optionally apply skeleton and morphing.
     * @param applySkeleton defines whether to apply the skeleton
     * @param applyMorph  defines whether to apply the morph target
     * @param data defines the position data to apply the skeleton and morph to
     * @returns the position data
     */
    getPositionData(applySkeleton?: boolean, applyMorph?: boolean, data?: Nullable<FloatArray>): Nullable<FloatArray>;
    /** @internal */
    _updateBoundingInfo(): AbstractMesh;
    /**
     * @internal
     */
    _updateSubMeshesBoundingInfo(matrix: DeepImmutable<Matrix>): AbstractMesh;
    /** @internal */
    protected _afterComputeWorldMatrix(): void;
    /**
     * Returns `true` if the mesh is within the frustum defined by the passed array of planes.
     * A mesh is in the frustum if its bounding box intersects the frustum
     * @param frustumPlanes defines the frustum to test
     * @returns true if the mesh is in the frustum planes
     */
    isInFrustum(frustumPlanes: Plane[]): boolean;
    /**
     * Returns `true` if the mesh is completely in the frustum defined be the passed array of planes.
     * A mesh is completely in the frustum if its bounding box it completely inside the frustum.
     * @param frustumPlanes defines the frustum to test
     * @returns true if the mesh is completely in the frustum planes
     */
    isCompletelyInFrustum(frustumPlanes: Plane[]): boolean;
    /**
     * True if the mesh intersects another mesh or a SolidParticle object
     * @param mesh defines a target mesh or SolidParticle to test
     * @param precise Unless the parameter `precise` is set to `true` the intersection is computed according to Axis Aligned Bounding Boxes (AABB), else according to OBB (Oriented BBoxes)
     * @param includeDescendants Can be set to true to test if the mesh defined in parameters intersects with the current mesh or any child meshes
     * @returns true if there is an intersection
     */
    intersectsMesh(mesh: AbstractMesh | SolidParticle, precise?: boolean, includeDescendants?: boolean): boolean;
    /**
     * Returns true if the passed point (Vector3) is inside the mesh bounding box
     * @param point defines the point to test
     * @returns true if there is an intersection
     */
    intersectsPoint(point: Vector3): boolean;
    /**
     * Gets or sets a boolean indicating that this mesh can be used in the collision engine
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_collisions
     */
    get checkCollisions(): boolean;
    set checkCollisions(collisionEnabled: boolean);
    /**
     * Gets Collider object used to compute collisions (not physics)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_collisions
     */
    get collider(): Nullable<Collider>;
    /**
     * Move the mesh using collision engine
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_collisions
     * @param displacement defines the requested displacement vector
     * @param slideOnCollide If true, the mesh will slide along a collider's surface.  If false, it will stop moving at the first collision. (true by default)
     * @returns the current mesh
     */
    moveWithCollisions(displacement: Vector3, slideOnCollide?: boolean): AbstractMesh;
    private _onCollisionPositionChange;
    /**
     * @internal
     */
    _collideForSubMesh(subMesh: SubMesh, transformMatrix: Matrix, collider: Collider): AbstractMesh;
    /**
     * @internal
     */
    _processCollisionsForSubMeshes(collider: Collider, transformMatrix: Matrix): AbstractMesh;
    /** @internal */
    _shouldConvertRHS(): boolean;
    /**
     * @internal
     */
    _checkCollision(collider: Collider): AbstractMesh;
    /** @internal */
    _generatePointsArray(): boolean;
    /**
     * Checks if the passed Ray intersects with the mesh. A mesh triangle can be picked both from its front and back sides,
     * irrespective of orientation.
     * @param ray defines the ray to use. It should be in the mesh's LOCAL coordinate space.
     * @param fastCheck defines if fast mode (but less precise) must be used (false by default)
     * @param trianglePredicate defines an optional predicate used to select faces when a mesh intersection is detected
     * @param onlyBoundingInfo defines a boolean indicating if picking should only happen using bounding info (false by default)
     * @param worldToUse defines the world matrix to use to get the world coordinate of the intersection point
     * @param skipBoundingInfo a boolean indicating if we should skip the bounding info check
     * @returns the picking info
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/interactions/mesh_intersect
     */
    intersects(ray: Ray, fastCheck?: boolean, trianglePredicate?: TrianglePickingPredicate, onlyBoundingInfo?: boolean, worldToUse?: Matrix, skipBoundingInfo?: boolean): PickingInfo;
    /**
     * Clones the current mesh
     * @param name defines the mesh name
     * @param newParent defines the new mesh parent
     * @param doNotCloneChildren defines a boolean indicating that children must not be cloned (false by default)
     * @returns the new mesh
     */
    clone(name: string, newParent: Nullable<Node>, doNotCloneChildren?: boolean): Nullable<AbstractMesh>;
    /**
     * Disposes all the submeshes of the current mesh
     * @param immediate should dispose the effects immediately or not
     * @returns the current mesh
     */
    releaseSubMeshes(immediate?: boolean): AbstractMesh;
    /**
     * Releases resources associated with this abstract mesh.
     * @param doNotRecurse Set to true to not recurse into each children (recurse into each children by default)
     * @param disposeMaterialAndTextures Set to true to also dispose referenced materials and textures (false by default)
     */
    dispose(doNotRecurse?: boolean, disposeMaterialAndTextures?: boolean): void;
    /** @internal */
    private _initFacetData;
    /**
     * Updates the mesh facetData arrays and the internal partitioning when the mesh is morphed or updated.
     * This method can be called within the render loop.
     * You don't need to call this method by yourself in the render loop when you update/morph a mesh with the methods CreateXXX() as they automatically manage this computation
     * @returns the current mesh
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    updateFacetData(): AbstractMesh;
    /**
     * Returns the facetLocalNormals array.
     * The normals are expressed in the mesh local spac
     * @returns an array of Vector3
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetLocalNormals(): Vector3[];
    /**
     * Returns the facetLocalPositions array.
     * The facet positions are expressed in the mesh local space
     * @returns an array of Vector3
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetLocalPositions(): Vector3[];
    /**
     * Returns the facetLocalPartitioning array
     * @returns an array of array of numbers
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetLocalPartitioning(): number[][];
    /**
     * Returns the i-th facet position in the world system.
     * This method allocates a new Vector3 per call
     * @param i defines the facet index
     * @returns a new Vector3
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetPosition(i: number): Vector3;
    /**
     * Sets the reference Vector3 with the i-th facet position in the world system
     * @param i defines the facet index
     * @param ref defines the target vector
     * @returns the current mesh
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetPositionToRef(i: number, ref: Vector3): AbstractMesh;
    /**
     * Returns the i-th facet normal in the world system.
     * This method allocates a new Vector3 per call
     * @param i defines the facet index
     * @returns a new Vector3
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetNormal(i: number): Vector3;
    /**
     * Sets the reference Vector3 with the i-th facet normal in the world system
     * @param i defines the facet index
     * @param ref defines the target vector
     * @returns the current mesh
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetNormalToRef(i: number, ref: Vector3): this;
    /**
     * Returns the facets (in an array) in the same partitioning block than the one the passed coordinates are located (expressed in the mesh local system)
     * @param x defines x coordinate
     * @param y defines y coordinate
     * @param z defines z coordinate
     * @returns the array of facet indexes
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetsAtLocalCoordinates(x: number, y: number, z: number): Nullable<number[]>;
    /**
     * Returns the closest mesh facet index at (x,y,z) World coordinates, null if not found
     * @param x defines x coordinate
     * @param y defines y coordinate
     * @param z defines z coordinate
     * @param projected sets as the (x,y,z) world projection on the facet
     * @param checkFace if true (default false), only the facet "facing" to (x,y,z) or only the ones "turning their backs", according to the parameter "facing" are returned
     * @param facing if facing and checkFace are true, only the facet "facing" to (x, y, z) are returned : positive dot (x, y, z) * facet position. If facing si false and checkFace is true, only the facet "turning their backs" to (x, y, z) are returned : negative dot (x, y, z) * facet position
     * @returns the face index if found (or null instead)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getClosestFacetAtCoordinates(x: number, y: number, z: number, projected?: Vector3, checkFace?: boolean, facing?: boolean): Nullable<number>;
    /**
     * Returns the closest mesh facet index at (x,y,z) local coordinates, null if not found
     * @param x defines x coordinate
     * @param y defines y coordinate
     * @param z defines z coordinate
     * @param projected sets as the (x,y,z) local projection on the facet
     * @param checkFace if true (default false), only the facet "facing" to (x,y,z) or only the ones "turning their backs", according to the parameter "facing" are returned
     * @param facing if facing and checkFace are true, only the facet "facing" to (x, y, z) are returned : positive dot (x, y, z) * facet position. If facing si false and checkFace is true, only the facet "turning their backs" to (x, y, z) are returned : negative dot (x, y, z) * facet position
     * @returns the face index if found (or null instead)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getClosestFacetAtLocalCoordinates(x: number, y: number, z: number, projected?: Vector3, checkFace?: boolean, facing?: boolean): Nullable<number>;
    /**
     * Returns the object "parameter" set with all the expected parameters for facetData computation by ComputeNormals()
     * @returns the parameters
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    getFacetDataParameters(): any;
    /**
     * Disables the feature FacetData and frees the related memory
     * @returns the current mesh
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/facetData
     */
    disableFacetData(): AbstractMesh;
    /**
     * Updates the AbstractMesh indices array
     * @param indices defines the data source
     * @param offset defines the offset in the index buffer where to store the new data (can be null)
     * @param gpuMemoryOnly defines a boolean indicating that only the GPU memory must be updated leaving the CPU version of the indices unchanged (false by default)
     * @returns the current mesh
     */
    updateIndices(indices: IndicesArray, offset?: number, gpuMemoryOnly?: boolean): AbstractMesh;
    /**
     * Creates new normals data for the mesh
     * @param updatable defines if the normal vertex buffer must be flagged as updatable
     * @returns the current mesh
     */
    createNormals(updatable: boolean): AbstractMesh;
    /**
     * Optimize the indices order so that we keep the faces with similar indices together
     * @returns the current mesh
     */
    optimizeIndicesAsync(): Promise<AbstractMesh>;
    /**
     * Align the mesh with a normal
     * @param normal defines the normal to use
     * @param upDirection can be used to redefined the up vector to use (will use the (0, 1, 0) by default)
     * @returns the current mesh
     */
    alignWithNormal(normal: Vector3, upDirection?: Vector3): AbstractMesh;
    /** @internal */
    _checkOcclusionQuery(): boolean;
    /**
     * Disables the mesh edge rendering mode
     * @returns the currentAbstractMesh
     */
    disableEdgesRendering(): AbstractMesh;
    /**
     * Enables the edge rendering mode on the mesh.
     * This mode makes the mesh edges visible
     * @param epsilon defines the maximal distance between two angles to detect a face
     * @param checkVerticesInsteadOfIndices indicates that we should check vertex list directly instead of faces
     * @param options options to the edge renderer
     * @returns the currentAbstractMesh
     * @see https://www.babylonjs-playground.com/#19O9TU#0
     */
    enableEdgesRendering(epsilon?: number, checkVerticesInsteadOfIndices?: boolean, options?: IEdgesRendererOptions): AbstractMesh;
    /**
     * This function returns all of the particle systems in the scene that use the mesh as an emitter.
     * @returns an array of particle systems in the scene that use the mesh as an emitter
     */
    getConnectedParticleSystems(): IParticleSystem[];
}

/**
 * Interface used to define ActionEvent
 */
interface IActionEvent {
    /** The mesh or sprite that triggered the action */
    source: any;
    /** The X mouse cursor position at the time of the event */
    pointerX: number;
    /** The Y mouse cursor position at the time of the event */
    pointerY: number;
    /** The mesh that is currently pointed at (can be null) */
    meshUnderPointer: Nullable<AbstractMesh>;
    /** the original (browser) event that triggered the ActionEvent */
    sourceEvent?: any;
    /** additional data for the event */
    additionalData?: any;
}
/**
 * ActionEvent is the event being sent when an action is triggered.
 */
declare class ActionEvent implements IActionEvent {
    /** The mesh or sprite that triggered the action */
    source: any;
    /** The X mouse cursor position at the time of the event */
    pointerX: number;
    /** The Y mouse cursor position at the time of the event */
    pointerY: number;
    /** The mesh that is currently pointed at (can be null) */
    meshUnderPointer: Nullable<AbstractMesh>;
    /** the original (browser) event that triggered the ActionEvent */
    sourceEvent?: any | undefined;
    /** additional data for the event */
    additionalData?: any | undefined;
    /**
     * Creates a new ActionEvent
     * @param source The mesh or sprite that triggered the action
     * @param pointerX The X mouse cursor position at the time of the event
     * @param pointerY The Y mouse cursor position at the time of the event
     * @param meshUnderPointer The mesh that is currently pointed at (can be null)
     * @param sourceEvent the original (browser) event that triggered the ActionEvent
     * @param additionalData additional data for the event
     */
    constructor(
    /** The mesh or sprite that triggered the action */
    source: any, 
    /** The X mouse cursor position at the time of the event */
    pointerX: number, 
    /** The Y mouse cursor position at the time of the event */
    pointerY: number, 
    /** The mesh that is currently pointed at (can be null) */
    meshUnderPointer: Nullable<AbstractMesh>, 
    /** the original (browser) event that triggered the ActionEvent */
    sourceEvent?: any | undefined, 
    /** additional data for the event */
    additionalData?: any | undefined);
    /**
     * Helper function to auto-create an ActionEvent from a source mesh.
     * @param source The source mesh that triggered the event
     * @param evt The original (browser) event
     * @param additionalData additional data for the event
     * @returns the new ActionEvent
     */
    static CreateNew(source: AbstractMesh, evt?: any, additionalData?: any): ActionEvent;
    /**
     * Helper function to auto-create an ActionEvent from a source sprite
     * @param source The source sprite that triggered the event
     * @param scene Scene associated with the sprite
     * @param evt The original (browser) event
     * @param additionalData additional data for the event
     * @returns the new ActionEvent
     */
    static CreateNewFromSprite(source: Sprite, scene: Scene, evt?: any, additionalData?: any): ActionEvent;
    /**
     * Helper function to auto-create an ActionEvent from a scene. If triggered by a mesh use ActionEvent.CreateNew
     * @param scene the scene where the event occurred
     * @param evt The original (browser) event
     * @returns the new ActionEvent
     */
    static CreateNewFromScene(scene: Scene, evt: any): ActionEvent;
    /**
     * Helper function to auto-create an ActionEvent from a primitive
     * @param prim defines the target primitive
     * @param pointerPos defines the pointer position
     * @param evt The original (browser) event
     * @param additionalData additional data for the event
     * @returns the new ActionEvent
     */
    static CreateNewFromPrimitive(prim: any, pointerPos: Vector2, evt?: Event, additionalData?: any): ActionEvent;
}

/**
 * Abstract class used to decouple action Manager from scene and meshes.
 * Do not instantiate.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions
 */
declare abstract class AbstractActionManager implements IDisposable {
    /** Gets the list of active triggers */
    static Triggers: {
        [key: string]: number;
    };
    /** Gets the cursor to use when hovering items */
    hoverCursor: string;
    /** Gets the list of actions */
    actions: IAction[];
    /**
     * Gets or sets a boolean indicating that the manager is recursive meaning that it can trigger action from children
     */
    isRecursive: boolean;
    /**
     * Gets or sets a boolean indicating if this ActionManager should be disposed once the last Mesh using it is disposed
     */
    disposeWhenUnowned: boolean;
    /**
     * Releases all associated resources
     */
    abstract dispose(): void;
    /**
     * Does this action manager has pointer triggers
     */
    abstract get hasPointerTriggers(): boolean;
    /**
     * Does this action manager has pick triggers
     */
    abstract get hasPickTriggers(): boolean;
    /**
     * Process a specific trigger
     * @param trigger defines the trigger to process
     * @param evt defines the event details to be processed
     */
    abstract processTrigger(trigger: number, evt?: IActionEvent): void;
    /**
     * Does this action manager handles actions of any of the given triggers
     * @param triggers defines the triggers to be tested
     * @returns a boolean indicating whether one (or more) of the triggers is handled
     */
    abstract hasSpecificTriggers(triggers: number[]): boolean;
    /**
     * Does this action manager handles actions of any of the given triggers. This function takes two arguments for
     * speed.
     * @param triggerA defines the trigger to be tested
     * @param triggerB defines the trigger to be tested
     * @returns a boolean indicating whether one (or more) of the triggers is handled
     */
    abstract hasSpecificTriggers2(triggerA: number, triggerB: number): boolean;
    /**
     * Does this action manager handles actions of a given trigger
     * @param trigger defines the trigger to be tested
     * @param parameterPredicate defines an optional predicate to filter triggers by parameter
     * @returns whether the trigger is handled
     */
    abstract hasSpecificTrigger(trigger: number, parameterPredicate?: (parameter: any) => boolean): boolean;
    /**
     * Serialize this manager to a JSON object
     * @param name defines the property name to store this manager
     * @returns a JSON representation of this manager
     */
    abstract serialize(name: string): any;
    /**
     * Registers an action to this action manager
     * @param action defines the action to be registered
     * @returns the action amended (prepared) after registration
     */
    abstract registerAction(action: IAction): Nullable<IAction>;
    /**
     * Unregisters an action to this action manager
     * @param action defines the action to be unregistered
     * @returns a boolean indicating whether the action has been unregistered
     */
    abstract unregisterAction(action: IAction): boolean;
    /**
     * Does exist one action manager with at least one trigger
     **/
    static get HasTriggers(): boolean;
    /**
     * Does exist one action manager with at least one pick trigger
     **/
    static get HasPickTriggers(): boolean;
    /**
     * Does exist one action manager that handles actions of a given trigger
     * @param trigger defines the trigger to be tested
     * @returns a boolean indicating whether the trigger is handled by at least one action manager
     **/
    static HasSpecificTrigger(trigger: number): boolean;
}

/**
 * Composed of a frame, and an action function
 */
declare class AnimationEvent {
    /** The frame for which the event is triggered **/
    frame: number;
    /** The event to perform when triggered **/
    action: (currentFrame: number) => void;
    /** Specifies if the event should be triggered only once**/
    onlyOnce?: boolean | undefined;
    /**
     * Specifies if the animation event is done
     */
    isDone: boolean;
    /**
     * Initializes the animation event
     * @param frame The frame for which the event is triggered
     * @param action The event to perform when triggered
     * @param onlyOnce Specifies if the event should be triggered only once
     */
    constructor(
    /** The frame for which the event is triggered **/
    frame: number, 
    /** The event to perform when triggered **/
    action: (currentFrame: number) => void, 
    /** Specifies if the event should be triggered only once**/
    onlyOnce?: boolean | undefined);
    /** @internal */
    _clone(): AnimationEvent;
}

/**
 * Defines an interface which represents an animation key frame
 */
interface IAnimationKey {
    /**
     * Frame of the key frame
     */
    frame: number;
    /**
     * Value at the specifies key frame
     */
    value: any;
    /**
     * The input tangent for the cubic hermite spline
     */
    inTangent?: any;
    /**
     * The output tangent for the cubic hermite spline
     */
    outTangent?: any;
    /**
     * The animation interpolation type
     */
    interpolation?: AnimationKeyInterpolation;
    /**
     * Property defined by UI tools to link (or not ) the tangents
     */
    lockedTangent?: boolean;
    /**
     * The easing function associated with the key frame (optional). If not defined, the easing function defined at the animation level (if any) will be used instead
     */
    easingFunction?: IEasingFunction;
}
/**
 * Enum for the animation key frame interpolation type
 */
declare const enum AnimationKeyInterpolation {
    /**
     * Use tangents to interpolate between start and end values.
     */
    NONE = 0,
    /**
     * Do not interpolate between keys and use the start key value only. Tangents are ignored
     */
    STEP = 1
}

/**
 * Options allowed during the creation of a sound track.
 */
interface ISoundTrackOptions {
    /**
     * The volume the sound track should take during creation
     */
    volume?: number;
    /**
     * Define if the sound track is the main sound track of the scene
     */
    mainTrack?: boolean;
}
/**
 * It could be useful to isolate your music & sounds on several tracks to better manage volume on a grouped instance of sounds.
 * It will be also used in a future release to apply effects on a specific track.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#using-sound-tracks
 */
declare class SoundTrack {
    /**
     * The unique identifier of the sound track in the scene.
     */
    id: number;
    /**
     * The list of sounds included in the sound track.
     */
    soundCollection: Array<Sound>;
    private _outputAudioNode;
    private _scene;
    private _connectedAnalyser;
    private _options;
    private _isInitialized;
    /**
     * Creates a new sound track.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#using-sound-tracks
     * @param scene Define the scene the sound track belongs to
     * @param options
     */
    constructor(scene?: Nullable<Scene>, options?: ISoundTrackOptions);
    private _initializeSoundTrackAudioGraph;
    /**
     * Release the sound track and its associated resources
     */
    dispose(): void;
    /**
     * Adds a sound to this sound track
     * @param sound define the sound to add
     * @ignoreNaming
     */
    addSound(sound: Sound): void;
    /**
     * Removes a sound to this sound track
     * @param sound define the sound to remove
     * @ignoreNaming
     */
    removeSound(sound: Sound): void;
    /**
     * Set a global volume for the full sound track.
     * @param newVolume Define the new volume of the sound track
     */
    setVolume(newVolume: number): void;
    /**
     * Switch the panning model to HRTF:
     * Renders a stereo output of higher quality than equalpower  it uses a convolution with measured impulse responses from human subjects.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
     */
    switchPanningModelToHRTF(): void;
    /**
     * Switch the panning model to Equal Power:
     * Represents the equal-power panning algorithm, generally regarded as simple and efficient. equalpower is the default value.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound
     */
    switchPanningModelToEqualPower(): void;
    /**
     * Connect the sound track to an audio analyser allowing some amazing
     * synchronization between the sounds/music and your visualization (VuMeter for instance).
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#using-the-analyser
     * @param analyser The analyser to connect to the engine
     */
    connectToAnalyser(analyser: Analyser): void;
}

declare module "../scene" {
    interface Scene {
        /**
         * @internal
         * Backing field
         */
        _mainSoundTrack: SoundTrack;
        /**
         * The main sound track played by the scene.
         * It contains your primary collection of sounds.
         * @deprecated please use AudioEngineV2 instead
         */
        mainSoundTrack: SoundTrack;
        /**
         * The list of sound tracks added to the scene
         * @deprecated please use AudioEngineV2 instead
         */
        soundTracks: Nullable<Array<SoundTrack>>;
        /**
         * Gets a sound using a given name
         * @param name defines the name to search for
         * @returns the found sound or null if not found at all.
         * @deprecated please use AudioEngineV2 instead
         */
        getSoundByName(name: string): Nullable<Sound>;
        /**
         * Gets or sets if audio support is enabled
         * @deprecated please use AudioEngineV2 instead
         */
        audioEnabled: boolean;
        /**
         * Gets or sets if audio will be output to headphones
         * @deprecated please use AudioEngineV2 instead
         */
        headphone: boolean;
        /**
         * Gets or sets custom audio listener position provider
         * @deprecated please use AudioEngineV2 instead
         */
        audioListenerPositionProvider: Nullable<() => Vector3>;
        /**
         * Gets or sets custom audio listener rotation provider
         * @deprecated please use AudioEngineV2 instead
         */
        audioListenerRotationProvider: Nullable<() => Vector3>;
        /**
         * Gets or sets a refresh rate when using 3D audio positioning
         * @deprecated please use AudioEngineV2 instead
         */
        audioPositioningRefreshRate: number;
    }
}

/**
 * Interface used to define a behavior
 */
interface Behavior<T> {
    /** gets or sets behavior's name */
    name: string;
    /**
     * Function called when the behavior needs to be initialized (before attaching it to a target)
     */
    init(): void;
    /**
     * Called when the behavior is attached to a target
     * @param target defines the target where the behavior is attached to
     */
    attach(target: T): void;
    /**
     * Called when the behavior is detached from its target
     */
    detach(): void;
    /**
     * Gets the current attached target
     */
    attachedNode: Nullable<T>;
}
/**
 * Interface implemented by classes supporting behaviors
 */
interface IBehaviorAware<T> {
    /**
     * Attach a behavior
     * @param behavior defines the behavior to attach
     * @returns the current host
     */
    addBehavior(behavior: Behavior<T>): T;
    /**
     * Remove a behavior from the current object
     * @param behavior defines the behavior to detach
     * @returns the current host
     */
    removeBehavior(behavior: Behavior<T>): T;
    /**
     * Gets a behavior using its name to search
     * @param name defines the name to search
     * @returns the behavior or null if not found
     */
    getBehaviorByName(name: string): Nullable<Behavior<T>>;
}

/**
 * Class used to manage all inputs for the scene.
 */
declare class InputManager {
    /** The distance in pixel that you have to move to prevent some events */
    static DragMovementThreshold: number;
    /** Time in milliseconds to wait to raise long press events if button is still pressed */
    static LongPressDelay: number;
    /** Time in milliseconds with two consecutive clicks will be considered as a double click */
    static DoubleClickDelay: number;
    /**
     * This flag will modify the behavior so that, when true, a click will happen if and only if
     * another click DOES NOT happen within the DoubleClickDelay time frame.  If another click does
     * happen within that time frame, the first click will not fire an event and and a double click will occur.
     */
    static ExclusiveDoubleClickMode: boolean;
    /** This is a defensive check to not allow control attachment prior to an already active one. If already attached, previous control is unattached before attaching the new one. */
    private _alreadyAttached;
    private _alreadyAttachedTo;
    private _onPointerMove;
    private _onPointerDown;
    private _onPointerUp;
    private _initClickEvent;
    private _initActionManager;
    private _delayedSimpleClick;
    private _meshPickProceed;
    private _previousButtonPressed;
    private _currentPickResult;
    private _previousPickResult;
    private _activePointerIds;
    /** Tracks the count of used slots in _activePointerIds for perf */
    private _activePointerIdsCount;
    private _doubleClickOccured;
    private _isSwiping;
    private _swipeButtonPressed;
    private _skipPointerTap;
    private _isMultiTouchGesture;
    private _pointerOverMesh;
    private _pickedDownMesh;
    private _pickedUpMesh;
    private _pointerX;
    private _pointerY;
    private _unTranslatedPointerX;
    private _unTranslatedPointerY;
    private _startingPointerPosition;
    private _previousStartingPointerPosition;
    private _startingPointerTime;
    private _previousStartingPointerTime;
    private _pointerCaptures;
    private _meshUnderPointerId;
    private _movePointerInfo;
    private _cameraObserverCount;
    private _delayedClicks;
    private _onKeyDown;
    private _onKeyUp;
    private _scene;
    private _deviceSourceManager;
    _originMouseEvent: IMouseEvent;
    /**
     * Creates a new InputManager
     * @param scene - defines the hosting scene
     */
    constructor(scene?: Scene);
    /**
     * Gets the mesh that is currently under the pointer
     * @returns Mesh that the pointer is pointer is hovering over
     */
    get meshUnderPointer(): Nullable<AbstractMesh>;
    /**
     * When using more than one pointer (for example in XR) you can get the mesh under the specific pointer
     * @param pointerId - the pointer id to use
     * @returns The mesh under this pointer id or null if not found
     */
    getMeshUnderPointerByPointerId(pointerId: number): Nullable<AbstractMesh>;
    /**
     * Gets the pointer coordinates in 2D without any translation (ie. straight out of the pointer event)
     * @returns Vector with X/Y values directly from pointer event
     */
    get unTranslatedPointer(): Vector2;
    /**
     * Gets or sets the current on-screen X position of the pointer
     * @returns Translated X with respect to screen
     */
    get pointerX(): number;
    set pointerX(value: number);
    /**
     * Gets or sets the current on-screen Y position of the pointer
     * @returns Translated Y with respect to screen
     */
    get pointerY(): number;
    set pointerY(value: number);
    private _updatePointerPosition;
    private _processPointerMove;
    /** @internal */
    _setRayOnPointerInfo(pickInfo: Nullable<PickingInfo>, event: IMouseEvent): void;
    /** @internal */
    _addCameraPointerObserver(observer: (p: PointerInfo, s: EventState) => void, mask?: number): Nullable<Observer<PointerInfo>>;
    /** @internal */
    _removeCameraPointerObserver(observer: Observer<PointerInfo>): boolean;
    private _checkForPicking;
    private _checkPrePointerObservable;
    /** @internal */
    _pickMove(evt: IPointerEvent): PickingInfo;
    private _setCursorAndPointerOverMesh;
    /**
     * Use this method to simulate a pointer move on a mesh
     * The pickResult parameter can be obtained from a scene.pick or scene.pickWithRay
     * @param pickResult - pickingInfo of the object wished to simulate pointer event on
     * @param pointerEventInit - pointer event state to be used when simulating the pointer event (eg. pointer id for multitouch)
     */
    simulatePointerMove(pickResult: PickingInfo, pointerEventInit?: PointerEventInit): void;
    /**
     * Use this method to simulate a pointer down on a mesh
     * The pickResult parameter can be obtained from a scene.pick or scene.pickWithRay
     * @param pickResult - pickingInfo of the object wished to simulate pointer event on
     * @param pointerEventInit - pointer event state to be used when simulating the pointer event (eg. pointer id for multitouch)
     */
    simulatePointerDown(pickResult: PickingInfo, pointerEventInit?: PointerEventInit): void;
    private _processPointerDown;
    /**
     * @internal
     * @internals Boolean if delta for pointer exceeds drag movement threshold
     */
    _isPointerSwiping(): boolean;
    /**
     * Use this method to simulate a pointer up on a mesh
     * The pickResult parameter can be obtained from a scene.pick or scene.pickWithRay
     * @param pickResult - pickingInfo of the object wished to simulate pointer event on
     * @param pointerEventInit - pointer event state to be used when simulating the pointer event (eg. pointer id for multitouch)
     * @param doubleTap - indicates that the pointer up event should be considered as part of a double click (false by default)
     */
    simulatePointerUp(pickResult: PickingInfo, pointerEventInit?: PointerEventInit, doubleTap?: boolean): void;
    private _processPointerUp;
    /**
     * Gets a boolean indicating if the current pointer event is captured (meaning that the scene has already handled the pointer down)
     * @param pointerId - defines the pointer id to use in a multi-touch scenario (0 by default)
     * @returns true if the pointer was captured
     */
    isPointerCaptured(pointerId?: number): boolean;
    /**
     * Attach events to the canvas (To handle actionManagers triggers and raise onPointerMove, onPointerDown and onPointerUp
     * @param attachUp - defines if you want to attach events to pointerup
     * @param attachDown - defines if you want to attach events to pointerdown
     * @param attachMove - defines if you want to attach events to pointermove
     * @param elementToAttachTo - defines the target DOM element to attach to (will use the canvas by default)
     */
    attachControl(attachUp?: boolean, attachDown?: boolean, attachMove?: boolean, elementToAttachTo?: Nullable<HTMLElement>): void;
    /**
     * Detaches all event handlers
     */
    detachControl(): void;
    /**
     * Set the value of meshUnderPointer for a given pointerId
     * @param mesh - defines the mesh to use
     * @param pointerId - optional pointer id when using more than one pointer. Defaults to 0
     * @param pickResult - optional pickingInfo data used to find mesh
     * @param evt - optional pointer event
     */
    setPointerOverMesh(mesh: Nullable<AbstractMesh>, pointerId?: number, pickResult?: Nullable<PickingInfo>, evt?: IPointerEvent): void;
    /**
     * Gets the mesh under the pointer
     * @returns a Mesh or null if no mesh is under the pointer
     */
    getPointerOverMesh(): Nullable<AbstractMesh>;
    /**
     * @param mesh - Mesh to invalidate
     * @internal
     */
    _invalidateMesh(mesh: AbstractMesh): void;
}

/**
 * Gather the list of pointer event types as constants.
 */
declare class PointerEventTypes {
    /**
     * The pointerdown event is fired when a pointer becomes active. For mouse, it is fired when the device transitions from no buttons depressed to at least one button depressed. For touch, it is fired when physical contact is made with the digitizer. For pen, it is fired when the stylus makes physical contact with the digitizer.
     */
    static readonly POINTERDOWN = 1;
    /**
     * The pointerup event is fired when a pointer is no longer active.
     */
    static readonly POINTERUP = 2;
    /**
     * The pointermove event is fired when a pointer changes coordinates.
     */
    static readonly POINTERMOVE = 4;
    /**
     * The pointerwheel event is fired when a mouse wheel has been rotated.
     */
    static readonly POINTERWHEEL = 8;
    /**
     * The pointerpick event is fired when a mesh or sprite has been picked by the pointer.
     */
    static readonly POINTERPICK = 16;
    /**
     * The pointertap event is fired when a the object has been touched and released without drag.
     */
    static readonly POINTERTAP = 32;
    /**
     * The pointerdoubletap event is fired when a the object has been touched and released twice without drag.
     */
    static readonly POINTERDOUBLETAP = 64;
}
/**
 * Base class of pointer info types.
 */
declare class PointerInfoBase {
    /**
     * Defines the type of event (PointerEventTypes)
     */
    type: number;
    /**
     * Defines the related dom event
     */
    event: IMouseEvent;
    /**
     * Instantiates the base class of pointers info.
     * @param type Defines the type of event (PointerEventTypes)
     * @param event Defines the related dom event
     */
    constructor(
    /**
     * Defines the type of event (PointerEventTypes)
     */
    type: number, 
    /**
     * Defines the related dom event
     */
    event: IMouseEvent);
}
/**
 * This class is used to store pointer related info for the onPrePointerObservable event.
 * Set the skipOnPointerObservable property to true if you want the engine to stop any process after this event is triggered, even not calling onPointerObservable
 */
declare class PointerInfoPre extends PointerInfoBase {
    /**
     * Ray from a pointer if available (eg. 6dof controller)
     */
    ray: Nullable<Ray>;
    /**
     * Defines picking info coming from a near interaction (proximity instead of ray-based picking)
     */
    nearInteractionPickingInfo: Nullable<PickingInfo>;
    /**
     * The original picking info that was used to trigger the pointer event
     */
    originalPickingInfo: Nullable<PickingInfo>;
    /**
     * Defines the local position of the pointer on the canvas.
     */
    localPosition: Vector2;
    /**
     * Defines whether the engine should skip the next OnPointerObservable associated to this pre.
     */
    skipOnPointerObservable: boolean;
    /**
     * Instantiates a PointerInfoPre to store pointer related info to the onPrePointerObservable event.
     * @param type Defines the type of event (PointerEventTypes)
     * @param event Defines the related dom event
     * @param localX Defines the local x coordinates of the pointer when the event occured
     * @param localY Defines the local y coordinates of the pointer when the event occured
     */
    constructor(type: number, event: IMouseEvent, localX: number, localY: number);
}
/**
 * This type contains all the data related to a pointer event in Babylon.js.
 * The event member is an instance of PointerEvent for all types except PointerWheel and is of type MouseWheelEvent when type equals PointerWheel. The different event types can be found in the PointerEventTypes class.
 */
declare class PointerInfo extends PointerInfoBase {
    private _pickInfo;
    private _inputManager;
    /**
     * Defines the picking info associated with this PointerInfo object (if applicable)
     */
    get pickInfo(): Nullable<PickingInfo>;
    /**
     * Instantiates a PointerInfo to store pointer related info to the onPointerObservable event.
     * @param type Defines the type of event (PointerEventTypes)
     * @param event Defines the related dom event
     * @param pickInfo Defines the picking info associated to the info (if any)
     * @param inputManager Defines the InputManager to use if there is no pickInfo
     */
    constructor(type: number, event: IMouseEvent, pickInfo: Nullable<PickingInfo>, inputManager?: Nullable<InputManager>);
    /**
     * Generates the picking info if needed
     */
    /** @internal */
    _generatePickInfo(): void;
}

/**
 * States of the webXR experience
 */
declare const enum WebXRState {
    /**
     * Transitioning to being in XR mode
     */
    ENTERING_XR = 0,
    /**
     * Transitioning to non XR mode
     */
    EXITING_XR = 1,
    /**
     * In XR mode and presenting
     */
    IN_XR = 2,
    /**
     * Not entered XR mode
     */
    NOT_IN_XR = 3
}
/**
 * The state of the XR camera's tracking
 */
declare const enum WebXRTrackingState {
    /**
     * No transformation received, device is not being tracked
     */
    NOT_TRACKING = 0,
    /**
     * Tracking lost - using emulated position
     */
    TRACKING_LOST = 1,
    /**
     * Transformation tracking works normally
     */
    TRACKING = 2
}
/**
 * Abstraction of the XR render target
 */
interface WebXRRenderTarget extends IDisposable {
    /**
     * xrpresent context of the canvas which can be used to display/mirror xr content
     */
    canvasContext: WebGLRenderingContext;
    /**
     * xr layer for the canvas
     */
    xrLayer: Nullable<XRWebGLLayer>;
    /**
     * Initializes a XRWebGLLayer to be used as the session's baseLayer.
     * @param xrSession xr session
     * @returns a promise that will resolve once the XR Layer has been created
     */
    initializeXRLayerAsync(xrSession: XRSession): Promise<XRWebGLLayer>;
}

/**
 * Configuration object for WebXR output canvas
 */
declare class WebXRManagedOutputCanvasOptions {
    /**
     * An optional canvas in case you wish to create it yourself and provide it here.
     * If not provided, a new canvas will be created
     */
    canvasElement?: HTMLCanvasElement;
    /**
     * Options for this XR Layer output
     */
    canvasOptions?: XRWebGLLayerInit;
    /**
     * CSS styling for a newly created canvas (if not provided)
     */
    newCanvasCssStyle?: string;
    /**
     * Get the default values of the configuration object
     * @param engine defines the engine to use (can be null)
     * @returns default values of this configuration object
     */
    static GetDefaults(engine?: AbstractEngine): WebXRManagedOutputCanvasOptions;
}

/** Covers all supported subclasses of WebXR's XRCompositionLayer */
type WebXRCompositionLayerType = "XRProjectionLayer";
type WebXRQuadLayerType = "XRQuadLayer";
/** Covers all supported subclasses of WebXR's XRLayer */
type WebXRLayerType = "XRWebGLLayer" | WebXRCompositionLayerType | WebXRQuadLayerType;
/**
 * Wrapper over subclasses of XRLayer.
 * @internal
 */
declare class WebXRLayerWrapper {
    /** The width of the layer's framebuffer. */
    getWidth: () => number;
    /** The height of the layer's framebuffer. */
    getHeight: () => number;
    /** The XR layer that this WebXRLayerWrapper wraps. */
    readonly layer: XRLayer;
    /** The type of XR layer that is being wrapped. */
    readonly layerType: WebXRLayerType;
    /** Create a render target provider for the wrapped layer. */
    private _createRenderTargetTextureProvider;
    private _rttWrapper;
    /**
     * Check if fixed foveation is supported on this device
     */
    get isFixedFoveationSupported(): boolean;
    /**
     * Get the fixed foveation currently set, as specified by the webxr specs
     * If this returns null, then fixed foveation is not supported
     */
    get fixedFoveation(): Nullable<number>;
    /**
     * Set the fixed foveation to the specified value, as specified by the webxr specs
     * This value will be normalized to be between 0 and 1, 1 being max foveation, 0 being no foveation
     */
    set fixedFoveation(value: Nullable<number>);
    /**
     * Create a render target provider for the wrapped layer.
     * @param xrSessionManager The XR Session Manager
     * @returns A new render target texture provider for the wrapped layer.
     */
    createRenderTargetTextureProvider(xrSessionManager: WebXRSessionManager): WebXRLayerRenderTargetTextureProvider;
    dispose(): void;
    protected constructor(
    /** The width of the layer's framebuffer. */
    getWidth: () => number, 
    /** The height of the layer's framebuffer. */
    getHeight: () => number, 
    /** The XR layer that this WebXRLayerWrapper wraps. */
    layer: XRLayer, 
    /** The type of XR layer that is being wrapped. */
    layerType: WebXRLayerType, 
    /** Create a render target provider for the wrapped layer. */
    _createRenderTargetTextureProvider: (xrSessionManager: WebXRSessionManager) => WebXRLayerRenderTargetTextureProvider);
}

/**
 * An interface for objects that provide render target textures for XR rendering.
 */
interface IWebXRRenderTargetTextureProvider extends IDisposable {
    /**
     * Attempts to set the framebuffer-size-normalized viewport to be rendered this frame for this view.
     * In the event of a failure, the supplied viewport is not updated.
     * @param viewport the viewport to which the view will be rendered
     * @param view the view for which to set the viewport
     * @returns whether the operation was successful
     */
    trySetViewportForView(viewport: Viewport, view: XRView): boolean;
    /**
     * Gets the correct render target texture to be rendered this frame for this eye
     * @param eye the eye for which to get the render target
     * @returns the render target for the specified eye or null if not available
     */
    getRenderTargetTextureForEye(eye: XREye): Nullable<RenderTargetTexture>;
    /**
     * Gets the correct render target texture to be rendered this frame for this view
     * @param view the view for which to get the render target
     * @returns the render target for the specified view or null if not available
     */
    getRenderTargetTextureForView(view: XRView): Nullable<RenderTargetTexture>;
}
/**
 * Provides render target textures and other important rendering information for a given XRLayer.
 * @internal
 */
declare abstract class WebXRLayerRenderTargetTextureProvider implements IWebXRRenderTargetTextureProvider {
    private readonly _scene;
    readonly layerWrapper: WebXRLayerWrapper;
    abstract trySetViewportForView(viewport: Viewport, view: XRView): boolean;
    abstract getRenderTargetTextureForEye(eye: XREye): Nullable<RenderTargetTexture>;
    abstract getRenderTargetTextureForView(view: XRView): Nullable<RenderTargetTexture>;
    protected _renderTargetTextures: RenderTargetTexture[];
    protected _framebufferDimensions: Nullable<{
        framebufferWidth: number;
        framebufferHeight: number;
    }>;
    private _engine;
    constructor(_scene: Scene, layerWrapper: WebXRLayerWrapper);
    private _createInternalTexture;
    protected _createRenderTargetTexture(width: number, height: number, framebuffer: Nullable<WebGLFramebuffer>, colorTexture?: WebGLTexture, depthStencilTexture?: WebGLTexture, multiview?: boolean): RenderTargetTexture;
    protected _destroyRenderTargetTexture(renderTargetTexture: RenderTargetTexture): void;
    getFramebufferDimensions(): Nullable<{
        framebufferWidth: number;
        framebufferHeight: number;
    }>;
    dispose(): void;
}

/**
 * Manages an XRSession to work with Babylon's engine
 * @see https://doc.babylonjs.com/features/featuresDeepDive/webXR/webXRSessionManagers
 */
declare class WebXRSessionManager implements IDisposable, IWebXRRenderTargetTextureProvider {
    /** The scene which the session should be created for */
    scene: Scene;
    private _engine;
    private _referenceSpace;
    private _baseLayerWrapper;
    private _baseLayerRTTProvider;
    private _xrNavigator;
    private _sessionMode;
    private _onEngineDisposedObserver;
    /**
     * The base reference space from which the session started. good if you want to reset your
     * reference space
     */
    baseReferenceSpace: XRReferenceSpace;
    /**
     * Current XR frame
     */
    currentFrame: Nullable<XRFrame>;
    /** WebXR timestamp updated every frame */
    currentTimestamp: number;
    /**
     * Used just in case of a failure to initialize an immersive session.
     * The viewer reference space is compensated using this height, creating a kind of "viewer-floor" reference space
     */
    defaultHeightCompensation: number;
    /**
     * Fires every time a new xrFrame arrives which can be used to update the camera
     */
    onXRFrameObservable: Observable<XRFrame>;
    /**
     * Fires when the reference space changed
     */
    onXRReferenceSpaceChanged: Observable<XRReferenceSpace>;
    /**
     * Fires when the xr session is ended either by the device or manually done
     */
    onXRSessionEnded: Observable<any>;
    /**
     * Fires when the xr session is initialized: right after requestSession was called and returned with a successful result
     */
    onXRSessionInit: Observable<XRSession>;
    /**
     * Fires when the xr reference space has been initialized
     */
    onXRReferenceSpaceInitialized: Observable<XRReferenceSpace>;
    /**
     * Fires when the session manager is rendering the first frame
     */
    onXRReady: Observable<WebXRSessionManager>;
    /**
     * Underlying xr session
     */
    session: XRSession;
    /**
     * The viewer (head position) reference space. This can be used to get the XR world coordinates
     * or get the offset the player is currently at.
     */
    viewerReferenceSpace: XRReferenceSpace;
    /**
     * Are we currently in the XR loop?
     */
    inXRFrameLoop: boolean;
    /**
     * Are we in an XR session?
     */
    inXRSession: boolean;
    private _worldScalingFactor;
    /**
     * Observable raised when the world scale has changed
     */
    onWorldScaleFactorChangedObservable: Observable<{
        previousScaleFactor: number;
        newScaleFactor: number;
    }>;
    /**
     * Scale factor to apply to all XR-related elements (camera, controllers)
     */
    get worldScalingFactor(): number;
    set worldScalingFactor(value: number);
    /**
     * Constructs a WebXRSessionManager, this must be initialized within a user action before usage
     * @param scene The scene which the session should be created for
     */
    constructor(
    /** The scene which the session should be created for */
    scene: Scene);
    /**
     * The current reference space used in this session. This reference space can constantly change!
     * It is mainly used to offset the camera's position.
     */
    get referenceSpace(): XRReferenceSpace;
    /**
     * Set a new reference space and triggers the observable
     */
    set referenceSpace(newReferenceSpace: XRReferenceSpace);
    /**
     * The mode for the managed XR session
     */
    get sessionMode(): XRSessionMode;
    /**
     * Disposes of the session manager
     * This should be called explicitly by the dev, if required.
     */
    dispose(): void;
    /**
     * Stops the xrSession and restores the render loop
     * @returns Promise which resolves after it exits XR
     */
    exitXRAsync(): Promise<void>;
    /**
     * Attempts to set the framebuffer-size-normalized viewport to be rendered this frame for this view.
     * In the event of a failure, the supplied viewport is not updated.
     * @param viewport the viewport to which the view will be rendered
     * @param view the view for which to set the viewport
     * @returns whether the operation was successful
     */
    trySetViewportForView(viewport: Viewport, view: XRView): boolean;
    /**
     * Gets the correct render target texture to be rendered this frame for this eye
     * @param eye the eye for which to get the render target
     * @returns the render target for the specified eye or null if not available
     */
    getRenderTargetTextureForEye(eye: XREye): Nullable<RenderTargetTexture>;
    /**
     * Gets the correct render target texture to be rendered this frame for this view
     * @param view the view for which to get the render target
     * @returns the render target for the specified view or null if not available
     */
    getRenderTargetTextureForView(view: XRView): Nullable<RenderTargetTexture>;
    /**
     * Creates a WebXRRenderTarget object for the XR session
     * @param options optional options to provide when creating a new render target
     * @returns a WebXR render target to which the session can render
     */
    getWebXRRenderTarget(options?: WebXRManagedOutputCanvasOptions): WebXRRenderTarget;
    /**
     * Initializes the manager
     * After initialization enterXR can be called to start an XR session
     * @returns Promise which resolves after it is initialized
     */
    initializeAsync(): Promise<void>;
    /**
     * Initializes an xr session
     * @param xrSessionMode mode to initialize
     * @param xrSessionInit defines optional and required values to pass to the session builder
     * @returns a promise which will resolve once the session has been initialized
     */
    initializeSessionAsync(xrSessionMode?: XRSessionMode, xrSessionInit?: XRSessionInit): Promise<XRSession>;
    /**
     * Checks if a session would be supported for the creation options specified
     * @param sessionMode session mode to check if supported eg. immersive-vr
     * @returns A Promise that resolves to true if supported and false if not
     */
    isSessionSupportedAsync(sessionMode: XRSessionMode): Promise<boolean>;
    /**
     * Resets the reference space to the one started the session
     */
    resetReferenceSpace(): void;
    /**
     * Starts rendering to the xr layer
     */
    runXRRenderLoop(): void;
    /**
     * Sets the reference space on the xr session
     * @param referenceSpaceType space to set
     * @returns a promise that will resolve once the reference space has been set
     */
    setReferenceSpaceTypeAsync(referenceSpaceType?: XRReferenceSpaceType): Promise<XRReferenceSpace>;
    /**
     * Updates the render state of the session.
     * Note that this is deprecated in favor of WebXRSessionManager.updateRenderState().
     * @param state state to set
     * @returns a promise that resolves once the render state has been updated
     * @deprecated Use updateRenderState() instead.
     */
    updateRenderStateAsync(state: XRRenderState): Promise<void>;
    /**
     * @internal
     */
    _setBaseLayerWrapper(baseLayerWrapper: Nullable<WebXRLayerWrapper>): void;
    /**
     * @internal
     */
    _getBaseLayerWrapper(): Nullable<WebXRLayerWrapper>;
    /**
     * Updates the render state of the session
     * @param state state to set
     */
    updateRenderState(state: XRRenderStateInit): void;
    /**
     * Returns a promise that resolves with a boolean indicating if the provided session mode is supported by this browser
     * @param sessionMode defines the session to test
     * @returns a promise with boolean as final value
     */
    static IsSessionSupportedAsync(sessionMode: XRSessionMode): Promise<boolean>;
    /**
     * Returns true if Babylon.js is using the BabylonNative backend, otherwise false
     */
    get isNative(): boolean;
    /**
     * The current frame rate as reported by the device
     */
    get currentFrameRate(): number | undefined;
    /**
     * A list of supported frame rates (only available in-session!
     */
    get supportedFrameRates(): Float32Array | undefined;
    /**
     * Set the framerate of the session.
     * @param rate the new framerate. This value needs to be in the supportedFrameRates array
     * @returns a promise that resolves once the framerate has been set
     */
    updateTargetFrameRate(rate: number): Promise<void>;
    /**
     * Run a callback in the xr render loop
     * @param callback the callback to call when in XR Frame
     * @param ignoreIfNotInSession if no session is currently running, run it first thing on the next session
     */
    runInXRFrame(callback: () => void, ignoreIfNotInSession?: boolean): void;
    /**
     * Check if fixed foveation is supported on this device
     */
    get isFixedFoveationSupported(): boolean;
    /**
     * Get the fixed foveation currently set, as specified by the webxr specs
     * If this returns null, then fixed foveation is not supported
     */
    get fixedFoveation(): Nullable<number>;
    /**
     * Set the fixed foveation to the specified value, as specified by the webxr specs
     * This value will be normalized to be between 0 and 1, 1 being max foveation, 0 being no foveation
     */
    set fixedFoveation(value: Nullable<number>);
    /**
     * Get the features enabled on the current session
     * This is only available in-session!
     * @see https://www.w3.org/TR/webxr/#dom-xrsession-enabledfeatures
     */
    get enabledFeatures(): Nullable<string[]>;
}

/**
 * This is the base class for all WebXR features.
 * Since most features require almost the same resources and callbacks, this class can be used to simplify the development
 * Note that since the features manager is using the `IWebXRFeature` you are in no way obligated to use this class
 */
declare abstract class WebXRAbstractFeature implements IWebXRFeature {
    protected _xrSessionManager: WebXRSessionManager;
    private _attached;
    private _removeOnDetach;
    /**
     * Is this feature disposed?
     */
    isDisposed: boolean;
    /**
     * Should auto-attach be disabled?
     */
    disableAutoAttach: boolean;
    protected _xrNativeFeatureName: string;
    /**
     * The name of the native xr feature name (like anchor, hit-test, or hand-tracking)
     */
    get xrNativeFeatureName(): string;
    set xrNativeFeatureName(name: string);
    /**
     * Observers registered here will be executed when the feature is attached
     */
    onFeatureAttachObservable: Observable<IWebXRFeature>;
    /**
     * Observers registered here will be executed when the feature is detached
     */
    onFeatureDetachObservable: Observable<IWebXRFeature>;
    /**
     * The dependencies of this feature, if any
     */
    dependsOn?: string[];
    /**
     * Construct a new (abstract) WebXR feature
     * @param _xrSessionManager the xr session manager for this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager);
    /**
     * Is this feature attached
     */
    get attached(): boolean;
    /**
     * attach this feature
     *
     * @param force should attachment be forced (even when already attached)
     * @returns true if successful, false is failed or already attached
     */
    attach(force?: boolean): boolean;
    /**
     * detach this feature.
     *
     * @returns true if successful, false if failed or already detached
     */
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    /**
     * This function will be executed during before enabling the feature and can be used to not-allow enabling it.
     * Note that at this point the session has NOT started, so this is purely checking if the browser supports it
     *
     * @returns whether or not the feature is compatible in this environment
     */
    isCompatible(): boolean;
    /**
     * This is used to register callbacks that will automatically be removed when detach is called.
     * @param observable the observable to which the observer will be attached
     * @param callback the callback to register
     * @param insertFirst should the callback be executed as soon as it is registered
     */
    protected _addNewAttachObserver<T>(observable: Observable<T>, callback: (eventData: T, eventState: EventState) => void, insertFirst?: boolean): void;
    /**
     * Code in this function will be executed on each xrFrame received from the browser.
     * This function will not execute after the feature is detached.
     * @param _xrFrame the current frame
     */
    protected abstract _onXRFrame(_xrFrame: XRFrame): void;
}

/**
 * An interface for all Hit test features
 */
interface IWebXRHitTestFeature<T extends IWebXRLegacyHitResult> extends IWebXRFeature {
    /**
     * Triggered when new babylon (transformed) hit test results are available
     */
    onHitTestResultObservable: Observable<T[]>;
}
/**
 * Options used for hit testing
 */
interface IWebXRLegacyHitTestOptions {
    /**
     * Only test when user interacted with the scene. Default - hit test every frame
     */
    testOnPointerDownOnly?: boolean;
    /**
     * The node to use to transform the local results to world coordinates
     */
    worldParentNode?: TransformNode;
}
/**
 * Interface defining the babylon result of raycasting/hit-test
 */
interface IWebXRLegacyHitResult {
    /**
     * Transformation matrix that can be applied to a node that will put it in the hit point location
     */
    transformationMatrix: Matrix;
    /**
     * The native hit test result
     */
    xrHitResult: XRHitResult | XRHitTestResult;
}

/**
 * Options used for hit testing (version 2)
 */
interface IWebXRHitTestOptions extends IWebXRLegacyHitTestOptions {
    /**
     * Do not create a permanent hit test. Will usually be used when only
     * transient inputs are needed.
     */
    disablePermanentHitTest?: boolean;
    /**
     * Enable transient (for example touch-based) hit test inspections
     */
    enableTransientHitTest?: boolean;
    /**
     * Override the default transient hit test profile (generic-touchscreen).
     */
    transientHitTestProfile?: string;
    /**
     * Offset ray for the permanent hit test
     */
    offsetRay?: Vector3;
    /**
     * Offset ray for the transient hit test
     */
    transientOffsetRay?: Vector3;
    /**
     * Instead of using viewer space for hit tests, use the reference space defined in the session manager
     */
    useReferenceSpace?: boolean;
    /**
     * Override the default entity type(s) of the hit-test result
     */
    entityTypes?: XRHitTestTrackableType[];
}
/**
 * Interface defining the babylon result of hit-test
 */
interface IWebXRHitResult extends IWebXRLegacyHitResult {
    /**
     * The input source that generated this hit test (if transient)
     */
    inputSource?: XRInputSource;
    /**
     * Is this a transient hit test
     */
    isTransient?: boolean;
    /**
     * Position of the hit test result
     */
    position: Vector3;
    /**
     * Rotation of the hit test result
     */
    rotationQuaternion: Quaternion;
    /**
     * The native hit test result
     */
    xrHitResult: XRHitTestResult;
}
/**
 * The currently-working hit-test module.
 * Hit test (or Ray-casting) is used to interact with the real world.
 * For further information read here - https://github.com/immersive-web/hit-test
 *
 * Tested on chrome (mobile) 80.
 */
declare class WebXRHitTest extends WebXRAbstractFeature implements IWebXRHitTestFeature<IWebXRHitResult> {
    /**
     * [Empty Object] options to use when constructing this feature
     */
    readonly options: IWebXRHitTestOptions;
    private _tmpMat;
    private _tmpPos;
    private _tmpQuat;
    private _transientXrHitTestSource;
    private _xrHitTestSource;
    private _initHitTestSource;
    /**
     * The module's name
     */
    static readonly Name: "xr-hit-test";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 2;
    /**
     * When set to true, each hit test will have its own position/rotation objects
     * When set to false, position and rotation objects will be reused for each hit test. It is expected that
     * the developers will clone them or copy them as they see fit.
     */
    autoCloneTransformation: boolean;
    /**
     * Triggered when new babylon (transformed) hit test results are available
     * Note - this will be called when results come back from the device. It can be an empty array!!
     */
    onHitTestResultObservable: Observable<IWebXRHitResult[]>;
    /**
     * Use this to temporarily pause hit test checks.
     */
    paused: boolean;
    /**
     * Creates a new instance of the hit test feature
     * @param _xrSessionManager an instance of WebXRSessionManager
     * @param options options to use when constructing this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, 
    /**
     * [Empty Object] options to use when constructing this feature
     */
    options?: IWebXRHitTestOptions);
    /**
     * attach this feature
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    attach(): boolean;
    /**
     * detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    protected _onXRFrame(frame: XRFrame): void;
    private _processWebXRHitTestResult;
}

/**
 * Configuration options of the anchor system
 */
interface IWebXRAnchorSystemOptions {
    /**
     * a node that will be used to convert local to world coordinates
     */
    worldParentNode?: TransformNode;
    /**
     * If set to true a reference of the created anchors will be kept until the next session starts
     * If not defined, anchors will be removed from the array when the feature is detached or the session ended.
     */
    doNotRemoveAnchorsOnSessionEnded?: boolean;
    /**
     * If set to true, all anchor arrays will be cleared when the session initializes
     */
    clearAnchorsOnSessionInit?: boolean;
}
/**
 * A babylon container for an XR Anchor
 */
interface IWebXRAnchor {
    /**
     * A babylon-assigned ID for this anchor
     */
    id: number;
    /**
     * Transformation matrix to apply to an object attached to this anchor
     */
    transformationMatrix: Matrix;
    /**
     * The native anchor object
     */
    xrAnchor: XRAnchor;
    /**
     * if defined, this object will be constantly updated by the anchor's position and rotation
     */
    attachedNode?: TransformNode;
    /**
     * Remove this anchor from the scene
     */
    remove(): void;
    /**
     * @internal - set to true when the anchor was removed
     */
    _removed: boolean;
}
/**
 * An implementation of the anchor system for WebXR.
 * For further information see https://github.com/immersive-web/anchors/
 */
declare class WebXRAnchorSystem extends WebXRAbstractFeature {
    private _options;
    private _lastFrameDetected;
    private _trackedAnchors;
    private _referenceSpaceForFrameAnchors;
    private _futureAnchors;
    /**
     * The module's name
     */
    static readonly Name: "xr-anchor-system";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Observers registered here will be executed when a new anchor was added to the session
     */
    onAnchorAddedObservable: Observable<IWebXRAnchor>;
    /**
     * Observers registered here will be executed when an anchor was removed from the session
     */
    onAnchorRemovedObservable: Observable<IWebXRAnchor>;
    /**
     * Observers registered here will be executed when an existing anchor updates
     * This can execute N times every frame
     */
    onAnchorUpdatedObservable: Observable<IWebXRAnchor>;
    /**
     * Set the reference space to use for anchor creation, when not using a hit test.
     * Will default to the session's reference space if not defined
     */
    set referenceSpaceForFrameAnchors(referenceSpace: XRReferenceSpace);
    /**
     * constructs a new anchor system
     * @param _xrSessionManager an instance of WebXRSessionManager
     * @param _options configuration object for this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, _options?: IWebXRAnchorSystemOptions);
    private _tmpVector;
    private _tmpQuaternion;
    private _populateTmpTransformation;
    /**
     * Create a new anchor point using a hit test result at a specific point in the scene
     * An anchor is tracked only after it is added to the trackerAnchors in xrFrame. The promise returned here does not yet guaranty that.
     * Use onAnchorAddedObservable to get newly added anchors if you require tracking guaranty.
     *
     * @param hitTestResult The hit test result to use for this anchor creation
     * @param position an optional position offset for this anchor
     * @param rotationQuaternion an optional rotation offset for this anchor
     * @returns A promise that fulfills when babylon has created the corresponding WebXRAnchor object and tracking has begun
     */
    addAnchorPointUsingHitTestResultAsync(hitTestResult: IWebXRHitResult, position?: Vector3, rotationQuaternion?: Quaternion): Promise<IWebXRAnchor>;
    /**
     * Add a new anchor at a specific position and rotation
     * This function will add a new anchor per default in the next available frame. Unless forced, the createAnchor function
     * will be called in the next xrFrame loop to make sure that the anchor can be created correctly.
     * An anchor is tracked only after it is added to the trackerAnchors in xrFrame. The promise returned here does not yet guaranty that.
     * Use onAnchorAddedObservable to get newly added anchors if you require tracking guaranty.
     *
     * @param position the position in which to add an anchor
     * @param rotationQuaternion an optional rotation for the anchor transformation
     * @param forceCreateInCurrentFrame force the creation of this anchor in the current frame. Must be called inside xrFrame loop!
     * @returns A promise that fulfills when babylon has created the corresponding WebXRAnchor object and tracking has begun
     */
    addAnchorAtPositionAndRotationAsync(position: Vector3, rotationQuaternion?: Quaternion, forceCreateInCurrentFrame?: boolean): Promise<IWebXRAnchor>;
    /**
     * Get the list of anchors currently being tracked by the system
     */
    get anchors(): IWebXRAnchor[];
    /**
     * detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    protected _onXRFrame(frame: XRFrame): void;
    /**
     * avoiding using Array.find for global support.
     * @param xrAnchor the plane to find in the array
     * @returns the index of the anchor in the array or -1 if not found
     */
    private _findIndexInAnchorArray;
    private _updateAnchorWithXRFrame;
    private _createAnchorAtTransformationAsync;
}

/**
 * Options interface for the background remover plugin
 */
interface IWebXRBackgroundRemoverOptions {
    /**
     * Further background meshes to disable when entering AR
     */
    backgroundMeshes?: AbstractMesh[];
    /**
     * flags to configure the removal of the environment helper.
     * If not set, the entire background will be removed. If set, flags should be set as well.
     */
    environmentHelperRemovalFlags?: {
        /**
         * Should the skybox be removed (default false)
         */
        skyBox?: boolean;
        /**
         * Should the ground be removed (default false)
         */
        ground?: boolean;
    };
    /**
     * don't disable the environment helper
     */
    ignoreEnvironmentHelper?: boolean;
}
/**
 * A module that will automatically disable background meshes when entering AR and will enable them when leaving AR.
 */
declare class WebXRBackgroundRemover extends WebXRAbstractFeature {
    /**
     * [Empty Object] read-only options to be used in this module
     */
    readonly options: IWebXRBackgroundRemoverOptions;
    /**
     * The module's name
     */
    static readonly Name: "xr-background-remover";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * registered observers will be triggered when the background state changes
     */
    onBackgroundStateChangedObservable: Observable<boolean>;
    /**
     * constructs a new background remover module
     * @param _xrSessionManager the session manager for this module
     * @param options read-only options to be used in this module
     */
    constructor(_xrSessionManager: WebXRSessionManager, 
    /**
     * [Empty Object] read-only options to be used in this module
     */
    options?: IWebXRBackgroundRemoverOptions);
    /**
     * attach this feature
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    attach(): boolean;
    /**
     * detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    protected _onXRFrame(_xrFrame: XRFrame): void;
    private _setBackgroundState;
}

/**
 * X-Y values for axes in WebXR
 */
interface IWebXRMotionControllerAxesValue {
    /**
     * The value of the x axis
     */
    x: number;
    /**
     * The value of the y-axis
     */
    y: number;
}
/**
 * changed / previous values for the values of this component
 */
interface IWebXRMotionControllerComponentChangesValues<T> {
    /**
     * current (this frame) value
     */
    current: T;
    /**
     * previous (last change) value
     */
    previous: T;
}
/**
 * Represents changes in the component between current frame and last values recorded
 */
interface IWebXRMotionControllerComponentChanges {
    /**
     * will be populated with previous and current values if axes changed
     */
    axes?: IWebXRMotionControllerComponentChangesValues<IWebXRMotionControllerAxesValue>;
    /**
     * will be populated with previous and current values if pressed changed
     */
    pressed?: IWebXRMotionControllerComponentChangesValues<boolean>;
    /**
     * will be populated with previous and current values if touched changed
     */
    touched?: IWebXRMotionControllerComponentChangesValues<boolean>;
    /**
     * will be populated with previous and current values if value changed
     */
    value?: IWebXRMotionControllerComponentChangesValues<number>;
}
/**
 * This class represents a single component (for example button or thumbstick) of a motion controller
 */
declare class WebXRControllerComponent implements IDisposable {
    /**
     * the id of this component
     */
    id: string;
    /**
     * the type of the component
     */
    type: MotionControllerComponentType;
    private _buttonIndex;
    private _axesIndices;
    private _axes;
    private _changes;
    private _currentValue;
    private _hasChanges;
    private _pressed;
    private _touched;
    /**
     * button component type
     */
    static BUTTON_TYPE: MotionControllerComponentType;
    /**
     * squeeze component type
     */
    static SQUEEZE_TYPE: MotionControllerComponentType;
    /**
     * Thumbstick component type
     */
    static THUMBSTICK_TYPE: MotionControllerComponentType;
    /**
     * Touchpad component type
     */
    static TOUCHPAD_TYPE: MotionControllerComponentType;
    /**
     * trigger component type
     */
    static TRIGGER_TYPE: MotionControllerComponentType;
    /**
     * If axes are available for this component (like a touchpad or thumbstick) the observers will be notified when
     * the axes data changes
     */
    onAxisValueChangedObservable: Observable<{
        x: number;
        y: number;
    }>;
    /**
     * Observers registered here will be triggered when the state of a button changes
     * State change is either pressed / touched / value
     */
    onButtonStateChangedObservable: Observable<WebXRControllerComponent>;
    /**
     * Creates a new component for a motion controller.
     * It is created by the motion controller itself
     *
     * @param id the id of this component
     * @param type the type of the component
     * @param _buttonIndex index in the buttons array of the gamepad
     * @param _axesIndices indices of the values in the axes array of the gamepad
     */
    constructor(
    /**
     * the id of this component
     */
    id: string, 
    /**
     * the type of the component
     */
    type: MotionControllerComponentType, _buttonIndex?: number, _axesIndices?: number[]);
    /**
     * The current axes data. If this component has no axes it will still return an object { x: 0, y: 0 }
     */
    get axes(): IWebXRMotionControllerAxesValue;
    /**
     * Get the changes. Elements will be populated only if they changed with their previous and current value
     */
    get changes(): IWebXRMotionControllerComponentChanges;
    /**
     * Return whether or not the component changed the last frame
     */
    get hasChanges(): boolean;
    /**
     * is the button currently pressed
     */
    get pressed(): boolean;
    /**
     * is the button currently touched
     */
    get touched(): boolean;
    /**
     * Get the current value of this component
     */
    get value(): number;
    /**
     * Dispose this component
     */
    dispose(): void;
    /**
     * Are there axes correlating to this component
     * @returns true is axes data is available
     */
    isAxes(): boolean;
    /**
     * Is this component a button (hence - pressable)
     * @returns true if can be pressed
     */
    isButton(): boolean;
    /**
     * update this component using the gamepad object it is in. Called on every frame
     * @param nativeController the native gamepad controller object
     */
    update(nativeController: IMinimalMotionControllerObject): void;
}

/**
 * Handedness type in xrInput profiles. These can be used to define layouts in the Layout Map.
 */
type MotionControllerHandedness = "none" | "left" | "right";
/**
 * The type of components available in motion controllers.
 * This is not the name of the component.
 */
type MotionControllerComponentType = "trigger" | "squeeze" | "touchpad" | "thumbstick" | "button";
/**
 * The state of a controller component
 */
type MotionControllerComponentStateType = "default" | "touched" | "pressed";
/**
 * The schema of motion controller layout.
 * No object will be initialized using this interface
 * This is used just to define the profile.
 */
interface IMotionControllerLayout {
    /**
     * Path to load the assets. Usually relative to the base path
     */
    assetPath: string;
    /**
     * Available components (unsorted)
     */
    components: {
        /**
         * A map of component Ids
         */
        [componentId: string]: {
            /**
             * The type of input the component outputs
             */
            type: MotionControllerComponentType;
            /**
             * The indices of this component in the gamepad object
             */
            gamepadIndices: {
                /**
                 * Index of button
                 */
                button?: number;
                /**
                 * If available, index of x-axis
                 */
                xAxis?: number;
                /**
                 * If available, index of y-axis
                 */
                yAxis?: number;
            };
            /**
             * The mesh's root node name
             */
            rootNodeName: string;
            /**
             * Animation definitions for this model
             */
            visualResponses: {
                [stateKey: string]: {
                    /**
                     * What property will be animated
                     */
                    componentProperty: "xAxis" | "yAxis" | "button" | "state";
                    /**
                     * What states influence this visual response
                     */
                    states: MotionControllerComponentStateType[];
                    /**
                     * Type of animation - movement or visibility
                     */
                    valueNodeProperty: "transform" | "visibility";
                    /**
                     * Base node name to move. Its position will be calculated according to the min and max nodes
                     */
                    valueNodeName?: string;
                    /**
                     * Minimum movement node
                     */
                    minNodeName?: string;
                    /**
                     * Max movement node
                     */
                    maxNodeName?: string;
                };
            };
            /**
             * If touch enabled, what is the name of node to display user feedback
             */
            touchPointNodeName?: string;
        };
    };
    /**
     * Is it xr standard mapping or not
     */
    gamepadMapping: "" | "xr-standard";
    /**
     * Base root node of this entire model
     */
    rootNodeName: string;
    /**
     * Defines the main button component id
     */
    selectComponentId: string;
}
/**
 * A helper-interface for the 3 meshes needed for controller axis animation.
 * This will be expanded when touchpad animations are fully supported
 * The meshes are provided to the _lerpAxisTransform function to calculate the current position of the value mesh
 */
interface IMotionControllerMeshMap {
    /**
     * the mesh that defines the maximum value mesh position.
     */
    maxMesh?: AbstractMesh;
    /**
     * the mesh that defines the minimum value mesh position.
     */
    minMesh?: AbstractMesh;
    /**
     * The mesh that will be changed when axis value changes
     */
    valueMesh?: AbstractMesh;
}
/**
 * The elements needed for change-detection of the gamepad objects in motion controllers
 */
interface IMinimalMotionControllerObject {
    /**
     * Available axes of this controller
     */
    axes: number[];
    /**
     * An array of available buttons
     */
    buttons: Array<{
        /**
         * Value of the button/trigger
         */
        value: number;
        /**
         * If the button/trigger is currently touched
         */
        touched: boolean;
        /**
         * If the button/trigger is currently pressed
         */
        pressed: boolean;
    }>;
    /**
     * EXPERIMENTAL haptic support.
     */
    hapticActuators?: Array<{
        pulse: (value: number, duration: number) => Promise<boolean>;
    }>;
}
/**
 * An Abstract Motion controller
 * This class receives an xrInput and a profile layout and uses those to initialize the components
 * Each component has an observable to check for changes in value and state
 */
declare abstract class WebXRAbstractMotionController implements IDisposable {
    protected scene: Scene;
    protected layout: IMotionControllerLayout;
    /**
     * The gamepad object correlating to this controller
     */
    gamepadObject: IMinimalMotionControllerObject;
    /**
     * handedness (left/right/none) of this controller
     */
    handedness: MotionControllerHandedness;
    /**
     * @internal
     * [false]
     */
    _doNotLoadControllerMesh: boolean;
    private _controllerCache?;
    private _initComponent;
    private _modelReady;
    /**
     * A map of components (WebXRControllerComponent) in this motion controller
     * Components have a ComponentType and can also have both button and axis definitions
     */
    readonly components: {
        [id: string]: WebXRControllerComponent;
    };
    /**
     * Disable the model's animation. Can be set at any time.
     */
    disableAnimation: boolean;
    /**
     * Observers registered here will be triggered when the model of this controller is done loading
     */
    onModelLoadedObservable: Observable<WebXRAbstractMotionController>;
    /**
     * The profile id of this motion controller
     */
    abstract profileId: string;
    /**
     * The root mesh of the model. It is null if the model was not yet initialized
     */
    rootMesh: Nullable<AbstractMesh>;
    /**
     * constructs a new abstract motion controller
     * @param scene the scene to which the model of the controller will be added
     * @param layout The profile layout to load
     * @param gamepadObject The gamepad object correlating to this controller
     * @param handedness handedness (left/right/none) of this controller
     * @param _doNotLoadControllerMesh set this flag to ignore the mesh loading
     * @param _controllerCache a cache holding controller models already loaded in this session
     */
    constructor(scene: Scene, layout: IMotionControllerLayout, 
    /**
     * The gamepad object correlating to this controller
     */
    gamepadObject: IMinimalMotionControllerObject, 
    /**
     * handedness (left/right/none) of this controller
     */
    handedness: MotionControllerHandedness, 
    /**
     * @internal
     * [false]
     */
    _doNotLoadControllerMesh?: boolean, _controllerCache?: Array<{
        filename: string;
        path: string;
        meshes: AbstractMesh[];
    }> | undefined);
    /**
     * Dispose this controller, the model mesh and all its components
     */
    dispose(): void;
    /**
     * Returns all components of specific type
     * @param type the type to search for
     * @returns an array of components with this type
     */
    getAllComponentsOfType(type: MotionControllerComponentType): WebXRControllerComponent[];
    /**
     * get a component based an its component id as defined in layout.components
     * @param id the id of the component
     * @returns the component correlates to the id or undefined if not found
     */
    getComponent(id: string): WebXRControllerComponent;
    /**
     * Get the list of components available in this motion controller
     * @returns an array of strings correlating to available components
     */
    getComponentIds(): string[];
    /**
     * Get the first component of specific type
     * @param type type of component to find
     * @returns a controller component or null if not found
     */
    getComponentOfType(type: MotionControllerComponentType): Nullable<WebXRControllerComponent>;
    /**
     * Get the main (Select) component of this controller as defined in the layout
     * @returns the main component of this controller
     */
    getMainComponent(): WebXRControllerComponent;
    /**
     * Loads the model correlating to this controller
     * When the mesh is loaded, the onModelLoadedObservable will be triggered
     * @returns A promise fulfilled with the result of the model loading
     */
    loadModel(): Promise<boolean>;
    /**
     * Update this model using the current XRFrame
     * @param xrFrame the current xr frame to use and update the model
     */
    updateFromXRFrame(xrFrame: XRFrame): void;
    /**
     * Backwards compatibility due to a deeply-integrated typo
     */
    get handness(): MotionControllerHandedness;
    /**
     * Pulse (vibrate) this controller
     * If the controller does not support pulses, this function will fail silently and return Promise<false> directly after called
     * Consecutive calls to this function will cancel the last pulse call
     *
     * @param value the strength of the pulse in 0.0...1.0 range
     * @param duration Duration of the pulse in milliseconds
     * @param hapticActuatorIndex optional index of actuator (will usually be 0)
     * @returns a promise that will send true when the pulse has ended and false if the device doesn't support pulse or an error accrued
     */
    pulse(value: number, duration: number, hapticActuatorIndex?: number): Promise<boolean>;
    protected _getChildByName(node: AbstractMesh, name: string): AbstractMesh | undefined;
    protected _getImmediateChildByName(node: AbstractMesh, name: string): AbstractMesh | undefined;
    /**
     * Moves the axis on the controller mesh based on its current state
     * @param axisMap
     * @param axisValue the value of the axis which determines the meshes new position
     * @internal
     */
    protected _lerpTransform(axisMap: IMotionControllerMeshMap, axisValue: number, fixValueCoordinates?: boolean): void;
    /**
     * Update the model itself with the current frame data
     * @param xrFrame the frame to use for updating the model mesh
     */
    protected updateModel(xrFrame: XRFrame): void;
    /**
     * Get the filename and path for this controller's model
     * @returns a map of filename and path
     */
    protected abstract _getFilenameAndPath(): {
        filename: string;
        path: string;
    };
    /**
     * This function is called before the mesh is loaded. It checks for loading constraints.
     * For example, this function can check if the GLB loader is available
     * If this function returns false, the generic controller will be loaded instead
     * @returns Is the client ready to load the mesh
     */
    protected abstract _getModelLoadingConstraints(): boolean;
    /**
     * This function will be called after the model was successfully loaded and can be used
     * for mesh transformations before it is available for the user
     * @param meshes the loaded meshes
     */
    protected abstract _processLoadedModel(meshes: AbstractMesh[]): void;
    /**
     * Set the root mesh for this controller. Important for the WebXR controller class
     * @param meshes the loaded meshes
     */
    protected abstract _setRootMesh(meshes: AbstractMesh[]): void;
    /**
     * A function executed each frame that updates the mesh (if needed)
     * @param xrFrame the current xrFrame
     */
    protected abstract _updateModel(xrFrame: XRFrame): void;
    private _getGenericFilenameAndPath;
    private _getGenericParentMesh;
}

/**
 * Manage the mouse inputs to control the movement of a free camera.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
 */
declare class FreeCameraMouseInput implements ICameraInput<FreeCamera> {
    /**
     * [true] Define if touch is enabled in the mouse input
     */
    touchEnabled: boolean;
    /**
     * Defines the camera the input is attached to.
     */
    camera: FreeCamera;
    /**
     * Defines the buttons associated with the input to handle camera move.
     */
    buttons: number[];
    /**
     * Defines the pointer angular sensibility  along the X and Y axis or how fast is the camera rotating.
     */
    angularSensibility: number;
    private _pointerInput;
    private _onMouseMove;
    private _observer;
    private _previousPosition;
    /**
     * Observable for when a pointer move event occurs containing the move offset
     */
    onPointerMovedObservable: Observable<{
        offsetX: number;
        offsetY: number;
    }>;
    /**
     * @internal
     * If the camera should be rotated automatically based on pointer movement
     */
    _allowCameraRotation: boolean;
    private _currentActiveButton;
    private _activePointerId;
    private _contextMenuBind;
    /**
     * Manage the mouse inputs to control the movement of a free camera.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
     * @param touchEnabled Defines if touch is enabled or not
     */
    constructor(
    /**
     * [true] Define if touch is enabled in the mouse input
     */
    touchEnabled?: boolean);
    /**
     * Attach the input controls to a specific dom element to get the input from.
     * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     */
    attachControl(noPreventDefault?: boolean): void;
    /**
     * Called on JS contextmenu event.
     * Override this method to provide functionality.
     * @param evt the context menu event
     */
    onContextMenu(evt: PointerEvent): void;
    /**
     * Detach the current controls from the specified dom element.
     */
    detachControl(): void;
    /**
     * Gets the class name of the current input.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Get the friendly name associated with the input class.
     * @returns the input friendly name
     */
    getSimpleName(): string;
}

/**
 * Base class for mouse wheel input..
 * See FollowCameraMouseWheelInput in src/Cameras/Inputs/freeCameraMouseWheelInput.ts
 * for example usage.
 */
declare abstract class BaseCameraMouseWheelInput implements ICameraInput<Camera> {
    /**
     * Defines the camera the input is attached to.
     */
    abstract camera: Camera;
    /**
     * How fast is the camera moves in relation to X axis mouseWheel events.
     * Use negative value to reverse direction.
     */
    wheelPrecisionX: number;
    /**
     * How fast is the camera moves in relation to Y axis mouseWheel events.
     * Use negative value to reverse direction.
     */
    wheelPrecisionY: number;
    /**
     * How fast is the camera moves in relation to Z axis mouseWheel events.
     * Use negative value to reverse direction.
     */
    wheelPrecisionZ: number;
    /**
     * Observable for when a mouse wheel move event occurs.
     */
    onChangedObservable: Observable<{
        wheelDeltaX: number;
        wheelDeltaY: number;
        wheelDeltaZ: number;
    }>;
    private _wheel;
    private _observer;
    /**
     * Attach the input controls to a specific dom element to get the input from.
     * @param noPreventDefault Defines whether event caught by the controls
     *   should call preventdefault().
     *   (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     */
    attachControl(noPreventDefault?: boolean): void;
    /**
     * Detach the current controls from the specified dom element.
     */
    detachControl(): void;
    /**
     * Called for each rendered frame.
     */
    checkInputs(): void;
    /**
     * Gets the class name of the current input.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Get the friendly name associated with the input class.
     * @returns the input friendly name
     */
    getSimpleName(): string;
    /**
     * Incremental value of multiple mouse wheel movements of the X axis.
     * Should be zero-ed when read.
     */
    protected _wheelDeltaX: number;
    /**
     * Incremental value of multiple mouse wheel movements of the Y axis.
     * Should be zero-ed when read.
     */
    protected _wheelDeltaY: number;
    /**
     * Incremental value of multiple mouse wheel movements of the Z axis.
     * Should be zero-ed when read.
     */
    protected _wheelDeltaZ: number;
    /**
     * Firefox uses a different scheme to report scroll distances to other
     * browsers. Rather than use complicated methods to calculate the exact
     * multiple we need to apply, let's just cheat and use a constant.
     * https://developer.mozilla.org/en-US/docs/Web/API/WheelEvent/deltaMode
     * https://stackoverflow.com/questions/20110224/what-is-the-height-of-a-line-in-a-wheel-event-deltamode-dom-delta-line
     */
    private readonly _ffMultiplier;
    /**
     * Different event attributes for wheel data fall into a few set ranges.
     * Some relevant but dated date here:
     * https://stackoverflow.com/questions/5527601/normalizing-mousewheel-speed-across-browsers
     */
    private readonly _normalize;
}

/**
 * Manage the mouse wheel inputs to control a free camera.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
 */
declare class FreeCameraMouseWheelInput extends BaseCameraMouseWheelInput {
    /**
     * Defines the camera the input is attached to.
     */
    camera: FreeCamera;
    /**
     * Gets the class name of the current input.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Set which movement axis (relative to camera's orientation) the mouse
     * wheel's X axis controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelXMoveRelative(axis: Nullable<Coordinate>);
    /**
     * Get the configured movement axis (relative to camera's orientation) the
     * mouse wheel's X axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelXMoveRelative(): Nullable<Coordinate>;
    /**
     * Set which movement axis (relative to camera's orientation) the mouse
     * wheel's Y axis controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelYMoveRelative(axis: Nullable<Coordinate>);
    /**
     * Get the configured movement axis (relative to camera's orientation) the
     * mouse wheel's Y axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelYMoveRelative(): Nullable<Coordinate>;
    /**
     * Set which movement axis (relative to camera's orientation) the mouse
     * wheel's Z axis controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelZMoveRelative(axis: Nullable<Coordinate>);
    /**
     * Get the configured movement axis (relative to camera's orientation) the
     * mouse wheel's Z axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelZMoveRelative(): Nullable<Coordinate>;
    /**
     * Set which rotation axis (relative to camera's orientation) the mouse
     * wheel's X axis controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelXRotateRelative(axis: Nullable<Coordinate>);
    /**
     * Get the configured rotation axis (relative to camera's orientation) the
     * mouse wheel's X axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelXRotateRelative(): Nullable<Coordinate>;
    /**
     * Set which rotation axis (relative to camera's orientation) the mouse
     * wheel's Y axis controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelYRotateRelative(axis: Nullable<Coordinate>);
    /**
     * Get the configured rotation axis (relative to camera's orientation) the
     * mouse wheel's Y axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelYRotateRelative(): Nullable<Coordinate>;
    /**
     * Set which rotation axis (relative to camera's orientation) the mouse
     * wheel's Z axis controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelZRotateRelative(axis: Nullable<Coordinate>);
    /**
     * Get the configured rotation axis (relative to camera's orientation) the
     * mouse wheel's Z axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelZRotateRelative(): Nullable<Coordinate>;
    /**
     * Set which movement axis (relative to the scene) the mouse wheel's X axis
     * controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelXMoveScene(axis: Nullable<Coordinate>);
    /**
     * Get the configured movement axis (relative to the scene) the mouse wheel's
     * X axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelXMoveScene(): Nullable<Coordinate>;
    /**
     * Set which movement axis (relative to the scene) the mouse wheel's Y axis
     * controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelYMoveScene(axis: Nullable<Coordinate>);
    /**
     * Get the configured movement axis (relative to the scene) the mouse wheel's
     * Y axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelYMoveScene(): Nullable<Coordinate>;
    /**
     * Set which movement axis (relative to the scene) the mouse wheel's Z axis
     * controls.
     * @param axis The axis to be moved. Set null to clear.
     */
    set wheelZMoveScene(axis: Nullable<Coordinate>);
    /**
     * Get the configured movement axis (relative to the scene) the mouse wheel's
     * Z axis controls.
     * @returns The configured axis or null if none.
     */
    get wheelZMoveScene(): Nullable<Coordinate>;
    /**
     * Called for each rendered frame.
     */
    checkInputs(): void;
    private _moveRelative;
    private _rotateRelative;
    private _moveScene;
    /**
     * These are set to the desired default behaviour.
     */
    private _wheelXAction;
    private _wheelXActionCoordinate;
    private _wheelYAction;
    private _wheelYActionCoordinate;
    private _wheelZAction;
    private _wheelZActionCoordinate;
    /**
     * Update the camera according to any configured properties for the 3
     * mouse-wheel axis.
     */
    private _updateCamera;
    /**
     * Update one property of the camera.
     * @param value
     * @param cameraProperty
     * @param coordinate
     */
    private _updateCameraProperty;
}

/**
 * Default Inputs manager for the FreeCamera.
 * It groups all the default supported inputs for ease of use.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
 */
declare class FreeCameraInputsManager extends CameraInputsManager<FreeCamera> {
    /**
     * @internal
     */
    _mouseInput: Nullable<FreeCameraMouseInput>;
    /**
     * @internal
     */
    _mouseWheelInput: Nullable<FreeCameraMouseWheelInput>;
    /**
     * Instantiates a new FreeCameraInputsManager.
     * @param camera Defines the camera the inputs belong to
     */
    constructor(camera: FreeCamera);
    /**
     * Add keyboard input support to the input manager.
     * @returns the current input manager
     */
    addKeyboard(): FreeCameraInputsManager;
    /**
     * Add mouse input support to the input manager.
     * @param touchEnabled if the FreeCameraMouseInput should support touch (default: true)
     * @returns the current input manager
     */
    addMouse(touchEnabled?: boolean): FreeCameraInputsManager;
    /**
     * Removes the mouse input support from the manager
     * @returns the current input manager
     */
    removeMouse(): FreeCameraInputsManager;
    /**
     * Add mouse wheel input support to the input manager.
     * @returns the current input manager
     */
    addMouseWheel(): FreeCameraInputsManager;
    /**
     * Removes the mouse wheel input support from the manager
     * @returns the current input manager
     */
    removeMouseWheel(): FreeCameraInputsManager;
    /**
     * Add touch input support to the input manager.
     * @returns the current input manager
     */
    addTouch(): FreeCameraInputsManager;
    /**
     * Remove all attached input methods from a camera
     */
    clear(): void;
}

/**
 * This represents a free type of camera. It can be useful in First Person Shooter game for instance.
 * Please consider using the new UniversalCamera instead as it adds more functionality like the gamepad.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_introduction#universal-camera
 */
declare class FreeCamera extends TargetCamera {
    /**
     * Define the collision ellipsoid of the camera.
     * This is helpful to simulate a camera body like the player body around the camera
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_collisions#arcrotatecamera
     */
    ellipsoid: Vector3;
    /**
     * Define an offset for the position of the ellipsoid around the camera.
     * This can be helpful to determine the center of the body near the gravity center of the body
     * instead of its head.
     */
    ellipsoidOffset: Vector3;
    /**
     * Enable or disable collisions of the camera with the rest of the scene objects.
     */
    checkCollisions: boolean;
    /**
     * Enable or disable gravity on the camera.
     */
    applyGravity: boolean;
    /**
     * Define the input manager associated to the camera.
     */
    inputs: FreeCameraInputsManager;
    /**
     * Gets the input sensibility for a mouse input. (default is 2000.0)
     * Higher values reduce sensitivity.
     */
    get angularSensibility(): number;
    /**
     * Sets the input sensibility for a mouse input. (default is 2000.0)
     * Higher values reduce sensitivity.
     */
    set angularSensibility(value: number);
    /**
     * Gets or Set the list of keyboard keys used to control the forward move of the camera.
     */
    get keysUp(): number[];
    set keysUp(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the upward move of the camera.
     */
    get keysUpward(): number[];
    set keysUpward(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the backward move of the camera.
     */
    get keysDown(): number[];
    set keysDown(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the downward move of the camera.
     */
    get keysDownward(): number[];
    set keysDownward(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the left strafe move of the camera.
     */
    get keysLeft(): number[];
    set keysLeft(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the right strafe move of the camera.
     */
    get keysRight(): number[];
    set keysRight(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the left rotation move of the camera.
     */
    get keysRotateLeft(): number[];
    set keysRotateLeft(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the right rotation move of the camera.
     */
    get keysRotateRight(): number[];
    set keysRotateRight(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the up rotation move of the camera.
     */
    get keysRotateUp(): number[];
    set keysRotateUp(value: number[]);
    /**
     * Gets or Set the list of keyboard keys used to control the down rotation move of the camera.
     */
    get keysRotateDown(): number[];
    set keysRotateDown(value: number[]);
    /**
     * Event raised when the camera collide with a mesh in the scene.
     */
    onCollide: (collidedMesh: AbstractMesh) => void;
    private _collider;
    private _needMoveForGravity;
    private _oldPosition;
    private _diffPosition;
    private _newPosition;
    /** @internal */
    _localDirection: Vector3;
    /** @internal */
    _transformedDirection: Vector3;
    /**
     * Instantiates a Free Camera.
     * This represents a free type of camera. It can be useful in First Person Shooter game for instance.
     * Please consider using the new UniversalCamera instead as it adds more functionality like touch to this camera.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_introduction#universal-camera
     * @param name Define the name of the camera in the scene
     * @param position Define the start position of the camera in the scene
     * @param scene Define the scene the camera belongs to
     * @param setActiveOnSceneIfNoneActive Defines whether the camera should be marked as active if not other active cameras have been defined
     */
    constructor(name: string, position: Vector3, scene?: Scene, setActiveOnSceneIfNoneActive?: boolean);
    /**
     * Attach the input controls to a specific dom element to get the input from.
     * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     */
    attachControl(noPreventDefault?: boolean): void;
    /**
     * Attach the input controls to a specific dom element to get the input from.
     * @param ignored defines an ignored parameter kept for backward compatibility.
     * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     * BACK COMPAT SIGNATURE ONLY.
     */
    attachControl(ignored: any, noPreventDefault?: boolean): void;
    /**
     * Detach the current controls from the specified dom element.
     */
    detachControl(): void;
    private _collisionMask;
    /**
     * Define a collision mask to limit the list of object the camera can collide with
     */
    get collisionMask(): number;
    set collisionMask(mask: number);
    /**
     * @internal
     */
    _collideWithWorld(displacement: Vector3): void;
    private _onCollisionPositionChange;
    /** @internal */
    _checkInputs(): void;
    /**
     * Enable movement without a user input. This allows gravity to always be applied.
     */
    set needMoveForGravity(value: boolean);
    /**
     * When true, gravity is applied whether there is user input or not.
     */
    get needMoveForGravity(): boolean;
    /** @internal */
    _decideIfNeedsToMove(): boolean;
    /** @internal */
    _updatePosition(): void;
    /**
     * Destroy the camera and release the current resources hold by it.
     */
    dispose(): void;
    /**
     * Gets the current object class name.
     * @returns the class name
     */
    getClassName(): string;
}

/**
 * WebXR Camera which holds the views for the xrSession
 * @see https://doc.babylonjs.com/features/featuresDeepDive/webXR/webXRCamera
 */
declare class WebXRCamera extends FreeCamera {
    private _xrSessionManager;
    private static _ScaleReadOnly;
    private _firstFrame;
    private _referenceQuaternion;
    private _referencedPosition;
    private _trackingState;
    /**
     * This will be triggered after the first XR Frame initialized the camera,
     * including the right number of views and their rendering parameters
     */
    onXRCameraInitializedObservable: Observable<WebXRCamera>;
    /**
     * Observable raised before camera teleportation
     * @deprecated use onBeforeCameraTeleport of the teleportation feature instead
     */
    onBeforeCameraTeleport: Observable<Vector3>;
    /**
     *  Observable raised after camera teleportation
     * @deprecated use onAfterCameraTeleport of the teleportation feature instead
     */
    onAfterCameraTeleport: Observable<Vector3>;
    /**
     * Notifies when the camera's tracking state has changed.
     * Notice - will also be triggered when tracking has started (at the beginning of the session)
     */
    onTrackingStateChanged: Observable<WebXRTrackingState>;
    /**
     * Should position compensation execute on first frame.
     * This is used when copying the position from a native (non XR) camera
     */
    compensateOnFirstFrame: boolean;
    /**
     * The last XRViewerPose from the current XRFrame
     * @internal
     */
    _lastXRViewerPose?: XRViewerPose;
    /**
     * webXRCamera relies on rotationQuaternion and doesn't use camera rotation property
     */
    rotationQuaternion: Quaternion;
    /**
     * Creates a new webXRCamera, this should only be set at the camera after it has been updated by the xrSessionManager
     * @param name the name of the camera
     * @param scene the scene to add the camera to
     * @param _xrSessionManager a constructed xr session manager
     */
    constructor(name: string, scene: Scene, _xrSessionManager: WebXRSessionManager);
    /**
     * Get the current XR tracking state of the camera
     */
    get trackingState(): WebXRTrackingState;
    private _setTrackingState;
    /**
     * Return the user's height, unrelated to the current ground.
     * This will be the y position of this camera, when ground level is 0.
     *
     * Note - this value is multiplied by the worldScalingFactor (if set), so it will be in the same units as the scene.
     */
    get realWorldHeight(): number;
    /** @internal */
    _updateForDualEyeDebugging(): void;
    /**
     * Sets this camera's transformation based on a non-vr camera
     * @param otherCamera the non-vr camera to copy the transformation from
     * @param resetToBaseReferenceSpace should XR reset to the base reference space
     */
    setTransformationFromNonVRCamera(otherCamera?: Camera, resetToBaseReferenceSpace?: boolean): void;
    /**
     * Gets the current instance class name ("WebXRCamera").
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Set the target for the camera to look at.
     * Note that this only rotates around the Y axis, as opposed to the default behavior of other cameras
     * @param target the target to set the camera to look at
     */
    setTarget(target: Vector3): void;
    dispose(): void;
    private _updateDepthNearFar;
    private _updateFromXRSession;
    private _updateNumberOfRigCameras;
    private _updateReferenceSpace;
}

/**
 * Configuration options for the WebXR controller creation
 */
interface IWebXRControllerOptions {
    /**
     * Should the controller mesh be animated when a user interacts with it
     * The pressed buttons / thumbstick and touchpad animations will be disabled
     */
    disableMotionControllerAnimation?: boolean;
    /**
     * Do not load the controller mesh, in case a different mesh needs to be loaded.
     */
    doNotLoadControllerMesh?: boolean;
    /**
     * Force a specific controller type for this controller.
     * This can be used when creating your own profile or when testing different controllers
     */
    forceControllerProfile?: string;
    /**
     * Defines a rendering group ID for meshes that will be loaded.
     * This is for the default controllers only.
     */
    renderingGroupId?: number;
}
/**
 * Represents an XR controller
 */
declare class WebXRInputSource {
    private _scene;
    /** The underlying input source for the controller  */
    inputSource: XRInputSource;
    private _options;
    private _tmpVector;
    private _uniqueId;
    private _disposed;
    /**
     * Represents the part of the controller that is held. This may not exist if the controller is the head mounted display itself, if that's the case only the pointer from the head will be available
     */
    grip?: AbstractMesh;
    /**
     * If available, this is the gamepad object related to this controller.
     * Using this object it is possible to get click events and trackpad changes of the
     * webxr controller that is currently being used.
     */
    motionController?: WebXRAbstractMotionController;
    /**
     * Event that fires when the controller is removed/disposed.
     * The object provided as event data is this controller, after associated assets were disposed.
     * uniqueId is still available.
     */
    onDisposeObservable: Observable<WebXRInputSource>;
    /**
     * Will be triggered when the mesh associated with the motion controller is done loading.
     * It is also possible that this will never trigger (!) if no mesh was loaded, or if the developer decides to load a different mesh
     * A shortened version of controller -> motion controller -> on mesh loaded.
     */
    onMeshLoadedObservable: Observable<AbstractMesh>;
    /**
     * Observers registered here will trigger when a motion controller profile was assigned to this xr controller
     */
    onMotionControllerInitObservable: Observable<WebXRAbstractMotionController>;
    /**
     * Pointer which can be used to select objects or attach a visible laser to
     */
    pointer: AbstractMesh;
    /**
     * The last XRPose the was calculated on the current XRFrame
     * @internal
     */
    _lastXRPose?: XRPose;
    /**
     * Creates the input source object
     * @see https://doc.babylonjs.com/features/featuresDeepDive/webXR/webXRInputControllerSupport
     * @param _scene the scene which the controller should be associated to
     * @param inputSource the underlying input source for the controller
     * @param _options options for this controller creation
     */
    constructor(_scene: Scene, 
    /** The underlying input source for the controller  */
    inputSource: XRInputSource, _options?: IWebXRControllerOptions);
    /**
     * Get this controllers unique id
     */
    get uniqueId(): string;
    /**
     * Disposes of the object
     */
    dispose(): void;
    /**
     * Gets a world space ray coming from the pointer or grip
     * @param result the resulting ray
     * @param gripIfAvailable use the grip mesh instead of the pointer, if available
     */
    getWorldPointerRayToRef(result: Ray, gripIfAvailable?: boolean): void;
    /**
     * Updates the controller pose based on the given XRFrame
     * @param xrFrame xr frame to update the pose with
     * @param referenceSpace reference space to use
     * @param xrCamera the xr camera, used for parenting
     * @param xrSessionManager the session manager used to get the world reference system
     */
    updateFromXRFrame(xrFrame: XRFrame, referenceSpace: XRReferenceSpace, xrCamera: WebXRCamera, xrSessionManager: WebXRSessionManager): void;
}

/**
 * The schema for initialization options of the XR Input class
 */
interface IWebXRInputOptions {
    /**
     * If set to true no model will be automatically loaded
     */
    doNotLoadControllerMeshes?: boolean;
    /**
     * If set, this profile will be used for all controllers loaded (for example "microsoft-mixed-reality")
     * If not found, the xr input profile data will be used.
     * Profiles are defined here - https://github.com/immersive-web/webxr-input-profiles/
     */
    forceInputProfile?: string;
    /**
     * Do not send a request to the controller repository to load the profile.
     *
     * Instead, use the controllers available in babylon itself.
     */
    disableOnlineControllerRepository?: boolean;
    /**
     * A custom URL for the controllers repository
     */
    customControllersRepositoryURL?: string;
    /**
     * Should the controller model's components not move according to the user input
     */
    disableControllerAnimation?: boolean;
    /**
     * Optional options to pass to the controller. Will be overridden by the Input options where applicable
     */
    controllerOptions?: IWebXRControllerOptions;
}
/**
 * XR input used to track XR inputs such as controllers/rays
 */
declare class WebXRInput implements IDisposable {
    /**
     * the xr session manager for this session
     */
    xrSessionManager: WebXRSessionManager;
    /**
     * the WebXR camera for this session. Mainly used for teleportation
     */
    xrCamera: WebXRCamera;
    private readonly _options;
    /**
     * XR controllers being tracked
     */
    controllers: Array<WebXRInputSource>;
    private _frameObserver;
    private _sessionEndedObserver;
    private _sessionInitObserver;
    /**
     * Event when a controller has been connected/added
     */
    onControllerAddedObservable: Observable<WebXRInputSource>;
    /**
     * Event when a controller has been removed/disconnected
     */
    onControllerRemovedObservable: Observable<WebXRInputSource>;
    /**
     * Initializes the WebXRInput
     * @param xrSessionManager the xr session manager for this session
     * @param xrCamera the WebXR camera for this session. Mainly used for teleportation
     * @param _options = initialization options for this xr input
     */
    constructor(
    /**
     * the xr session manager for this session
     */
    xrSessionManager: WebXRSessionManager, 
    /**
     * the WebXR camera for this session. Mainly used for teleportation
     */
    xrCamera: WebXRCamera, _options?: IWebXRInputOptions);
    private _onInputSourcesChange;
    private _addAndRemoveControllers;
    /**
     * Disposes of the object
     */
    dispose(): void;
}

/**
 * The options container for the controller movement module
 */
interface IWebXRControllerMovementOptions {
    /**
     * Override default behaviour and provide your own movement controls
     */
    customRegistrationConfigurations?: WebXRControllerMovementRegistrationConfiguration[];
    /**
     * Is movement enabled
     */
    movementEnabled?: boolean;
    /**
     * Camera direction follows view pose and movement by default will move independently of the viewer's pose.
     */
    movementOrientationFollowsViewerPose: boolean;
    /**
     * Movement speed factor (default is 1.0)
     */
    movementSpeed?: number;
    /**
     * Minimum threshold the controller's thumbstick/touchpad must pass before being recognized for movement (avoids jitter/unintentional movement)
     */
    movementThreshold?: number;
    /**
     * Is rotation enabled
     */
    rotationEnabled?: boolean;
    /**
     * Minimum threshold the controller's thumstick/touchpad must pass before being recognized for rotation (avoids jitter/unintentional rotation)
     */
    rotationThreshold?: number;
    /**
     * Movement speed factor (default is 1.0)
     */
    rotationSpeed?: number;
    /**
     * Babylon XR Input class for controller
     */
    xrInput: WebXRInput;
    /**
     * If movement orientation should follow controller orientation instead of viewer pose.
     * Make sure to set movementOrientationFollowsViewerPose to false, otherwise it will be ignored.
     */
    movementOrientationFollowsController: boolean;
    /**
     * If orientation follows the controller, this is the preferred handedness to use for forward movement.
     * If not set (or handedness not found), the handedness will be selected by the controller triggering the movement.
     * Note that this only works if movementOrientationFollowsController is true.
     */
    orientationPreferredHandedness?: XRHandedness;
}
/**
 * Feature context is used in handlers and on each XR frame to control the camera movement/direction.
 */
type WebXRControllerMovementFeatureContext = {
    movementEnabled: boolean;
    movementOrientationFollowsViewerPose: boolean;
    movementOrientationFollowsController: boolean;
    orientationPreferredHandedness?: XRHandedness;
    movementSpeed: number;
    movementThreshold: number;
    rotationEnabled: boolean;
    rotationSpeed: number;
    rotationThreshold: number;
};
/**
 * Current state of Movements shared across components and handlers.
 */
type WebXRControllerMovementState = {
    moveX: number;
    moveY: number;
    rotateX: number;
    rotateY: number;
};
/**
 * Button of Axis Handler must be specified.
 */
type WebXRControllerMovementRegistrationConfiguration = {
    /**
     * handlers are filtered to these types only
     */
    allowedComponentTypes?: MotionControllerComponentType[];
    /**
     * For registering movement to specific hand only.  Useful if your app has a "main hand" and "off hand" for determining the functionality of a controller.
     */
    forceHandedness?: XRHandedness;
    /**
     * For main component only (useful for buttons and may not trigger axis changes).
     */
    mainComponentOnly?: boolean;
    /**
     * Additional predicate to apply to controllers to restrict a handler being added.
     */
    componentSelectionPredicate?: (xrController: WebXRInputSource) => Nullable<WebXRControllerComponent>;
} & ({
    /**
     * Called when axis changes occur.
     */
    axisChangedHandler: (axes: IWebXRMotionControllerAxesValue, movementState: WebXRControllerMovementState, featureContext: WebXRControllerMovementFeatureContext, xrInput: WebXRInput) => void;
} | {
    /**
     * Called when the button state changes.
     */
    buttonChangedHandler: (pressed: IWebXRMotionControllerComponentChangesValues<boolean>, movementState: WebXRControllerMovementState, featureContext: WebXRControllerMovementFeatureContext, xrInput: WebXRInput) => void;
});
/**
 * This is a movement feature to be used with WebXR-enabled motion controllers.
 * When enabled and attached, the feature will allow a user to move around and rotate in the scene using
 * the input of the attached controllers.
 */
declare class WebXRControllerMovement extends WebXRAbstractFeature {
    private _controllers;
    private _currentRegistrationConfigurations;
    private _featureContext;
    private _movementDirection;
    private _movementState;
    private _xrInput;
    private _tmpRotationMatrix;
    private _tmpTranslationDirection;
    private _tmpMovementTranslation;
    private _tempCacheQuaternion;
    /**
     * The module's name
     */
    static readonly Name: "xr-controller-movement";
    /**
     * Standard controller configurations.
     */
    static readonly REGISTRATIONS: {
        [key: string]: WebXRControllerMovementRegistrationConfiguration[];
    };
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the webxr specs version
     */
    static readonly Version = 1;
    /**
     * Current movement direction.  Will be null before XR Frames have been processed.
     */
    get movementDirection(): Quaternion;
    /**
     * Is movement enabled
     */
    get movementEnabled(): boolean;
    /**
     * Sets whether movement is enabled or not
     * @param enabled is movement enabled
     */
    set movementEnabled(enabled: boolean);
    /**
     * If movement follows viewer pose
     */
    get movementOrientationFollowsViewerPose(): boolean;
    /**
     * Sets whether movement follows viewer pose
     * @param followsPose is movement should follow viewer pose
     */
    set movementOrientationFollowsViewerPose(followsPose: boolean);
    /**
     * Gets movement speed
     */
    get movementSpeed(): number;
    /**
     * Sets movement speed
     * @param movementSpeed movement speed
     */
    set movementSpeed(movementSpeed: number);
    /**
     * Gets minimum threshold the controller's thumbstick/touchpad must pass before being recognized for movement (avoids jitter/unintentional movement)
     */
    get movementThreshold(): number;
    /**
     * Sets minimum threshold the controller's thumbstick/touchpad must pass before being recognized for movement (avoids jitter/unintentional movement)
     * @param movementThreshold new threshold
     */
    set movementThreshold(movementThreshold: number);
    /**
     * Is rotation enabled
     */
    get rotationEnabled(): boolean;
    /**
     * Sets whether rotation is enabled or not
     * @param enabled is rotation enabled
     */
    set rotationEnabled(enabled: boolean);
    /**
     * Gets rotation speed factor
     */
    get rotationSpeed(): number;
    /**
     * Sets rotation speed factor (1.0 is default)
     * @param rotationSpeed new rotation speed factor
     */
    set rotationSpeed(rotationSpeed: number);
    /**
     * Gets minimum threshold the controller's thumbstick/touchpad must pass before being recognized for rotation (avoids jitter/unintentional rotation)
     */
    get rotationThreshold(): number;
    /**
     * Sets minimum threshold the controller's thumbstick/touchpad must pass before being recognized for rotation (avoids jitter/unintentional rotation)
     * @param threshold new threshold
     */
    set rotationThreshold(threshold: number);
    /**
     * constructs a new movement controller system
     * @param _xrSessionManager an instance of WebXRSessionManager
     * @param options configuration object for this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, options: IWebXRControllerMovementOptions);
    attach(): boolean;
    detach(): boolean;
    /**
     * Occurs on every XR frame.
     * @param _xrFrame
     */
    protected _onXRFrame(_xrFrame: XRFrame): void;
    private _attachController;
    private _detachController;
}

/**
 * The interface for the physics aggregate parameters
 */
interface PhysicsAggregateParameters {
    /**
     * The mass of the physics aggregate
     */
    mass: number;
    /**
     * The friction of the physics aggregate
     */
    friction?: number;
    /**
     * The coefficient of restitution of the physics aggregate
     */
    restitution?: number;
    /**
     * Radius for sphere, cylinder and capsule
     */
    radius?: number;
    /**
     * Starting point for cylinder/capsule
     */
    pointA?: Vector3;
    /**
     * Ending point for cylinder/capsule
     */
    pointB?: Vector3;
    /**
     * Extents for box
     */
    extents?: Vector3;
    /**
     * Orientation for box
     */
    rotation?: Quaternion;
    /**
     * mesh local center
     */
    center?: Vector3;
    /**
     * mesh object. Used for mesh and convex hull aggregates.
     */
    mesh?: Mesh;
    /**
     * Physics engine will try to make this body sleeping and not active
     */
    startAsleep?: boolean;
    /**
     * If true, mark the created shape as a trigger shape
     */
    isTriggerShape?: boolean;
}
/**
 * Helper class to create and interact with a PhysicsAggregate.
 * This is a transition object that works like Physics Plugin V1 Impostors.
 * This helper instantiates all mandatory physics objects to get a body/shape and material.
 * It's less efficient than handling body and shapes independently but for prototyping or
 * a small numbers of physics objects, it's good enough.
 */
declare class PhysicsAggregate {
    /**
     * The physics-enabled object used as the physics aggregate
     */
    transformNode: TransformNode;
    /**
     * The type of the physics aggregate
     */
    type: PhysicsShapeType | PhysicsShape;
    private _options;
    private _scene?;
    /**
     * The body that is associated with this aggregate
     */
    body: PhysicsBody;
    /**
     * The shape that is associated with this aggregate
     */
    shape: PhysicsShape;
    /**
     * The material that is associated with this aggregate
     */
    material: PhysicsMaterial;
    private _disposeShapeWhenDisposed;
    private _nodeDisposeObserver;
    constructor(
    /**
     * The physics-enabled object used as the physics aggregate
     */
    transformNode: TransformNode, 
    /**
     * The type of the physics aggregate
     */
    type: PhysicsShapeType | PhysicsShape, _options?: PhysicsAggregateParameters, _scene?: Scene | undefined);
    private _getObjectBoundingBox;
    private _hasVertices;
    private _addSizeOptions;
    /**
     * Releases the body, shape and material
     */
    dispose(): void;
}

/**
 * Options for the controller physics feature
 */
declare class IWebXRControllerPhysicsOptions {
    /**
     * Should the headset get its own impostor
     */
    enableHeadsetImpostor?: boolean;
    /**
     * Optional parameters for the headset impostor
     */
    headsetImpostorParams?: {
        /**
         * The type of impostor to create. Default is sphere
         */
        impostorType: number;
        /**
         * the size of the impostor. Defaults to 10cm
         */
        impostorSize?: number | {
            width: number;
            height: number;
            depth: number;
        };
        /**
         * Friction definitions
         */
        friction?: number;
        /**
         * Restitution
         */
        restitution?: number;
    };
    /**
     * The physics properties of the future impostors
     */
    physicsProperties?: {
        /**
         * If set to true, a mesh impostor will be created when the controller mesh was loaded
         * Note that this requires a physics engine that supports mesh impostors!
         */
        useControllerMesh?: boolean;
        /**
         * The type of impostor to create. Default is sphere
         */
        impostorType?: number;
        /**
         * the size of the impostor. Defaults to 10cm
         */
        impostorSize?: number | {
            width: number;
            height: number;
            depth: number;
        };
        /**
         * Friction definitions
         */
        friction?: number;
        /**
         * Restitution
         */
        restitution?: number;
    };
    /**
     * the xr input to use with this pointer selection
     */
    xrInput: WebXRInput;
}
/**
 * Add physics impostor to your webxr controllers,
 * including naive calculation of their linear and angular velocity
 */
declare class WebXRControllerPhysics extends WebXRAbstractFeature {
    private readonly _options;
    private _attachController;
    private _attachControllerV1;
    private _attachControllerV2;
    private _mapImpostorTypeToShapeType;
    private _createPhysicsImpostor;
    private _createPhysicsAggregate;
    private _controllers;
    private _debugMode;
    private _delta;
    private _headsetImpostor?;
    private _headsetMesh?;
    private _headsetAggregateV2?;
    private _lastTimestamp;
    private _physicsVersion;
    private _tmpQuaternion;
    private _tmpVector;
    /**
     * The module's name
     */
    static readonly Name: "xr-physics-controller";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the webxr specs version
     */
    static readonly Version = 2;
    /**
     * Construct a new Controller Physics Feature
     * @param _xrSessionManager the corresponding xr session manager
     * @param _options options to create this feature with
     */
    constructor(_xrSessionManager: WebXRSessionManager, _options: IWebXRControllerPhysicsOptions);
    /**
     * @internal
     * enable debugging - will show console outputs and the impostor mesh
     */
    _enablePhysicsDebug(): void;
    /**
     * Manually add a controller (if no xrInput was provided or physics engine was not enabled)
     * @param xrController the controller to add
     */
    addController(xrController: WebXRInputSource): void;
    /**
     * attach this feature
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    attach(): boolean;
    /**
     * detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Get the headset impostor, if enabled
     * @returns the impostor
     */
    getHeadsetImpostor(): PhysicsImpostor | undefined;
    /**
     * Get the physics impostor of a specific controller.
     * The impostor is not attached to a mesh because a mesh for each controller is not obligatory
     * @param controller the controller or the controller id of which to get the impostor
     * @returns the impostor or null
     */
    getImpostorForController(controller: WebXRInputSource | string): Nullable<PhysicsImpostor>;
    /**
     * Get the physics aggregate for a controller (v2 only)
     * @param controller the controller or the controller id
     * @returns the aggregate or null
     */
    getPhysicsAggregateForController(controller: WebXRInputSource | string): Nullable<PhysicsAggregate>;
    /**
     * Get the physics body for a controller (v2 only)
     * @param controller the controller or the controller id
     * @returns the physics body or null
     */
    getPhysicsBodyForController(controller: WebXRInputSource | string): Nullable<PhysicsBody>;
    /**
     * Get the headset physics aggregate (v2 only)
     * @returns the physics aggregate or null
     */
    getHeadsetPhysicsAggregate(): Nullable<PhysicsAggregate>;
    /**
     * Update the physics properties provided in the constructor
     * @param newProperties the new properties object
     * @param newProperties.impostorType
     * @param newProperties.impostorSize
     * @param newProperties.friction
     * @param newProperties.restitution
     */
    setPhysicsProperties(newProperties: {
        impostorType?: number;
        impostorSize?: number | {
            width: number;
            height: number;
            depth: number;
        };
        friction?: number;
        restitution?: number;
    }): void;
    protected _onXRFrame(_xrFrame: any): void;
    private _onXRFrameV1;
    private _onXRFrameV2;
    private _enableHeadsetPhysicsV1;
    private _enableHeadsetPhysicsV2;
    private _detachController;
}

/**
 * Options interface for the pointer selection module
 */
interface IWebXRControllerPointerSelectionOptions {
    /**
     * if provided, this scene will be used to render meshes.
     */
    customUtilityLayerScene?: Scene;
    /**
     * Disable the pointer up event when the xr controller in screen and gaze mode is disposed (meaning - when the user removed the finger from the screen)
     * If not disabled, the last picked point will be used to execute a pointer up event
     * If disabled, pointer up event will be triggered right after the pointer down event.
     * Used in screen and gaze target ray mode only
     */
    disablePointerUpOnTouchOut: boolean;
    /**
     * For gaze mode for tracked-pointer / controllers (time to select instead of button press)
     */
    forceGazeMode: boolean;
    /**
     * Factor to be applied to the pointer-moved function in the gaze mode. How sensitive should the gaze mode be when checking if the pointer moved
     * to start a new countdown to the pointer down event.
     * Defaults to 1.
     */
    gazeModePointerMovedFactor?: number;
    /**
     * Different button type to use instead of the main component
     */
    overrideButtonId?: string;
    /**
     *  use this rendering group id for the meshes (optional)
     */
    renderingGroupId?: number;
    /**
     * The amount of time in milliseconds it takes between pick found something to a pointer down event.
     * Used in gaze modes. Tracked pointer uses the trigger, screen uses touch events
     * 3000 means 3 seconds between pointing at something and selecting it
     */
    timeToSelect?: number;
    /**
     * Should meshes created here be added to a utility layer or the main scene
     */
    useUtilityLayer?: boolean;
    /**
     * Optional WebXR camera to be used for gaze selection
     */
    gazeCamera?: WebXRCamera;
    /**
     * the xr input to use with this pointer selection
     */
    xrInput: WebXRInput;
    /**
     * Should the scene pointerX and pointerY update be disabled
     * This is required for fullscreen AR GUI, but might slow down other experiences.
     * Disable in VR, if not needed.
     * The first rig camera (left eye) will be used to calculate the projection
     */
    disableScenePointerVectorUpdate: boolean;
    /**
     * Enable pointer selection on all controllers instead of switching between them
     */
    enablePointerSelectionOnAllControllers?: boolean;
    /**
     * The preferred hand to give the pointer selection to. This will be prioritized when the controller initialize.
     * If switch is enabled, it will still allow the user to switch between the different controllers
     */
    preferredHandedness?: XRHandedness;
    /**
     * Disable switching the pointer selection from one controller to the other.
     * If the preferred hand is set it will be fixed on this hand, and if not it will be fixed on the first controller added to the scene
     */
    disableSwitchOnClick?: boolean;
    /**
     * The maximum distance of the pointer selection feature. Defaults to 100.
     */
    maxPointerDistance?: number;
    /**
     * A function that will be called when a new selection mesh is generated.
     * This function should return a mesh that will be used as the selection mesh.
     * The default is a torus with a 0.01 diameter and 0.0075 thickness .
     */
    customSelectionMeshGenerator?: () => Mesh;
    /**
     * A function that will be called when a new laser pointer mesh is generated.
     * This function should return a mesh that will be used as the laser pointer mesh.
     * The height (y) of the mesh must be 1.
     */
    customLasterPointerMeshGenerator?: () => AbstractMesh;
    /**
     * Use the grip space instead of the pointer space for selection, if available.
     */
    forceGripIfAvailable?: boolean;
    /**
     * If set to true, the hand rays will be disabled and the user will be able to look and pick objects.
     * This requires system support (like in the vision OS) and will not work in all systems.
     * @experimental - this is an experimental feature and might change int he future
     */
    lookAndPickMode?: boolean;
}
/**
 * A module that will enable pointer selection for motion controllers of XR Input Sources
 */
declare class WebXRControllerPointerSelection extends WebXRAbstractFeature {
    private readonly _options;
    private static _IdCounter;
    private _attachController;
    private _controllers;
    private _scene;
    private _tmpVectorForPickCompare;
    private _attachedController;
    /**
     * The module's name
     */
    static readonly Name: "xr-controller-pointer-selection";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Disable lighting on the laser pointer (so it will always be visible)
     */
    disablePointerLighting: boolean;
    /**
     * Disable lighting on the selection mesh (so it will always be visible)
     */
    disableSelectionMeshLighting: boolean;
    /**
     * Should the laser pointer be displayed
     */
    displayLaserPointer: boolean;
    /**
     * Should the selection mesh be displayed (The ring at the end of the laser pointer)
     */
    displaySelectionMesh: boolean;
    /**
     * This color will be set to the laser pointer when selection is triggered
     */
    laserPointerPickedColor: Color3;
    /**
     * Default color of the laser pointer
     */
    laserPointerDefaultColor: Color3;
    /**
     * default color of the selection ring
     */
    selectionMeshDefaultColor: Color3;
    /**
     * This color will be applied to the selection ring when selection is triggered
     */
    selectionMeshPickedColor: Color3;
    /**
     * Optional filter to be used for ray selection.  This predicate shares behavior with
     * scene.pointerMovePredicate which takes priority if it is also assigned.
     */
    raySelectionPredicate: (mesh: AbstractMesh) => boolean;
    /**
     * constructs a new background remover module
     * @param _xrSessionManager the session manager for this module
     * @param _options read-only options to be used in this module
     */
    constructor(_xrSessionManager: WebXRSessionManager, _options: IWebXRControllerPointerSelectionOptions);
    /**
     * attach this feature
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    attach(): boolean;
    /**
     * detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Will get the mesh under a specific pointer.
     * `scene.meshUnderPointer` will only return one mesh - either left or right.
     * @param controllerId the controllerId to check
     * @returns The mesh under pointer or null if no mesh is under the pointer
     */
    getMeshUnderPointer(controllerId: string): Nullable<AbstractMesh>;
    /**
     * Get the xr controller that correlates to the pointer id in the pointer event
     *
     * @param id the pointer id to search for
     * @returns the controller that correlates to this id or null if not found
     */
    getXRControllerByPointerId(id: number): Nullable<WebXRInputSource>;
    /**
     * @internal
     */
    _getPointerSelectionDisabledByPointerId(id: number): boolean;
    /**
     * @internal
     */
    _setPointerSelectionDisabledByPointerId(id: number, state: boolean): void;
    private _identityMatrix;
    private _screenCoordinatesRef;
    private _viewportRef;
    protected _onXRFrame(_xrFrame: XRFrame): void;
    private get _utilityLayerScene();
    private _attachGazeMode;
    private _attachScreenRayMode;
    private _attachTrackedPointerRayMode;
    private _convertNormalToDirectionOfRay;
    private _detachController;
    private _generateNewMeshPair;
    private _pickingMoved;
    private _updatePointerDistance;
    private _augmentPointerInit;
    /** @internal */
    get lasterPointerDefaultColor(): Color3;
}

/**
 * The options container for the teleportation module
 */
interface IWebXRTeleportationOptions {
    /**
     * if provided, this scene will be used to render meshes.
     */
    customUtilityLayerScene?: Scene;
    /**
     * Values to configure the default target mesh
     */
    defaultTargetMeshOptions?: {
        /**
         * Fill color of the teleportation area
         */
        teleportationFillColor?: string;
        /**
         * Border color for the teleportation area
         */
        teleportationBorderColor?: string;
        /**
         * Disable the mesh's animation sequence
         */
        disableAnimation?: boolean;
        /**
         * Disable lighting on the material or the ring and arrow
         */
        disableLighting?: boolean;
        /**
         * Override the default material of the torus and arrow
         */
        torusArrowMaterial?: Material;
        /**
         * Override the default material of the Landing Zone
         */
        teleportationCircleMaterial?: Material;
    };
    /**
     * A list of meshes to use as floor meshes.
     * Meshes can be added and removed after initializing the feature using the
     * addFloorMesh and removeFloorMesh functions
     * If empty, rotation will still work
     */
    floorMeshes?: AbstractMesh[];
    /**
     *  use this rendering group id for the meshes (optional)
     */
    renderingGroupId?: number;
    /**
     * Should teleportation move only to snap points
     */
    snapPointsOnly?: boolean;
    /**
     * An array of points to which the teleportation will snap to.
     * If the teleportation ray is in the proximity of one of those points, it will be corrected to this point.
     */
    snapPositions?: Vector3[];
    /**
     * How close should the teleportation ray be in order to snap to position.
     * Default to 0.8 units (meters)
     */
    snapToPositionRadius?: number;
    /**
     * Provide your own teleportation mesh instead of babylon's wonderful doughnut.
     * If you want to support rotation, make sure your mesh has a direction indicator.
     *
     * When left untouched, the default mesh will be initialized.
     */
    teleportationTargetMesh?: AbstractMesh;
    /**
     * If main component is used (no thumbstick), how long in milliseconds should the "long press" take before teleport. Defaults to 3 seconds
     */
    timeToTeleport?: number;
    /**
     * If the main component is used, how long in milliseconds should the "long press" take before teleport starts. Defaults to 0
     */
    timeToTeleportStart?: number;
    /**
     * Disable using the thumbstick and use the main component (usually trigger) on long press.
     * This will be automatically true if the controller doesn't have a thumbstick or touchpad.
     */
    useMainComponentOnly?: boolean;
    /**
     * Should meshes created here be added to a utility layer or the main scene
     */
    useUtilityLayer?: boolean;
    /**
     * Babylon XR Input class for controller
     */
    xrInput: WebXRInput;
    /**
     * Meshes that the teleportation ray cannot go through
     */
    pickBlockerMeshes?: AbstractMesh[];
    /**
     * define an optional predicate to select which meshes should block the teleportation ray
     */
    blockerMeshesPredicate?: (mesh: AbstractMesh) => boolean;
    /**
     * Should the teleportation ray be blocked by all of the scene's pickable meshes?
     * Defaults to false
     */
    blockAllPickableMeshes?: boolean;
    /**
     * Color of the teleportation ray when it is blocked by a mesh in the pickBlockerMeshes array
     * Defaults to red.
     */
    blockedRayColor?: Color4;
    /**
     * Should teleport work only on a specific hand?
     */
    forceHandedness?: XRHandedness;
    /**
     * If provided, this function will be used to generate the ray mesh instead of the lines mesh being used per default
     */
    generateRayPathMesh?: (points: Vector3[], pickingInfo: PickingInfo) => AbstractMesh;
}
/**
 * This is a teleportation feature to be used with WebXR-enabled motion controllers.
 * When enabled and attached, the feature will allow a user to move around and rotate in the scene using
 * the input of the attached controllers.
 */
declare class WebXRMotionControllerTeleportation extends WebXRAbstractFeature {
    private _options;
    private _controllers;
    private _currentTeleportationControllerId;
    private _floorMeshes;
    private _quadraticBezierCurve;
    private _selectionFeature;
    private _snapToPositions;
    private _snappedToPoint;
    private _teleportationRingMaterial?;
    private _blockedRayColor;
    private _cachedColor4White;
    private _tmpRay;
    private _tmpVector;
    private _tmpQuaternion;
    private _worldScaleObserver?;
    /**
     * Skip the next teleportation. This can be controlled by the user to prevent the user from teleportation
     * to sections that are not yet "unlocked", but should still show the teleportation mesh.
     */
    skipNextTeleportation: boolean;
    /**
     * The module's name
     */
    static readonly Name: "xr-controller-teleportation";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the webxr specs version
     */
    static readonly Version = 1;
    /**
     * Is movement backwards enabled
     */
    backwardsMovementEnabled: boolean;
    /**
     * Distance to travel when moving backwards
     */
    backwardsTeleportationDistance: number;
    /**
     * The distance from the user to the inspection point in the direction of the controller
     * A higher number will allow the user to move further
     * defaults to 5 (meters, in xr units)
     */
    parabolicCheckRadius: number;
    /**
     * Should the module support parabolic ray on top of direct ray
     * If enabled, the user will be able to point "at the sky" and move according to predefined radius distance
     * Very helpful when moving between floors / different heights
     */
    parabolicRayEnabled: boolean;
    /**
     * The second type of ray - straight line.
     * Should it be enabled or should the parabolic line be the only one.
     */
    straightRayEnabled: boolean;
    /**
     * How much rotation should be applied when rotating right and left
     */
    rotationAngle: number;
    /**
     * This observable will notify when the target mesh position was updated.
     * The picking info it provides contains the point to which the target mesh will move ()
     */
    onTargetMeshPositionUpdatedObservable: Observable<PickingInfo>;
    /**
     * Is teleportation enabled. Can be used to allow rotation only.
     */
    teleportationEnabled: boolean;
    private _rotationEnabled;
    /**
     * Observable raised before camera rotation
     */
    onBeforeCameraTeleportRotation: Observable<number>;
    /**
     *  Observable raised after camera rotation
     */
    onAfterCameraTeleportRotation: Observable<Quaternion>;
    /**
     * Observable raised before camera teleportation
     */
    onBeforeCameraTeleport: Observable<Vector3>;
    /**
     *  Observable raised after camera teleportation
     */
    onAfterCameraTeleport: Observable<Vector3>;
    /**
     * Is rotation enabled when moving forward?
     * Disabling this feature will prevent the user from deciding the direction when teleporting
     */
    get rotationEnabled(): boolean;
    /**
     * Sets whether rotation is enabled or not
     * @param enabled is rotation enabled when teleportation is shown
     */
    set rotationEnabled(enabled: boolean);
    /**
     * Exposes the currently set teleportation target mesh.
     */
    get teleportationTargetMesh(): Nullable<AbstractMesh>;
    /**
     * constructs a new teleportation system
     * @param _xrSessionManager an instance of WebXRSessionManager
     * @param _options configuration object for this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, _options: IWebXRTeleportationOptions);
    /**
     * Get the snapPointsOnly flag
     */
    get snapPointsOnly(): boolean;
    /**
     * Sets the snapPointsOnly flag
     * @param snapToPoints should teleportation be exclusively to snap points
     */
    set snapPointsOnly(snapToPoints: boolean);
    /**
     * Add a new mesh to the floor meshes array
     * @param mesh the mesh to use as floor mesh
     */
    addFloorMesh(mesh: AbstractMesh): void;
    /**
     * Add a mesh to the list of meshes blocking the teleportation ray
     * @param mesh The mesh to add to the teleportation-blocking meshes
     */
    addBlockerMesh(mesh: AbstractMesh): void;
    /**
     * Add a new snap-to point to fix teleportation to this position
     * @param newSnapPoint The new Snap-To point
     */
    addSnapPoint(newSnapPoint: Vector3): void;
    attach(): boolean;
    detach(): boolean;
    dispose(): void;
    /**
     * Remove a mesh from the floor meshes array
     * @param mesh the mesh to remove
     */
    removeFloorMesh(mesh: AbstractMesh): void;
    /**
     * Remove a mesh from the blocker meshes array
     * @param mesh the mesh to remove
     */
    removeBlockerMesh(mesh: AbstractMesh): void;
    /**
     * Remove a mesh from the floor meshes array using its name
     * @param name the mesh name to remove
     */
    removeFloorMeshByName(name: string): void;
    /**
     * This function will iterate through the array, searching for this point or equal to it. It will then remove it from the snap-to array
     * @param snapPointToRemove the point (or a clone of it) to be removed from the array
     * @returns was the point found and removed or not
     */
    removeSnapPoint(snapPointToRemove: Vector3): boolean;
    /**
     * This function sets a selection feature that will be disabled when
     * the forward ray is shown and will be reattached when hidden.
     * This is used to remove the selection rays when moving.
     * @param selectionFeature the feature to disable when forward movement is enabled
     */
    setSelectionFeature(selectionFeature: Nullable<IWebXRFeature>): void;
    protected _onXRFrame(_xrFrame: XRFrame): void;
    private _attachController;
    private _createDefaultTargetMesh;
    private _detachController;
    private _findClosestSnapPointWithRadius;
    private _setTargetMeshPosition;
    private _setTargetMeshVisibility;
    private _disposeBezierCurve;
    private _colorArray;
    private _showParabolicPath;
    private _teleportForward;
}

type WebXRDepthUsage = "cpu" | "gpu";
type WebXRDepthDataFormat = "ushort" | "float" | "luminance-alpha";
/**
 * Options for Depth Sensing feature
 */
interface IWebXRDepthSensingOptions {
    /**
     *  The desired depth sensing usage for the session
     */
    usagePreference: WebXRDepthUsage[];
    /**
     * The desired depth sensing data format for the session
     */
    dataFormatPreference: WebXRDepthDataFormat[];
    /**
     * Depth sensing will be enabled on all materials per default, if the GPU variant is enabled.
     * If you just want to use the texture or the CPU variant instead set this to true.
     */
    disableDepthSensingOnMaterials?: boolean;
    /**
     * If set to true the occluded pixels will not be discarded but the pixel color will be changed based on the occlusion factor
     * Enabling this will lead to worse performance but slightly better outcome.
     * It is possible we will change this in the future to look even better.
     */
    useToleranceFactorForDepthSensing?: boolean;
    /**
     * If set to true the texture will be set to be used for visualization.
     * In this case it will probably NOT work correctly on the materials.
     * So be aware that, for the time being, you can only use one or the other.
     */
    prepareTextureForVisualization?: boolean;
}
type GetDepthInMetersType = (x: number, y: number) => number;
/**
 * WebXR Feature for WebXR Depth Sensing Module
 * @since 5.49.1
 */
declare class WebXRDepthSensing extends WebXRAbstractFeature {
    readonly options: IWebXRDepthSensingOptions;
    private _width;
    private _height;
    private _rawValueToMeters;
    private _textureType;
    private _normDepthBufferFromNormView;
    private _cachedDepthBuffer;
    private _cachedWebGLTexture;
    private _cachedDepthImageTexture;
    private _onCameraObserver;
    /**
     * Width of depth data. If depth data is not exist, returns null.
     */
    get width(): Nullable<number>;
    /**
     * Height of depth data. If depth data is not exist, returns null.
     */
    get height(): Nullable<number>;
    /**
     * Scale factor by which the raw depth values must be multiplied in order to get the depths in meters.
     */
    get rawValueToMeters(): Nullable<number>;
    /**
     * An XRRigidTransform that needs to be applied when indexing into the depth buffer.
     */
    get normDepthBufferFromNormView(): Nullable<XRRigidTransform>;
    /**
     * Describes which depth-sensing usage ("cpu" or "gpu") is used.
     */
    get depthUsage(): WebXRDepthUsage;
    /**
     * Describes which depth sensing data format ("ushort" or "float") is used.
     */
    get depthDataFormat(): WebXRDepthDataFormat;
    /**
     * Latest cached InternalTexture which containing depth buffer information.
     * This can be used when the depth usage is "gpu".
     * @deprecated This will be removed in the future. Use latestDepthImageTexture
     */
    get latestInternalTexture(): Nullable<InternalTexture>;
    /**
     * cached depth buffer
     */
    get latestDepthBuffer(): Nullable<ArrayBufferView>;
    /**
     * Event that notify when `DepthInformation.getDepthInMeters` is available.
     * `getDepthInMeters` method needs active XRFrame (not available for cached XRFrame)
     */
    onGetDepthInMetersAvailable: Observable<GetDepthInMetersType>;
    /**
     * Latest cached Texture of depth image which is made from the depth buffer data.
     */
    get latestDepthImageTexture(): Nullable<RawTexture>;
    /**
     * XRWebGLBinding which is used for acquiring WebGLDepthInformation
     */
    private _glBinding?;
    /**
     * The module's name
     */
    static readonly Name: "xr-depth-sensing";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Creates a new instance of the depth sensing feature
     * @param _xrSessionManager the WebXRSessionManager
     * @param options options for WebXR Depth Sensing Feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, options: IWebXRDepthSensingOptions);
    /**
     * attach this feature
     * Will usually be called by the features manager
     * @param force should attachment be forced (even when already attached)
     * @returns true if successful.
     */
    attach(force?: boolean): boolean;
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    protected _onXRFrame(_xrFrame: XRFrame): void;
    private _updateDepthInformationAndTextureCPUDepthUsage;
    private _updateDepthInformationAndTextureWebGLDepthUsage;
    /**
     * Extends the session init object if needed
     * @returns augmentation object for the xr session init object.
     */
    getXRSessionInitExtension(): Promise<Partial<XRSessionInit>>;
    private _getInternalTextureFromDepthInfo;
}

/**
 * Options for DOM Overlay feature
 */
interface IWebXRDomOverlayOptions {
    /**
     * DOM Element or document query selector string for overlay.
     *
     * NOTE: UA may make this element background transparent in XR.
     */
    element: Element | string;
    /**
     * Supress XR Select events on container element (DOM blocks interaction to scene).
     */
    supressXRSelectEvents?: boolean;
}
/**
 * Type of DOM overlay provided by UA.
 */
type WebXRDomOverlayType = 
/**
 * Covers the entire physical screen for a screen-based device, for example handheld AR
 */
"screen"
/**
 * Appears as a floating rectangle in space
 */
 | "floating"
/**
 * Follows the users head movement consistently, appearing similar to a HUD
 */
 | "head-locked";
/**
 * DOM Overlay Feature
 *
 * @since 5.0.0
 */
declare class WebXRDomOverlay extends WebXRAbstractFeature {
    /**
     * options to use when constructing this feature
     */
    readonly options: IWebXRDomOverlayOptions;
    /**
     * Type of overlay - non-null when available
     */
    private _domOverlayType;
    /**
     * Event Listener to supress "beforexrselect" events.
     */
    private _beforeXRSelectListener;
    /**
     * Element used for overlay
     */
    private _element;
    /**
     * The module's name
     */
    static readonly Name: "xr-dom-overlay";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Creates a new instance of the dom-overlay feature
     * @param _xrSessionManager an instance of WebXRSessionManager
     * @param options options to use when constructing this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, 
    /**
     * options to use when constructing this feature
     */
    options: IWebXRDomOverlayOptions);
    /**
     * attach this feature
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    attach(): boolean;
    /**
     * The type of DOM overlay (null when not supported).  Provided by UA and remains unchanged for duration of session.
     */
    get domOverlayType(): Nullable<WebXRDomOverlayType>;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    protected _onXRFrame(_xrFrame: XRFrame): void;
    /**
     * Extends the session init object if needed
     * @returns augmentation object for the xr session init object.
     */
    getXRSessionInitExtension(): Promise<Partial<XRSessionInit>>;
}

/**
 * The WebXR Eye Tracking feature grabs eye data from the device and provides it in an easy-access format.
 * Currently only enabled for BabylonNative applications.
 */
declare class WebXREyeTracking extends WebXRAbstractFeature {
    private _latestEyeSpace;
    private _gazeRay;
    /**
     * The module's name
     */
    static readonly Name: "xr-eye-tracking";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * This observable will notify registered observers when eye tracking starts
     */
    readonly onEyeTrackingStartedObservable: Observable<Ray>;
    /**
     * This observable will notify registered observers when eye tracking ends
     */
    readonly onEyeTrackingEndedObservable: Observable<void>;
    /**
     * This observable will notify registered observers on each frame that has valid tracking
     */
    readonly onEyeTrackingFrameUpdateObservable: Observable<Ray>;
    /**
     * Creates a new instance of the XR eye tracking feature.
     * @param _xrSessionManager An instance of WebXRSessionManager.
     */
    constructor(_xrSessionManager: WebXRSessionManager);
    /**
     * Dispose this feature and all of the resources attached.
     */
    dispose(): void;
    /**
     * Returns whether the gaze data is valid or not
     * @returns true if the data is valid
     */
    get isEyeGazeValid(): boolean;
    /**
     * Get a reference to the gaze ray. This data is valid while eye tracking persists, and will be set to null when gaze data is no longer available
     * @returns a reference to the gaze ray if it exists and is valid, returns null otherwise.
     */
    getEyeGaze(): Nullable<Ray>;
    protected _onXRFrame(frame: XRFrame): void;
    private _eyeTrackingStartListener;
    private _eyeTrackingEndListener;
    private _init;
}

/**
 * A babylon interface for a "WebXR" feature point.
 * Represents the position and confidence value of a given feature point.
 */
interface IWebXRFeaturePoint {
    /**
     * Represents the position of the feature point in world space.
     */
    position: Vector3;
    /**
     * Represents the confidence value of the feature point in world space. 0 being least confident, and 1 being most confident.
     */
    confidenceValue: number;
}
/**
 * The feature point system is used to detect feature points from real world geometry.
 * This feature is currently experimental and only supported on BabylonNative, and should not be used in the browser.
 * The newly introduced API can be seen in webxr.nativeextensions.d.ts and described in FeaturePoints.md.
 */
declare class WebXRFeaturePointSystem extends WebXRAbstractFeature {
    private _enabled;
    private _featurePointCloud;
    /**
     * The module's name
     */
    static readonly Name: "xr-feature-points";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Observers registered here will be executed whenever new feature points are added (on XRFrame while the session is tracking).
     * Will notify the observers about which feature points have been added.
     */
    readonly onFeaturePointsAddedObservable: Observable<number[]>;
    /**
     * Observers registered here will be executed whenever a feature point has been updated (on XRFrame while the session is tracking).
     * Will notify the observers about which feature points have been updated.
     */
    readonly onFeaturePointsUpdatedObservable: Observable<number[]>;
    /**
     * The current feature point cloud maintained across frames.
     */
    get featurePointCloud(): Array<IWebXRFeaturePoint>;
    /**
     * construct the feature point system
     * @param _xrSessionManager an instance of xr Session manager
     */
    constructor(_xrSessionManager: WebXRSessionManager);
    /**
     * Detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    /**
     * On receiving a new XR frame if this feature is attached notify observers new feature point data is available.
     * @param frame
     */
    protected _onXRFrame(frame: XRFrame): void;
    /**
     * Initializes the feature. If the feature point feature is not available for this environment do not mark the feature as enabled.
     */
    private _init;
}

/**
 * Configuration interface for the hand tracking feature
 */
interface IWebXRHandTrackingOptions {
    /**
     * The xrInput that will be used as source for new hands
     */
    xrInput: WebXRInput;
    /**
     * Configuration object for the joint meshes.
     */
    jointMeshes?: {
        /**
         * Should the meshes created be invisible (defaults to false).
         */
        invisible?: boolean;
        /**
         * A source mesh to be used to create instances. Defaults to an icosphere with two subdivisions and smooth lighting.
         * This mesh will be the source for all other (25) meshes.
         * It should have the general size of a single unit, as the instances will be scaled according to the provided radius.
         */
        sourceMesh?: Mesh;
        /**
         * This function will be called after a mesh was created for a specific joint.
         * Using this function you can either manipulate the instance or return a new mesh.
         * When returning a new mesh the instance created before will be disposed.
         * @param meshInstance An instance of the original joint mesh being used for the joint.
         * @param jointId The joint's index, see https://immersive-web.github.io/webxr-hand-input/#skeleton-joints-section for more info.
         * @param hand Which hand ("left", "right") the joint will be on.
         */
        onHandJointMeshGenerated?: (meshInstance: InstancedMesh, jointId: number, hand: XRHandedness) => AbstractMesh | undefined;
        /**
         * Should the source mesh stay visible (defaults to false).
         */
        keepOriginalVisible?: boolean;
        /**
         * Should each instance have its own physics impostor
         */
        enablePhysics?: boolean;
        /**
         * If enabled, override default physics properties
         */
        physicsProps?: {
            friction?: number;
            restitution?: number;
            impostorType?: number;
        };
        /**
         * Scale factor for all joint meshes (defaults to 1)
         */
        scaleFactor?: number;
    };
    /**
     * Configuration object for the hand meshes.
     */
    handMeshes?: {
        /**
         * Should the default hand mesh be disabled. In this case, the spheres will be visible (unless set invisible).
         */
        disableDefaultMeshes?: boolean;
        /**
         * Rigged hand meshes that will be tracked to the user's hands. This will override the default hand mesh.
         */
        customMeshes?: {
            right: AbstractMesh;
            left: AbstractMesh;
        };
        /**
         * Are the meshes prepared for a left-handed system. Default hand meshes are right-handed.
         */
        meshesUseLeftHandedCoordinates?: boolean;
        /**
         * If a hand mesh was provided, this array will define what axis will update which node. This will override the default hand mesh
         */
        customRigMappings?: {
            right: XRHandMeshRigMapping;
            left: XRHandMeshRigMapping;
        };
        /**
         * Override the colors of the hand meshes.
         */
        customColors?: {
            base?: Color3;
            fresnel?: Color3;
            fingerColor?: Color3;
            tipFresnel?: Color3;
        };
        /**
         * Define whether or not the hand meshes should be disposed on just invisible when the session ends.
         * Not setting, or setting to false, will maintain the hand meshes in the scene after the session ends, which will allow q quicker re-entry into XR.
         */
        disposeOnSessionEnd?: boolean;
        /**
         * Setting this will allow the developer to avoid loading the NME material and use the standard material instead.
         */
        disableHandShader?: boolean;
    };
}
/**
 * Parts of the hands divided to writs and finger names
 */
declare const enum HandPart {
    /**
     * HandPart - Wrist
     */
    WRIST = "wrist",
    /**
     * HandPart - The thumb
     */
    THUMB = "thumb",
    /**
     * HandPart - Index finger
     */
    INDEX = "index",
    /**
     * HandPart - Middle finger
     */
    MIDDLE = "middle",
    /**
     * HandPart - Ring finger
     */
    RING = "ring",
    /**
     * HandPart - Little finger
     */
    LITTLE = "little"
}
/**
 * Joints of the hand as defined by the WebXR specification.
 * https://immersive-web.github.io/webxr-hand-input/#skeleton-joints-section
 */
declare const enum WebXRHandJoint {
    /** Wrist */
    WRIST = "wrist",
    /** Thumb near wrist */
    THUMB_METACARPAL = "thumb-metacarpal",
    /** Thumb first knuckle */
    THUMB_PHALANX_PROXIMAL = "thumb-phalanx-proximal",
    /** Thumb second knuckle */
    THUMB_PHALANX_DISTAL = "thumb-phalanx-distal",
    /** Thumb tip */
    THUMB_TIP = "thumb-tip",
    /** Index finger near wrist */
    INDEX_FINGER_METACARPAL = "index-finger-metacarpal",
    /** Index finger first knuckle */
    INDEX_FINGER_PHALANX_PROXIMAL = "index-finger-phalanx-proximal",
    /** Index finger second knuckle */
    INDEX_FINGER_PHALANX_INTERMEDIATE = "index-finger-phalanx-intermediate",
    /** Index finger third knuckle */
    INDEX_FINGER_PHALANX_DISTAL = "index-finger-phalanx-distal",
    /** Index finger tip */
    INDEX_FINGER_TIP = "index-finger-tip",
    /** Middle finger near wrist */
    MIDDLE_FINGER_METACARPAL = "middle-finger-metacarpal",
    /** Middle finger first knuckle */
    MIDDLE_FINGER_PHALANX_PROXIMAL = "middle-finger-phalanx-proximal",
    /** Middle finger second knuckle */
    MIDDLE_FINGER_PHALANX_INTERMEDIATE = "middle-finger-phalanx-intermediate",
    /** Middle finger third knuckle */
    MIDDLE_FINGER_PHALANX_DISTAL = "middle-finger-phalanx-distal",
    /** Middle finger tip */
    MIDDLE_FINGER_TIP = "middle-finger-tip",
    /** Ring finger near wrist */
    RING_FINGER_METACARPAL = "ring-finger-metacarpal",
    /** Ring finger first knuckle */
    RING_FINGER_PHALANX_PROXIMAL = "ring-finger-phalanx-proximal",
    /** Ring finger second knuckle */
    RING_FINGER_PHALANX_INTERMEDIATE = "ring-finger-phalanx-intermediate",
    /** Ring finger third knuckle */
    RING_FINGER_PHALANX_DISTAL = "ring-finger-phalanx-distal",
    /** Ring finger tip */
    RING_FINGER_TIP = "ring-finger-tip",
    /** Pinky finger near wrist */
    PINKY_FINGER_METACARPAL = "pinky-finger-metacarpal",
    /** Pinky finger first knuckle */
    PINKY_FINGER_PHALANX_PROXIMAL = "pinky-finger-phalanx-proximal",
    /** Pinky finger second knuckle */
    PINKY_FINGER_PHALANX_INTERMEDIATE = "pinky-finger-phalanx-intermediate",
    /** Pinky finger third knuckle */
    PINKY_FINGER_PHALANX_DISTAL = "pinky-finger-phalanx-distal",
    /** Pinky finger tip */
    PINKY_FINGER_TIP = "pinky-finger-tip"
}
/** A type encapsulating a dictionary mapping WebXR joints to bone names in a rigged hand mesh.  */
type XRHandMeshRigMapping = {
    [webXRJointName in WebXRHandJoint]: string;
};
/**
 * Representing a single hand (with its corresponding native XRHand object)
 */
declare class WebXRHand implements IDisposable {
    /** The controller to which the hand correlates. */
    readonly xrController: WebXRInputSource;
    private readonly _jointMeshes;
    private _handMesh;
    /** An optional rig mapping for the hand mesh. If not provided (but a hand mesh is provided),
     * it will be assumed that the hand mesh's bones are named directly after the WebXR bone names. */
    readonly rigMapping: Nullable<XRHandMeshRigMapping>;
    private readonly _leftHandedMeshes;
    private readonly _jointsInvisible;
    private readonly _jointScaleFactor;
    /**
     * This observable will notify registered observers when the hand object has been set with a new mesh.
     * you can get the hand mesh using `webxrHand.handMesh`
     */
    onHandMeshSetObservable: Observable<WebXRHand>;
    private _scene;
    /**
     * Transform nodes that will directly receive the transforms from the WebXR matrix data.
     */
    private _jointTransforms;
    /**
     * The float array that will directly receive the transform matrix data from WebXR.
     */
    private _jointTransformMatrices;
    private _jointSpaces;
    private _tempJointMatrix;
    /**
     * The float array that will directly receive the joint radii from WebXR.
     */
    private _jointRadii;
    /**
     * The hand mesh's top-most parent, if any.
     */
    private _handMeshRoot;
    /**
     * Get the hand mesh.
     */
    get handMesh(): Nullable<AbstractMesh>;
    /**
     * Get meshes of part of the hand.
     * @param part The part of hand to get.
     * @returns An array of meshes that correlate to the hand part requested.
     */
    getHandPartMeshes(part: HandPart): AbstractMesh[];
    /**
     * Retrieves a mesh linked to a named joint in the hand.
     * @param jointName The name of the joint.
     * @returns An AbstractMesh whose position corresponds with the joint position.
     */
    getJointMesh(jointName: WebXRHandJoint): AbstractMesh;
    /**
     * Construct a new hand object
     * @param xrController The controller to which the hand correlates.
     * @param _jointMeshes The meshes to be used to track the hand joints.
     * @param _handMesh An optional hand mesh.
     * @param rigMapping An optional rig mapping for the hand mesh.
     *                   If not provided (but a hand mesh is provided),
     *                   it will be assumed that the hand mesh's bones are named
     *                   directly after the WebXR bone names.
     * @param _leftHandedMeshes Are the hand meshes left-handed-system meshes
     * @param _jointsInvisible Are the tracked joint meshes visible
     * @param _jointScaleFactor Scale factor for all joint meshes
     */
    constructor(
    /** The controller to which the hand correlates. */
    xrController: WebXRInputSource, _jointMeshes: AbstractMesh[], _handMesh: Nullable<AbstractMesh>, 
    /** An optional rig mapping for the hand mesh. If not provided (but a hand mesh is provided),
     * it will be assumed that the hand mesh's bones are named directly after the WebXR bone names. */
    rigMapping: Nullable<XRHandMeshRigMapping>, _leftHandedMeshes?: boolean, _jointsInvisible?: boolean, _jointScaleFactor?: number);
    /**
     * Sets the current hand mesh to render for the WebXRHand.
     * @param handMesh The rigged hand mesh that will be tracked to the user's hand.
     * @param rigMapping The mapping from XRHandJoint to bone names to use with the mesh.
     * @param _xrSessionManager The XRSessionManager used to initialize the hand mesh.
     */
    setHandMesh(handMesh: AbstractMesh, rigMapping: Nullable<XRHandMeshRigMapping>, _xrSessionManager?: WebXRSessionManager): void;
    /**
     * Update this hand from the latest xr frame.
     * @param xrFrame The latest frame received from WebXR.
     * @param referenceSpace The current viewer reference space.
     * @param xrCamera the xr camera, used for parenting
     */
    updateFromXRFrame(xrFrame: XRFrame, referenceSpace: XRReferenceSpace, xrCamera: WebXRCamera): void;
    /**
     * Dispose this Hand object
     * @param disposeMeshes Should the meshes be disposed as well
     */
    dispose(disposeMeshes?: boolean): void;
}
/**
 * WebXR Hand Joint tracking feature, available for selected browsers and devices
 */
declare class WebXRHandTracking extends WebXRAbstractFeature {
    /** Options to use when constructing this feature. */
    readonly options: IWebXRHandTrackingOptions;
    /**
     * The module's name
     */
    static readonly Name: "xr-hand-tracking";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /** The base URL for the default hand model. */
    static DEFAULT_HAND_MODEL_BASE_URL: string;
    /** The filename to use for the default right hand model. */
    static DEFAULT_HAND_MODEL_RIGHT_FILENAME: string;
    /** The filename to use for the default left hand model. */
    static DEFAULT_HAND_MODEL_LEFT_FILENAME: string;
    /** The URL pointing to the default hand model NodeMaterial shader. */
    static DEFAULT_HAND_MODEL_SHADER_URL: string;
    private static readonly _ICOSPHERE_PARAMS;
    private static _RightHandGLB;
    private static _LeftHandGLB;
    private static _GenerateTrackedJointMeshes;
    private static _GenerateDefaultHandMeshesAsync;
    /**
     * Generates a mapping from XRHandJoint to bone name for the default hand mesh.
     * @param handedness The handedness being mapped for.
     * @returns A mapping from XRHandJoint to bone name.
     */
    private static _GenerateDefaultHandMeshRigMapping;
    private _attachedHands;
    private _trackingHands;
    private _handResources;
    private _worldScaleObserver?;
    /**
     * This observable will notify registered observers when a new hand object was added and initialized
     */
    onHandAddedObservable: Observable<WebXRHand>;
    /**
     * This observable will notify its observers right before the hand object is disposed
     */
    onHandRemovedObservable: Observable<WebXRHand>;
    private _originalMesh?;
    /**
     * Check if the needed objects are defined.
     * This does not mean that the feature is enabled, but that the objects needed are well defined.
     * @returns true if the needed objects for this feature are defined
     */
    isCompatible(): boolean;
    /**
     * Get the hand object according to the controller id
     * @param controllerId the controller id to which we want to get the hand
     * @returns null if not found or the WebXRHand object if found
     */
    getHandByControllerId(controllerId: string): Nullable<WebXRHand>;
    /**
     * Get a hand object according to the requested handedness
     * @param handedness the handedness to request
     * @returns null if not found or the WebXRHand object if found
     */
    getHandByHandedness(handedness: XRHandedness): Nullable<WebXRHand>;
    /**
     * Creates a new instance of the XR hand tracking feature.
     * @param _xrSessionManager An instance of WebXRSessionManager.
     * @param options Options to use when constructing this feature.
     */
    constructor(_xrSessionManager: WebXRSessionManager, 
    /** Options to use when constructing this feature. */
    options: IWebXRHandTrackingOptions);
    /**
     * Attach this feature.
     * Will usually be called by the features manager.
     *
     * @returns true if successful.
     */
    attach(): boolean;
    protected _onXRFrame(_xrFrame: XRFrame): void;
    private _attachHand;
    private _detachHandById;
    private _detachHand;
    /**
     * Detach this feature.
     * Will usually be called by the features manager.
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached.
     */
    dispose(): void;
}

/**
 * Options interface for the background remover plugin
 */
interface IWebXRImageTrackingOptions {
    /**
     * A required array with images to track
     */
    images: {
        /**
         * The source of the image. can be a URL or an image bitmap
         */
        src: string | ImageBitmap;
        /**
         * The estimated width in the real world (in meters)
         */
        estimatedRealWorldWidth: number;
    }[];
}
/**
 * An object representing an image tracked by the system
 */
interface IWebXRTrackedImage {
    /**
     * The ID of this image (which is the same as the position in the array that was used to initialize the feature)
     */
    id: number;
    /**
     * Is the transformation provided emulated. If it is, the system "guesses" its real position. Otherwise it can be considered as exact position.
     */
    emulated?: boolean;
    /**
     * Just in case it is needed - the image bitmap that is being tracked
     */
    originalBitmap: ImageBitmap;
    /**
     * The native XR result image tracking result, untouched
     */
    xrTrackingResult?: XRImageTrackingResult;
    /**
     * Width in real world (meters)
     */
    realWorldWidth?: number;
    /**
     * A transformation matrix of this current image in the current reference space.
     */
    transformationMatrix: Matrix;
    /**
     * The width/height ratio of this image. can be used to calculate the size of the detected object/image
     */
    ratio?: number;
}
/**
 * Image tracking for immersive AR sessions.
 * Providing a list of images and their estimated widths will enable tracking those images in the real world.
 */
declare class WebXRImageTracking extends WebXRAbstractFeature {
    /**
     * read-only options to be used in this module
     */
    readonly options: IWebXRImageTrackingOptions;
    /**
     * The module's name
     */
    static readonly Name: "xr-image-tracking";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * This will be triggered if the underlying system deems an image untrackable.
     * The index is the index of the image from the array used to initialize the feature.
     */
    onUntrackableImageFoundObservable: Observable<number>;
    /**
     * An image was deemed trackable, and the system will start tracking it.
     */
    onTrackableImageFoundObservable: Observable<IWebXRTrackedImage>;
    /**
     * The image was found and its state was updated.
     */
    onTrackedImageUpdatedObservable: Observable<IWebXRTrackedImage>;
    private _trackableScoreStatus;
    private _trackedImages;
    private _originalTrackingRequest;
    /**
     * constructs the image tracking feature
     * @param _xrSessionManager the session manager for this module
     * @param options read-only options to be used in this module
     */
    constructor(_xrSessionManager: WebXRSessionManager, 
    /**
     * read-only options to be used in this module
     */
    options: IWebXRImageTrackingOptions);
    /**
     * attach this feature
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    attach(): boolean;
    /**
     * detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Get a tracked image by its ID.
     *
     * @param id the id of the image to load (position in the init array)
     * @returns a trackable image, if exists in this location
     */
    getTrackedImageById(id: number): Nullable<IWebXRTrackedImage>;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    /**
     * Extends the session init object if needed
     * @returns augmentation object fo the xr session init object.
     */
    getXRSessionInitExtension(): Promise<Partial<XRSessionInit>>;
    protected _onXRFrame(_xrFrame: XRFrame): void;
    private _checkScoresAsync;
}

/**
 * Wraps xr webgl layers.
 * @internal
 */
declare class WebXRWebGLLayerWrapper extends WebXRLayerWrapper {
    readonly layer: XRWebGLLayer;
    /**
     * @param layer is the layer to be wrapped.
     * @returns a new WebXRLayerWrapper wrapping the provided XRWebGLLayer.
     */
    constructor(layer: XRWebGLLayer);
}

/**
 * Wraps xr composition layers.
 * @internal
 */
declare class WebXRCompositionLayerWrapper extends WebXRLayerWrapper {
    getWidth: () => number;
    getHeight: () => number;
    readonly layer: XRCompositionLayer;
    readonly layerType: WebXRLayerType;
    readonly isMultiview: boolean;
    createRTTProvider: (xrSessionManager: WebXRSessionManager) => WebXRLayerRenderTargetTextureProvider;
    _originalInternalTexture: Nullable<InternalTexture>;
    constructor(getWidth: () => number, getHeight: () => number, layer: XRCompositionLayer, layerType: WebXRLayerType, isMultiview: boolean, createRTTProvider: (xrSessionManager: WebXRSessionManager) => WebXRLayerRenderTargetTextureProvider, _originalInternalTexture?: Nullable<InternalTexture>);
}

/**
 * Wraps xr projection layers.
 * @internal
 */
declare class WebXRProjectionLayerWrapper extends WebXRCompositionLayerWrapper {
    readonly layer: XRProjectionLayer;
    constructor(layer: XRProjectionLayer, isMultiview: boolean, xrGLBinding: XRWebGLBinding);
}

/**
 * Interface defining options used to create a dynamic texture
 */
interface IDynamicTextureOptions extends ITextureCreationOptions {
    /** defines the width of the texture (default: 0) */
    width?: number;
    /** defines the height of the texture (default: 0) */
    height?: number;
    /** defines the hosting scene (default: null) */
    scene?: Nullable<Scene>;
}
/**
 * A class extending Texture allowing drawing on a texture
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/dynamicTexture
 */
declare class DynamicTexture extends Texture {
    private _generateMipMaps;
    private _canvas;
    private _ownCanvas;
    private _context;
    /**
     * Creates a DynamicTexture
     * @param name defines the name of the texture
     * @param canvasOrSize provides 3 alternatives for width and height of texture, a canvas, object with width and height properties, number for both width and height
     * @param options The options to be used when constructing the dynamic texture
     */
    constructor(name: string, canvasOrSize: ICanvas | {
        width: number;
        height: number;
    } | number, options?: IDynamicTextureOptions);
    /**
     * Creates a DynamicTexture
     * @param name defines the name of the texture
     * @param options provides 3 alternatives for width and height of texture, a canvas, object with width and height properties, number for both width and height
     * @param scene defines the scene where you want the texture
     * @param generateMipMaps defines the use of MipMaps or not (default is false)
     * @param samplingMode defines the sampling mode to use (default is Texture.TRILINEAR_SAMPLINGMODE)
     * @param format defines the texture format to use (default is Engine.TEXTUREFORMAT_RGBA)
     * @param invertY defines if the texture needs to be inverted on the y axis during loading
     */
    constructor(name: string, options: ICanvas | {
        width: number;
        height: number;
    } | number, scene?: Nullable<Scene>, generateMipMaps?: boolean, samplingMode?: number, format?: number, invertY?: boolean);
    /** @internal */
    constructor(name: string, canvasOrSize: ICanvas | {
        width: number;
        height: number;
    } | number, sceneOrOptions?: Nullable<Scene> | IDynamicTextureOptions, generateMipMaps?: boolean, samplingMode?: number, format?: number, invertY?: boolean);
    /**
     * Get the current class name of the texture useful for serialization or dynamic coding.
     * @returns "DynamicTexture"
     */
    getClassName(): string;
    /**
     * Gets the current state of canRescale
     */
    get canRescale(): boolean;
    private _recreate;
    /**
     * Scales the texture
     * @param ratio the scale factor to apply to both width and height
     */
    scale(ratio: number): void;
    /**
     * Resizes the texture
     * @param width the new width
     * @param height the new height
     */
    scaleTo(width: number, height: number): void;
    /**
     * Gets the context of the canvas used by the texture
     * @returns the canvas context of the dynamic texture
     */
    getContext(): ICanvasRenderingContext;
    /**
     * Clears the texture
     * @param clearColor Defines the clear color to use
     */
    clear(clearColor?: string): void;
    /**
     * Updates the texture
     * @param invertY defines the direction for the Y axis (default is true - y increases downwards)
     * @param premulAlpha defines if alpha is stored as premultiplied (default is false)
     * @param allowGPUOptimization true to allow some specific GPU optimizations (subject to engine feature "allowGPUOptimizationsForGUI" being true)
     */
    update(invertY?: boolean, premulAlpha?: boolean, allowGPUOptimization?: boolean): void;
    /**
     * Draws text onto the texture
     * @param text defines the text to be drawn
     * @param x defines the placement of the text from the left
     * @param y defines the placement of the text from the top when invertY is true and from the bottom when false
     * @param font defines the font to be used with font-style, font-size, font-name
     * @param color defines the color used for the text
     * @param fillColor defines the color for the canvas, use null to not overwrite canvas (this blends with the background to replace, use the clear function)
     * @param invertY defines the direction for the Y axis (default is true - y increases downwards)
     * @param update defines whether texture is immediately update (default is true)
     */
    drawText(text: string, x: number | null | undefined, y: number | null | undefined, font: string, color: string | null, fillColor: string | null, invertY?: boolean, update?: boolean): void;
    /**
     * Disposes the dynamic texture.
     */
    dispose(): void;
    /**
     * Clones the texture
     * @returns the clone of the texture.
     */
    clone(): DynamicTexture;
    /**
     * Serializes the dynamic texture.  The scene should be ready before the dynamic texture is serialized
     * @returns a serialized dynamic texture object
     */
    serialize(): any;
    private static _IsCanvasElement;
    /** @internal */
    _rebuild(): void;
}

/**
 * Configuration options of the layers feature
 */
interface IWebXRLayersOptions {
    /**
     * Whether to try initializing the base projection layer as a multiview render target, if multiview is supported.
     * Defaults to false.
     */
    preferMultiviewOnInit?: boolean;
    /**
     * Optional configuration for the base projection layer.
     */
    projectionLayerInit?: Partial<XRProjectionLayerInit>;
}
/**
 * Exposes the WebXR Layers API.
 */
declare class WebXRLayers extends WebXRAbstractFeature {
    private readonly _options;
    /**
     * The module's name
     */
    static readonly Name: "xr-layers";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Already-created layers
     */
    private _existingLayers;
    private _glContext;
    private _xrWebGLBinding;
    private _isMultiviewEnabled;
    private _projectionLayerInitialized;
    private _compositionLayerTextureMapping;
    private _layerToRTTProviderMapping;
    constructor(_xrSessionManager: WebXRSessionManager, _options?: IWebXRLayersOptions);
    /**
     * Attach this feature.
     * Will usually be called by the features manager.
     *
     * @returns true if successful.
     */
    attach(): boolean;
    detach(): boolean;
    /**
     * Creates a new XRWebGLLayer.
     * @param params an object providing configuration options for the new XRWebGLLayer
     * @returns the XRWebGLLayer
     */
    createXRWebGLLayer(params?: XRWebGLLayerInit): WebXRWebGLLayerWrapper;
    private _validateLayerInit;
    private _extendXRLayerInit;
    /**
     * Creates a new XRProjectionLayer.
     * @param params an object providing configuration options for the new XRProjectionLayer.
     * @param multiview whether the projection layer should render with multiview. Will be tru automatically if the extension initialized with multiview.
     * @returns the projection layer
     */
    createProjectionLayer(params?: XRProjectionLayerInit, multiview?: boolean): WebXRProjectionLayerWrapper;
    /**
     * Note about making it private - this function will be exposed once I decide on a proper API to support all of the XR layers' options
     * @param options an object providing configuration options for the new XRQuadLayer.
     * @param babylonTexture the texture to display in the layer
     * @returns the quad layer
     */
    private _createQuadLayer;
    /**
     * @experimental
     * This will support full screen ADT when used with WebXR Layers. This API might change in the future.
     * Note that no interaction will be available with the ADT when using this method
     * @param texture the texture to display in the layer
     * @param options optional parameters for the layer
     * @returns a composition layer containing the texture
     */
    addFullscreenAdvancedDynamicTexture(texture: DynamicTexture, options?: {
        distanceFromHeadset: number;
    }): WebXRCompositionLayerWrapper;
    /**
     * @experimental
     * This functions allows you to add a lens flare system to the XR scene.
     * Note - this will remove the lens flare system from the scene and add it to the XR scene.
     * This feature is experimental and might change in the future.
     * @param flareSystem the flare system to add
     * @returns a composition layer containing the flare system
     */
    protected _addLensFlareSystem(flareSystem: LensFlareSystem): WebXRCompositionLayerWrapper;
    /**
     * Add a new layer to the already-existing list of layers
     * @param wrappedLayer the new layer to add to the existing ones
     */
    addXRSessionLayer(wrappedLayer: WebXRLayerWrapper): void;
    /**
     * Sets the layers to be used by the XR session.
     * Note that you must call this function with any layers you wish to render to
     * since it adds them to the XR session's render state
     * (replacing any layers that were added in a previous call to setXRSessionLayers or updateRenderState).
     * This method also sets up the session manager's render target texture provider
     * as the first layer in the array, which feeds the WebXR camera(s) attached to the session.
     * @param wrappedLayers An array of WebXRLayerWrapper, usually returned from the WebXRLayers createLayer functions.
     */
    setXRSessionLayers(wrappedLayers?: Array<WebXRLayerWrapper>): void;
    isCompatible(): boolean;
    /**
     * Dispose this feature and all of the resources attached.
     */
    dispose(): void;
    protected _onXRFrame(_xrFrame: XRFrame): void;
}

/**
 * A directional light is defined by a direction (what a surprise!).
 * The light is emitted from everywhere in the specified direction, and has an infinite range.
 * An example of a directional light is when a distance planet is lit by the apparently parallel lines of light from its sun. Light in a downward direction will light the top of an object.
 * Documentation: https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
 */
declare class DirectionalLight extends ShadowLight {
    private _shadowFrustumSize;
    /**
     * Fix frustum size for the shadow generation. This is disabled if the value is 0.
     */
    get shadowFrustumSize(): number;
    /**
     * Specifies a fix frustum size for the shadow generation.
     */
    set shadowFrustumSize(value: number);
    private _shadowOrthoScale;
    /**
     * Gets the shadow projection scale against the optimal computed one.
     * 0.1 by default which means that the projection window is increase by 10% from the optimal size.
     * This does not impact in fixed frustum size (shadowFrustumSize being set)
     */
    get shadowOrthoScale(): number;
    /**
     * Sets the shadow projection scale against the optimal computed one.
     * 0.1 by default which means that the projection window is increase by 10% from the optimal size.
     * This does not impact in fixed frustum size (shadowFrustumSize being set)
     */
    set shadowOrthoScale(value: number);
    /**
     * Automatically compute the projection matrix to best fit (including all the casters)
     * on each frame.
     */
    autoUpdateExtends: boolean;
    /**
     * Automatically compute the shadowMinZ and shadowMaxZ for the projection matrix to best fit (including all the casters)
     * on each frame. autoUpdateExtends must be set to true for this to work
     */
    autoCalcShadowZBounds: boolean;
    private _orthoLeft;
    private _orthoRight;
    private _orthoTop;
    private _orthoBottom;
    /**
     * Gets or sets the orthoLeft property used to build the light frustum
     */
    get orthoLeft(): number;
    set orthoLeft(left: number);
    /**
     * Gets or sets the orthoRight property used to build the light frustum
     */
    get orthoRight(): number;
    set orthoRight(right: number);
    /**
     * Gets or sets the orthoTop property used to build the light frustum
     */
    get orthoTop(): number;
    set orthoTop(top: number);
    /**
     * Gets or sets the orthoBottom property used to build the light frustum
     */
    get orthoBottom(): number;
    set orthoBottom(bottom: number);
    /**
     * Creates a DirectionalLight object in the scene, oriented towards the passed direction (Vector3).
     * The directional light is emitted from everywhere in the given direction.
     * It can cast shadows.
     * Documentation : https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
     * @param name The friendly name of the light
     * @param direction The direction of the light
     * @param scene The scene the light belongs to
     * @param dontAddToScene True to not add the light to the scene
     */
    constructor(name: string, direction: Vector3, scene?: Scene, dontAddToScene?: boolean);
    /**
     * Returns the string "DirectionalLight".
     * @returns The class name
     */
    getClassName(): string;
    /**
     * Returns the integer 1.
     * @returns The light Type id as a constant defines in Light.LIGHTTYPEID_x
     */
    getTypeID(): number;
    /**
     * Sets the passed matrix "matrix" as projection matrix for the shadows cast by the light according to the passed view matrix.
     * Returns the DirectionalLight Shadow projection matrix.
     * @param matrix
     * @param viewMatrix
     * @param renderList
     */
    protected _setDefaultShadowProjectionMatrix(matrix: Matrix, viewMatrix: Matrix, renderList: Array<AbstractMesh>): void;
    /**
     * Sets the passed matrix "matrix" as fixed frustum projection matrix for the shadows cast by the light according to the passed view matrix.
     * Returns the DirectionalLight Shadow projection matrix.
     * @param matrix
     */
    protected _setDefaultFixedFrustumShadowProjectionMatrix(matrix: Matrix): void;
    /**
     * Sets the passed matrix "matrix" as auto extend projection matrix for the shadows cast by the light according to the passed view matrix.
     * Returns the DirectionalLight Shadow projection matrix.
     * @param matrix
     * @param viewMatrix
     * @param renderList
     */
    protected _setDefaultAutoExtendShadowProjectionMatrix(matrix: Matrix, viewMatrix: Matrix, renderList: Array<AbstractMesh>): void;
    protected _buildUniformLayout(): void;
    /**
     * Sets the passed Effect object with the DirectionalLight transformed position (or position if not parented) and the passed name.
     * @param effect The effect to update
     * @param lightIndex The index of the light in the effect to update
     * @returns The directional light
     */
    transferToEffect(effect: Effect, lightIndex: string): DirectionalLight;
    transferToNodeMaterialEffect(effect: Effect, lightDataUniformName: string): Light;
    /**
     * Gets the minZ used for shadow according to both the scene and the light.
     *
     * Values are fixed on directional lights as it relies on an ortho projection hence the need to convert being
     * -1 and 1 to 0 and 1 doing (depth + min) / (min + max) -> (depth + 1) / (1 + 1) -> (depth * 0.5) + 0.5.
     * (when not using reverse depth buffer / NDC half Z range)
     * @param _activeCamera The camera we are returning the min for (not used)
     * @returns the depth min z
     */
    getDepthMinZ(_activeCamera: Nullable<Camera>): number;
    /**
     * Gets the maxZ used for shadow according to both the scene and the light.
     *
     * Values are fixed on directional lights as it relies on an ortho projection hence the need to convert being
     * -1 and 1 to 0 and 1 doing (depth + min) / (min + max) -> (depth + 1) / (1 + 1) -> (depth * 0.5) + 0.5.
     * (when not using reverse depth buffer / NDC half Z range)
     * @param _activeCamera The camera we are returning the max for
     * @returns the depth max z
     */
    getDepthMaxZ(_activeCamera: Nullable<Camera>): number;
    /**
     * Prepares the list of defines specific to the light type.
     * @param defines the list of defines
     * @param lightIndex defines the index of the light for the effect
     */
    prepareLightSpecificDefines(defines: any, lightIndex: number): void;
}

/**
 * Options for Light Estimation feature
 */
interface IWebXRLightEstimationOptions {
    /**
     * Disable the cube map reflection feature. In this case only light direction and color will be updated
     */
    disableCubeMapReflection?: boolean;
    /**
     * Should the scene's env texture be set to the cube map reflection texture
     * Note that this doesn't work is disableCubeMapReflection if set to false
     */
    setSceneEnvironmentTexture?: boolean;
    /**
     * How often should the cubemap update in ms.
     * If not set the cubemap will be updated every time the underlying system updates the environment texture.
     */
    cubeMapPollInterval?: number;
    /**
     * How often should the light estimation properties update in ms.
     * If not set the light estimation properties will be updated on every frame (depending on the underlying system)
     */
    lightEstimationPollInterval?: number;
    /**
     * Should a directional light source be created.
     * If created, this light source will be updated whenever the light estimation values change
     */
    createDirectionalLightSource?: boolean;
    /**
     * The scale factor to multiply the intensity of the directional light by. Defaults to 1.0.
     */
    directionalLightIntensityFactor?: number;
    /**
     * Define the format to be used for the light estimation texture.
     */
    reflectionFormat?: XRReflectionFormat;
    /**
     * Should the light estimation's needed vectors be constructed on each frame.
     * Use this when you use those vectors and don't want their values to change outside of the light estimation feature
     */
    disableVectorReuse?: boolean;
    /**
     * disable applying the spherical polynomial to the cube map texture
     */
    disableSphericalPolynomial?: boolean;
    /**
     * disable prefiltering the cube map texture
     */
    disablePreFiltering?: boolean;
}
/**
 * An interface describing the result of a light estimation
 */
interface IWebXRLightEstimation {
    /**
     * The intensity of the light source
     */
    lightIntensity: number;
    /**
     * Color of light source
     */
    lightColor: Color3;
    /**
     * The direction from the light source
     */
    lightDirection: Vector3;
    /**
     * Spherical harmonics coefficients of the light source
     */
    sphericalHarmonics: SphericalHarmonics;
}
/**
 * Light Estimation Feature
 *
 * @since 5.0.0
 */
declare class WebXRLightEstimation extends WebXRAbstractFeature {
    /**
     * options to use when constructing this feature
     */
    readonly options: IWebXRLightEstimationOptions;
    private _canvasContext;
    private _reflectionCubeMap;
    private _xrLightEstimate;
    private _xrLightProbe;
    private _xrWebGLBinding;
    private _lightDirection;
    private _lightColor;
    private _intensity;
    private _sphericalHarmonics;
    private _cubeMapPollTime;
    private _lightEstimationPollTime;
    /**
     * The module's name
     */
    static readonly Name: "xr-light-estimation";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * ARCore's reflection cube map size is 16x16.
     * Once other systems support this feature we will need to change this to be dynamic.
     * see https://github.com/immersive-web/lighting-estimation/blob/main/lighting-estimation-explainer.md#cube-map-open-questions
     */
    private _reflectionCubeMapTextureSize;
    private _hdrFilter;
    /**
     * If createDirectionalLightSource is set to true this light source will be created automatically.
     * Otherwise this can be set with an external directional light source.
     * This light will be updated whenever the light estimation values change.
     */
    directionalLight: Nullable<DirectionalLight>;
    /**
     * The scale factor to multiply the intensity of the directional light by. Defaults to 1.0.
     */
    directionalLightIntensityFactor: number;
    /**
     * This observable will notify when the reflection cube map is updated.
     */
    onReflectionCubeMapUpdatedObservable: Observable<BaseTexture>;
    /**
     * Creates a new instance of the light estimation feature
     * @param _xrSessionManager an instance of WebXRSessionManager
     * @param options options to use when constructing this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, 
    /**
     * options to use when constructing this feature
     */
    options: IWebXRLightEstimationOptions);
    /**
     * While the estimated cube map is expected to update over time to better reflect the user's environment as they move around those changes are unlikely to happen with every XRFrame.
     * Since creating and processing the cube map is potentially expensive, especially if mip maps are needed, you can listen to the onReflectionCubeMapUpdatedObservable to determine
     * when it has been updated.
     */
    get reflectionCubeMapTexture(): Nullable<BaseTexture>;
    /**
     * The most recent light estimate.  Available starting on the first frame where the device provides a light probe.
     */
    get xrLightingEstimate(): Nullable<IWebXRLightEstimation>;
    private _getCanvasContext;
    private _getXRGLBinding;
    /**
     * Event Listener for "reflectionchange" events.
     */
    private _updateReflectionCubeMap;
    /**
     * attach this feature
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    attach(): boolean;
    /**
     * detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    protected _onXRFrame(_xrFrame: XRFrame): void;
}

/**
 * Options used in the mesh detector module
 */
interface IWebXRMeshDetectorOptions {
    /**
     * The node to use to transform the local results to world coordinates
     */
    worldParentNode?: TransformNode;
    /**
     * If set to true a reference of the created meshes will be kept until the next session starts
     * If not defined, meshes will be removed from the array when the feature is detached or the session ended.
     */
    doNotRemoveMeshesOnSessionEnded?: boolean;
    /**
     * Preferred detector configuration, not all preferred options will be supported by all platforms.
     * Babylon native only!
     */
    preferredDetectorOptions?: XRGeometryDetectorOptions;
    /**
     * If set to true, WebXRMeshDetector will convert coordinate systems for meshes.
     * If not defined, mesh conversions from right handed to left handed coordinate systems won't be conducted.
     * Right handed mesh data will be available through IWebXRVertexData.xrMesh.
     */
    convertCoordinateSystems?: boolean;
    /**
     * If set to true, the feature will generate meshes for the detected data.
     * Note that this might be time consuming, as the mesh's vertex data will be updated on every change.
     * Setting this to true will also set convertCoordinateSystems to true.
     * Note - the meshes will NOT be disposed automatically when the feature is detached or the session ended.
     */
    generateMeshes?: boolean;
}
/**
 * A babylon interface for a XR mesh's vertex data.
 */
interface IWebXRVertexData {
    /**
     * A babylon-assigned ID for this mesh
     */
    id: number;
    /**
     * Data required for constructing a mesh in Babylon.js.
     */
    xrMesh: XRMesh;
    /**
     * The node to use to transform the local results to world coordinates.
     * WorldParentNode will only exist if it was declared in the IWebXRMeshDetectorOptions.
     */
    worldParentNode?: TransformNode;
    /**
     * An array of vertex positions in babylon space. right/left hand system is taken into account.
     * Positions will only be calculated if convertCoordinateSystems is set to true in the IWebXRMeshDetectorOptions.
     */
    positions?: Float32Array;
    /**
     * An array of indices in babylon space. Indices have a counterclockwise winding order.
     * Indices will only be populated if convertCoordinateSystems is set to true in the IWebXRMeshDetectorOptions.
     */
    indices?: Uint32Array;
    /**
     * An array of vertex normals in babylon space. right/left hand system is taken into account.
     * Normals will not be calculated if convertCoordinateSystems is undefined in the IWebXRMeshDetectorOptions.
     * Different platforms may or may not support mesh normals when convertCoordinateSystems is set to true.
     */
    normals?: Float32Array;
    /**
     * A transformation matrix to apply on the mesh that will be built using the meshDefinition.
     * Local vs. World are decided if worldParentNode was provided or not in the options when constructing the module.
     * TransformationMatrix will only be calculated if convertCoordinateSystems is set to true in the IWebXRMeshDetectorOptions.
     */
    transformationMatrix?: Matrix;
    /**
     * If generateMeshes is set to true in the IWebXRMeshDetectorOptions, this will be the generated mesh.
     * This mesh will be updated with the vertex data provided and not regenerated every time.
     */
    mesh?: Mesh;
}
/**
 * The mesh detector is used to detect meshes in the real world when in AR
 */
declare class WebXRMeshDetector extends WebXRAbstractFeature {
    private _options;
    private _detectedMeshes;
    /**
     * The module's name
     */
    static readonly Name: "xr-mesh-detection";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Observers registered here will be executed when a new mesh was added to the session
     */
    onMeshAddedObservable: Observable<IWebXRVertexData>;
    /**
     * Observers registered here will be executed when a mesh is no longer detected in the session
     */
    onMeshRemovedObservable: Observable<IWebXRVertexData>;
    /**
     * Observers registered here will be executed when an existing mesh updates
     */
    onMeshUpdatedObservable: Observable<IWebXRVertexData>;
    constructor(_xrSessionManager: WebXRSessionManager, _options?: IWebXRMeshDetectorOptions);
    detach(): boolean;
    dispose(): void;
    protected _onXRFrame(frame: XRFrame): void;
    private _init;
    private _updateVertexDataWithXRMesh;
}

declare module "./subMesh" {
    interface SubMesh {
        /** @internal */
        _projectOnTrianglesToRef(vector: Vector3, positions: Vector3[], indices: IndicesArray, step: number, checkStopper: boolean, ref: Vector3): number;
        /** @internal */
        _projectOnUnIndexedTrianglesToRef(vector: Vector3, positions: Vector3[], indices: IndicesArray, ref: Vector3): number;
        /**
         * Projects a point on this submesh and stores the result in "ref"
         *
         * @param vector point to project
         * @param positions defines mesh's positions array
         * @param indices defines mesh's indices array
         * @param ref vector that will store the result
         * @returns distance from the point and the submesh, or -1 if the mesh rendering mode doesn't support projections
         */
        projectToRef(vector: Vector3, positions: Vector3[], indices: IndicesArray, ref: Vector3): number;
    }
}

/**
 * Where should the near interaction mesh be attached to when using a motion controller for near interaction
 */
declare const enum WebXRNearControllerMode {
    /**
     * Motion controllers will not support near interaction
     */
    DISABLED = 0,
    /**
     * The interaction point for motion controllers will be inside of them
     */
    CENTERED_ON_CONTROLLER = 1,
    /**
     * The interaction point for motion controllers will be in front of the controller
     */
    CENTERED_IN_FRONT = 2
}
/**
 * Options interface for the near interaction module
 */
interface IWebXRNearInteractionOptions {
    /**
     * If provided, this scene will be used to render meshes.
     */
    customUtilityLayerScene?: Scene;
    /**
     * Should meshes created here be added to a utility layer or the main scene
     */
    useUtilityLayer?: boolean;
    /**
     * The xr input to use with this near interaction
     */
    xrInput: WebXRInput;
    /**
     * Enable near interaction on all controllers instead of switching between them
     */
    enableNearInteractionOnAllControllers?: boolean;
    /**
     * The preferred hand to give the near interaction to. This will be prioritized when the controller initialize.
     * If switch is enabled, it will still allow the user to switch between the different controllers
     */
    preferredHandedness?: XRHandedness;
    /**
     * Disable switching the near interaction from one controller to the other.
     * If the preferred hand is set it will be fixed on this hand, and if not it will be fixed on the first controller added to the scene
     */
    disableSwitchOnClick?: boolean;
    /**
     * Far interaction feature to toggle when near interaction takes precedence
     */
    farInteractionFeature?: WebXRControllerPointerSelection;
    /**
     * Near interaction mode for motion controllers
     */
    nearInteractionControllerMode?: WebXRNearControllerMode;
    /**
     * Optional material for the motion controller orb, if enabled
     */
    motionControllerOrbMaterial?: Material;
    /**
     * If provided, this URL will be used by Node Material to generate the material for the motion controller orb
     * If not provided, a snippet will be downloaded from the Babylon.js snippet server CDN.
     * The NME JSON file can be found here - https://github.com/BabylonJS/Assets/blob/master/nme/nearInteractionTouchMaterial.json
     */
    motionControllerTouchMaterialSnippetUrl?: string;
}
/**
 * A module that will enable near interaction near interaction for hands and motion controllers of XR Input Sources
 */
declare class WebXRNearInteraction extends WebXRAbstractFeature {
    private readonly _options;
    private static _IdCounter;
    private _tmpRay;
    private _attachController;
    private _controllers;
    private _scene;
    private _attachedController;
    private _farInteractionFeature;
    /**
     * The module's name
     */
    static readonly Name: "xr-near-interaction";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * default color of the selection ring
     */
    selectionMeshDefaultColor: Color3;
    /**
     * This color will be applied to the selection ring when selection is triggered
     */
    selectionMeshPickedColor: Color3;
    /**
     * If set to true, the selection mesh will always be hidden. Otherwise it will be shown only when needed
     */
    alwaysHideSelectionMesh: boolean;
    /**
     * constructs a new background remover module
     * @param _xrSessionManager the session manager for this module
     * @param _options read-only options to be used in this module
     */
    constructor(_xrSessionManager: WebXRSessionManager, _options: IWebXRNearInteractionOptions);
    /**
     * Attach this feature
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    attach(): boolean;
    /**
     * Detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Will get the mesh under a specific pointer.
     * `scene.meshUnderPointer` will only return one mesh - either left or right.
     * @param controllerId the controllerId to check
     * @returns The mesh under pointer or null if no mesh is under the pointer
     */
    getMeshUnderPointer(controllerId: string): Nullable<AbstractMesh>;
    /**
     * Get the xr controller that correlates to the pointer id in the pointer event
     *
     * @param id the pointer id to search for
     * @returns the controller that correlates to this id or null if not found
     */
    getXRControllerByPointerId(id: number): Nullable<WebXRInputSource>;
    /**
     * This function sets webXRControllerPointerSelection feature that will be disabled when
     * the hover range is reached for a mesh and will be reattached when not in hover range.
     * This is used to remove the selection rays when moving.
     * @param farInteractionFeature the feature to disable when finger is in hover range for a mesh
     */
    setFarInteractionFeature(farInteractionFeature: Nullable<WebXRControllerPointerSelection>): void;
    /**
     * Filter used for near interaction pick and hover
     * @param mesh the mesh candidate to be pick-filtered
     * @returns if the mesh should be included in the list of candidate meshes for near interaction
     */
    private _nearPickPredicate;
    /**
     * Filter used for near interaction grab
     * @param mesh the mesh candidate to be pick-filtered
     * @returns if the mesh should be included in the list of candidate meshes for near interaction
     */
    private _nearGrabPredicate;
    /**
     * Filter used for any near interaction
     * @param mesh the mesh candidate to be pick-filtered
     * @returns if the mesh should be included in the list of candidate meshes for near interaction
     */
    private _nearInteractionPredicate;
    private _controllerAvailablePredicate;
    private _handleTransitionAnimation;
    private readonly _hoverRadius;
    private readonly _pickRadius;
    private readonly _controllerPickRadius;
    private readonly _nearGrabLengthScale;
    private _processTouchPoint;
    protected _onXRFrame(_xrFrame: XRFrame): void;
    private get _utilityLayerScene();
    private _generateVisualCue;
    private _isControllerReadyForNearInteraction;
    private _attachNearInteractionMode;
    private _detachController;
    private _generateNewTouchPointMesh;
    private _pickWithSphere;
    /**
     * Picks a mesh with a sphere
     * @param mesh the mesh to pick
     * @param sphere picking sphere in world coordinates
     * @param skipBoundingInfo a boolean indicating if we should skip the bounding info check
     * @returns the picking info
     */
    static PickMeshWithSphere(mesh: AbstractMesh, sphere: BoundingSphere, skipBoundingInfo?: boolean): PickingInfo;
}

/**
 * Options used in the plane detector module
 */
interface IWebXRPlaneDetectorOptions {
    /**
     * The node to use to transform the local results to world coordinates
     */
    worldParentNode?: TransformNode;
    /**
     * If set to true a reference of the created planes will be kept until the next session starts
     * If not defined, planes will be removed from the array when the feature is detached or the session ended.
     */
    doNotRemovePlanesOnSessionEnded?: boolean;
    /**
     * Preferred detector configuration, not all preferred options will be supported by all platforms.
     */
    preferredDetectorOptions?: XRGeometryDetectorOptions;
}
/**
 * A babylon interface for a WebXR plane.
 * A Plane is actually a polygon, built from N points in space
 *
 * Supported in chrome 79, not supported in canary 81 ATM
 */
interface IWebXRPlane {
    /**
     * a babylon-assigned ID for this polygon
     */
    id: number;
    /**
     * an array of vector3 points in babylon space. right/left hand system is taken into account.
     */
    polygonDefinition: Array<Vector3>;
    /**
     * A transformation matrix to apply on the mesh that will be built using the polygonDefinition
     * Local vs. World are decided if worldParentNode was provided or not in the options when constructing the module
     */
    transformationMatrix: Matrix;
    /**
     * the native xr-plane object
     */
    xrPlane: XRPlane;
}
/**
 * The plane detector is used to detect planes in the real world when in AR
 * For more information see https://github.com/immersive-web/real-world-geometry/
 */
declare class WebXRPlaneDetector extends WebXRAbstractFeature {
    private _options;
    private _detectedPlanes;
    private _enabled;
    private _lastFrameDetected;
    /**
     * The module's name
     */
    static readonly Name: "xr-plane-detection";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Observers registered here will be executed when a new plane was added to the session
     */
    onPlaneAddedObservable: Observable<IWebXRPlane>;
    /**
     * Observers registered here will be executed when a plane is no longer detected in the session
     */
    onPlaneRemovedObservable: Observable<IWebXRPlane>;
    /**
     * Observers registered here will be executed when an existing plane updates (for example - expanded)
     * This can execute N times every frame
     */
    onPlaneUpdatedObservable: Observable<IWebXRPlane>;
    /**
     * construct a new Plane Detector
     * @param _xrSessionManager an instance of xr Session manager
     * @param _options configuration to use when constructing this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, _options?: IWebXRPlaneDetectorOptions);
    /**
     * detach this feature.
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    /**
     * Check if the needed objects are defined.
     * This does not mean that the feature is enabled, but that the objects needed are well defined.
     * @returns true if the initial compatibility test passed
     */
    isCompatible(): boolean;
    /**
     * Enable room capture mode.
     * When enabled and supported by the system,
     * the detectedPlanes array will be populated with the detected room boundaries
     * @see https://immersive-web.github.io/real-world-geometry/plane-detection.html#dom-xrsession-initiateroomcapture
     * @returns true if plane detection is enabled and supported. Will reject if not supported.
     */
    initiateRoomCapture(): Promise<void>;
    protected _onXRFrame(frame: XRFrame): void;
    private _init;
    private _updatePlaneWithXRPlane;
    /**
     * avoiding using Array.find for global support.
     * @param xrPlane the plane to find in the array
     * @returns the index of the plane in the array or -1 if not found
     */
    private _findIndexInPlaneArray;
}

/**
 * Options for raw camera access
 */
interface IWebXRRawCameraAccessOptions {
    /**
     * Keep the created textures and metadata when detaching the feature.
     */
    doNotDisposeOnDetach?: boolean;
}
/**
 * WebXR Feature for WebXR raw camera access
 * @since 6.31.0
 * @see https://immersive-web.github.io/raw-camera-access/
 */
declare class WebXRRawCameraAccess extends WebXRAbstractFeature {
    readonly options: IWebXRRawCameraAccessOptions;
    private _cachedInternalTextures;
    /**
     * This is an array of camera views
     * Note that mostly the array will contain a single view
     * If you want to know the order of the views, use the `viewIndex` array
     */
    texturesData: BaseTexture[];
    /**
     * If needed, this array will contain the eye definition of each texture in `texturesArray`
     */
    viewIndex: string[];
    /**
     * If needed, this array will contain the camera's intrinsics
     * You can use this data to convert from camera space to screen space and vice versa
     */
    cameraIntrinsics: {
        u0: number;
        v0: number;
        ax: number;
        ay: number;
        gamma: number;
        width: number;
        height: number;
        viewportX: number;
        viewportY: number;
    }[];
    /**
     * An observable that will notify when the camera's textures are updated
     */
    onTexturesUpdatedObservable: Observable<BaseTexture[]>;
    private _glBinding?;
    private _glContext;
    /**
     * The module's name
     */
    static readonly Name: "xr-raw-camera-access";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * Creates a new instance of the feature
     * @param _xrSessionManager the WebXRSessionManager
     * @param options options for the Feature
     */
    constructor(_xrSessionManager: WebXRSessionManager, options?: IWebXRRawCameraAccessOptions);
    attach(force?: boolean): boolean;
    detach(): boolean;
    /**
     * Dispose this feature and all of the resources attached
     */
    dispose(): void;
    /**
     * @see https://github.com/immersive-web/raw-camera-access/blob/main/explainer.md
     * @param view the XRView to update
     * @param index the index of the view in the views array
     */
    private _updateCameraIntrinsics;
    private _updateInternalTextures;
    protected _onXRFrame(_xrFrame: XRFrame): void;
}

/**
 * WebXR Space Warp Render Target Texture Provider
 */
declare class WebXRSpaceWarpRenderTargetTextureProvider implements IWebXRRenderTargetTextureProvider {
    protected readonly _scene: Scene;
    protected readonly _xrSessionManager: WebXRSessionManager;
    protected readonly _xrWebGLBinding: XRWebGLBinding;
    protected _lastSubImages: Map<XRView, XRWebGLSubImage>;
    protected _renderTargetTextures: Map<XREye, RenderTargetTexture>;
    protected _framebufferDimensions: Nullable<{
        framebufferWidth: number;
        framebufferHeight: number;
    }>;
    protected _engine: Engine;
    constructor(_scene: Scene, _xrSessionManager: WebXRSessionManager, _xrWebGLBinding: XRWebGLBinding);
    private _getSubImageForView;
    protected _setViewportForSubImage(viewport: Viewport, subImage: XRWebGLSubImage): void;
    protected _createRenderTargetTexture(width: number, height: number, framebuffer: Nullable<WebGLFramebuffer>, motionVectorTexture: WebGLTexture, depthStencilTexture: WebGLTexture): RenderTargetTexture;
    protected _getRenderTargetForSubImage(subImage: XRWebGLSubImage, view: XRView): RenderTargetTexture;
    trySetViewportForView(viewport: Viewport, view: XRView): boolean;
    /**
     * Access the motion vector (which will turn on Space Warp)
     * @param view the view to access the motion vector texture for
     */
    accessMotionVector(view: XRView): void;
    getRenderTargetTextureForEye(_eye: XREye): Nullable<RenderTargetTexture>;
    getRenderTargetTextureForView(view: XRView): Nullable<RenderTargetTexture>;
    dispose(): void;
}
/**
 * the WebXR Space Warp feature.
 */
declare class WebXRSpaceWarp extends WebXRAbstractFeature {
    /**
     * The module's name
     */
    static readonly Name: "xr-space-warp";
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number does not correspond to the WebXR specs version
     */
    static readonly Version = 1;
    /**
     * The space warp provider
     */
    spaceWarpRTTProvider: Nullable<WebXRSpaceWarpRenderTargetTextureProvider>;
    private _glContext;
    private _xrWebGLBinding;
    private _renderTargetTexture;
    private _onAfterRenderObserver;
    /**
     * constructor for the space warp feature
     * @param _xrSessionManager the xr session manager for this feature
     */
    constructor(_xrSessionManager: WebXRSessionManager);
    /**
     * Attach this feature.
     * Will usually be called by the features manager.
     *
     * @returns true if successful.
     */
    attach(): boolean;
    detach(): boolean;
    private _onAfterRender;
    dependsOn: string[];
    isCompatible(): boolean;
    dispose(): void;
    protected _onXRFrame(_xrFrame: XRFrame): void;
}

/**
 * Options for the walking locomotion feature.
 */
interface IWebXRWalkingLocomotionOptions {
    /**
     * The target to be moved by walking locomotion. This should be the transform node
     * which is the root of the XR space (i.e., the WebXRCamera's parent node). However,
     * for simple cases and legacy purposes, articulating the WebXRCamera itself is also
     * supported as a deprecated feature.
     */
    locomotionTarget: WebXRCamera | TransformNode;
}
/**
 * A module that will enable VR locomotion by detecting when the user walks in place.
 */
declare class WebXRWalkingLocomotion extends WebXRAbstractFeature {
    /**
     * The module's name.
     */
    static get Name(): string;
    /**
     * The (Babylon) version of this module.
     * This is an integer representing the implementation version.
     * This number has no external basis.
     */
    static get Version(): number;
    private _sessionManager;
    private _up;
    private _forward;
    private _position;
    private _movement;
    private _walker;
    private _locomotionTarget;
    private _isLocomotionTargetWebXRCamera;
    /**
     * The target to be articulated by walking locomotion.
     * When the walking locomotion feature detects walking in place, this element's
     * X and Z coordinates will be modified to reflect locomotion. This target should
     * be either the XR space's origin (i.e., the parent node of the WebXRCamera) or
     * the WebXRCamera itself. Note that the WebXRCamera path will modify the position
     * of the WebXRCamera directly and is thus discouraged.
     */
    get locomotionTarget(): WebXRCamera | TransformNode;
    /**
     * The target to be articulated by walking locomotion.
     * When the walking locomotion feature detects walking in place, this element's
     * X and Z coordinates will be modified to reflect locomotion. This target should
     * be either the XR space's origin (i.e., the parent node of the WebXRCamera) or
     * the WebXRCamera itself. Note that the WebXRCamera path will modify the position
     * of the WebXRCamera directly and is thus discouraged.
     */
    set locomotionTarget(locomotionTarget: WebXRCamera | TransformNode);
    /**
     * Construct a new Walking Locomotion feature.
     * @param sessionManager manager for the current XR session
     * @param options creation options, prominently including the vector target for locomotion
     */
    constructor(sessionManager: WebXRSessionManager, options: IWebXRWalkingLocomotionOptions);
    /**
     * Checks whether this feature is compatible with the current WebXR session.
     * Walking locomotion is only compatible with "immersive-vr" sessions.
     * @returns true if compatible, false otherwise
     */
    isCompatible(): boolean;
    /**
     * Attaches the feature.
     * Typically called automatically by the features manager.
     * @returns true if attach succeeded, false otherwise
     */
    attach(): boolean;
    /**
     * Detaches the feature.
     * Typically called automatically by the features manager.
     * @returns true if detach succeeded, false otherwise
     */
    detach(): boolean;
    protected _onXRFrame(frame: XRFrame): void;
}

/**
 * Defining the interface required for a (webxr) feature
 */
interface IWebXRFeature extends IDisposable {
    /**
     * Is this feature attached
     */
    attached: boolean;
    /**
     * Should auto-attach be disabled?
     */
    disableAutoAttach: boolean;
    /**
     * Attach the feature to the session
     * Will usually be called by the features manager
     *
     * @param force should attachment be forced (even when already attached)
     * @returns true if successful.
     */
    attach(force?: boolean): boolean;
    /**
     * Detach the feature from the session
     * Will usually be called by the features manager
     *
     * @returns true if successful.
     */
    detach(): boolean;
    /**
     * This function will be executed during before enabling the feature and can be used to not-allow enabling it.
     * Note that at this point the session has NOT started, so this is purely checking if the browser supports it
     *
     * @returns whether or not the feature is compatible in this environment
     */
    isCompatible(): boolean;
    /**
     * Was this feature disposed;
     */
    isDisposed: boolean;
    /**
     * The name of the native xr feature name, if applicable (like anchor, hit-test, or hand-tracking)
     */
    xrNativeFeatureName?: string;
    /**
     * A list of (Babylon WebXR) features this feature depends on
     */
    dependsOn?: string[];
    /**
     * If this feature requires to extend the XRSessionInit object, this function will return the partial XR session init object
     */
    getXRSessionInitExtension?: () => Promise<Partial<XRSessionInit>>;
    /**
     * Triggered when the feature is attached
     */
    onFeatureAttachObservable: Observable<IWebXRFeature>;
    /**
     * Triggered when the feature is detached
     */
    onFeatureDetachObservable: Observable<IWebXRFeature>;
}
/**
 * A list of the currently available features without referencing them
 */
declare class WebXRFeatureName {
    /**
     * The name of the anchor system feature
     */
    static readonly ANCHOR_SYSTEM: "xr-anchor-system";
    /**
     * The name of the background remover feature
     */
    static readonly BACKGROUND_REMOVER: "xr-background-remover";
    /**
     * The name of the hit test feature
     */
    static readonly HIT_TEST: "xr-hit-test";
    /**
     * The name of the mesh detection feature
     */
    static readonly MESH_DETECTION: "xr-mesh-detection";
    /**
     * physics impostors for xr controllers feature
     */
    static readonly PHYSICS_CONTROLLERS: "xr-physics-controller";
    /**
     * The name of the plane detection feature
     */
    static readonly PLANE_DETECTION: "xr-plane-detection";
    /**
     * The name of the pointer selection feature
     */
    static readonly POINTER_SELECTION: "xr-controller-pointer-selection";
    /**
     * The name of the teleportation feature
     */
    static readonly TELEPORTATION: "xr-controller-teleportation";
    /**
     * The name of the feature points feature.
     */
    static readonly FEATURE_POINTS: "xr-feature-points";
    /**
     * The name of the hand tracking feature.
     */
    static readonly HAND_TRACKING: "xr-hand-tracking";
    /**
     * The name of the image tracking feature
     */
    static readonly IMAGE_TRACKING: "xr-image-tracking";
    /**
     * The name of the near interaction feature
     */
    static readonly NEAR_INTERACTION: "xr-near-interaction";
    /**
     * The name of the DOM overlay feature
     */
    static readonly DOM_OVERLAY: "xr-dom-overlay";
    /**
     * The name of the movement feature
     */
    static readonly MOVEMENT: "xr-controller-movement";
    /**
     * The name of the light estimation feature
     */
    static readonly LIGHT_ESTIMATION: "xr-light-estimation";
    /**
     * The name of the eye tracking feature
     */
    static readonly EYE_TRACKING: "xr-eye-tracking";
    /**
     * The name of the walking locomotion feature
     */
    static readonly WALKING_LOCOMOTION: "xr-walking-locomotion";
    /**
     * The name of the composition layers feature
     */
    static readonly LAYERS: "xr-layers";
    /**
     * The name of the depth sensing feature
     */
    static readonly DEPTH_SENSING: "xr-depth-sensing";
    /**
     * The name of the WebXR Space Warp feature
     */
    static readonly SPACE_WARP: "xr-space-warp";
    /**
     * The name of the WebXR Raw Camera Access feature
     */
    static readonly RAW_CAMERA_ACCESS: "xr-raw-camera-access";
}
type WebXRFeatureNameType = (typeof WebXRFeatureName)[Exclude<keyof typeof WebXRFeatureName, "prototype">];
interface IWebXRFeatureNameTypeMap {
    [WebXRFeatureName.ANCHOR_SYSTEM]: WebXRAnchorSystem;
    [WebXRFeatureName.BACKGROUND_REMOVER]: WebXRBackgroundRemover;
    [WebXRFeatureName.DEPTH_SENSING]: WebXRDepthSensing;
    [WebXRFeatureName.DOM_OVERLAY]: WebXRDomOverlay;
    [WebXRFeatureName.EYE_TRACKING]: WebXREyeTracking;
    [WebXRFeatureName.FEATURE_POINTS]: WebXRFeaturePointSystem;
    [WebXRFeatureName.HAND_TRACKING]: WebXRHandTracking;
    [WebXRFeatureName.HIT_TEST]: WebXRHitTest;
    [WebXRFeatureName.IMAGE_TRACKING]: WebXRImageTracking;
    [WebXRFeatureName.LAYERS]: WebXRLayers;
    [WebXRFeatureName.LIGHT_ESTIMATION]: WebXRLightEstimation;
    [WebXRFeatureName.MESH_DETECTION]: WebXRMeshDetector;
    [WebXRFeatureName.MOVEMENT]: WebXRControllerMovement;
    [WebXRFeatureName.NEAR_INTERACTION]: WebXRNearInteraction;
    [WebXRFeatureName.PHYSICS_CONTROLLERS]: WebXRControllerPhysics;
    [WebXRFeatureName.PLANE_DETECTION]: WebXRPlaneDetector;
    [WebXRFeatureName.POINTER_SELECTION]: WebXRControllerPointerSelection;
    [WebXRFeatureName.RAW_CAMERA_ACCESS]: WebXRRawCameraAccess;
    [WebXRFeatureName.SPACE_WARP]: WebXRSpaceWarp;
    [WebXRFeatureName.TELEPORTATION]: WebXRMotionControllerTeleportation;
    [WebXRFeatureName.WALKING_LOCOMOTION]: WebXRWalkingLocomotion;
}
/**
 * Maps feature names to their corresponding options interfaces.
 */
interface IWebXRFeatureNameOptionsMap {
    [WebXRFeatureName.ANCHOR_SYSTEM]: IWebXRAnchorSystemOptions;
    [WebXRFeatureName.BACKGROUND_REMOVER]: IWebXRBackgroundRemoverOptions;
    [WebXRFeatureName.DEPTH_SENSING]: IWebXRDepthSensingOptions;
    [WebXRFeatureName.DOM_OVERLAY]: IWebXRDomOverlayOptions;
    [WebXRFeatureName.EYE_TRACKING]: undefined;
    [WebXRFeatureName.FEATURE_POINTS]: undefined;
    [WebXRFeatureName.HAND_TRACKING]: IWebXRHandTrackingOptions;
    [WebXRFeatureName.HIT_TEST]: IWebXRHitTestOptions;
    [WebXRFeatureName.IMAGE_TRACKING]: IWebXRImageTrackingOptions;
    [WebXRFeatureName.LAYERS]: IWebXRLayersOptions;
    [WebXRFeatureName.LIGHT_ESTIMATION]: IWebXRLightEstimationOptions;
    [WebXRFeatureName.MESH_DETECTION]: IWebXRMeshDetectorOptions;
    [WebXRFeatureName.MOVEMENT]: IWebXRControllerMovementOptions;
    [WebXRFeatureName.NEAR_INTERACTION]: IWebXRNearInteractionOptions;
    [WebXRFeatureName.PHYSICS_CONTROLLERS]: IWebXRControllerPhysicsOptions;
    [WebXRFeatureName.PLANE_DETECTION]: IWebXRPlaneDetectorOptions;
    [WebXRFeatureName.POINTER_SELECTION]: IWebXRControllerPointerSelectionOptions;
    [WebXRFeatureName.RAW_CAMERA_ACCESS]: IWebXRRawCameraAccessOptions;
    [WebXRFeatureName.SPACE_WARP]: undefined;
    [WebXRFeatureName.TELEPORTATION]: IWebXRTeleportationOptions;
    [WebXRFeatureName.WALKING_LOCOMOTION]: IWebXRWalkingLocomotionOptions;
}
/**
 * Helper type that expands/flattens a type to show its properties inline in IntelliSense
 */
type Expand<T> = T extends infer O ? {
    [K in keyof O]: O[K];
} : never;
/**
 * Helper type to resolve the specific feature type based on the feature name,
 * or fallback to IWebXRFeature if the feature name is not in the type map.
 */
type ResolveWebXRFeature<T extends WebXRFeatureNameType> = T extends keyof IWebXRFeatureNameTypeMap ? IWebXRFeatureNameTypeMap[T] : IWebXRFeature;
/**
 * Helper type to resolve the options type for a specific feature based on the feature name,
 * or fallback to any if the feature name is not in the type map.
 * The Expand utility type flattens the interface to show properties inline in IntelliSense.
 */
type ResolveWebXRFeatureOptions<T extends WebXRFeatureNameType> = T extends keyof IWebXRFeatureNameOptionsMap ? IWebXRFeatureNameOptionsMap[T] extends undefined ? undefined : Expand<IWebXRFeatureNameOptionsMap[T]> : any;
/**
 * Defining the constructor of a feature. Used to register the modules.
 */
type WebXRFeatureConstructor = (xrSessionManager: WebXRSessionManager, options?: any) => () => IWebXRFeature;
/**
 * The WebXR features manager is responsible of enabling or disabling features required for the current XR session.
 * It is mainly used in AR sessions.
 *
 * A feature can have a version that is defined by Babylon (and does not correspond with the webxr version).
 */
declare class WebXRFeaturesManager implements IDisposable {
    private _xrSessionManager;
    private static readonly _AvailableFeatures;
    private _features;
    /**
     * The key is the feature to check and the value is the feature that conflicts.
     */
    private static readonly _ConflictingFeatures;
    /**
     * constructs a new features manages.
     *
     * @param _xrSessionManager an instance of WebXRSessionManager
     */
    constructor(_xrSessionManager: WebXRSessionManager);
    /**
     * Used to register a module. After calling this function a developer can use this feature in the scene.
     * Mainly used internally.
     *
     * @param featureName the name of the feature to register
     * @param constructorFunction the function used to construct the module
     * @param version the (babylon) version of the module
     * @param stable is that a stable version of this module
     */
    static AddWebXRFeature(featureName: string, constructorFunction: WebXRFeatureConstructor, version?: number, stable?: boolean): void;
    /**
     * Returns a constructor of a specific feature.
     *
     * @param featureName the name of the feature to construct
     * @param version the version of the feature to load
     * @param xrSessionManager the xrSessionManager. Used to construct the module
     * @param options optional options provided to the module.
     * @returns a function that, when called, will return a new instance of this feature
     */
    static ConstructFeature(featureName: string, version: number | undefined, xrSessionManager: WebXRSessionManager, options?: any): () => IWebXRFeature;
    /**
     * Can be used to return the list of features currently registered
     *
     * @returns an Array of available features
     */
    static GetAvailableFeatures(): string[];
    /**
     * Gets the versions available for a specific feature
     * @param featureName the name of the feature
     * @returns an array with the available versions
     */
    static GetAvailableVersions(featureName: string): string[];
    /**
     * Return the latest unstable version of this feature
     * @param featureName the name of the feature to search
     * @returns the version number. if not found will return -1
     */
    static GetLatestVersionOfFeature(featureName: string): number;
    /**
     * Return the latest stable version of this feature
     * @param featureName the name of the feature to search
     * @returns the version number. if not found will return -1
     */
    static GetStableVersionOfFeature(featureName: string): number;
    /**
     * Attach a feature to the current session. Mainly used when session started to start the feature effect.
     * Can be used during a session to start a feature
     * @param featureName the name of feature to attach
     */
    attachFeature(featureName: string): void;
    /**
     * Can be used inside a session or when the session ends to detach a specific feature
     * @param featureName the name of the feature to detach
     */
    detachFeature(featureName: string): void;
    /**
     * Used to disable an already-enabled feature
     * The feature will be disposed and will be recreated once enabled.
     * @param featureName the feature to disable
     * @returns true if disable was successful
     */
    disableFeature(featureName: string | {
        Name: string;
    }): boolean;
    /**
     * dispose this features manager
     */
    dispose(): void;
    /**
     * Enable a feature using its name and a version. This will enable it in the scene, and will be responsible to attach it when the session starts.
     * If used twice, the old version will be disposed and a new one will be constructed. This way you can re-enable with different configuration.
     *
     * @param featureName the name of the feature to load or the class of the feature
     * @param version optional version to load. if not provided the latest version will be enabled
     * @param moduleOptions options provided to the module. Ses the module documentation / constructor
     * @param attachIfPossible if set to true (default) the feature will be automatically attached, if it is currently possible
     * @param required is this feature required to the app. If set to true the session init will fail if the feature is not available.
     * @returns a new constructed feature or throws an error if feature not found or conflicts with another enabled feature.
     */
    enableFeature<T extends WebXRFeatureNameType>(featureName: T | {
        Name: T;
    }, version?: number | string, moduleOptions?: ResolveWebXRFeatureOptions<T>, attachIfPossible?: boolean, required?: boolean): ResolveWebXRFeature<T>;
    /**
     * get the implementation of an enabled feature.
     * @param featureName the name of the feature to load
     * @returns the feature class, if found
     */
    getEnabledFeature<T extends WebXRFeatureNameType>(featureName: T): ResolveWebXRFeature<T>;
    /**
     * Get the list of enabled features
     * @returns an array of enabled features
     */
    getEnabledFeatures(): string[];
    /**
     * This function will extend the session creation configuration object with enabled features.
     * If, for example, the anchors feature is enabled, it will be automatically added to the optional or required features list,
     * according to the defined "required" variable, provided during enableFeature call
     * @param xrSessionInit the xr Session init object to extend
     *
     * @returns an extended XRSessionInit object
     */
    _extendXRSessionInitObject(xrSessionInit: XRSessionInit): Promise<XRSessionInit>;
}

/**
 * Options for setting up XR spectator camera.
 */
interface WebXRSpectatorModeOption {
    /**
     * Expected refresh rate (frames per sec) for a spectator camera.
     */
    fps?: number;
    /**
     * The index of rigCameras array in a WebXR camera.
     */
    preferredCameraIndex?: number;
}
/**
 * Base set of functionality needed to create an XR experience (WebXRSessionManager, Camera, StateManagement, etc.)
 * @see https://doc.babylonjs.com/features/featuresDeepDive/webXR/webXRExperienceHelpers
 */
declare class WebXRExperienceHelper implements IDisposable {
    private _scene;
    private _nonVRCamera;
    private _attachedToElement;
    private _spectatorCamera;
    private _originalSceneAutoClear;
    private _supported;
    private _spectatorMode;
    private _lastTimestamp;
    /**
     * Camera used to render xr content
     */
    camera: WebXRCamera;
    /** A features manager for this xr session */
    featuresManager: WebXRFeaturesManager;
    /**
     * Observers registered here will be triggered after the camera's initial transformation is set
     * This can be used to set a different ground level or an extra rotation.
     *
     * Note that ground level is considered to be at 0. The height defined by the XR camera will be added
     * to the position set after this observable is done executing.
     */
    onInitialXRPoseSetObservable: Observable<WebXRCamera>;
    /**
     * Fires when the state of the experience helper has changed
     */
    onStateChangedObservable: Observable<WebXRState>;
    /** Session manager used to keep track of xr session */
    sessionManager: WebXRSessionManager;
    /**
     * The current state of the XR experience (eg. transitioning, in XR or not in XR)
     */
    state: WebXRState;
    /**
     * Creates a WebXRExperienceHelper
     * @param _scene The scene the helper should be created in
     */
    private constructor();
    /**
     * Creates the experience helper
     * @param scene the scene to attach the experience helper to
     * @returns a promise for the experience helper
     */
    static CreateAsync(scene: Scene): Promise<WebXRExperienceHelper>;
    /**
     * Disposes of the experience helper
     */
    dispose(): void;
    /**
     * Enters XR mode (This must be done within a user interaction in most browsers eg. button click)
     * @param sessionMode options for the XR session
     * @param referenceSpaceType frame of reference of the XR session
     * @param renderTarget the output canvas that will be used to enter XR mode
     * @param sessionCreationOptions optional XRSessionInit object to init the session with
     * @returns promise that resolves after xr mode has entered
     */
    enterXRAsync(sessionMode: XRSessionMode, referenceSpaceType: XRReferenceSpaceType, renderTarget?: WebXRRenderTarget, sessionCreationOptions?: XRSessionInit): Promise<WebXRSessionManager>;
    /**
     * Exits XR mode and returns the scene to its original state
     * @returns promise that resolves after xr mode has exited
     */
    exitXRAsync(): Promise<void>;
    /**
     * Enable spectator mode for desktop VR experiences.
     * When spectator mode is enabled a camera will be attached to the desktop canvas and will
     * display the first rig camera's view on the desktop canvas.
     * Please note that this will degrade performance, as it requires another camera render.
     * It is also not recommended to enable this in devices like the quest, as it brings no benefit there.
     * @param options giving WebXRSpectatorModeOption for specutator camera to setup when the spectator mode is enabled.
     */
    enableSpectatorMode(options?: WebXRSpectatorModeOption): void;
    /**
     * Disable spectator mode for desktop VR experiences.
     */
    disableSpecatatorMode(): void;
    private _switchSpectatorMode;
    private _nonXRToXRCamera;
    private _setState;
}

/**
 * Represents a gamepad control stick position
 */
declare class StickValues {
    /**
     * The x component of the control stick
     */
    x: number;
    /**
     * The y component of the control stick
     */
    y: number;
    /**
     * Initializes the gamepad x and y control stick values
     * @param x The x component of the gamepad control stick value
     * @param y The y component of the gamepad control stick value
     */
    constructor(
    /**
     * The x component of the control stick
     */
    x: number, 
    /**
     * The y component of the control stick
     */
    y: number);
}
/**
 * Represents a gamepad
 */
declare class Gamepad {
    /**
     * The id of the gamepad
     */
    id: string;
    /**
     * The index of the gamepad
     */
    index: number;
    /**
     * The browser gamepad
     */
    browserGamepad: any;
    /**
     * Specifies what type of gamepad this represents
     */
    type: number;
    private _leftStick;
    private _rightStick;
    /** @internal */
    _isConnected: boolean;
    private _leftStickAxisX;
    private _leftStickAxisY;
    private _rightStickAxisX;
    private _rightStickAxisY;
    /**
     * Triggered when the left control stick has been changed
     */
    private _onleftstickchanged;
    /**
     * Triggered when the right control stick has been changed
     */
    private _onrightstickchanged;
    /**
     * Represents a gamepad controller
     */
    static GAMEPAD: number;
    /**
     * Represents a generic controller
     */
    static GENERIC: number;
    /**
     * Represents an XBox controller
     */
    static XBOX: number;
    /**
     * Represents a pose-enabled controller
     */
    static POSE_ENABLED: number;
    /**
     * Represents an Dual Shock controller
     */
    static DUALSHOCK: number;
    /**
     * Specifies whether the left control stick should be Y-inverted
     */
    protected _invertLeftStickY: boolean;
    /**
     * Specifies if the gamepad has been connected
     */
    get isConnected(): boolean;
    /**
     * Initializes the gamepad
     * @param id The id of the gamepad
     * @param index The index of the gamepad
     * @param browserGamepad The browser gamepad
     * @param leftStickX The x component of the left joystick
     * @param leftStickY The y component of the left joystick
     * @param rightStickX The x component of the right joystick
     * @param rightStickY The y component of the right joystick
     */
    constructor(
    /**
     * The id of the gamepad
     */
    id: string, 
    /**
     * The index of the gamepad
     */
    index: number, 
    /**
     * The browser gamepad
     */
    browserGamepad: any, leftStickX?: number, leftStickY?: number, rightStickX?: number, rightStickY?: number);
    /**
     * Callback triggered when the left joystick has changed
     * @param callback callback to trigger
     */
    onleftstickchanged(callback: (values: StickValues) => void): void;
    /**
     * Callback triggered when the right joystick has changed
     * @param callback callback to trigger
     */
    onrightstickchanged(callback: (values: StickValues) => void): void;
    /**
     * Gets the left joystick
     */
    get leftStick(): StickValues;
    /**
     * Sets the left joystick values
     */
    set leftStick(newValues: StickValues);
    /**
     * Gets the right joystick
     */
    get rightStick(): StickValues;
    /**
     * Sets the right joystick value
     */
    set rightStick(newValues: StickValues);
    /**
     * Updates the gamepad joystick positions
     */
    update(): void;
    /**
     * Disposes the gamepad
     */
    dispose(): void;
}

declare module "../../Cameras/arcRotateCameraInputsManager" {
    interface ArcRotateCameraInputsManager {
        /**
         * Add orientation input support to the input manager.
         * @returns the current input manager
         */
        addVRDeviceOrientation(): ArcRotateCameraInputsManager;
    }
}

declare module "../../Cameras/freeCameraInputsManager" {
    interface FreeCameraInputsManager {
        /**
         * @internal
         */
        _deviceOrientationInput: Nullable<FreeCameraDeviceOrientationInput>;
        /**
         * Add orientation input support to the input manager.
         * @param smoothFactor deviceOrientation smoothing. 0: no smoothing, 1: new data ignored, 0.9 recommended for smoothing
         * @returns the current input manager
         */
        addDeviceOrientation(smoothFactor?: number): FreeCameraInputsManager;
    }
}
/**
 * Takes information about the orientation of the device as reported by the deviceorientation event to orient the camera.
 * Screen rotation is taken into account.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
 */
declare class FreeCameraDeviceOrientationInput implements ICameraInput<FreeCamera> {
    private _camera;
    private _screenOrientationAngle;
    private _constantTransform;
    private _screenQuaternion;
    private _alpha;
    private _beta;
    private _gamma;
    /** alpha+beta+gamma smoothing. 0: no smoothing, 1: new data ignored, 0.9 recommended for smoothing */
    smoothFactor: number;
    /**
     * Can be used to detect if a device orientation sensor is available on a device
     * @param timeout amount of time in milliseconds to wait for a response from the sensor (default: infinite)
     * @returns a promise that will resolve on orientation change
     */
    static WaitForOrientationChangeAsync(timeout?: number): Promise<void>;
    /**
     * @internal
     */
    _onDeviceOrientationChangedObservable: Observable<void>;
    /**
     * Instantiates a new input
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/customizingCameraInputs
     */
    constructor();
    /**
     * Define the camera controlled by the input.
     */
    get camera(): FreeCamera;
    set camera(camera: FreeCamera);
    /**
     * Attach the input controls to a specific dom element to get the input from.
     */
    attachControl(): void;
    private _orientationChanged;
    private _deviceOrientation;
    /**
     * Detach the current controls from the specified dom element.
     */
    detachControl(): void;
    /**
     * Update the current camera state depending on the inputs that have been used this frame.
     * This is a dynamically created lambda to avoid the performance penalty of looping for inputs in the render loop.
     */
    checkInputs(): void;
    /**
     * Gets the class name of the current input.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Get the friendly name associated with the input class.
     * @returns the input friendly name
     */
    getSimpleName(): string;
}

declare module "../../Cameras/freeCameraInputsManager" {
    interface FreeCameraInputsManager {
        /**
         * Add virtual joystick input support to the input manager.
         * @returns the current input manager
         */
        addVirtualJoystick(): FreeCameraInputsManager;
    }
}

/**
 * This is a camera specifically designed to react to device orientation events such as a modern mobile device
 * being tilted forward or back and left or right.
 */
declare class DeviceOrientationCamera extends FreeCamera {
    private _initialQuaternion;
    private _quaternionCache;
    private _tmpDragQuaternion;
    private _disablePointerInputWhenUsingDeviceOrientation;
    /**
     * Creates a new device orientation camera
     * @param name The name of the camera
     * @param position The start position camera
     * @param scene The scene the camera belongs to
     */
    constructor(name: string, position: Vector3, scene?: Scene);
    /**
     * Gets or sets a boolean indicating that pointer input must be disabled on first orientation sensor update (Default: true)
     */
    get disablePointerInputWhenUsingDeviceOrientation(): boolean;
    set disablePointerInputWhenUsingDeviceOrientation(value: boolean);
    private _dragFactor;
    /**
     * Enabled turning on the y axis when the orientation sensor is active
     * @param dragFactor the factor that controls the turn speed (default: 1/300)
     */
    enableHorizontalDragging(dragFactor?: number): void;
    /**
     * Gets the current instance class name ("DeviceOrientationCamera").
     * This helps avoiding instanceof at run time.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * @internal
     * Checks and applies the current values of the inputs to the camera. (Internal use only)
     */
    _checkInputs(): void;
    /**
     * Reset the camera to its default orientation on the specified axis only.
     * @param axis The axis to reset
     */
    resetToCurrentRotation(axis?: Axis): void;
}

/**
 * Manager for handling gamepads
 */
declare class GamepadManager {
    private _scene?;
    private _babylonGamepads;
    private _oneGamepadConnected;
    /** @internal */
    _isMonitoring: boolean;
    private _gamepadEventSupported;
    private _gamepadSupport?;
    /**
     * observable to be triggered when the gamepad controller has been connected
     */
    onGamepadConnectedObservable: Observable<Gamepad>;
    /**
     * observable to be triggered when the gamepad controller has been disconnected
     */
    onGamepadDisconnectedObservable: Observable<Gamepad>;
    private _onGamepadConnectedEvent;
    private _onGamepadDisconnectedEvent;
    /**
     * Initializes the gamepad manager
     * @param _scene BabylonJS scene
     */
    constructor(_scene?: Scene | undefined);
    /**
     * The gamepads in the game pad manager
     */
    get gamepads(): Gamepad[];
    /**
     * Get the gamepad controllers based on type
     * @param type The type of gamepad controller
     * @returns Nullable gamepad
     */
    getGamepadByType(type?: number): Nullable<Gamepad>;
    /**
     * Disposes the gamepad manager
     */
    dispose(): void;
    private _addNewGamepad;
    private _startMonitoringGamepads;
    private _stopMonitoringGamepads;
    private _loggedErrors;
    /** @internal */
    _checkGamepadsStatus(): void;
    private _updateGamepadObjects;
}

declare module "../scene" {
    interface Scene {
        /** @internal */
        _gamepadManager: Nullable<GamepadManager>;
        /**
         * Gets the gamepad manager associated with the scene
         * @see https://doc.babylonjs.com/features/featuresDeepDive/input/gamepads
         */
        gamepadManager: GamepadManager;
    }
}
declare module "../Cameras/freeCameraInputsManager" {
    /**
     * Interface representing a free camera inputs manager
     */
    interface FreeCameraInputsManager {
        /**
         * Adds gamepad input support to the FreeCameraInputsManager.
         * @returns the FreeCameraInputsManager
         */
        addGamepad(): FreeCameraInputsManager;
    }
}
declare module "../Cameras/arcRotateCameraInputsManager" {
    /**
     * Interface representing an arc rotate camera inputs manager
     */
    interface ArcRotateCameraInputsManager {
        /**
         * Adds gamepad input support to the ArcRotateCamera InputManager.
         * @returns the camera inputs manager
         */
        addGamepad(): ArcRotateCameraInputsManager;
    }
}

/**
 * This represents all the required metrics to create a VR camera.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_introduction#device-orientation-camera
 */
declare class VRCameraMetrics {
    /**
     * Define the horizontal resolution off the screen.
     */
    hResolution: number;
    /**
     * Define the vertical resolution off the screen.
     */
    vResolution: number;
    /**
     * Define the horizontal screen size.
     */
    hScreenSize: number;
    /**
     * Define the vertical screen size.
     */
    vScreenSize: number;
    /**
     * Define the vertical screen center position.
     */
    vScreenCenter: number;
    /**
     * Define the distance of the eyes to the screen.
     */
    eyeToScreenDistance: number;
    /**
     * Define the distance between both lenses
     */
    lensSeparationDistance: number;
    /**
     * Define the distance between both viewer's eyes.
     */
    interpupillaryDistance: number;
    /**
     * Define the distortion factor of the VR postprocess.
     * Please, touch with care.
     */
    distortionK: number[];
    /**
     * Define the chromatic aberration correction factors for the VR post process.
     */
    chromaAbCorrection: number[];
    /**
     * Define the scale factor of the post process.
     * The smaller the better but the slower.
     */
    postProcessScaleFactor: number;
    /**
     * Define an offset for the lens center.
     */
    lensCenterOffset: number;
    /**
     * Define if the current vr camera should compensate the distortion of the lens or not.
     */
    compensateDistortion: boolean;
    /**
     * Defines if multiview should be enabled when rendering (Default: false)
     */
    multiviewEnabled: boolean;
    /**
     * Gets the rendering aspect ratio based on the provided resolutions.
     */
    get aspectRatio(): number;
    /**
     * Gets the aspect ratio based on the FOV, scale factors, and real screen sizes.
     */
    get aspectRatioFov(): number;
    /**
     * @internal
     */
    get leftHMatrix(): Matrix;
    /**
     * @internal
     */
    get rightHMatrix(): Matrix;
    /**
     * @internal
     */
    get leftPreViewMatrix(): Matrix;
    /**
     * @internal
     */
    get rightPreViewMatrix(): Matrix;
    /**
     * Get the default VRMetrics based on the most generic setup.
     * @returns the default vr metrics
     */
    static GetDefault(): VRCameraMetrics;
}

/**
 * Camera used to simulate VR rendering (based on FreeCamera)
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_introduction#vr-device-orientation-cameras
 */
declare class VRDeviceOrientationFreeCamera extends DeviceOrientationCamera {
    /**
     * Creates a new VRDeviceOrientationFreeCamera
     * @param name defines camera name
     * @param position defines the start position of the camera
     * @param scene defines the scene the camera belongs to
     * @param compensateDistortion defines if the camera needs to compensate the lens distortion
     * @param vrCameraMetrics defines the vr metrics associated to the camera
     */
    constructor(name: string, position: Vector3, scene?: Scene, compensateDistortion?: boolean, vrCameraMetrics?: VRCameraMetrics);
    /**
     * Gets camera class name
     * @returns VRDeviceOrientationFreeCamera
     */
    getClassName(): string;
    protected _setRigMode: (rigParams: any) => void;
}

/**
 * Button which can be used to enter a different mode of XR
 */
declare class WebXREnterExitUIButton {
    /** button element */
    element: HTMLElement;
    /** XR initialization options for the button */
    sessionMode: XRSessionMode;
    /** Reference space type */
    referenceSpaceType: XRReferenceSpaceType;
    /**
     * Creates a WebXREnterExitUIButton
     * @param element button element
     * @param sessionMode XR initialization session mode
     * @param referenceSpaceType the type of reference space to be used
     */
    constructor(
    /** button element */
    element: HTMLElement, 
    /** XR initialization options for the button */
    sessionMode: XRSessionMode, 
    /** Reference space type */
    referenceSpaceType: XRReferenceSpaceType);
    /**
     * Extendable function which can be used to update the button's visuals when the state changes
     * @param activeButton the current active button in the UI
     */
    update(activeButton: Nullable<WebXREnterExitUIButton>): void;
}
/**
 * Options to create the webXR UI
 */
declare class WebXREnterExitUIOptions {
    /**
     * User provided buttons to enable/disable WebXR. The system will provide default if not set
     */
    customButtons?: Array<WebXREnterExitUIButton>;
    /**
     * A reference space type to use when creating the default button.
     * Default is local-floor
     */
    referenceSpaceType?: XRReferenceSpaceType;
    /**
     * Context to enter xr with
     */
    renderTarget?: Nullable<WebXRRenderTarget>;
    /**
     * A session mode to use when creating the default button.
     * Default is immersive-vr
     */
    sessionMode?: XRSessionMode;
    /**
     * A list of optional features to init the session with
     */
    optionalFeatures?: string[];
    /**
     * A list of optional features to init the session with
     */
    requiredFeatures?: string[];
    /**
     * If set, the `sessiongranted` event will not be registered. `sessiongranted` is used to move seamlessly between WebXR experiences.
     * If set to true the user will be forced to press the "enter XR" button even if sessiongranted event was triggered.
     * If not set and a sessiongranted event was triggered, the XR session will start automatically.
     */
    ignoreSessionGrantedEvent?: boolean;
    /**
     * If defined, this function will be executed if the UI encounters an error when entering XR
     */
    onError?: (error: any) => void;
}
/**
 * UI to allow the user to enter/exit XR mode
 */
declare class WebXREnterExitUI implements IDisposable {
    private _scene;
    /** version of the options passed to this UI */
    options: WebXREnterExitUIOptions;
    private _activeButton;
    private _buttons;
    private _helper;
    private _renderTarget?;
    /**
     * The HTML Div Element to which buttons are added.
     */
    readonly overlay: HTMLDivElement;
    /**
     * Fired every time the active button is changed.
     *
     * When xr is entered via a button that launches xr that button will be the callback parameter
     *
     * When exiting xr the callback parameter will be null)
     */
    activeButtonChangedObservable: Observable<Nullable<WebXREnterExitUIButton>>;
    /**
     * Construct a new EnterExit UI class
     *
     * @param _scene babylon scene object to use
     * @param options (read-only) version of the options passed to this UI
     */
    constructor(_scene: Scene, 
    /** version of the options passed to this UI */
    options: WebXREnterExitUIOptions);
    /**
     * Set the helper to be used with this UI component.
     * The UI is bound to an experience helper. If not provided the UI can still be used but the events should be registered by the developer.
     *
     * @param helper the experience helper to attach
     * @param renderTarget an optional render target (in case it is created outside of the helper scope)
     * @returns a promise that resolves when the ui is ready
     */
    setHelperAsync(helper: WebXRExperienceHelper, renderTarget?: WebXRRenderTarget): Promise<void>;
    /**
     * Creates UI to allow the user to enter/exit XR mode
     * @param scene the scene to add the ui to
     * @param helper the xr experience helper to enter/exit xr with
     * @param options options to configure the UI
     * @returns the created ui
     */
    static CreateAsync(scene: Scene, helper: WebXRExperienceHelper, options: WebXREnterExitUIOptions): Promise<WebXREnterExitUI>;
    private _enterXRWithButtonIndexAsync;
    /**
     * Disposes of the XR UI component
     */
    dispose(): void;
    private _onSessionGranted;
    private _updateButtons;
}

/**
 * Options for the default xr helper
 */
declare class WebXRDefaultExperienceOptions {
    /**
     * Enable or disable default UI to enter XR
     */
    disableDefaultUI?: boolean;
    /**
     * Should pointer selection not initialize.
     * Note that disabling pointer selection also disables teleportation.
     * Defaults to false.
     */
    disablePointerSelection?: boolean;
    /**
     * Should teleportation not initialize. Defaults to false.
     */
    disableTeleportation?: boolean;
    /**
     * Should nearInteraction not initialize. Defaults to false.
     */
    disableNearInteraction?: boolean;
    /**
     * Should hand tracking be disabled. Defaults to false.
     */
    disableHandTracking?: boolean;
    /**
     * Floor meshes that will be used for teleport
     */
    floorMeshes?: Array<AbstractMesh>;
    /**
     * If set to true, the first frame will not be used to reset position
     * The first frame is mainly used when copying transformation from the old camera
     * Mainly used in AR
     */
    ignoreNativeCameraTransformation?: boolean;
    /**
     * Optional configuration for the XR input object
     */
    inputOptions?: Partial<IWebXRInputOptions>;
    /**
     * optional configuration for pointer selection
     */
    pointerSelectionOptions?: Partial<IWebXRControllerPointerSelectionOptions>;
    /**
     * optional configuration for near interaction
     */
    nearInteractionOptions?: Partial<IWebXRNearInteractionOptions>;
    /**
     * optional configuration for hand tracking
     */
    handSupportOptions?: Partial<IWebXRHandTrackingOptions>;
    /**
     * optional configuration for teleportation
     */
    teleportationOptions?: Partial<IWebXRTeleportationOptions>;
    /**
     * optional configuration for the output canvas
     */
    outputCanvasOptions?: WebXRManagedOutputCanvasOptions;
    /**
     * optional UI options. This can be used among other to change session mode and reference space type
     */
    uiOptions?: Partial<WebXREnterExitUIOptions>;
    /**
     * When loading teleportation and pointer select, use stable versions instead of latest.
     */
    useStablePlugins?: boolean;
    /**
     * An optional rendering group id that will be set globally for teleportation, pointer selection and default controller meshes
     */
    renderingGroupId?: number;
    /**
     * A list of optional features to init the session with
     * If set to true, all features we support will be added
     */
    optionalFeatures?: boolean | string[];
}
/**
 * Default experience for webxr
 */
declare class WebXRDefaultExperience {
    /**
     * Base experience
     */
    baseExperience: WebXRExperienceHelper;
    /**
     * Enables ui for entering/exiting xr
     */
    enterExitUI: WebXREnterExitUI;
    /**
     * Input experience extension
     */
    input: WebXRInput;
    /**
     * Enables laser pointer and selection
     */
    pointerSelection: WebXRControllerPointerSelection;
    /**
     * Default target xr should render to
     */
    renderTarget: WebXRRenderTarget;
    /**
     * Enables teleportation
     */
    teleportation: WebXRMotionControllerTeleportation;
    /**
     * Enables near interaction for hands/controllers
     */
    nearInteraction: WebXRNearInteraction;
    private constructor();
    /**
     * Creates the default xr experience
     * @param scene scene
     * @param options options for basic configuration
     * @returns resulting WebXRDefaultExperience
     */
    static CreateAsync(scene: Scene, options?: WebXRDefaultExperienceOptions): Promise<WebXRDefaultExperience>;
    /**
     * Disposes of the experience helper
     */
    dispose(): void;
}

/**
 * Options to modify the vr teleportation behavior.
 */
interface VRTeleportationOptions {
    /**
     * The name of the mesh which should be used as the teleportation floor. (default: null)
     */
    floorMeshName?: string;
    /**
     * A list of meshes to be used as the teleportation floor. (default: empty)
     */
    floorMeshes?: Mesh[];
    /**
     * The teleportation mode. (default: TELEPORTATIONMODE_CONSTANTTIME)
     */
    teleportationMode?: number;
    /**
     * The duration of the animation in ms, apply when animationMode is TELEPORTATIONMODE_CONSTANTTIME. (default 122ms)
     */
    teleportationTime?: number;
    /**
     * The speed of the animation in distance/sec, apply when animationMode is TELEPORTATIONMODE_CONSTANTSPEED. (default 20 units / sec)
     */
    teleportationSpeed?: number;
    /**
     * The easing function used in the animation or null for Linear. (default CircleEase)
     */
    easingFunction?: EasingFunction;
}
/**
 * Options to modify the vr experience helper's behavior.
 */
interface VRExperienceHelperOptions {
    /**
     * Create a DeviceOrientationCamera to be used as your out of vr camera. (default: true)
     */
    createDeviceOrientationCamera?: boolean;
    /**
     * Create a VRDeviceOrientationFreeCamera to be used for VR when no external HMD is found. (default: true)
     */
    createFallbackVRDeviceOrientationFreeCamera?: boolean;
    /**
     * Uses the main button on the controller to toggle the laser casted. (default: true)
     */
    laserToggle?: boolean;
    /**
     * A list of meshes to be used as the teleportation floor. If specified, teleportation will be enabled (default: undefined)
     */
    floorMeshes?: Mesh[];
    /**
     * Distortion metrics for the fallback vrDeviceOrientationCamera (default: VRCameraMetrics.Default)
     */
    vrDeviceOrientationCameraMetrics?: VRCameraMetrics;
    /**
     * Defines if WebXR should be used (if available)
     */
    useXR?: boolean;
}
/**
 * Event containing information after VR has been entered
 */
declare class OnAfterEnteringVRObservableEvent {
    /**
     * If entering vr was successful
     */
    success: boolean;
}
/**
 * Helps to quickly add VR support to an existing scene.
 * See https://doc.babylonjs.com/features/featuresDeepDive/cameras/webVRHelper
 * @deprecated Use WebXR instead!
 */
declare class VRExperienceHelper {
    /** [Empty object] Options to modify the vr experience helper's behavior. */
    webVROptions: VRExperienceHelperOptions;
    private _scene;
    private _position;
    private _btnVR;
    private _btnVRDisplayed;
    private _hasEnteredVR;
    private _fullscreenVRpresenting;
    private _inputElement;
    private _vrDeviceOrientationCamera;
    private _deviceOrientationCamera;
    private _existingCamera;
    private _onKeyDown;
    private _onVrDisplayPresentChangeBind;
    /**
     * Gets or sets a boolean indicating that gaze can be enabled even if pointer lock is not engage (useful on iOS where fullscreen mode and pointer lock are not supported)
     */
    enableGazeEvenWhenNoPointerLock: boolean;
    /**
     * Gets or sets a boolean indicating that the VREXperienceHelper will exit VR if double tap is detected
     */
    exitVROnDoubleTap: boolean;
    /**
     * Observable raised right before entering VR.
     */
    onEnteringVRObservable: Observable<VRExperienceHelper>;
    /**
     * Observable raised when entering VR has completed.
     */
    onAfterEnteringVRObservable: Observable<OnAfterEnteringVRObservableEvent>;
    /**
     * Observable raised when exiting VR.
     */
    onExitingVRObservable: Observable<VRExperienceHelper>;
    /** Return this.onEnteringVRObservable
     * Note: This one is for backward compatibility. Please use onEnteringVRObservable directly
     */
    get onEnteringVR(): Observable<VRExperienceHelper>;
    /** Return this.onExitingVRObservable
     * Note: This one is for backward compatibility. Please use onExitingVRObservable directly
     */
    get onExitingVR(): Observable<VRExperienceHelper>;
    private _useCustomVRButton;
    private _teleportActive;
    private _floorMeshName;
    private _floorMeshesCollection;
    private _teleportationMode;
    private _teleportationTime;
    private _teleportationSpeed;
    private _teleportationEasing;
    private _rotationAllowed;
    private _teleportBackwardsVector;
    private _teleportationTarget;
    private _isDefaultTeleportationTarget;
    private _postProcessMove;
    private _teleportationFillColor;
    private _teleportationBorderColor;
    private _rotationAngle;
    private _haloCenter;
    private _cameraGazer;
    private _padSensibilityUp;
    private _padSensibilityDown;
    private _pickedLaserColor;
    private _pickedGazeColor;
    /**
     * Observable raised when a new mesh is selected based on meshSelectionPredicate
     */
    onNewMeshSelected: Observable<AbstractMesh>;
    /**
     * Observable raised when a new mesh is picked based on meshSelectionPredicate
     */
    onNewMeshPicked: Observable<PickingInfo>;
    private _circleEase;
    /**
     * Observable raised before camera teleportation
     */
    onBeforeCameraTeleport: Observable<Vector3>;
    /**
     *  Observable raised after camera teleportation
     */
    onAfterCameraTeleport: Observable<Vector3>;
    /**
     * Observable raised when current selected mesh gets unselected
     */
    onSelectedMeshUnselected: Observable<AbstractMesh>;
    private _raySelectionPredicate;
    /**
     * To be optionally changed by user to define custom ray selection
     */
    raySelectionPredicate: (mesh: AbstractMesh) => boolean;
    /**
     * To be optionally changed by user to define custom selection logic (after ray selection)
     */
    meshSelectionPredicate: (mesh: AbstractMesh) => boolean;
    /**
     * Set teleportation enabled. If set to false camera teleportation will be disabled but camera rotation will be kept.
     */
    teleportationEnabled: boolean;
    private _defaultHeight;
    private _teleportationInitialized;
    private _interactionsEnabled;
    private _displayGaze;
    private _displayLaserPointer;
    /**
     * The mesh used to display where the user is going to teleport.
     */
    get teleportationTarget(): Mesh;
    /**
     * Sets the mesh to be used to display where the user is going to teleport.
     */
    set teleportationTarget(value: Mesh);
    /**
     * The mesh used to display where the user is selecting, this mesh will be cloned and set as the gazeTracker for the left and right controller
     * when set bakeCurrentTransformIntoVertices will be called on the mesh.
     * See https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/center_origin/bakingTransforms
     */
    get gazeTrackerMesh(): Mesh;
    set gazeTrackerMesh(value: Mesh);
    /**
     * If the gaze trackers scale should be updated to be constant size when pointing at near/far meshes
     */
    updateGazeTrackerScale: boolean;
    /**
     * If the gaze trackers color should be updated when selecting meshes
     */
    updateGazeTrackerColor: boolean;
    /**
     * If the controller laser color should be updated when selecting meshes
     */
    updateControllerLaserColor: boolean;
    /**
     * If the ray of the gaze should be displayed.
     */
    get displayGaze(): boolean;
    /**
     * Sets if the ray of the gaze should be displayed.
     */
    set displayGaze(value: boolean);
    /**
     * If the ray of the LaserPointer should be displayed.
     */
    get displayLaserPointer(): boolean;
    /**
     * Sets if the ray of the LaserPointer should be displayed.
     */
    set displayLaserPointer(value: boolean);
    /**
     * The deviceOrientationCamera used as the camera when not in VR.
     */
    get deviceOrientationCamera(): Nullable<DeviceOrientationCamera>;
    /**
     * Based on the current WebVR support, returns the current VR camera used.
     */
    get currentVRCamera(): Nullable<Camera>;
    /**
     * The deviceOrientationCamera that is used as a fallback when vr device is not connected.
     */
    get vrDeviceOrientationCamera(): Nullable<VRDeviceOrientationFreeCamera>;
    /**
     * The html button that is used to trigger entering into VR.
     */
    get vrButton(): Nullable<HTMLButtonElement>;
    private get _teleportationRequestInitiated();
    /**
     * Defines whether or not Pointer lock should be requested when switching to
     * full screen.
     */
    requestPointerLockOnFullScreen: boolean;
    /**
     * If asking to force XR, this will be populated with the default xr experience
     */
    xr: WebXRDefaultExperience;
    /**
     * Was the XR test done already. If this is true AND this.xr exists, xr is initialized.
     * If this is true and no this.xr, xr exists but is not supported, using WebVR.
     */
    xrTestDone: boolean;
    /**
     * Instantiates a VRExperienceHelper.
     * Helps to quickly add VR support to an existing scene.
     * @param scene The scene the VRExperienceHelper belongs to.
     * @param webVROptions Options to modify the vr experience helper's behavior.
     */
    constructor(scene: Scene, 
    /** [Empty object] Options to modify the vr experience helper's behavior. */
    webVROptions?: VRExperienceHelperOptions);
    private _completeVRInit;
    private _onResize;
    private _onFullscreenChange;
    /**
     * Gets a value indicating if we are currently in VR mode.
     */
    get isInVRMode(): boolean;
    private _moveButtonToBottomRight;
    private _displayVRButton;
    private _updateButtonVisibility;
    private _cachedAngularSensibility;
    /**
     * Attempt to enter VR. If a headset is connected and ready, will request present on that.
     * Otherwise, will use the fullscreen API.
     */
    enterVR(): void;
    /**
     * Attempt to exit VR, or fullscreen.
     */
    exitVR(): void;
    /**
     * The position of the vr experience helper.
     */
    get position(): Vector3;
    /**
     * Sets the position of the vr experience helper.
     */
    set position(value: Vector3);
    /**
     * Enables controllers and user interactions such as selecting and object or clicking on an object.
     */
    enableInteractions(): void;
    private _beforeRender;
    private _isTeleportationFloor;
    /**
     * Adds a floor mesh to be used for teleportation.
     * @param floorMesh the mesh to be used for teleportation.
     */
    addFloorMesh(floorMesh: Mesh): void;
    /**
     * Removes a floor mesh from being used for teleportation.
     * @param floorMesh the mesh to be removed.
     */
    removeFloorMesh(floorMesh: Mesh): void;
    /**
     * Enables interactions and teleportation using the VR controllers and gaze.
     * @param vrTeleportationOptions options to modify teleportation behavior.
     */
    enableTeleportation(vrTeleportationOptions?: VRTeleportationOptions): void;
    private _onNewGamepadConnected;
    private _checkTeleportWithRay;
    private _checkRotate;
    private _checkTeleportBackwards;
    private _createTeleportationCircles;
    private _hideTeleportationTarget;
    private _rotateCamera;
    private _workingVector;
    private _workingQuaternion;
    private _workingMatrix;
    /**
     * Time Constant Teleportation Mode
     */
    static readonly TELEPORTATIONMODE_CONSTANTTIME = 0;
    /**
     * Speed Constant Teleportation Mode
     */
    static readonly TELEPORTATIONMODE_CONSTANTSPEED = 1;
    /**
     * Teleports the users feet to the desired location
     * @param location The location where the user's feet should be placed
     */
    teleportCamera(location: Vector3): void;
    /**
     * Permanently set new colors for the laser pointer
     * @param color the new laser color
     * @param pickedColor the new laser color when picked mesh detected
     */
    setLaserColor(color: Color3, pickedColor?: Color3): void;
    /**
     * Set lighting enabled / disabled on the laser pointer of both controllers
     * @param _enabled should the lighting be enabled on the laser pointer
     */
    setLaserLightingState(_enabled?: boolean): void;
    /**
     * Permanently set new colors for the gaze pointer
     * @param color the new gaze color
     * @param pickedColor the new gaze color when picked mesh detected
     */
    setGazeColor(color: Color3, pickedColor?: Color3): void;
    /**
     * Sets the color of the laser ray from the vr controllers.
     * @param _color new color for the ray.
     */
    changeLaserColor(_color: Color3): void;
    /**
     * Sets the color of the ray from the vr headsets gaze.
     * @param color new color for the ray.
     */
    changeGazeColor(color: Color3): void;
    /**
     * Exits VR and disposes of the vr experience helper
     */
    dispose(): void;
    /**
     * Gets the name of the VRExperienceHelper class
     * @returns "VRExperienceHelper"
     */
    getClassName(): string;
}

/** @internal */
interface ICollisionCoordinator {
    createCollider(): Collider;
    getNewPosition(position: Vector3, displacement: Vector3, collider: Collider, maximumRetry: number, excludedMesh: Nullable<AbstractMesh>, onNewPosition: (collisionIndex: number, newPosition: Vector3, collidedMesh: Nullable<AbstractMesh>) => void, collisionIndex: number, slideOnCollide?: boolean): Vector3;
    init(scene: Scene): void;
}

/** @internal */
interface IComputeContext {
    clear(): void;
}

/**
 * Type used to locate a resource in a compute shader.
 * TODO: remove this when browsers support reflection for wgsl shaders
 */
type ComputeBindingLocation = {
    group: number;
    binding: number;
};
/**
 * Type used to lookup a resource and retrieve its binding location
 * TODO: remove this when browsers support reflection for wgsl shaders
 */
type ComputeBindingMapping = {
    [key: string]: ComputeBindingLocation;
};
/**
 * Types of messages that can be generated during compilation
 */
type ComputeCompilationMessageType = "error" | "warning" | "info";
/**
 * Messages generated during compilation
 */
interface ComputeCompilationMessages {
    /**
     * Number of errors generated during compilation
     */
    numErrors: number;
    /**
     * List of messages generated during compilation
     */
    messages: {
        type: ComputeCompilationMessageType;
        text: string;
        line?: number;
        column?: number;
        length?: number;
        offset?: number;
    }[];
}
/** @internal */
declare const enum ComputeBindingType {
    Texture = 0,
    StorageTexture = 1,
    UniformBuffer = 2,
    StorageBuffer = 3,
    TextureWithoutSampler = 4,
    Sampler = 5,
    ExternalTexture = 6,
    DataBuffer = 7,
    InternalTexture = 8
}
/** @internal */
type ComputeBindingList = {
    [key: string]: {
        type: ComputeBindingType;
        object: any;
        indexInGroupEntries?: number;
    };
};
declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Creates a new compute effect
         * @param baseName Name of the effect
         * @param options Options used to create the effect
         * @returns The new compute effect
         */
        createComputeEffect(baseName: string | (IComputeShaderPath & {
            /**
             * @internal
             */
            computeToken?: string;
        }), options: IComputeEffectCreationOptions): ComputeEffect;
        /**
         * Creates a new compute pipeline context
         * @returns the new pipeline
         */
        createComputePipelineContext(): IComputePipelineContext;
        /**
         * Creates a new compute context
         * @returns the new context
         */
        createComputeContext(): IComputeContext | undefined;
        /**
         * Dispatches a compute shader
         * @param effect The compute effect
         * @param context The compute context
         * @param bindings The list of resources to bind to the shader
         * @param x The number of workgroups to execute on the X dimension
         * @param y The number of workgroups to execute on the Y dimension
         * @param z The number of workgroups to execute on the Z dimension
         * @param bindingsMapping list of bindings mapping (key is property name, value is binding location)
         * @param gpuPerfCounter GPU time computed for the compute shader will be assigned to this object
         */
        computeDispatch(effect: ComputeEffect, context: IComputeContext, bindings: ComputeBindingList, x: number, y?: number, z?: number, bindingsMapping?: ComputeBindingMapping, gpuPerfCounter?: WebGPUPerfCounter): void;
        /**
         * Dispatches a compute shader
         * @param effect The compute effect
         * @param context The compute context
         * @param bindings The list of resources to bind to the shader
         * @param buffer The buffer containing the dispatch parameters
         * @param offset The offset in the buffer where the dispatch parameters start
         * @param bindingsMapping list of bindings mapping (key is property name, value is binding location)
         * @param gpuPerfCounter GPU time computed for the compute shader will be assigned to this object
         */
        computeDispatchIndirect(effect: ComputeEffect, context: IComputeContext, bindings: ComputeBindingList, buffer: DataBuffer, offset?: number, bindingsMapping?: ComputeBindingMapping, gpuPerfCounter?: WebGPUPerfCounter): void;
        /**
         * Gets a boolean indicating if all created compute effects are ready
         * @returns true if all effects are ready
         */
        areAllComputeEffectsReady(): boolean;
        /**
         * Forces the engine to release all cached compute effects. This means that next effect compilation will have to be done completely even if a similar effect was already compiled
         */
        releaseComputeEffects(): void;
        /** @internal */
        _prepareComputePipelineContext(pipelineContext: IComputePipelineContext, computeSourceCode: string, rawComputeSourceCode: string, defines: Nullable<string>, entryPoint: string): void;
        /** @internal */
        _rebuildComputeEffects(): void;
        /** @internal */
        _executeWhenComputeStateIsCompiled(pipelineContext: IComputePipelineContext, action: (messages: Nullable<ComputeCompilationMessages>) => void): void;
        /** @internal */
        _releaseComputeEffect(effect: ComputeEffect): void;
        /** @internal */
        _deleteComputePipelineContext(pipelineContext: IComputePipelineContext): void;
    }
}

/**
 * Contains an array of blocks representing the octree
 */
interface IOctreeContainer<T> {
    /**
     * Blocks within the octree
     */
    blocks: Array<OctreeBlock<T>>;
}
/**
 * Class used to store a cell in an octree
 * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimizeOctrees
 */
declare class OctreeBlock<T> {
    /**
     * Gets the content of the current block
     */
    entries: T[];
    /**
     * Gets the list of block children
     */
    blocks: Array<OctreeBlock<T>>;
    private _depth;
    private _maxDepth;
    private _capacity;
    private _minPoint;
    private _maxPoint;
    private _boundingVectors;
    private _creationFunc;
    /**
     * Creates a new block
     * @param minPoint defines the minimum vector (in world space) of the block's bounding box
     * @param maxPoint defines the maximum vector (in world space) of the block's bounding box
     * @param capacity defines the maximum capacity of this block (if capacity is reached the block will be split into sub blocks)
     * @param depth defines the current depth of this block in the octree
     * @param maxDepth defines the maximal depth allowed (beyond this value, the capacity is ignored)
     * @param creationFunc defines a callback to call when an element is added to the block
     */
    constructor(minPoint: Vector3, maxPoint: Vector3, capacity: number, depth: number, maxDepth: number, creationFunc: (entry: T, block: OctreeBlock<T>) => void);
    /**
     * Gets the maximum capacity of this block (if capacity is reached the block will be split into sub blocks)
     */
    get capacity(): number;
    /**
     * Gets the minimum vector (in world space) of the block's bounding box
     */
    get minPoint(): Vector3;
    /**
     * Gets the maximum vector (in world space) of the block's bounding box
     */
    get maxPoint(): Vector3;
    /**
     * Add a new element to this block
     * @param entry defines the element to add
     */
    addEntry(entry: T): void;
    /**
     * Remove an element from this block
     * @param entry defines the element to remove
     */
    removeEntry(entry: T): void;
    /**
     * Add an array of elements to this block
     * @param entries defines the array of elements to add
     */
    addEntries(entries: T[]): void;
    /**
     * Test if the current block intersects the frustum planes and if yes, then add its content to the selection array
     * @param frustumPlanes defines the frustum planes to test
     * @param selection defines the array to store current content if selection is positive
     * @param allowDuplicate defines if the selection array can contains duplicated entries
     */
    select(frustumPlanes: Plane[], selection: SmartArrayNoDuplicate<T>, allowDuplicate?: boolean): void;
    /**
     * Test if the current block intersect with the given bounding sphere and if yes, then add its content to the selection array
     * @param sphereCenter defines the bounding sphere center
     * @param sphereRadius defines the bounding sphere radius
     * @param selection defines the array to store current content if selection is positive
     * @param allowDuplicate defines if the selection array can contains duplicated entries
     */
    intersects(sphereCenter: Vector3, sphereRadius: number, selection: SmartArrayNoDuplicate<T>, allowDuplicate?: boolean): void;
    /**
     * Test if the current block intersect with the given ray and if yes, then add its content to the selection array
     * @param ray defines the ray to test with
     * @param selection defines the array to store current content if selection is positive
     */
    intersectsRay(ray: Ray, selection: SmartArrayNoDuplicate<T>): void;
    /**
     * Subdivide the content into child blocks (this block will then be empty)
     */
    createInnerBlocks(): void;
    /**
     * @internal
     */
    static _CreateBlocks<T>(worldMin: Vector3, worldMax: Vector3, entries: T[], maxBlockCapacity: number, currentDepth: number, maxDepth: number, target: IOctreeContainer<T>, creationFunc: (entry: T, block: OctreeBlock<T>) => void): void;
}

/**
 * Octrees are a really powerful data structure that can quickly select entities based on space coordinates.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimizeOctrees
 */
declare class Octree<T> {
    /** [2] Defines the maximum depth (sub-levels) for your octree. Default value is 2, which means 8 8 8 = 512 blocks :) (This parameter takes precedence over capacity.) */
    maxDepth: number;
    /**
     * Blocks within the octree containing objects
     */
    blocks: Array<OctreeBlock<T>>;
    /**
     * Content stored in the octree
     */
    dynamicContent: T[];
    private _maxBlockCapacity;
    private _selectionContent;
    private _creationFunc;
    /**
     * Creates a octree
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimizeOctrees
     * @param creationFunc function to be used to instantiate the octree
     * @param maxBlockCapacity defines the maximum number of meshes you want on your octree's leaves (default: 64)
     * @param maxDepth defines the maximum depth (sub-levels) for your octree. Default value is 2, which means 8 8 8 = 512 blocks :) (This parameter takes precedence over capacity.)
     */
    constructor(creationFunc: (entry: T, block: OctreeBlock<T>) => void, maxBlockCapacity?: number, 
    /** [2] Defines the maximum depth (sub-levels) for your octree. Default value is 2, which means 8 8 8 = 512 blocks :) (This parameter takes precedence over capacity.) */
    maxDepth?: number);
    /**
     * Updates the octree by adding blocks for the passed in meshes within the min and max world parameters
     * @param worldMin worldMin for the octree blocks var blockSize = new Vector3((worldMax.x - worldMin.x) / 2, (worldMax.y - worldMin.y) / 2, (worldMax.z - worldMin.z) / 2);
     * @param worldMax worldMax for the octree blocks var blockSize = new Vector3((worldMax.x - worldMin.x) / 2, (worldMax.y - worldMin.y) / 2, (worldMax.z - worldMin.z) / 2);
     * @param entries meshes to be added to the octree blocks
     */
    update(worldMin: Vector3, worldMax: Vector3, entries: T[]): void;
    /**
     * Adds a mesh to the octree
     * @param entry Mesh to add to the octree
     */
    addMesh(entry: T): void;
    /**
     * Remove an element from the octree
     * @param entry defines the element to remove
     */
    removeMesh(entry: T): void;
    /**
     * Selects an array of meshes within the frustum
     * @param frustumPlanes The frustum planes to use which will select all meshes within it
     * @param allowDuplicate If duplicate objects are allowed in the resulting object array
     * @returns array of meshes within the frustum
     */
    select(frustumPlanes: Plane[], allowDuplicate?: boolean): SmartArray<T>;
    /**
     * Test if the octree intersect with the given bounding sphere and if yes, then add its content to the selection array
     * @param sphereCenter defines the bounding sphere center
     * @param sphereRadius defines the bounding sphere radius
     * @param allowDuplicate defines if the selection array can contains duplicated entries
     * @returns an array of objects that intersect the sphere
     */
    intersects(sphereCenter: Vector3, sphereRadius: number, allowDuplicate?: boolean): SmartArray<T>;
    /**
     * Test if the octree intersect with the given ray and if yes, then add its content to resulting array
     * @param ray defines the ray to test with
     * @returns array of intersected objects
     */
    intersectsRay(ray: Ray): SmartArray<T>;
    /**
     * Adds a mesh into the octree block if it intersects the block
     * @param entry defines the mesh to try to add to the block
     * @param block defines the block where the mesh should be added
     */
    static CreationFuncForMeshes: (entry: AbstractMesh, block: OctreeBlock<AbstractMesh>) => void;
    /**
     * Adds a submesh into the octree block if it intersects the block
     * @param entry defines the submesh to try to add to the block
     * @param block defines the block where the submesh should be added
     */
    static CreationFuncForSubMeshes: (entry: SubMesh, block: OctreeBlock<SubMesh>) => void;
}

declare module "../../scene" {
    interface Scene {
        /**
         * @internal
         * Backing Filed
         */
        _selectionOctree: Octree<AbstractMesh>;
        /**
         * Gets the octree used to boost mesh selection (picking)
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimizeOctrees
         */
        selectionOctree: Octree<AbstractMesh>;
        /**
         * Creates or updates the octree used to boost selection (picking)
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimizeOctrees
         * @param maxCapacity defines the maximum capacity per leaf
         * @param maxDepth defines the maximum depth of the octree
         * @returns an octree of AbstractMesh
         */
        createOrUpdateSelectionOctree(maxCapacity?: number, maxDepth?: number): Octree<AbstractMesh>;
    }
}
declare module "../../Meshes/abstractMesh" {
    interface AbstractMesh {
        /**
         * @internal
         * Backing Field
         */
        _submeshesOctree: Octree<SubMesh>;
        /**
         * This function will create an octree to help to select the right submeshes for rendering, picking and collision computations.
         * Please note that you must have a decent number of submeshes to get performance improvements when using an octree
         * @param maxCapacity defines the maximum size of each block (64 by default)
         * @param maxDepth defines the maximum depth to use (no more than 2 levels by default)
         * @returns the new octree
         * @see https://www.babylonjs-playground.com/#NA4OQ#12
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimizeOctrees
         */
        createOrUpdateSubmeshesOctree(maxCapacity?: number, maxDepth?: number): Octree<SubMesh>;
    }
}

/**
 * Interface used to define scene explorer extensibility option
 */
interface IExplorerExtensibilityOption {
    /**
     * Define the option label
     */
    label: string;
    /**
     * Defines the action to execute on click
     */
    action: (entity: any) => void;
    /**
     * Keep popup open after click
     */
    keepOpenAfterClick?: boolean;
}
/**
 * Defines a group of actions associated with a predicate to use when extending the Inspector scene explorer
 */
interface IExplorerExtensibilityGroup {
    /**
     * Defines a predicate to test if a given type mut be extended
     */
    predicate: (entity: any) => boolean;
    /**
     * Gets the list of options added to a type
     */
    entries: IExplorerExtensibilityOption[];
}
/**
 * Defines a new node that will be displayed as top level node in the explorer
 */
interface IExplorerAdditionalChild {
    /**
     * Gets the name of the additional node
     */
    name: string;
    /**
     * Function used to return the class name of the child node
     */
    getClassName(): string;
    /**
     * List of inspectable custom properties (used by the Inspector)
     * @see https://doc.babylonjs.com/toolsAndResources/inspector#extensibility
     */
    inspectableCustomProperties: IInspectable[];
}
/**
 * Defines a new node that will be displayed as top level node in the explorer
 */
interface IExplorerAdditionalNode {
    /**
     * Gets the name of the additional node
     */
    name: string;
    /**
     * Function used to return the list of child entries
     */
    getContent(): IExplorerAdditionalChild[];
}
type IInspectorContextMenuType = "pipeline" | "node" | "materials" | "spriteManagers" | "particleSystems" | "frameGraphs";
/**
 * Context menu item
 */
interface IInspectorContextMenuItem {
    /**
     * Display label - menu item
     */
    label: string;
    /**
     * Callback function that will be called when the menu item is selected
     * @param entity the entity that is currently selected in the scene explorer
     */
    action: (entity?: unknown) => void;
}
/**
 * Interface used to define the options to use to create the Inspector
 */
interface IInspectorOptions {
    /**
     * Display in overlay mode (default: false)
     */
    overlay?: boolean;
    /**
     * HTML element to use as root (the parent of the rendering canvas will be used as default value)
     */
    globalRoot?: HTMLElement;
    /**
     * Display the Scene explorer
     */
    showExplorer?: boolean;
    /**
     * Display the property inspector
     */
    showInspector?: boolean;
    /**
     * Display in embed mode (both panes on the right)
     */
    embedMode?: boolean;
    /**
     * let the Inspector handles resize of the canvas when panes are resized (default to true)
     */
    handleResize?: boolean;
    /**
     * Allow the panes to popup (default: true)
     */
    enablePopup?: boolean;
    /**
     * Allow the panes to be closed by users (default: true)
     */
    enableClose?: boolean;
    /**
     * Optional list of extensibility entries
     */
    explorerExtensibility?: IExplorerExtensibilityGroup[];
    /**
     * Optional list of additional top level nodes
     */
    additionalNodes?: IExplorerAdditionalNode[];
    /**
     * Optional URL to get the inspector script from (by default it uses the babylonjs CDN).
     */
    inspectorURL?: string;
    /**
     * Optional initial tab (default to DebugLayerTab.Properties)
     */
    initialTab?: DebugLayerTab;
    /**
     * Optional camera to use to render the gizmos from the inspector (default to the scene.activeCamera or the latest from scene.activeCameras)
     */
    gizmoCamera?: Camera;
    /**
     * Context menu for inspector tools such as "Post Process", "Nodes", "Materials", etc.
     */
    contextMenu?: Partial<Record<IInspectorContextMenuType, IInspectorContextMenuItem[]>>;
    /**
     * List of context menu items that should be completely overridden by custom items from the contextMenu property.
     */
    contextMenuOverride?: IInspectorContextMenuType[];
    /**
     * Should the default font loading be skipped
     */
    skipDefaultFontLoading?: boolean;
}
declare module "../scene" {
    interface Scene {
        /**
         * @internal
         * Backing field
         */
        _debugLayer?: DebugLayer;
        /**
         * Gets the debug layer (aka Inspector) associated with the scene
         * @see https://doc.babylonjs.com/toolsAndResources/inspector
         */
        debugLayer: DebugLayer;
    }
}
/**
 * Enum of inspector action tab
 */
declare const enum DebugLayerTab {
    /**
     * Properties tag (default)
     */
    Properties = 0,
    /**
     * Debug tab
     */
    Debug = 1,
    /**
     * Statistics tab
     */
    Statistics = 2,
    /**
     * Tools tab
     */
    Tools = 3,
    /**
     * Settings tab
     */
    Settings = 4
}
/**
 * The debug layer (aka Inspector) is the go to tool in order to better understand
 * what is happening in your scene
 * @see https://doc.babylonjs.com/toolsAndResources/inspector
 */
declare class DebugLayer {
    /**
     * Define the url to get the inspector script from.
     * By default it uses the babylonjs CDN.
     * @ignoreNaming
     */
    static InspectorURL: string;
    /**
     * The default configuration of the inspector
     */
    static Config: IInspectorOptions;
    private _scene;
    protected BJSINSPECTOR: any;
    private _onPropertyChangedObservable?;
    /**
     * Observable triggered when a property is changed through the inspector.
     */
    get onPropertyChangedObservable(): any;
    private _onSelectionChangedObservable?;
    /**
     * Observable triggered when the selection is changed through the inspector.
     */
    get onSelectionChangedObservable(): any;
    /**
     * Instantiates a new debug layer.
     * The debug layer (aka Inspector) is the go to tool in order to better understand
     * what is happening in your scene
     * @see https://doc.babylonjs.com/toolsAndResources/inspector
     * @param scene Defines the scene to inspect
     */
    constructor(scene?: Scene);
    /**
     * Creates the inspector window.
     * @param config
     */
    private _createInspector;
    /**
     * Select a specific entity in the scene explorer and highlight a specific block in that entity property grid
     * @param entity defines the entity to select
     * @param lineContainerTitles defines the specific blocks to highlight (could be a string or an array of strings)
     */
    select(entity: any, lineContainerTitles?: string | string[]): void;
    /**
     * Get the inspector from bundle or global
     * @returns the inspector instance if found otherwise, null
     */
    private _getGlobalInspector;
    /**
     * Get if the inspector is visible or not.
     * @returns true if visible otherwise, false
     */
    isVisible(): boolean;
    /**
     * Hide the inspector and close its window.
     */
    hide(): void;
    /**
     * Get the number of opened panes in the inspector
     */
    get openedPanes(): any;
    /**
     * Update the scene in the inspector
     */
    setAsActiveScene(): void;
    popupSceneExplorer(): void;
    popupInspector(): void;
    popupEmbed(): void;
    /**
     * Launch the debugLayer.
     * @param config Define the configuration of the inspector
     * @returns a promise fulfilled when the debug layer is visible
     */
    show(config?: IInspectorOptions): Promise<DebugLayer>;
}

/**
 * The HemisphericLight simulates the ambient environment light,
 * so the passed direction is the light reflection direction, not the incoming direction.
 */
declare class HemisphericLight extends Light {
    /**
     * The groundColor is the light in the opposite direction to the one specified during creation.
     * You can think of the diffuse and specular light as coming from the centre of the object in the given direction and the groundColor light in the opposite direction.
     */
    groundColor: Color3;
    /**
     * The light reflection direction, not the incoming direction.
     */
    direction: Vector3;
    /**
     * Creates a HemisphericLight object in the scene according to the passed direction (Vector3).
     * The HemisphericLight simulates the ambient environment light, so the passed direction is the light reflection direction, not the incoming direction.
     * The HemisphericLight can't cast shadows.
     * Documentation : https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
     * @param name The friendly name of the light
     * @param direction The direction of the light reflection
     * @param scene The scene the light belongs to
     * @param dontAddToScene True to not add the light to the scene
     */
    constructor(name: string, direction: Vector3, scene?: Scene, dontAddToScene?: boolean);
    protected _buildUniformLayout(): void;
    /**
     * Returns the string "HemisphericLight".
     * @returns The class name
     */
    getClassName(): string;
    /**
     * Sets the HemisphericLight direction towards the passed target (Vector3).
     * Returns the updated direction.
     * @param target The target the direction should point to
     * @returns The computed direction
     */
    setDirectionToTarget(target: Vector3): Vector3;
    /**
     * Returns the shadow generator associated to the light.
     * @returns Always null for hemispheric lights because it does not support shadows.
     */
    getShadowGenerator(): Nullable<IShadowGenerator>;
    /**
     * Sets the passed Effect object with the HemisphericLight normalized direction and color and the passed name (string).
     * @param _effect The effect to update
     * @param lightIndex The index of the light in the effect to update
     * @returns The hemispheric light
     */
    transferToEffect(_effect: Effect, lightIndex: string): HemisphericLight;
    transferToNodeMaterialEffect(effect: Effect, lightDataUniformName: string): this;
    /**
     * Computes the world matrix of the node
     * @returns the world matrix
     */
    computeWorldMatrix(): Matrix;
    /**
     * Returns the integer 3.
     * @returns The light Type id as a constant defines in Light.LIGHTTYPEID_x
     */
    getTypeID(): number;
    /**
     * Prepares the list of defines specific to the light type.
     * @param defines the list of defines
     * @param lightIndex defines the index of the light for the effect
     */
    prepareLightSpecificDefines(defines: any, lightIndex: number): void;
}

/**
 * Renders a layer on top of an existing scene
 */
declare class UtilityLayerRenderer implements IDisposable {
    /** the original scene that will be rendered on top of */
    originalScene: Scene;
    readonly handleEvents: boolean;
    private _pointerCaptures;
    private _lastPointerEvents;
    /** @internal */
    static _DefaultUtilityLayer: Nullable<UtilityLayerRenderer>;
    /** @internal */
    static _DefaultKeepDepthUtilityLayer: Nullable<UtilityLayerRenderer>;
    private _sharedGizmoLight;
    private _renderCamera;
    /**
     * Gets the camera that is used to render the utility layer (when not set, this will be the last active camera)
     * @param getRigParentIfPossible if the current active camera is a rig camera, should its parent camera be returned
     * @returns the camera that is used when rendering the utility layer
     */
    getRenderCamera(getRigParentIfPossible?: boolean): Camera;
    /**
     * Sets the camera that should be used when rendering the utility layer (If set to null the last active camera will be used)
     * @param cam the camera that should be used when rendering the utility layer
     */
    setRenderCamera(cam: Nullable<Camera>): void;
    /**
     * @internal
     * Light which used by gizmos to get light shading
     */
    _getSharedGizmoLight(): HemisphericLight;
    /**
     * If the picking should be done on the utility layer prior to the actual scene (Default: true)
     */
    pickUtilitySceneFirst: boolean;
    /**
     * A shared utility layer that can be used to overlay objects into a scene (Depth map of the previous scene is cleared before drawing on top of it)
     */
    static get DefaultUtilityLayer(): UtilityLayerRenderer;
    /**
     * Creates an utility layer, and set it as a default utility layer
     * @param scene associated scene
     * @internal
     */
    static _CreateDefaultUtilityLayerFromScene(scene: Scene): UtilityLayerRenderer;
    /**
     * A shared utility layer that can be used to embed objects into a scene (Depth map of the previous scene is not cleared before drawing on top of it)
     */
    static get DefaultKeepDepthUtilityLayer(): UtilityLayerRenderer;
    /**
     * Creates an utility layer, and set it as a default utility layer (Depth map of the previous scene is not cleared before drawing on top of it)
     * @param scene associated scene
     * @internal
     */
    static _CreateDefaultKeepUtilityLayerFromScene(scene: Scene): UtilityLayerRenderer;
    /**
     * The scene that is rendered on top of the original scene
     */
    utilityLayerScene: Scene;
    /**
     *  If the utility layer should automatically be rendered on top of existing scene
     */
    shouldRender: boolean;
    /**
     * If set to true, only pointer down onPointerObservable events will be blocked when picking is occluded by original scene
     */
    onlyCheckPointerDownEvents: boolean;
    /**
     * If set to false, only pointerUp, pointerDown and pointerMove will be sent to the utilityLayerScene (false by default)
     */
    processAllEvents: boolean;
    /**
     * Set to false to disable picking
     */
    pickingEnabled: boolean;
    /**
     * Observable raised when the pointer moves from the utility layer scene to the main scene
     */
    onPointerOutObservable: Observable<number>;
    /** Gets or sets a predicate that will be used to indicate utility meshes present in the main scene */
    mainSceneTrackerPredicate: (mesh: Nullable<AbstractMesh>) => boolean;
    private _afterRenderObserver;
    private _sceneDisposeObserver;
    private _originalPointerObserver;
    /**
     * Instantiates a UtilityLayerRenderer
     * @param originalScene the original scene that will be rendered on top of
     * @param handleEvents boolean indicating if the utility layer should handle events
     * @param manualRender boolean indicating if the utility layer should render manually.
     */
    constructor(
    /** the original scene that will be rendered on top of */
    originalScene: Scene, handleEvents?: boolean, manualRender?: boolean);
    private _notifyObservers;
    /**
     * Renders the utility layers scene on top of the original scene
     */
    render(): void;
    /**
     * Disposes of the renderer
     */
    dispose(): void;
    private _updateCamera;
}

/**
 * Type to handle enforcement of inputs
 */
type DeviceInput<T extends DeviceType> = T extends DeviceType.Keyboard | DeviceType.Generic ? number : T extends DeviceType.Mouse | DeviceType.Touch ? Exclude<PointerInput, PointerInput.Move | PointerInput.MouseWheelX | PointerInput.MouseWheelY | PointerInput.MouseWheelZ> : T extends DeviceType.DualShock ? DualShockInput : T extends DeviceType.Xbox ? XboxInput : T extends DeviceType.Switch ? SwitchInput : T extends DeviceType.DualSense ? DualSenseInput : never;

/**
 * Interface for DeviceInputSystem implementations (JS and Native)
 */
interface IDeviceInputSystem extends IDisposable {
    /**
     * Checks for current device input value, given an id and input index. Throws exception if requested device not initialized.
     * @param deviceType Enum specifying device type
     * @param deviceSlot "Slot" or index that device is referenced in
     * @param inputIndex Id of input to be checked
     * @returns Current value of input
     */
    pollInput(deviceType: DeviceType, deviceSlot: number, inputIndex: number): number;
    /**
     * Check for a specific device in the DeviceInputSystem
     * @param deviceType Type of device to check for
     * @returns bool with status of device's existence
     */
    isDeviceAvailable(deviceType: DeviceType): boolean;
}

/**
 * Subset of DeviceInput that only handles pointers and keyboard
 */
type DeviceSourceEvent<T extends DeviceType> = T extends DeviceType.Keyboard ? IKeyboardEvent : T extends DeviceType.Mouse ? IWheelEvent | IPointerEvent : T extends DeviceType.Touch ? IPointerEvent : never;
/**
 * Class that handles all input for a specific device
 */
declare class DeviceSource<T extends DeviceType> {
    /** Type of device */
    readonly deviceType: T;
    /** [0] "Slot" or index that device is referenced in */
    readonly deviceSlot: number;
    /**
     * Observable to handle device input changes per device
     */
    readonly onInputChangedObservable: Observable<DeviceSourceEvent<T>>;
    private readonly _deviceInputSystem;
    /**
     * Default Constructor
     * @param deviceInputSystem - Reference to DeviceInputSystem
     * @param deviceType - Type of device
     * @param deviceSlot - "Slot" or index that device is referenced in
     */
    constructor(deviceInputSystem: IDeviceInputSystem, 
    /** Type of device */
    deviceType: T, 
    /** [0] "Slot" or index that device is referenced in */
    deviceSlot?: number);
    /**
     * Get input for specific input
     * @param inputIndex - index of specific input on device
     * @returns Input value from DeviceInputSystem
     */
    getInput(inputIndex: DeviceInput<T>): number;
}

type Distribute<T> = T extends DeviceType ? DeviceSource<T> : never;
type DeviceSourceType = Distribute<DeviceType>;
declare module "../Engines/abstractEngine" {
    interface AbstractEngine {
        /** @internal */
        _deviceSourceManager?: InternalDeviceSourceManager;
    }
}
/** @internal */
interface IObservableManager {
    onDeviceConnectedObservable: Observable<DeviceSourceType>;
    onDeviceDisconnectedObservable: Observable<DeviceSourceType>;
    _onInputChanged(deviceType: DeviceType, deviceSlot: number, eventData: IUIEvent): void;
    _addDevice(deviceSource: DeviceSource<DeviceType>): void;
    _removeDevice(deviceType: DeviceType, deviceSlot: number): void;
}
/** @internal */
declare class InternalDeviceSourceManager implements IDisposable {
    readonly _deviceInputSystem: IDeviceInputSystem;
    private readonly _devices;
    private readonly _registeredManagers;
    _refCount: number;
    constructor(engine: AbstractEngine);
    readonly registerManager: (manager: IObservableManager) => void;
    readonly unregisterManager: (manager: IObservableManager) => void;
    dispose(): void;
}

/**
 * Interface used to describe the capabilities of the engine relatively to the current browser
 */
interface EngineCapabilities {
    /** Maximum textures units per fragment shader */
    maxTexturesImageUnits: number;
    /** Maximum texture units per vertex shader */
    maxVertexTextureImageUnits: number;
    /** Maximum textures units in the entire pipeline */
    maxCombinedTexturesImageUnits: number;
    /** Maximum texture size */
    maxTextureSize: number;
    /** Maximum texture samples */
    maxSamples?: number;
    /** Maximum draw buffers */
    maxDrawBuffers?: number;
    /** Maximum cube texture size */
    maxCubemapTextureSize: number;
    /** Maximum render texture size */
    maxRenderTextureSize: number;
    /** Maximum number of vertex attributes */
    maxVertexAttribs: number;
    /** Maximum number of varyings */
    maxVaryingVectors: number;
    /** Maximum number of uniforms per vertex shader */
    maxVertexUniformVectors: number;
    /** Maximum number of uniforms per fragment shader */
    maxFragmentUniformVectors: number;
    /** The number of bits that can be accurately represented in shader floats */
    shaderFloatPrecision: number;
    /** Defines if standard derivatives (dx/dy) are supported */
    standardDerivatives: boolean;
    /** Defines if s3tc texture compression is supported */
    s3tc?: WEBGL_compressed_texture_s3tc;
    /** Defines if s3tc sRGB texture compression is supported */
    s3tc_srgb?: WEBGL_compressed_texture_s3tc_srgb;
    /** Defines if pvrtc texture compression is supported */
    pvrtc: any;
    /** Defines if etc1 texture compression is supported */
    etc1: any;
    /** Defines if etc2 texture compression is supported */
    etc2: any;
    /** Defines if astc texture compression is supported */
    astc: any;
    /** Defines if bptc texture compression is supported */
    bptc: any;
    /** Defines if float textures are supported */
    textureFloat: boolean;
    /** Defines if vertex array objects are supported */
    vertexArrayObject: boolean;
    /** Gets the webgl extension for anisotropic filtering (null if not supported) */
    textureAnisotropicFilterExtension?: EXT_texture_filter_anisotropic;
    /** Gets the maximum level of anisotropy supported */
    maxAnisotropy: number;
    /** Defines if instancing is supported */
    instancedArrays: boolean;
    /** Defines if 32 bits indices are supported */
    uintIndices: boolean;
    /** Defines if high precision shaders are supported */
    highPrecisionShaderSupported: boolean;
    /** Defines if depth reading in the fragment shader is supported */
    fragmentDepthSupported: boolean;
    /** Defines if float texture linear filtering is supported*/
    textureFloatLinearFiltering: boolean;
    /** Defines if rendering to float textures is supported */
    textureFloatRender: boolean;
    /** Defines if half float textures are supported*/
    textureHalfFloat: boolean;
    /** Defines if half float texture linear filtering is supported*/
    textureHalfFloatLinearFiltering: boolean;
    /** Defines if rendering to half float textures is supported */
    textureHalfFloatRender: boolean;
    /** Defines if textureLOD shader command is supported */
    textureLOD: boolean;
    /** Defines if texelFetch shader command is supported */
    texelFetch: boolean;
    /** Defines if draw buffers extension is supported */
    drawBuffersExtension: boolean;
    /** Defines if depth textures are supported */
    depthTextureExtension: boolean;
    /** Defines if float color buffer are supported */
    colorBufferFloat: boolean;
    /** Defines if float color blending is supported */
    blendFloat: boolean;
    /** Defines if half float color buffer are supported */
    colorBufferHalfFloat?: boolean;
    /** Gets disjoint timer query extension (null if not supported) */
    timerQuery?: EXT_disjoint_timer_query;
    /** Defines if timestamp can be used with timer query */
    canUseTimestampForTimerQuery: boolean;
    /** Defines if occlusion queries are supported by the engine */
    supportOcclusionQuery: boolean;
    /** Defines if multiview is supported (https://www.khronos.org/registry/webgl/extensions/WEBGL_multiview/) */
    multiview?: any;
    /** Defines if oculus multiview is supported (https://developer.oculus.com/documentation/oculus-browser/latest/concepts/browser-multiview/) */
    oculusMultiview?: any;
    /** Function used to let the system compiles shaders in background */
    parallelShaderCompile?: {
        COMPLETION_STATUS_KHR: number;
    };
    /** Max number of texture samples for MSAA */
    maxMSAASamples: number;
    /** Defines if the blend min max extension is supported */
    blendMinMax: boolean;
    /** In some iOS + WebGL1, gl_InstanceID (and gl_InstanceIDEXT) is undefined even if instancedArrays is true. So don't use gl_InstanceID in those cases */
    canUseGLInstanceID: boolean;
    /** Defines if gl_vertexID is available */
    canUseGLVertexID: boolean;
    /** Defines if compute shaders are supported by the engine */
    supportComputeShaders: boolean;
    /** Defines if sRGB texture formats are supported */
    supportSRGBBuffers: boolean;
    /** Defines if transform feedbacks are supported */
    supportTransformFeedbacks: boolean;
    /** Defines if texture max level are supported */
    textureMaxLevel: boolean;
    /** Defines the maximum layer count for a 2D Texture array. */
    texture2DArrayMaxLayerCount: number;
    /** Defines if the morph target texture is supported. */
    disableMorphTargetTexture: boolean;
    /** Defines if float textures like r32f, rg32f or rgba32f support being used as a resolve target */
    supportFloatTexturesResolve: boolean;
    /** Defines if RG11B10UFloat texture format is color renderable */
    rg11b10ufColorRenderable: boolean;
    /** Defines if EXT_texture_norm16 is available which enables the following texture formats: R16_EXT, RG16_EXT, RGB16_EXT, RGBA16_EXT, R16_SNORM_EXT, RG16_SNORM_EXT, RGB16_SNORM_EXT, RGBA16_SNORM_EXT */
    textureNorm16: boolean;
    /** Defines if blend parameters can be defined per target */
    blendParametersPerTarget: boolean;
    /** Defines if dual source blending is supported */
    dualSourceBlending: boolean;
}

/**
 * @internal
 **/
declare class _TimeToken {
    _startTimeQuery: Nullable<WebGLQuery>;
    _endTimeQuery: Nullable<WebGLQuery>;
    _timeElapsedQuery: Nullable<WebGLQuery>;
    _timeElapsedQueryEnded: boolean;
}

declare module "../Materials/effect" {
    /** internal */
    interface Effect {
        /** internal */
        _checkedNonFloatVertexBuffers?: boolean;
    }
}

declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /** @internal */
        _gpuFrameTime: Nullable<PerfCounter>;
        /**
         * Get the performance counter associated with the frame time computation
         * @returns the perf counter
         */
        getGPUFrameTimeCounter(): PerfCounter;
        /**
         * Enable or disable the GPU frame time capture
         * @param value True to enable, false to disable
         */
        captureGPUFrameTime(value: boolean): void;
    }
}

/**
 * Class used to define an additional view for the engine
 * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/multiCanvas
 */
declare class EngineView {
    /**
     * A randomly generated unique id
     */
    readonly id: string;
    /** Defines the canvas where to render the view */
    target: HTMLCanvasElement;
    /**
     * Defines an optional camera or array of cameras used to render the view (will use active camera / cameras else)
     * Support for array of cameras @since
     */
    camera?: Camera | Camera[];
    /** Indicates if the destination view canvas should be cleared before copying the parent canvas. Can help if the scene clear color has alpha < 1 */
    clearBeforeCopy?: boolean;
    /** Indicates if the view is enabled (true by default) */
    enabled: boolean;
    /** Defines a custom function to handle canvas size changes. (the canvas to render into is provided to the callback) */
    customResize?: (canvas: HTMLCanvasElement) => void;
}
declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /** @internal */
        _inputElement: Nullable<HTMLElement>;
        /**
         * Gets or sets the  HTML element to use for attaching events
         */
        inputElement: Nullable<HTMLElement>;
        /**
         * Observable to handle when a change to inputElement occurs
         * @internal
         */
        _onEngineViewChanged?: () => void;
        /**
         * Will be triggered before the view renders
         */
        readonly onBeforeViewRenderObservable: Observable<EngineView>;
        /**
         * Will be triggered after the view rendered
         */
        readonly onAfterViewRenderObservable: Observable<EngineView>;
        /**
         * Gets the current engine view
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/multiCanvas
         */
        activeView: Nullable<EngineView>;
        /** Gets or sets the list of views */
        views: EngineView[];
        /**
         * Register a new child canvas
         * @param canvas defines the canvas to register
         * @param camera defines an optional camera or array of cameras to use with this canvas (it will overwrite the scene.activeCamera / scene.activeCameras for this view). Support for array of cameras @since
         * @param clearBeforeCopy Indicates if the destination view canvas should be cleared before copying the parent canvas. Can help if the scene clear color has alpha \< 1
         * @returns the associated view
         */
        registerView(canvas: HTMLCanvasElement, camera?: Camera | Camera[], clearBeforeCopy?: boolean): EngineView;
        /**
         * Remove a registered child canvas
         * @param canvas defines the canvas to remove
         * @returns the current engine
         */
        unRegisterView(canvas: HTMLCanvasElement): AbstractEngine;
        /**
         * @internal
         */
        _renderViewStep(view: EngineView): boolean;
    }
}

/**
 * Note that users may not import this file, so each time we want to call one of them, we must check if it exists.
 * @internal
 */
declare module "../../Engines/abstractEngine" {
    interface AbstractEngine {
        /** @internal */
        _debugPushGroup(groupName: string): void;
        /** @internal */
        _debugPopGroup(): void;
        /** @internal */
        _debugInsertMarker(text: string): void;
    }
}

declare module "../../Engines/thinEngine" {
    interface ThinEngine {
        /**
         * @internal
         */
        _captureGPUFrameTime: boolean;
        /**
         * Starts a time query (used to measure time spent by the GPU on a specific frame)
         * Please note that only one query can be issued at a time
         * @returns a time token used to track the time span
         */
        startTimeQuery(): Nullable<_TimeToken>;
        /**
         * Ends a time query
         * @param token defines the token used to measure the time span
         * @returns the time spent (in ns)
         */
        endTimeQuery(token: _TimeToken): int;
        /** @internal */
        _currentNonTimestampToken: Nullable<_TimeToken>;
        /** @internal */
        _gpuFrameTimeToken: Nullable<_TimeToken>;
        /** @internal */
        _onBeginFrameObserver: Nullable<Observer<AbstractEngine>>;
        /** @internal */
        _onEndFrameObserver: Nullable<Observer<AbstractEngine>>;
        /** @internal */
        _createTimeQuery(): Nullable<WebGLQuery>;
        /** @internal */
        _deleteTimeQuery(query: WebGLQuery): void;
        /** @internal */
        _getGlAlgorithmType(algorithmType: number): number;
        /** @internal */
        _getTimeQueryResult(query: WebGLQuery): any;
        /** @internal */
        _getTimeQueryAvailability(query: WebGLQuery): any;
    }
}

declare module "../../Engines/engine" {
    interface Engine {
        /**
         * Creates a webGL transform feedback object
         * Please makes sure to check webGLVersion property to check if you are running webGL 2+
         * @returns the webGL transform feedback object
         */
        createTransformFeedback(): WebGLTransformFeedback;
        /**
         * Delete a webGL transform feedback object
         * @param value defines the webGL transform feedback object to delete
         */
        deleteTransformFeedback(value: WebGLTransformFeedback): void;
        /**
         * Bind a webGL transform feedback object to the webgl context
         * @param value defines the webGL transform feedback object to bind
         */
        bindTransformFeedback(value: Nullable<WebGLTransformFeedback>): void;
        /**
         * Begins a transform feedback operation
         * @param usePoints defines if points or triangles must be used
         */
        beginTransformFeedback(usePoints: boolean): void;
        /**
         * Ends a transform feedback operation
         */
        endTransformFeedback(): void;
        /**
         * Specify the varyings to use with transform feedback
         * @param program defines the associated webGL program
         * @param value defines the list of strings representing the varying names
         */
        setTranformFeedbackVaryings(program: WebGLProgram, value: string[]): void;
        /**
         * Bind a webGL buffer for a transform feedback operation
         * @param value defines the webGL buffer to bind
         */
        bindTransformFeedbackBuffer(value: Nullable<DataBuffer>): void;
        /**
         * Read data back from the bound transform feedback buffer
         * @param target defines the webGL buffer to write to
         */
        readTransformFeedbackBuffer(target: ArrayBufferView): void;
    }
}

declare module "../../Engines/engine" {
    interface Engine {
        /**
         * Creates a new multiview render target
         * @param width defines the width of the texture
         * @param height defines the height of the texture
         * @returns the created multiview render target wrapper
         */
        createMultiviewRenderTargetTexture(width: number, height: number, colorTexture?: WebGLTexture, depthStencilTexture?: WebGLTexture): RenderTargetWrapper;
        /**
         * Binds a multiview render target wrapper to be drawn to
         * @param multiviewTexture render target wrapper to bind
         */
        bindMultiviewFramebuffer(multiviewTexture: RenderTargetWrapper): void;
        /**
         * Binds a Space Warp render target wrapper to be drawn to
         * @param spaceWarpTexture render target wrapper to bind
         */
        bindSpaceWarpFramebuffer(spaceWarpTexture: RenderTargetWrapper): void;
    }
}
declare module "../../Cameras/camera" {
    interface Camera {
        /**
         * @internal
         * For cameras that cannot use multiview images to display directly. (e.g. webVR camera will render to multiview texture, then copy to each eye texture and go from there)
         */
        _useMultiviewToSingleView: boolean;
        /**
         * @internal
         * For cameras that cannot use multiview images to display directly. (e.g. webVR camera will render to multiview texture, then copy to each eye texture and go from there)
         */
        _multiviewTexture: Nullable<RenderTargetTexture>;
        /**
         * @internal
         * For WebXR cameras that are rendering to multiview texture arrays.
         */
        _renderingMultiview: boolean;
        /**
         * @internal
         * ensures the multiview texture of the camera exists and has the specified width/height
         * @param width height to set on the multiview texture
         * @param height width to set on the multiview texture
         */
        _resizeOrCreateMultiviewTexture(width: number, height: number): void;
    }
}
declare module "../../scene" {
    interface Scene {
        /** @internal */
        _transformMatrixR: Matrix;
        /** @internal */
        _multiviewSceneUbo: Nullable<UniformBuffer>;
        /** @internal */
        _createMultiviewUbo(): void;
        /** @internal */
        _updateMultiviewUbo(viewR?: Matrix, projectionR?: Matrix): void;
        /** @internal */
        _renderMultiviewToSingleView(camera: Camera): void;
    }
}

declare module "../../Engines/engine" {
    interface Engine {
        /** @internal */
        _excludedCompressedTextures: string[];
        /** @internal */
        _textureFormatInUse: string;
        /**
         * Gets the list of texture formats supported
         */
        readonly texturesSupported: Array<string>;
        /**
         * Gets the texture format in use
         */
        readonly textureFormatInUse: Nullable<string>;
        /**
         * Set the compressed texture extensions or file names to skip.
         *
         * @param skippedFiles defines the list of those texture files you want to skip
         * Example: [".dds", ".env", "myfile.png"]
         */
        setCompressedTextureExclusions(skippedFiles: Array<string>): void;
        /**
         * Set the compressed texture format to use, based on the formats you have, and the formats
         * supported by the hardware / browser.
         *
         * Khronos Texture Container (.ktx) files are used to support this.  This format has the
         * advantage of being specifically designed for OpenGL.  Header elements directly correspond
         * to API arguments needed to compressed textures.  This puts the burden on the container
         * generator to house the arcane code for determining these for current & future formats.
         *
         * for description see https://www.khronos.org/opengles/sdk/tools/KTX/
         * for file layout see https://www.khronos.org/opengles/sdk/tools/KTX/file_format_spec/
         *
         * Note: The result of this call is not taken into account when a texture is base64.
         *
         * @param formatsAvailable defines the list of those format families you have created
         * on your server.  Syntax: '-' + format family + '.ktx'.  (Case and order do not matter.)
         *
         * Current families are astc, dxt, pvrtc, etc2, & etc1.
         * @returns The extension selected.
         */
        setTextureFormatToUse(formatsAvailable: Array<string>): Nullable<string>;
    }
}

declare module "../../webgpuEngine" {
    interface WebGPUEngine {
        /** @internal */
        _createComputePipelineStageDescriptor(computeShader: string, defines: Nullable<string>, entryPoint: string): GPUProgrammableStage;
        /** @internal
         * Either all of x,y,z or buffer and offset should be defined.
         */
        _computeDispatch(effect: ComputeEffect, context: IComputeContext, bindings: ComputeBindingList, x?: number, y?: number, z?: number, buffer?: DataBuffer, offset?: number, bindingsMapping?: ComputeBindingMapping, gpuPerfCounter?: WebGPUPerfCounter): void;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * Creates a dynamic texture
         * @param width defines the width of the texture
         * @param height defines the height of the texture
         * @param generateMipMaps defines if the engine should generate the mip levels
         * @param samplingMode defines the required sampling mode (Texture.NEAREST_SAMPLINGMODE by default)
         * @returns the dynamic texture inside an InternalTexture
         */
        createDynamicTexture(width: number, height: number, generateMipMaps: boolean, samplingMode: number): InternalTexture;
        /**
         * Update the content of a dynamic texture
         * @param texture defines the texture to update
         * @param source defines the source containing the data
         * @param invertY defines if data must be stored with Y axis inverted
         * @param premulAlpha defines if alpha is stored as premultiplied
         * @param format defines the format of the data
         * @param forceBindTexture if the texture should be forced to be bound eg. after a graphics context loss (Default: false)
         * @param allowGPUOptimization true to allow some specific GPU optimizations (subject to engine feature "allowGPUOptimizationsForGUI" being true)
         */
        updateDynamicTexture(texture: Nullable<InternalTexture>, source: ImageSource | ICanvas, invertY?: boolean, premulAlpha?: boolean, format?: number, forceBindTexture?: boolean, allowGPUOptimization?: boolean): void;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * Unbind a list of render target textures from the webGL context
         * This is used only when drawBuffer extension or webGL2 are active
         * @param rtWrapper defines the render target wrapper to unbind
         * @param disableGenerateMipMaps defines a boolean indicating that mipmaps must not be generated
         * @param onBeforeUnbind defines a function which will be called before the effective unbind
         */
        unBindMultiColorAttachmentFramebuffer(rtWrapper: RenderTargetWrapper, disableGenerateMipMaps: boolean, onBeforeUnbind?: () => void): void;
        /**
         * Create a multi render target texture
         * @see https://doc.babylonjs.com/setup/support/webGL2#multiple-render-target
         * @param size defines the size of the texture
         * @param options defines the creation options
         * @param initializeBuffers if set to true, the engine will make an initializing call of drawBuffers
         * @returns a new render target wrapper ready to render textures
         */
        createMultipleRenderTarget(size: TextureSize, options: IMultiRenderTargetOptions, initializeBuffers?: boolean): RenderTargetWrapper;
        /**
         * Update the sample count for a given multiple render target texture
         * @see https://doc.babylonjs.com/setup/support/webGL2#multisample-render-targets
         * @param rtWrapper defines the render target wrapper to update
         * @param samples defines the sample count to set
         * @param initializeBuffers if set to true, the engine will make an initializing call of drawBuffers
         * @returns the effective sample count (could be 0 if multisample render targets are not supported)
         */
        updateMultipleRenderTargetTextureSampleCount(rtWrapper: Nullable<RenderTargetWrapper>, samples: number, initializeBuffers?: boolean): number;
        /**
         * Generates mipmaps for the texture of the (multi) render target
         * @param texture The render target containing the textures to generate the mipmaps for
         */
        generateMipMapsMultiFramebuffer(texture: RenderTargetWrapper): void;
        /**
         * Resolves the MSAA textures of the (multi) render target into their non-MSAA version.
         * Note that if "texture" is not a MSAA render target, no resolve is performed.
         * @param texture The render target texture containing the MSAA textures to resolve
         * @param resolveColors If true, resolve the color textures (default: true) - still subject to texture.resolveMSAAColors
         */
        resolveMultiFramebuffer(texture: RenderTargetWrapper, resolveColors?: boolean): void;
        /**
         * Select a subsets of attachments to draw to.
         * @param attachments gl attachments
         */
        bindAttachments(attachments: number[]): void;
        /**
         * Creates a layout object to draw/clear on specific textures in a MRT
         * @param textureStatus textureStatus[i] indicates if the i-th is active
         * @param backBufferLayout if true, the layout will be built to account for the back buffer only, and textureStatus won't be used
         * @returns A layout to be fed to the engine, calling `bindAttachments`.
         */
        buildTextureLayout(textureStatus: boolean[], backBufferLayout?: boolean): number[];
        /**
         * Restores the webgl state to only draw on the main color attachment
         * when the frame buffer associated is the canvas frame buffer
         */
        restoreSingleAttachment(): void;
        /**
         * Restores the webgl state to only draw on the main color attachment
         * when the frame buffer associated is not the canvas frame buffer
         */
        restoreSingleAttachmentForRenderTarget(): void;
    }
}

declare module "../../abstractEngine" {
    interface AbstractEngine {
        /**
         * Update a video texture
         * @param texture defines the texture to update
         * @param video defines the video element to use
         * @param invertY defines if data must be stored with Y axis inverted
         */
        updateVideoTexture(texture: Nullable<InternalTexture>, video: HTMLVideoElement | Nullable<ExternalTexture>, invertY: boolean): void;
    }
}

declare module "../../../Engines/thinNativeEngine" {
    interface ThinNativeEngine {
        /**
         * Creates a cube texture
         * @param rootUrl defines the url where the files to load is located
         * @param scene defines the current scene
         * @param files defines the list of files to load (1 per face)
         * @param noMipmap defines a boolean indicating that no mipmaps shall be generated (false by default)
         * @param onLoad defines an optional callback raised when the texture is loaded
         * @param onError defines an optional callback raised if there is an issue to load the texture
         * @param format defines the format of the data
         * @param forcedExtension defines the extension to use to pick the right loader
         * @param createPolynomials if a polynomial sphere should be created for the cube texture
         * @param lodScale defines the scale applied to environment texture. This manages the range of LOD level used for IBL according to the roughness
         * @param lodOffset defines the offset applied to environment texture. This manages first LOD level used for IBL according to the roughness
         * @param fallback defines texture to use while falling back when (compressed) texture file not found.
         * @param loaderOptions options to be passed to the loader
         * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
         * @param buffer defines the data buffer to load instead of loading the rootUrl
         * @returns the cube texture as an InternalTexture
         */
        createCubeTexture(rootUrl: string, scene: Nullable<Scene>, files: Nullable<string[]>, noMipmap?: boolean, onLoad?: Nullable<(data?: any) => void>, onError?: Nullable<(message?: string, exception?: any) => void>, format?: number, forcedExtension?: any, createPolynomials?: boolean, lodScale?: number, lodOffset?: number, fallback?: Nullable<InternalTexture>, loaderOptions?: any, useSRGBBuffer?: boolean, buffer?: Nullable<ArrayBufferView>): InternalTexture;
    }
}

/** @internal */
interface EngineFeatures {
    /** Force using Bitmap when Bitmap or HTMLImageElement can be used */
    forceBitmapOverHTMLImageElement: boolean;
    /** Indicates that the engine support rendering to as well as copying to lod float textures */
    supportRenderAndCopyToLodForFloatTextures: boolean;
    /** Indicates that the engine support handling depth/stencil textures */
    supportDepthStencilTexture: boolean;
    /** Indicates that the engine support shadow samplers */
    supportShadowSamplers: boolean;
    /** Indicates to check the matrix bytes per bytes to know if it has changed or not. If false, only the updateFlag of the matrix is checked */
    uniformBufferHardCheckMatrix: boolean;
    /** Indicates that prefiltered mipmaps can be generated in some processes (for eg when loading an HDR cube texture) */
    allowTexturePrefiltering: boolean;
    /** Indicates to track the usage of ubos and to create new ones as necessary during a frame duration */
    trackUbosInFrame: boolean;
    /** Indicates that the current content of a ubo should be compared to the content of the corresponding GPU buffer and the GPU buffer updated only if different. Requires trackUbosInFrame to be true */
    checkUbosContentBeforeUpload: boolean;
    /** Indicates that the Cascaded Shadow Map technic is supported */
    supportCSM: boolean;
    /** Indicates that the textures transcoded by the basis transcoder must have power of 2 width and height */
    basisNeedsPOT: boolean;
    /** Indicates that the engine supports 3D textures */
    support3DTextures: boolean;
    /** Indicates that constants need a type suffix in shaders (used by realtime filtering...) */
    needTypeSuffixInShaderConstants: boolean;
    /** Indicates that MSAA is supported */
    supportMSAA: boolean;
    /** Indicates that SSAO2 is supported */
    supportSSAO2: boolean;
    /** Indicates that IBL Shadows are supported */
    supportIBLShadows: boolean;
    /** Indicates that some additional texture formats are supported (like TEXTUREFORMAT_R for eg) */
    supportExtendedTextureFormats: boolean;
    /** Indicates that the switch/case construct is supported in shaders */
    supportSwitchCaseInShader: boolean;
    /** Indicates that synchronous texture reading is supported */
    supportSyncTextureRead: boolean;
    /** Indicates that y should be inverted when dealing with bitmaps (notably in environment tools) */
    needsInvertingBitmap: boolean;
    /** Indicates that the engine should cache the bound UBO */
    useUBOBindingCache: boolean;
    /** Indicates that the inliner should be run over every shader code */
    needShaderCodeInlining: boolean;
    /** Indicates that even if we don't have to update the properties of a uniform buffer (because of some optimzations in the material) we still need to bind the uniform buffer themselves */
    needToAlwaysBindUniformBuffers: boolean;
    /**  Indicates that the engine supports render passes */
    supportRenderPasses: boolean;
    /**  Indicates that the engine supports sprite instancing */
    supportSpriteInstancing: boolean;
    /** Indicates that the stride and (byte) offset of a vertex buffer must always be a multiple of 4 bytes */
    forceVertexBufferStrideAndOffsetMultiple4Bytes: boolean;
    /** @internal */
    _checkNonFloatVertexBuffersDontRecreatePipelineContext: boolean;
    /** @internal */
    _collectUbosUpdatedInFrame: boolean;
}

/**
 * This class is used to store keyboard related info for the onKeyboardObservable event.
 */
declare class KeyboardInfo {
    /**
     * Defines the type of event (KeyboardEventTypes)
     */
    type: number;
    /**
     * Defines the related dom event
     */
    event: IKeyboardEvent;
    /**
     * Instantiates a new keyboard info.
     * This class is used to store keyboard related info for the onKeyboardObservable event.
     * @param type Defines the type of event (KeyboardEventTypes)
     * @param event Defines the related dom event
     */
    constructor(
    /**
     * Defines the type of event (KeyboardEventTypes)
     */
    type: number, 
    /**
     * Defines the related dom event
     */
    event: IKeyboardEvent);
}
/**
 * This class is used to store keyboard related info for the onPreKeyboardObservable event.
 * Set the skipOnKeyboardObservable property to true if you want the engine to stop any process after this event is triggered, even not calling onKeyboardObservable
 */
declare class KeyboardInfoPre extends KeyboardInfo {
    /**
     * Defines the type of event (KeyboardEventTypes)
     */
    type: number;
    /**
     * Defines the related dom event
     */
    event: IKeyboardEvent;
    /**
     * Defines whether the engine should skip the next onKeyboardObservable associated to this pre.
     */
    skipOnKeyboardObservable: boolean;
    /**
     * Defines whether the engine should skip the next onKeyboardObservable associated to this pre.
     * @deprecated use skipOnKeyboardObservable property instead
     */
    get skipOnPointerObservable(): boolean;
    set skipOnPointerObservable(value: boolean);
    /**
     * Instantiates a new keyboard pre info.
     * This class is used to store keyboard related info for the onPreKeyboardObservable event.
     * @param type Defines the type of event (KeyboardEventTypes)
     * @param event Defines the related dom event
     */
    constructor(
    /**
     * Defines the type of event (KeyboardEventTypes)
     */
    type: number, 
    /**
     * Defines the related dom event
     */
    event: IKeyboardEvent);
}

/**
 * Description of a custom block to be used in the node render graph editor
 */
interface INodeRenderGraphCustomBlockDescription {
    /** Block name. It will be used as the block name in the left menu of the editor. Spaces must be replaced by underscores in the name. */
    name: string;
    /** Description (tooltip) of the block. */
    description: string;
    /** Category of the block. Spaces must be replaced by underscores in the category name. */
    menu: string;
    /** Factory function to create the block. */
    factory: (frameGraph: FrameGraph, scene: Scene) => NodeRenderGraphBlock;
}
/**
 * Interface used to configure the node render graph editor
 */
interface INodeRenderGraphEditorOptions {
    /** Define the URL to load node editor script from */
    editorURL?: string;
    /** Additional configuration for the FGE */
    nodeRenderGraphEditorConfig?: {
        backgroundColor?: Color4;
        hostScene?: Scene;
        customBlockDescriptions?: INodeRenderGraphCustomBlockDescription[];
    };
}
/**
 * Options that can be passed to the node render graph build method
 */
interface INodeRenderGraphCreateOptions {
    /** If true, textures created by the node render graph will be visible in the inspector, for easier debugging (default: false) */
    debugTextures?: boolean;
    /** Rebuild the node render graph when the screen is resized (default: true) */
    rebuildGraphOnEngineResize?: boolean;
    /** Defines if the build should log activity (default: false) */
    verbose?: boolean;
    /** Defines if the autoConfigure method should be called when initializing blocks (default: false) */
    autoConfigure?: boolean;
    /** If true, external inputs like object lists and cameras will be filled with default values, taken from the scene. Note that external textures are not concerned (default: true). */
    autoFillExternalInputs?: boolean;
}
/**
 * Defines the kind of connection point for node render graph nodes
 */
declare enum NodeRenderGraphBlockConnectionPointTypes {
    /** General purpose texture */
    Texture = 1,
    /** Back buffer color texture */
    TextureBackBuffer = 2,
    /** Back buffer depth/stencil attachment */
    TextureBackBufferDepthStencilAttachment = 4,
    /** Depth/stencil attachment */
    TextureDepthStencilAttachment = 8,
    /** Depth (in view space) geometry texture */
    TextureViewDepth = 16,
    /** Normal (in view space) geometry texture */
    TextureViewNormal = 32,
    /** Albedo geometry texture */
    TextureAlbedo = 64,
    /** Reflectivity geometry texture */
    TextureReflectivity = 128,
    /** Position (in world space) geometry texture */
    TextureWorldPosition = 256,
    /** Velocity geometry texture */
    TextureVelocity = 512,
    /** Irradiance geometry texture */
    TextureIrradiance = 1024,
    /** Albedo (sqrt) geometry texture */
    TextureAlbedoSqrt = 2048,
    /** Depth (in screen space) geometry texture */
    TextureScreenDepth = 4096,
    /** Normal (in world space) geometry texture */
    TextureWorldNormal = 8192,
    /** Position (in local space) geometry texture */
    TextureLocalPosition = 16384,
    /** Linear velocity geometry texture */
    TextureLinearVelocity = 32768,
    /** Normalied depth (in view space) geometry texture */
    TextureNormalizedViewDepth = 65536,
    /** Bit field for all textures but back buffer depth/stencil */
    TextureAllButBackBufferDepthStencil = 1048571,
    /** Bit field for all textures but back buffer color and depth/stencil */
    TextureAllButBackBuffer = 1048569,
    /** Bit field for all textures */
    TextureAll = 1048575,
    /** Resource container */
    ResourceContainer = 1048576,
    /** Shadow generator */
    ShadowGenerator = 2097152,
    /** Light */
    ShadowLight = 4194304,
    /** Camera */
    Camera = 16777216,
    /** List of objects (meshes, particle systems, sprites) */
    ObjectList = 33554432,
    /** Detect type based on connection */
    AutoDetect = 268435456,
    /** Output type that will be defined by input type */
    BasedOnInput = 536870912,
    /** Undefined */
    Undefined = 1073741824,
    /** Custom object */
    Object = 2147483648,
    /** Bitmask of all types */
    All = 4294967295
}
/**
 * Enum used to define the compatibility state between two connection points
 */
declare const enum NodeRenderGraphConnectionPointCompatibilityStates {
    /** Points are compatibles */
    Compatible = 0,
    /** Points are incompatible because of their types */
    TypeIncompatible = 1,
    /** Points are incompatible because they are in the same hierarchy **/
    HierarchyIssue = 2
}
/**
 * Defines the direction of a connection point
 */
declare const enum NodeRenderGraphConnectionPointDirection {
    /** Input */
    Input = 0,
    /** Output */
    Output = 1
}
/**
 * Defines the type of a connection point value
 */
type NodeRenderGraphBlockConnectionPointValueType = FrameGraphTextureHandle | Camera | FrameGraphObjectList | IShadowLight | FrameGraphShadowGeneratorTask | FrameGraphObjectRendererTask;

/**
 * Defines a connection point for a block
 */
declare class NodeRenderGraphConnectionPoint {
    private readonly _ownerBlock;
    private _connectedPoint;
    /** @internal */
    _acceptedConnectionPointType: Nullable<NodeRenderGraphConnectionPoint>;
    private _endpoints;
    private readonly _direction;
    private _type;
    /** @internal */
    _linkedConnectionSource: Nullable<NodeRenderGraphConnectionPoint>;
    /** @internal */
    _isMainLinkSource: boolean;
    /** @internal */
    _typeConnectionSource: Nullable<NodeRenderGraphConnectionPoint | (() => NodeRenderGraphConnectionPoint)>;
    /** @internal */
    _defaultConnectionPointType: Nullable<NodeRenderGraphBlockConnectionPointTypes>;
    /** Gets the direction of the point */
    get direction(): NodeRenderGraphConnectionPointDirection;
    /**
     * Checks if the value is a texture handle
     * @param value The value to check
     * @returns True if the value is a texture handle
     */
    static IsTextureHandle(value: NodeRenderGraphBlockConnectionPointValueType | undefined): boolean;
    /**
     * Checks if the value is a shadow generator task
     * @param value The value to check
     * @returns True if the value is a shadow generator
     */
    static IsShadowGenerator(value: NodeRenderGraphBlockConnectionPointValueType | undefined): boolean;
    /**
     * Checks if the value is a shadow light
     * @param value The value to check
     * @returns True if the value is a shadow light
     */
    static IsShadowLight(value: NodeRenderGraphBlockConnectionPointValueType | undefined): boolean;
    /**
     * The value stored in this connection point
     */
    value: NodeRenderGraphBlockConnectionPointValueType | undefined;
    /** Indicates that this connection point needs dual validation before being connected to another point */
    needDualDirectionValidation: boolean;
    /**
     * Gets or sets the additional types supported by this connection point
     */
    acceptedConnectionPointTypes: NodeRenderGraphBlockConnectionPointTypes[];
    /**
     * Gets or sets the additional types excluded by this connection point
     */
    excludedConnectionPointTypes: NodeRenderGraphBlockConnectionPointTypes[];
    /**
     * Observable triggered when this point is connected
     */
    onConnectionObservable: Observable<NodeRenderGraphConnectionPoint>;
    /**
     * Observable triggered when this point is disconnected
     */
    onDisconnectionObservable: Observable<NodeRenderGraphConnectionPoint>;
    /**
     * Gets or sets a boolean indicating that this connection point is exposed on a frame
     */
    isExposedOnFrame: boolean;
    /**
     * Gets or sets number indicating the position that the port is exposed to on a frame
     */
    exposedPortPosition: number;
    /**
     * Gets or sets the connection point type (default is Undefined)
     */
    get type(): NodeRenderGraphBlockConnectionPointTypes;
    set type(value: NodeRenderGraphBlockConnectionPointTypes);
    /**
     * Gets or sets the connection point name
     */
    name: string;
    /**
     * Gets or sets the connection point display name
     */
    displayName: string;
    /**
     * Gets or sets a boolean indicating that this connection point can be omitted
     */
    isOptional: boolean;
    /**
     * Gets a boolean indicating that the current point is connected to another NodeRenderGraphBlock
     */
    get isConnected(): boolean;
    /** Get the other side of the connection (if any) */
    get connectedPoint(): Nullable<NodeRenderGraphConnectionPoint>;
    /** Get the block that owns this connection point */
    get ownerBlock(): NodeRenderGraphBlock;
    /** Get the block connected on the other side of this connection (if any) */
    get sourceBlock(): Nullable<NodeRenderGraphBlock>;
    /** Get the block connected on the endpoints of this connection (if any) */
    get connectedBlocks(): Array<NodeRenderGraphBlock>;
    /** Gets the list of connected endpoints */
    get endpoints(): NodeRenderGraphConnectionPoint[];
    /** Gets a boolean indicating if that output point is connected to at least one input */
    get hasEndpoints(): boolean;
    /** Get the inner type (ie AutoDetect for instance instead of the inferred one) */
    get innerType(): NodeRenderGraphBlockConnectionPointTypes;
    /**
     * Creates a block suitable to be used as an input for this input point.
     * If null is returned, a block based on the point type will be created.
     * @returns The returned string parameter is the name of the output point of NodeRenderGraphBlock (first parameter of the returned array) that can be connected to the input
     */
    createCustomInputBlock(): Nullable<[NodeRenderGraphBlock, string]>;
    /**
     * Creates a new connection point
     * @param name defines the connection point name
     * @param ownerBlock defines the block hosting this connection point
     * @param direction defines the direction of the connection point
     */
    constructor(name: string, ownerBlock: NodeRenderGraphBlock, direction: NodeRenderGraphConnectionPointDirection);
    /**
     * Gets the current class name e.g. "NodeRenderGraphConnectionPoint"
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets a boolean indicating if the current point can be connected to another point
     * @param connectionPoint defines the other connection point
     * @returns a boolean
     */
    canConnectTo(connectionPoint: NodeRenderGraphConnectionPoint): boolean;
    /**
     * Gets a number indicating if the current point can be connected to another point
     * @param connectionPoint defines the other connection point
     * @returns a number defining the compatibility state
     */
    checkCompatibilityState(connectionPoint: NodeRenderGraphConnectionPoint): NodeRenderGraphConnectionPointCompatibilityStates;
    /**
     * Connect this point to another connection point
     * @param connectionPoint defines the other connection point
     * @param ignoreConstraints defines if the system will ignore connection type constraints (default is false)
     * @returns the current connection point
     */
    connectTo(connectionPoint: NodeRenderGraphConnectionPoint, ignoreConstraints?: boolean): NodeRenderGraphConnectionPoint;
    /**
     * Disconnect this point from one of his endpoint
     * @param endpoint defines the other connection point
     * @returns the current connection point
     */
    disconnectFrom(endpoint: NodeRenderGraphConnectionPoint): NodeRenderGraphConnectionPoint;
    /**
     * Fills the list of excluded connection point types with all types other than those passed in the parameter
     * @param mask Types (ORed values of NodeRenderGraphBlockConnectionPointTypes) that are allowed, and thus will not be pushed to the excluded list
     */
    addExcludedConnectionPointFromAllowedTypes(mask: number): void;
    /**
     * Adds accepted connection point types
     * @param mask Types (ORed values of NodeRenderGraphBlockConnectionPointTypes) that are allowed to connect to this point
     */
    addAcceptedConnectionPointTypes(mask: number): void;
    /**
     * Serializes this point in a JSON representation
     * @param isInput defines if the connection point is an input (default is true)
     * @returns the serialized point object
     */
    serialize(isInput?: boolean): any;
    /**
     * Release resources
     */
    dispose(): void;
}

/**
 * Defines a block that can be used inside a node render graph
 */
declare class NodeRenderGraphBlock {
    private _name;
    private _buildId;
    protected _isInput: boolean;
    protected _isTeleportOut: boolean;
    protected _isTeleportIn: boolean;
    protected _isDebug: boolean;
    protected _isUnique: boolean;
    protected _scene: Scene;
    protected _engine: AbstractEngine;
    protected _frameGraph: FrameGraph;
    protected _frameGraphTask?: FrameGraphTask;
    /**
     * Gets or sets the disable flag of the task associated with this block
     */
    get disabled(): boolean;
    set disabled(value: boolean);
    /**
     * Gets the frame graph task associated with this block
     */
    get task(): FrameGraphTask | undefined;
    /**
     * Gets an observable raised when the block is built
     */
    onBuildObservable: Observable<NodeRenderGraphBlock>;
    /** @internal */
    _inputs: NodeRenderGraphConnectionPoint[];
    /** @internal */
    _outputs: NodeRenderGraphConnectionPoint[];
    /** @internal */
    _codeVariableName: string;
    /** @internal */
    _additionalConstructionParameters: Nullable<unknown[]>;
    /**
     * Gets the list of input points
     */
    get inputs(): NodeRenderGraphConnectionPoint[];
    /** Gets the list of output points */
    get outputs(): NodeRenderGraphConnectionPoint[];
    /**
     * Gets or sets the unique id of the node
     */
    uniqueId: number;
    /**
     * Gets or set the name of the block
     */
    get name(): string;
    set name(value: string);
    /**
     * Gets a boolean indicating if this block is an input
     */
    get isInput(): boolean;
    /**
     * Gets a boolean indicating if this block is a teleport out
     */
    get isTeleportOut(): boolean;
    /**
     * Gets a boolean indicating if this block is a teleport in
     */
    get isTeleportIn(): boolean;
    /**
     * Gets a boolean indicating if this block is a debug block
     */
    get isDebug(): boolean;
    /**
     * Gets a boolean indicating that this block can only be used once per node render graph
     */
    get isUnique(): boolean;
    /**
     * A free comment about the block
     */
    comments: string;
    /** Gets or sets a boolean indicating that this input can be edited from a collapsed frame */
    visibleOnFrame: boolean;
    /**
     * Gets the current class name e.g. "NodeRenderGraphBlock"
     * @returns the class name
     */
    getClassName(): string;
    protected _inputRename(name: string): string;
    protected _outputRename(name: string): string;
    /**
     * Checks if the current block is an ancestor of a given block
     * @param block defines the potential descendant block to check
     * @returns true if block is a descendant
     */
    isAnAncestorOf(block: NodeRenderGraphBlock): boolean;
    /**
     * Checks if the current block is an ancestor of a given type
     * @param type defines the potential type to check
     * @returns true if block is a descendant
     */
    isAnAncestorOfType(type: string): boolean;
    /**
     * Get the first descendant using a predicate
     * @param predicate defines the predicate to check
     * @returns descendant or null if none found
     */
    getDescendantOfPredicate(predicate: (block: NodeRenderGraphBlock) => boolean): Nullable<NodeRenderGraphBlock>;
    /**
     * Creates a new NodeRenderGraphBlock
     * @param name defines the block name
     * @param frameGraph defines the hosting frame graph
     * @param scene defines the hosting scene
     * @param _additionalConstructionParameters defines additional parameters to pass to the block constructor
     */
    constructor(name: string, frameGraph: FrameGraph, scene: Scene, ..._additionalConstructionParameters: unknown[]);
    /**
     * Register a new input. Must be called inside a block constructor
     * @param name defines the connection point name
     * @param type defines the connection point type
     * @param isOptional defines a boolean indicating that this input can be omitted
     * @param point an already created connection point. If not provided, create a new one
     * @returns the current block
     */
    registerInput(name: string, type: NodeRenderGraphBlockConnectionPointTypes, isOptional?: boolean, point?: NodeRenderGraphConnectionPoint): this;
    /**
     * Register a new output. Must be called inside a block constructor
     * @param name defines the connection point name
     * @param type defines the connection point type
     * @param point an already created connection point. If not provided, create a new one
     * @returns the current block
     */
    registerOutput(name: string, type: NodeRenderGraphBlockConnectionPointTypes, point?: NodeRenderGraphConnectionPoint): this;
    protected _addDependenciesInput(additionalAllowedTypes?: number): NodeRenderGraphConnectionPoint;
    protected _buildBlock(_state: NodeRenderGraphBuildState): void;
    protected _customBuildStep(_state: NodeRenderGraphBuildState): void;
    protected _propagateInputValueToOutput(inputConnectionPoint: NodeRenderGraphConnectionPoint, outputConnectionPoint: NodeRenderGraphConnectionPoint): void;
    /**
     * Build the current node and generate the vertex data
     * @param state defines the current generation state
     * @returns true if already built
     */
    build(state: NodeRenderGraphBuildState): boolean;
    protected _getConnectedTextures(targetConnectedPoint: Nullable<NodeRenderGraphConnectionPoint>): number | number[] | undefined;
    protected _linkConnectionTypes(inputIndex0: number, inputIndex1: number, looseCoupling?: boolean): void;
    /**
     * Initialize the block and prepare the context for build
     */
    initialize(): void;
    /**
     * Lets the block try to connect some inputs automatically
     */
    autoConfigure(): void;
    /**
     * Find an input by its name
     * @param name defines the name of the input to look for
     * @returns the input or null if not found
     */
    getInputByName(name: string): NodeRenderGraphConnectionPoint | null;
    /**
     * Find an output by its name
     * @param name defines the name of the output to look for
     * @returns the output or null if not found
     */
    getOutputByName(name: string): NodeRenderGraphConnectionPoint | null;
    /**
     * Serializes this block in a JSON representation
     * @returns the serialized block object
     */
    serialize(): any;
    /**
     * @internal
     */
    _deserialize(serializationObject: any): void;
    private _deserializePortDisplayNamesAndExposedOnFrame;
    protected _dumpPropertiesCode(): string;
    /**
     * @internal
     */
    _dumpCodeForOutputConnections(alreadyDumped: NodeRenderGraphBlock[]): string;
    /**
     * @internal
     */
    _dumpCode(uniqueNames: string[], alreadyDumped: NodeRenderGraphBlock[]): string;
    /**
     * Clone the current block to a new identical block
     * @returns a copy of the current block
     */
    clone(): NodeRenderGraphBlock | null;
    /**
     * Release resources
     */
    dispose(): void;
}

/**
 * Represents a task in a frame graph.
 */
declare abstract class FrameGraphTask {
    protected readonly _frameGraph: FrameGraph;
    private readonly _passes;
    private readonly _passesDisabled;
    protected _name: string;
    /**
     * The name of the task.
     */
    get name(): string;
    set name(value: string);
    protected _disabled: boolean;
    /**
     * Whether the task is disabled.
     */
    get disabled(): boolean;
    set disabled(value: boolean);
    /**
     * Gets the passes of the task.
     */
    get passes(): IFrameGraphPass[];
    /**
     * Gets the disabled passes of the task.
     */
    get passesDisabled(): IFrameGraphPass[];
    /**
     * The (texture) dependencies of the task (optional).
     */
    dependencies?: Set<FrameGraphTextureHandle>;
    /** @internal */
    _disableDebugMarkers: boolean;
    /**
     * Records the task in the frame graph. Use this function to add content (render passes, ...) to the task.
     * @param skipCreationOfDisabledPasses If true, the disabled passe(s) won't be created.
     */
    abstract record(skipCreationOfDisabledPasses?: boolean): void;
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * This function is called once after the task has been added to the frame graph and before the frame graph is built for the first time.
     * This allows you to initialize asynchronous resources, which is not possible in the constructor.
     * @returns A promise that resolves when the initialization is complete.
     */
    initAsync(): Promise<unknown>;
    /**
     * An observable that is triggered after the textures have been allocated.
     */
    onTexturesAllocatedObservable: Observable<FrameGraphRenderContext>;
    /**
     * An observable that is triggered before the task is executed.
     */
    onBeforeTaskExecute: Observable<FrameGraphTask>;
    /**
     * An observable that is triggered after the task is executed.
     */
    onAfterTaskExecute: Observable<FrameGraphTask>;
    /**
     * Checks if the task is ready to be executed.
     * @returns True if the task is ready to be executed, else false.
     */
    isReady(): boolean;
    /**
     * Disposes of the task.
     */
    dispose(): void;
    /**
     * Constructs a new frame graph task.
     * @param name The name of the task.
     * @param frameGraph The frame graph this task is associated with.
     */
    constructor(name: string, frameGraph: FrameGraph);
    /** @internal */
    _reset(): void;
    /** @internal */
    _addPass(pass: IFrameGraphPass, disabled: boolean): void;
    /** @internal */
    _checkTask(): void;
    /** @internal */
    _execute(): void;
    /** @internal */
    _initializePasses(): void;
    private _checkSameRenderTarget;
}

/**
 * Task which copies a texture to the backbuffer color texture.
 */
declare class FrameGraphCopyToBackbufferColorTask extends FrameGraphTask {
    /**
     * The source texture to copy to the backbuffer color texture.
     */
    sourceTexture: FrameGraphTextureHandle;
    getClassName(): string;
    record(): void;
}

/**
 * Block used to generate the final graph
 */
declare class NodeRenderGraphOutputBlock extends NodeRenderGraphBlock {
    protected _frameGraphTask: FrameGraphCopyToBackbufferColorTask;
    /**
     * Gets the frame graph task associated with this block
     */
    get task(): FrameGraphCopyToBackbufferColorTask;
    /**
     * Create a new NodeRenderGraphOutputBlock
     * @param name defines the block name
     * @param frameGraph defines the hosting frame graph
     * @param scene defines the hosting scene
     */
    constructor(name: string, frameGraph: FrameGraph, scene: Scene);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the texture input component
     */
    get texture(): NodeRenderGraphConnectionPoint;
    protected _buildBlock(state: NodeRenderGraphBuildState): void;
}

/**
 * Base class for a frame graph pass.
 */
declare class FrameGraphPass<T extends FrameGraphContext> implements IFrameGraphPass {
    name: string;
    protected readonly _parentTask: FrameGraphTask;
    protected readonly _context: T;
    private _executeFunc;
    private _initFunc?;
    /**
     * Whether the pass is disabled. Disabled passes will be skipped during execution.
     */
    disabled: boolean;
    /** @internal */
    constructor(name: string, _parentTask: FrameGraphTask, _context: T);
    /**
     * Initializes the pass.
     * This function is called once after the frame graph has been built
     * @param func The function to initialize the pass.
     */
    setInitializeFunc(func: (context: T) => void): void;
    /**
     * Sets the function to execute when the pass is executed
     * @param func The function to execute when the pass is executed
     */
    setExecuteFunc(func: (context: T) => void): void;
    /** @internal */
    _execute(): void;
    /** @internal */
    _initialize(): void;
    /** @internal */
    _isValid(): Nullable<string>;
    /** @internal */
    _dispose(): void;
}

/**
 * Type used to define layer and face indices for multi-render target rendering scenarios.
 */
type LayerAndFaceIndex = {
    /** Index of the texture to update */
    targetIndex: number;
    /** Index of the layer to set (optional - not used if the texture is not an array or a 3D texture) */
    layerIndex?: number;
    /** Index of the cube face to set (optional - not used if the texture is not a cube texture) */
    faceIndex?: number;
};
/**
 * Render pass used to render objects.
 */
declare class FrameGraphRenderPass extends FrameGraphPass<FrameGraphRenderContext> {
    protected readonly _engine: AbstractEngine;
    protected _renderTarget: FrameGraphTextureHandle | FrameGraphTextureHandle[] | undefined;
    protected _renderTargetDepth: FrameGraphTextureHandle | undefined;
    protected _frameGraphRenderTarget: FrameGraphRenderTarget;
    protected _dependencies: Set<FrameGraphTextureHandle>;
    /**
     * Checks if a pass is a render pass.
     * @param pass The pass to check.
     * @returns True if the pass is a render pass, else false.
     */
    static IsRenderPass(pass: IFrameGraphPass): pass is FrameGraphRenderPass;
    /**
     * Gets the handle(s) of the render target(s) used by the render pass.
     */
    get renderTarget(): FrameGraphTextureHandle | FrameGraphTextureHandle[] | undefined;
    /**
     * Gets the handle of the render target depth used by the render pass.
     */
    get renderTargetDepth(): FrameGraphTextureHandle | undefined;
    /**
     * Gets the frame graph render target used by the render pass.
     */
    get frameGraphRenderTarget(): FrameGraphRenderTarget;
    /**
     * If true, the depth attachment will be read-only (may allow some optimizations in WebGPU)
     */
    depthReadOnly: boolean;
    /**
     * If true, the stencil attachment will be read-only (may allow some optimizations in WebGPU)
     */
    stencilReadOnly: boolean;
    /** @internal */
    constructor(name: string, parentTask: FrameGraphTask, context: FrameGraphRenderContext, engine: AbstractEngine);
    /**
     * Sets the render target(s) to use for rendering.
     * @param renderTargetHandle The render target to use for rendering, or an array of render targets to use for multi render target rendering.
     */
    setRenderTarget(renderTargetHandle?: FrameGraphTextureHandle | FrameGraphTextureHandle[]): void;
    /**
     * Sets the render target depth to use for rendering.
     * @param renderTargetHandle The render target depth to use for rendering.
     */
    setRenderTargetDepth(renderTargetHandle?: FrameGraphTextureHandle): void;
    /**
     * Adds dependencies to the render pass.
     * @param dependencies The dependencies to add.
     */
    addDependencies(dependencies?: FrameGraphTextureHandle | FrameGraphTextureHandle[]): void;
    /**
     * Collects the dependencies of the render pass.
     * @param dependencies The set of dependencies to update.
     */
    collectDependencies(dependencies: Set<FrameGraphTextureHandle>): void;
    /**
     * Sets the output layer and face indices for multi-render target rendering.
     * @param indices The array of layer and face indices.
     */
    setOutputLayerAndFaceIndices(indices: LayerAndFaceIndex[]): void;
    /** @internal */
    _initialize(): void;
    /** @internal */
    _execute(): void;
    /** @internal */
    _isValid(): Nullable<string>;
    /** @internal */
    _dispose(): void;
}

/**
 * Object list pass used to generate a list of objects.
 */
declare class FrameGraphObjectListPass extends FrameGraphPass<FrameGraphContext> {
    protected readonly _engine: AbstractEngine;
    protected _objectList: FrameGraphObjectList;
    /**
     * Checks if a pass is an object list pass.
     * @param pass The pass to check.
     * @returns True if the pass is an object list pass, else false.
     */
    static IsObjectListPass(pass: IFrameGraphPass): pass is FrameGraphObjectListPass;
    /**
     * Gets the object list used by the pass.
     */
    get objectList(): FrameGraphObjectList;
    /**
     * Sets the object list to use for the pass.
     * @param objectList The object list to use for the pass.
     */
    setObjectList(objectList: FrameGraphObjectList): void;
    /** @internal */
    constructor(name: string, parentTask: FrameGraphTask, context: FrameGraphContext, engine: AbstractEngine);
    /** @internal */
    _isValid(): Nullable<string>;
}

/**
 * Base class for frame graph context.
 */
declare class FrameGraphContext {
    protected readonly _engine: AbstractEngine;
    protected readonly _textureManager: FrameGraphTextureManager;
    protected readonly _scene: Scene;
    private _depthTest;
    private _depthWrite;
    /**
     * If true, debug markers will be enabled in the context.
     */
    enableDebugMarkers: boolean;
    /** @internal */
    constructor(_engine: AbstractEngine, _textureManager: FrameGraphTextureManager, _scene: Scene);
    /**
     * Renders a component without managing the render target.
     * Use this method when you have a component that handles its own rendering logic which is not fully integrated into the frame graph system.
     * @param component The component to render.
     * @param intermediateRendering If true, the scene's intermediate rendering flag will be set to true during the render call (default: true)
     */
    renderUnmanaged(component: {
        render: () => void;
    }, intermediateRendering?: boolean): void;
    /**
     * Gets a texture from a handle.
     * Note that if the texture is a history texture, the read texture for the current frame will be returned.
     * @param handle The handle of the texture
     * @returns The texture or null if not found
     */
    getTextureFromHandle(handle: FrameGraphTextureHandle): Nullable<InternalTexture>;
    /**
     * Pushes a debug group to the engine's debug stack.
     * @param name The name of the debug group
     */
    pushDebugGroup(name: string): void;
    /**
     * Pops a debug group from the engine's debug stack.
     */
    popDebugGroup(): void;
    /**
     * Inserts a debug marker in the engine's debug stack.
     * @param text The text of the debug marker
     */
    insertDebugMarker(text: string): void;
    /**
     * Saves the current depth states (depth testing and depth writing)
     */
    saveDepthStates(): void;
    /**
     * Restores the depth states saved by saveDepthStates
     */
    restoreDepthStates(): void;
    /**
     * Sets the depth states for the current render target
     * @param depthTest If true, depth testing is enabled
     * @param depthWrite If true, depth writing is enabled
     */
    setDepthStates(depthTest: boolean, depthWrite: boolean): void;
    /**
     * Sets the current viewport
     * @param viewport defines the viewport element to be used
     * @param requiredWidth defines the width required for rendering. If not provided, the width of the render texture is used.
     * @param requiredHeight defines the height required for rendering. If not provided the height of the render texture is used.
     */
    setViewport(viewport: IViewportLike, requiredWidth?: number, requiredHeight?: number): void;
}

/**
 * @internal
 */
declare class FrameGraphRenderTarget {
    protected readonly _textureManager: FrameGraphTextureManager;
    protected readonly _renderTargets: FrameGraphTextureHandle[] | undefined;
    protected readonly _renderTargetDepth: FrameGraphTextureHandle | undefined;
    protected _renderTargetWrapper: RenderTargetWrapper | undefined;
    protected _isBackBuffer: boolean;
    readonly name: string;
    constructor(name: string, textureManager: FrameGraphTextureManager, renderTargets?: FrameGraphTextureHandle | FrameGraphTextureHandle[], renderTargetDepth?: FrameGraphTextureHandle);
    get renderTargetWrapper(): RenderTargetWrapper | undefined;
    equals(other: FrameGraphRenderTarget): boolean;
    dispose(): void;
}

type HistoryTexture = {
    textures: Array<Nullable<InternalTexture>>;
    handles: Array<FrameGraphTextureHandle>;
    index: number;
    references: Array<{
        renderTargetWrapper: RenderTargetWrapper;
        textureIndex: number;
    }>;
};
type TextureLifespan = {
    firstTask: number;
    lastTask: number;
};
type TextureEntry = {
    texture: Nullable<InternalTexture>;
    name: string;
    creationOptions: FrameGraphTextureCreationOptions;
    namespace: FrameGraphTextureNamespace;
    textureIndex?: number;
    debug?: Texture;
    refHandle?: FrameGraphTextureHandle;
    textureDescriptionHash?: string;
    lifespan?: TextureLifespan;
    aliasHandle?: FrameGraphTextureHandle;
    historyTexture?: boolean;
};
declare enum FrameGraphTextureNamespace {
    Task = 0,
    Graph = 1,
    External = 2
}
/**
 * Manages the textures used by a frame graph
 */
declare class FrameGraphTextureManager {
    readonly engine: AbstractEngine;
    private readonly _debugTextures;
    private readonly _scene;
    private static _Counter;
    /** @internal */
    readonly _textures: Map<FrameGraphTextureHandle, TextureEntry>;
    /** @internal */
    readonly _historyTextures: Map<FrameGraphTextureHandle, HistoryTexture>;
    /** @internal */
    _isRecordingTask: boolean;
    /**
     * Gets or sets a boolean indicating if debug logs should be shown when applying texture allocation optimization (default: false)
     */
    showDebugLogsForTextureAllcationOptimization: boolean;
    private _backBufferTextureEntry;
    private _backBufferDepthStencilTextureEntry;
    private _backBufferTextureOverriden;
    /**
     * Constructs a new instance of the texture manager
     * @param engine The engine to use
     * @param _debugTextures If true, debug textures will be created so that they are visible in the inspector
     * @param _scene The scene the manager belongs to
     */
    constructor(engine: AbstractEngine, _debugTextures: boolean | undefined, _scene: Scene);
    /**
     * Checks if a handle is a backbuffer handle (color or depth/stencil)
     * @param handle The handle to check
     * @returns True if the handle is a backbuffer handle
     */
    isBackbuffer(handle: FrameGraphTextureHandle): boolean;
    /** @internal */
    _isBackbuffer(handle: FrameGraphTextureHandle): boolean;
    /**
     * Checks if a handle is a backbuffer color handle
     * @param handle The handle to check
     * @returns True if the handle is a backbuffer color handle
     */
    isBackbufferColor(handle: FrameGraphTextureHandle): boolean;
    /**
     * Checks if a handle is a backbuffer depth/stencil handle
     * @param handle The handle to check
     * @returns True if the handle is a backbuffer depth/stencil handle
     */
    isBackbufferDepthStencil(handle: FrameGraphTextureHandle): boolean;
    /**
     * Checks if a handle is a history texture (or points to a history texture, for a dangling handle)
     * @param handle The handle to check
     * @param checkAllTextures If false (default), the function will check if the handle is the main handle of a history texture (the first handle of the history texture).
     *   If true, the function will also check if the handle is one of the other handles of a history texture.
     * @returns True if the handle is a history texture, otherwise false
     */
    isHistoryTexture(handle: FrameGraphTextureHandle, checkAllTextures?: boolean): boolean;
    /**
     * Gets the creation options of a texture
     * @param handle Handle of the texture
     * @param preserveHistoryTextureFlag If true, the isHistoryTexture flag in the returned creation options will be the same as when the texture was created (default: false)
     * @returns The creation options of the texture
     */
    getTextureCreationOptions(handle: FrameGraphTextureHandle, preserveHistoryTextureFlag?: boolean): FrameGraphTextureCreationOptions;
    /**
     * Gets the description of a texture
     * @param handle Handle of the texture
     * @returns The description of the texture
     */
    getTextureDescription(handle: FrameGraphTextureHandle): FrameGraphTextureDescription;
    /**
     * Gets a texture handle or creates a new texture if the handle is not provided.
     * If handle is not provided, newTextureName and creationOptions must be provided.
     * @param handle If provided, will simply return the handle
     * @param newTextureName Name of the new texture to create
     * @param creationOptions Options to use when creating the new texture
     * @returns The handle to the texture.
     */
    getTextureHandleOrCreateTexture(handle?: FrameGraphTextureHandle, newTextureName?: string, creationOptions?: FrameGraphTextureCreationOptions): FrameGraphTextureHandle;
    /**
     * Gets a texture from a handle.
     * Note that if the texture is a history texture, the read texture for the current frame will be returned, except if historyGetWriteTexture is true.
     * @param handle The handle of the texture
     * @param historyGetWriteTexture If true and the texture is a history texture, the write texture for the current frame will be returned (default: false)
     * @returns The texture or null if not found
     */
    getTextureFromHandle(handle: FrameGraphTextureHandle, historyGetWriteTexture?: boolean): Nullable<InternalTexture>;
    /**
     * Imports a texture into the texture manager
     * @param name Name of the texture
     * @param texture Texture to import
     * @param handle Existing handle to use for the texture. If not provided (default), a new handle will be created.
     * @returns The handle to the texture
     */
    importTexture(name: string, texture: InternalTexture, handle?: FrameGraphTextureHandle): FrameGraphTextureHandle;
    /**
     * Creates a new render target texture
     * If multiple textures are described in FrameGraphTextureCreationOptions, the handle of the first texture is returned, handle+1 is the handle of the second texture, etc.
     * @param name Name of the texture
     * @param creationOptions Options to use when creating the texture
     * @param handle Existing handle to use for the texture. If not provided (default), a new handle will be created.
     * @returns The handle to the texture
     */
    createRenderTargetTexture(name: string, creationOptions: FrameGraphTextureCreationOptions, handle?: FrameGraphTextureHandle): FrameGraphTextureHandle;
    /**
     * Creates a (frame graph) render target wrapper
     * Note that renderTargets or renderTargetDepth can be undefined, but not both at the same time!
     * @param name Name of the render target wrapper
     * @param renderTargets Render target handles (textures) to use
     * @param renderTargetDepth Render target depth handle (texture) to use
     * @param depthReadOnly If true, the depth buffer will be read-only
     * @param stencilReadOnly If true, the stencil buffer will be read-only
     * @returns The created render target wrapper
     */
    createRenderTarget(name: string, renderTargets?: FrameGraphTextureHandle | FrameGraphTextureHandle[], renderTargetDepth?: FrameGraphTextureHandle, depthReadOnly?: boolean, stencilReadOnly?: boolean): FrameGraphRenderTarget;
    /**
     * Creates a handle which is not associated with any texture.
     * Call resolveDanglingHandle to associate the handle with a valid texture handle.
     * @returns The dangling handle
     */
    createDanglingHandle(): number;
    /**
     * Associates a texture with a dangling handle
     * @param danglingHandle The dangling handle
     * @param handle The handle to associate with the dangling handle (if not provided, a new texture handle will be created, using the newTextureName and creationOptions parameters)
     * @param newTextureName The name of the new texture to create (if handle is not provided)
     * @param creationOptions The options to use when creating the new texture (if handle is not provided)
     */
    resolveDanglingHandle(danglingHandle: FrameGraphTextureHandle, handle?: FrameGraphTextureHandle, newTextureName?: string, creationOptions?: FrameGraphTextureCreationOptions): void;
    /**
     * Gets the absolute dimensions of a texture.
     * @param size The size of the texture. Width and height must be expressed as a percentage of the screen size (100=100%)!
     * @param screenWidth The width of the screen (default: the width of the rendering canvas)
     * @param screenHeight The height of the screen (default: the height of the rendering canvas)
     * @returns The absolute dimensions of the texture
     */
    getAbsoluteDimensions(size: TextureSize, screenWidth?: number, screenHeight?: number): {
        width: number;
        height: number;
    };
    /**
     * Gets the absolute dimensions of a texture from its handle or creation options.
     * @param handleOrCreationOptions The handle or creation options of the texture
     * @returns The absolute dimensions of the texture
     */
    getTextureAbsoluteDimensions(handleOrCreationOptions: FrameGraphTextureHandle | FrameGraphTextureCreationOptions): {
        width: number;
        height: number;
    };
    /**
     * Calculates the total byte size of all textures used by the frame graph texture manager (including external textures)
     * @param optimizedSize True if the calculation should not factor in aliased textures
     * @param outputWidth The output width of the frame graph. Will be used to calculate the size of percentage-based textures
     * @param outputHeight The output height of the frame graph. Will be used to calculate the size of percentage-based textures
     * @returns The total size of all textures
     */
    computeTotalTextureSize(optimizedSize: boolean, outputWidth: number, outputHeight: number): number;
    /**
     * True if the back buffer texture has been overriden by a call to setBackBufferTexture
     */
    get backBufferTextureOverriden(): boolean;
    /**
     * Overrides the default back buffer color/depth-stencil textures used by the frame graph.
     * Note that if both textureCreationOptions and depthStencilTextureCreationOptions are provided,
     * the engine will use them to create the back buffer color and depth/stencil textures respectively.
     * In that case, width and height are ignored.
     * @param width The width of the back buffer color/depth-stencil texture (if 0, the engine's current back buffer color/depth-stencil texture width will be used)
     * @param height The height of the back buffer color/depth-stencil texture (if 0, the engine's current back buffer color/depth-stencil texture height will be used)
     * @param textureCreationOptions The color texture creation options (optional)
     * @param depthStencilTextureCreationOptions The depth/stencil texture creation options (optional)
     */
    setBackBufferTextures(width: number, height: number, textureCreationOptions?: FrameGraphTextureCreationOptions, depthStencilTextureCreationOptions?: FrameGraphTextureCreationOptions): void;
    /**
     * Resets the back buffer color/depth-stencil textures to the default (the engine's current back buffer textures)
     * It has no effect if setBackBufferTextures has not been called before.
     */
    resetBackBufferTextures(): void;
    /**
     * Returns true if the texture manager has at least one history texture
     */
    get hasHistoryTextures(): boolean;
    /** @internal */
    _dispose(): void;
    /** @internal */
    _allocateTextures(tasks?: FrameGraphTask[]): void;
    /** @internal */
    _releaseTextures(releaseAll?: boolean): void;
    /** @internal */
    _updateHistoryTextures(): void;
    private _addSystemTextures;
    private _createDebugTexture;
    private _freeEntry;
    private _createHandleForTexture;
    private _createTextureDescriptionHash;
    private _optimizeTextureAllocation;
    private _computeTextureLifespan;
    private _computeTextureLifespanForPasses;
    private _updateLifespan;
    /**
     * Clones a texture options
     * @param options The options to clone
     * @param textureIndex The index of the texture in the types, formats, etc array of FrameGraphTextureOptions. If not provided, all options are cloned.
     * @param preserveLabels True if the labels should be preserved (default: false)
     * @returns The cloned options
     */
    static CloneTextureOptions(options: FrameGraphTextureOptions, textureIndex?: number, preserveLabels?: boolean): FrameGraphTextureOptions;
    /**
     * Gets the texture block information.
     * @param type Type of the texture.
     * @param format Format of the texture.
     * @returns The texture block information. You can calculate the byte size of the texture by doing: Math.ceil(width / blockInfo.width) * Math.ceil(height / blockInfo.height) * blockInfo.length
     */
    private static _GetTextureBlockInformation;
}

/**
 * Class used to implement a frame graph
 */
declare class FrameGraph implements IDisposable {
    private readonly _linkedNodeRenderGraph;
    /**
     * Gets the texture manager used by the frame graph
     */
    readonly textureManager: FrameGraphTextureManager;
    private readonly _engine;
    private readonly _scene;
    private readonly _tasks;
    private readonly _passContext;
    private readonly _renderContext;
    private readonly _initAsyncPromises;
    private _currentProcessedTask;
    private _whenReadyAsyncCancel;
    private _importPromise;
    /**
     * Name of the frame graph
     */
    name: string;
    /**
     * Gets the unique id of the frame graph
     */
    readonly uniqueId: number;
    /**
     * Gets or sets a boolean indicating that texture allocation should be optimized (that is, reuse existing textures when possible to limit GPU memory usage) (default: true)
     */
    optimizeTextureAllocation: boolean;
    /**
     * Observable raised when the node render graph is built
     */
    onBuildObservable: Observable<FrameGraph>;
    /**
     * Gets the engine used by the frame graph
     */
    get engine(): AbstractEngine;
    /**
     * Gets the scene used by the frame graph
     */
    get scene(): Scene;
    /**
     * Gets the list of tasks in the frame graph
     */
    get tasks(): FrameGraphTask[];
    /**
     * Indicates whether the execution of the frame graph is paused (default is false)
     */
    pausedExecution: boolean;
    /**
     * Gets the node render graph linked to the frame graph (if any)
     * @returns the linked node render graph or null if none
     */
    getLinkedNodeRenderGraph(): Nullable<NodeRenderGraph>;
    /**
     * Constructs the frame graph
     * @param scene defines the scene the frame graph is associated with
     * @param debugTextures defines a boolean indicating that textures created by the frame graph should be visible in the inspector (default is false)
     * @param _linkedNodeRenderGraph defines the linked node render graph (if any)
     */
    constructor(scene: Scene, debugTextures?: boolean, _linkedNodeRenderGraph?: Nullable<NodeRenderGraph>);
    /**
     * Gets the class name of the frame graph
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets a task by name
     * @param name Name of the task to get
     * @returns The task or undefined if not found
     */
    getTaskByName<T extends FrameGraphTask>(name: string): T | undefined;
    /**
     * Gets all tasks of a specific type
     * @param taskType Type of the task(s) to get
     * @returns The list of tasks of the specified type
     */
    getTasksByType<T extends FrameGraphTask>(taskType: new (...args: any[]) => T): T[];
    /**
     * Gets all tasks of a specific type, based on their class name
     * @param taskClassName Class name(s) of the task(s) to get
     * @returns The list of tasks of the specified type
     */
    getTasksByClassName<T extends FrameGraphTask>(taskClassName: string | string[]): T[];
    /**
     * Adds a task to the frame graph
     * @param task Task to add
     */
    addTask(task: FrameGraphTask): void;
    /**
     * Adds a pass to a task. This method can only be called during a Task.record execution.
     * @param name The name of the pass
     * @param whenTaskDisabled If true, the pass will be added to the list of passes to execute when the task is disabled (default is false)
     * @returns The render pass created
     */
    addPass(name: string, whenTaskDisabled?: boolean): FrameGraphPass<FrameGraphContext>;
    /**
     * Adds a render pass to a task. This method can only be called during a Task.record execution.
     * @param name The name of the pass
     * @param whenTaskDisabled If true, the pass will be added to the list of passes to execute when the task is disabled (default is false)
     * @returns The render pass created
     */
    addRenderPass(name: string, whenTaskDisabled?: boolean): FrameGraphRenderPass;
    /**
     * Adds an object list pass to a task. This method can only be called during a Task.record execution.
     * @param name The name of the pass
     * @param whenTaskDisabled If true, the pass will be added to the list of passes to execute when the task is disabled (default is false)
     * @returns The object list pass created
     */
    addObjectListPass(name: string, whenTaskDisabled?: boolean): FrameGraphObjectListPass;
    private _addPass;
    /** @internal */
    _whenAsynchronousInitializationDoneAsync(): Promise<void>;
    /**
     * Builds the frame graph.
     * This method should be called after all tasks have been added to the frame graph (FrameGraph.addTask) and before the graph is executed (FrameGraph.execute).
     * @param waitForReadiness If true, the method will wait for the frame graph to be ready before returning (default is true)
     */
    buildAsync(waitForReadiness?: boolean): Promise<void>;
    /**
     * Checks if the frame graph is ready to be executed.
     * Note that you can use the whenReadyAsync method to wait for the frame graph to be ready.
     * @returns True if the frame graph is ready to be executed, else false
     */
    isReady(): boolean;
    /**
     * Returns a promise that resolves when the frame graph is ready to be executed.
     * In general, calling await buildAsync() should suffice, as this function also waits for readiness by default.
     * @param timeStep Time step in ms between retries (default is 16)
     * @param maxTimeout Maximum time in ms to wait for the graph to be ready (default is 10000)
     * @returns The promise that resolves when the graph is ready
     */
    whenReadyAsync(timeStep?: number, maxTimeout?: number): Promise<void>;
    /**
     * Executes the frame graph.
     */
    execute(): void;
    /**
     * Clears the frame graph (remove the tasks and release the textures).
     * The frame graph can be built again after this method is called.
     */
    clear(): void;
    /**
     * Disposes the frame graph
     */
    dispose(): void;
}

type NodeRenderGraphValueType = InternalTexture | Camera | FrameGraphObjectList | IShadowLight;
type NodeRenderGraphInputCreationOptions = FrameGraphTextureCreationOptions;
/**
 * Block used to expose an input value
 */
declare class NodeRenderGraphInputBlock extends NodeRenderGraphBlock {
    private _storedValue;
    private _type;
    /** Gets an observable raised when the value is changed */
    onValueChangedObservable: Observable<NodeRenderGraphInputBlock>;
    /** Indicates that the input is externally managed */
    isExternal: boolean;
    /** Gets or sets the options to create the input value */
    creationOptions: NodeRenderGraphInputCreationOptions;
    /**
     * Gets or sets the connection point type (default is Undefined)
     */
    get type(): NodeRenderGraphBlockConnectionPointTypes;
    /**
     * Creates a new NodeRenderGraphInputBlock
     * @param name defines the block name
     * @param frameGraph defines the hosting frame graph
     * @param scene defines the hosting scene
     * @param type defines the type of the input (can be set to NodeRenderGraphBlockConnectionPointTypes.Undefined)
     */
    constructor(name: string, frameGraph: FrameGraph, scene: Scene, type?: NodeRenderGraphBlockConnectionPointTypes);
    /**
     * Set the input block to its default value (based on its type)
     */
    setDefaultValue(): void;
    /**
     * Gets or sets the value of that point.
     */
    get value(): Nullable<NodeRenderGraphValueType>;
    set value(value: Nullable<NodeRenderGraphValueType>);
    /**
     * Gets the value as a specific type
     * @returns the value as a specific type
     */
    getTypedValue<T extends NodeRenderGraphValueType>(): T;
    /**
     * Gets the value as an internal texture
     * @returns The internal texture stored in value if value is an internal texture, otherwise null
     */
    getInternalTextureFromValue(): Nullable<InternalTexture>;
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the output component
     */
    get output(): NodeRenderGraphConnectionPoint;
    /**
     * Check if the block is a texture of any type
     * @returns true if the block is a texture
     */
    isAnyTexture(): boolean;
    /**
     * Gets a boolean indicating that the connection point is the back buffer texture
     * @returns true if the connection point is the back buffer texture
     */
    isBackBuffer(): boolean;
    /**
     * Gets a boolean indicating that the connection point is a depth/stencil attachment texture
     * @returns true if the connection point is a depth/stencil attachment texture
     */
    isBackBufferDepthStencilAttachment(): boolean;
    /**
     * Check if the block is a camera
     * @returns true if the block is a camera
     */
    isCamera(): boolean;
    /**
     * Check if the block is an object list
     * @returns true if the block is an object list
     */
    isObjectList(): boolean;
    /**
     * Check if the block is a shadow light
     * @returns true if the block is a shadow light
     */
    isShadowLight(): boolean;
    protected _buildBlock(state: NodeRenderGraphBuildState): void;
    dispose(): void;
    protected _dumpPropertiesCode(): string;
    serialize(): any;
    _deserialize(serializationObject: any): void;
}

/**
 * Defines a node render graph
 */
declare class NodeRenderGraph {
    private static _BuildIdGenerator;
    private _buildId;
    /** Define the Url to load node editor script */
    static EditorURL: string;
    /** Define the Url to load snippets */
    static SnippetUrl: string;
    /** Description of custom blocks to use in the node render graph editor */
    static CustomBlockDescriptions: INodeRenderGraphCustomBlockDescription[];
    private BJSNODERENDERGRAPHEDITOR;
    /** @returns the inspector from bundle or global */
    private _getGlobalNodeRenderGraphEditor;
    /**
     * Gets or sets data used by visual editor
     * @see https://nrge.babylonjs.com
     */
    editorData: any;
    /**
     * Gets an array of blocks that needs to be serialized even if they are not yet connected
     */
    attachedBlocks: NodeRenderGraphBlock[];
    /**
     * Observable raised before the node render graph is built
     */
    onBeforeBuildObservable: Observable<FrameGraph>;
    /**
     * Observable raised after the node render graph is built
     * Note that this is the same observable as the one in the underlying FrameGraph!
     */
    get onBuildObservable(): Observable<FrameGraph>;
    /**
     * Observable raised when an error is detected
     */
    onBuildErrorObservable: Observable<string>;
    /** Gets or sets the RenderGraphOutputBlock used to gather the final node render graph data */
    outputBlock: Nullable<NodeRenderGraphOutputBlock>;
    /**
     * Snippet ID if the graph was created from the snippet server
     */
    snippetId: string;
    /**
     * The name of the node render graph
     */
    name: string;
    /**
     * A free comment about the graph
     */
    comment: string;
    private readonly _engine;
    private readonly _scene;
    private readonly _resizeObserver;
    private readonly _frameGraph;
    private readonly _options;
    /**
     * Gets the frame graph used by this node render graph
     */
    get frameGraph(): FrameGraph;
    /**
     * Gets the scene used by this node render graph
     * @returns the scene used by this node render graph
     */
    getScene(): Scene;
    /**
     * Gets the options used to create this node render graph
     */
    get options(): Immutable<INodeRenderGraphCreateOptions>;
    /**
     * Creates a new node render graph
     * @param name defines the name of the node render graph
     * @param scene defines the scene to use to execute the graph
     * @param options defines the options to use when creating the graph
     */
    constructor(name: string, scene: Scene, options?: INodeRenderGraphCreateOptions);
    /**
     * Gets the current class name ("NodeRenderGraph")
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets a block by its name
     * @param name defines the name of the block to retrieve
     * @returns the required block or null if not found
     */
    getBlockByName<T extends NodeRenderGraphBlock>(name: string): Nullable<T>;
    /**
     * Get a block using a predicate
     * @param predicate defines the predicate used to find the good candidate
     * @returns the required block or null if not found
     */
    getBlockByPredicate<T extends NodeRenderGraphBlock>(predicate: (block: NodeRenderGraphBlock) => boolean): Nullable<T>;
    /**
     * Get all blocks that match a predicate
     * @param predicate defines the predicate used to find the good candidate(s)
     * @returns the list of blocks found
     */
    getBlocksByPredicate<T extends NodeRenderGraphBlock>(predicate: (block: NodeRenderGraphBlock) => boolean): T[];
    /**
     * Gets the list of input blocks attached to this material
     * @returns an array of InputBlocks
     */
    getInputBlocks(): NodeRenderGraphInputBlock[];
    /**
     * Launch the node render graph editor
     * @param config Define the configuration of the editor
     * @returns a promise fulfilled when the node editor is visible
     */
    edit(config?: INodeRenderGraphEditorOptions): Promise<void>;
    /**
     * Creates the node editor window.
     * @param additionalConfig Additional configuration for the FGE
     */
    private _createNodeEditor;
    /**
     * Build the final list of blocks that will be executed by the "execute" method.
     * It also builds the underlying frame graph unless specified otherwise.
     * @param dontBuildFrameGraph If the underlying frame graph should not be built (default: false)
     * @param waitForReadiness If the method should wait for the frame graph to be ready before resolving (default: true). Note that this parameter has no effect if "dontBuildFrameGraph" is true.
     * @param setAsSceneFrameGraph If the built frame graph must be set as the scene's frame graph (default: true)
     */
    buildAsync(dontBuildFrameGraph?: boolean, waitForReadiness?: boolean, setAsSceneFrameGraph?: boolean): Promise<void>;
    private _autoFillExternalInputs;
    /**
     * Returns a promise that resolves when the node render graph is ready to be executed
     * This method must be called after the graph has been built (NodeRenderGraph.build called)!
     * @param timeStep Time step in ms between retries (default is 16)
     * @param maxTimeout Maximum time in ms to wait for the graph to be ready (default is 10000)
     * @returns The promise that resolves when the graph is ready
     */
    whenReadyAsync(timeStep?: number, maxTimeout?: number): Promise<void>;
    /**
     * Execute the graph (the graph must have been built before!)
     */
    execute(): void;
    private _initializeBlock;
    /**
     * Clear the current graph
     */
    clear(): void;
    /**
     * Remove a block from the current graph
     * @param block defines the block to remove
     */
    removeBlock(block: NodeRenderGraphBlock): void;
    /**
     * Clear the current graph and load a new one from a serialization object
     * @param source defines the JSON representation of the graph
     * @param merge defines whether or not the source must be merged or replace the current content
     */
    parseSerializedObject(source: any, merge?: boolean): void;
    private _restoreConnections;
    /**
     * Generate a string containing the code declaration required to create an equivalent of this node render graph
     * @returns a string
     */
    generateCode(): string;
    private _gatherBlocks;
    /**
     * Clear the current graph and set it to a default state
     */
    setToDefault(): void;
    /**
     * Makes a duplicate of the current node render graph.
     * Note that you should call buildAsync() on the returned graph to make it usable.
     * @param name defines the name to use for the new node render graph
     * @returns the new node render graph
     */
    clone(name: string): NodeRenderGraph;
    /**
     * Serializes this node render graph in a JSON representation
     * @param selectedBlocks defines the list of blocks to save (if null the whole node render graph will be saved)
     * @returns the serialized node render graph object
     */
    serialize(selectedBlocks?: NodeRenderGraphBlock[]): any;
    /**
     * Disposes the resources
     */
    dispose(): void;
    /**
     * Creates a new node render graph set to default basic configuration
     * @param name defines the name of the node render graph
     * @param scene defines the scene to use
     * @param nodeRenderGraphOptions defines options to use when creating the node render graph
     * @returns a new NodeRenderGraph
     */
    static CreateDefaultAsync(name: string, scene: Scene, nodeRenderGraphOptions?: INodeRenderGraphCreateOptions): Promise<NodeRenderGraph>;
    /**
     * Creates a node render graph from parsed graph data
     * @param source defines the JSON representation of the node render graph
     * @param scene defines the scene to use
     * @param nodeRenderGraphOptions defines options to use when creating the node render
     * @param skipBuild defines whether to skip building the node render graph (default is true)
     * @returns a new node render graph
     */
    static Parse(source: any, scene: Scene, nodeRenderGraphOptions?: INodeRenderGraphCreateOptions, skipBuild?: boolean): NodeRenderGraph;
    /**
     * Creates a node render graph from a snippet saved by the node render graph editor
     * @param snippetId defines the snippet to load
     * @param scene defines the scene to use
     * @param nodeRenderGraphOptions defines options to use when creating the node render graph
     * @param nodeRenderGraph defines a node render graph to update (instead of creating a new one)
     * @param skipBuild defines whether to skip building the node render graph (default is true)
     * @returns a promise that will resolve to the new node render graph
     */
    static ParseFromSnippetAsync(snippetId: string, scene: Scene, nodeRenderGraphOptions?: INodeRenderGraphCreateOptions, nodeRenderGraph?: NodeRenderGraph, skipBuild?: boolean): Promise<NodeRenderGraph>;
}

/**
 * Class used to store node based render graph build state
 */
declare class NodeRenderGraphBuildState {
    /** Gets or sets the build identifier */
    buildId: number;
    /** Gets or sets a boolean indicating that verbose mode is on */
    verbose: boolean;
    /**
     * Gets or sets the list of non connected mandatory inputs
     * @internal
     */
    _notConnectedNonOptionalInputs: NodeRenderGraphConnectionPoint[];
    /**
     * Emits console errors and exceptions if there is a failing check
     * @param errorObservable defines an Observable to send the error message
     * @returns true if all checks pass
     */
    emitErrors(errorObservable?: Nullable<Observable<string>>): boolean;
}

/**
 * Glow layer options. This helps customizing the behaviour
 * of the glow layer.
 */
interface IThinGlowLayerOptions extends IThinEffectLayerOptions {
    /**
     * How big is the kernel of the blur texture. Default: 32
     */
    blurKernelSize?: number;
    /**
     * Forces the merge step to be done in ldr (clamp values > 1). Default: false
     */
    ldrMerge?: boolean;
    /**
     * Exclude all meshes from the glow layer by default.
     * This is useful if you have dynamic meshes and you want to control them specifically and
     * make sure that there are no "leaking" glowing meshes.
     * Default: false
     */
    excludeByDefault?: boolean;
}
/**
 * @internal
 */
declare class ThinGlowLayer extends ThinEffectLayer {
    /**
     * Effect Name of the layer.
     */
    static readonly EffectName = "GlowLayer";
    /**
     * The default blur kernel size used for the glow.
     */
    static DefaultBlurKernelSize: number;
    /**
     * Gets the ldrMerge option.
     */
    get ldrMerge(): boolean;
    /**
     * Sets the kernel size of the blur.
     */
    set blurKernelSize(value: number);
    /**
     * Gets the kernel size of the blur.
     */
    get blurKernelSize(): number;
    /**
     * Sets the glow intensity.
     */
    set intensity(value: number);
    /**
     * Gets the glow intensity.
     */
    get intensity(): number;
    /** @internal */
    _options: Required<IThinGlowLayerOptions>;
    private _intensity;
    private _horizontalBlurPostprocess1;
    private _verticalBlurPostprocess1;
    private _horizontalBlurPostprocess2;
    private _verticalBlurPostprocess2;
    /** @internal */
    _includedOnlyMeshes: number[];
    /** @internal */
    _excludedMeshes: number[];
    private _meshesUsingTheirOwnMaterials;
    /**
     * Callback used to let the user override the color selection on a per mesh basis
     */
    customEmissiveColorSelector: (mesh: Mesh, subMesh: SubMesh, material: Material, result: Color4) => void;
    /**
     * Callback used to let the user override the texture selection on a per mesh basis
     */
    customEmissiveTextureSelector: (mesh: Mesh, subMesh: SubMesh, material: Material) => Texture;
    /** @internal */
    _renderPassId: number;
    /**
     * Instantiates a new glow Layer and references it to the scene.
     * @param name The name of the layer
     * @param scene The scene to use the layer in
     * @param options Sets of none mandatory options to use with the layer (see IGlowLayerOptions for more information)
     * @param dontCheckIfReady Specifies if the layer should disable checking whether all the post processes are ready (default: false). To save performance, this should be set to true and you should call `isReady` manually before rendering to the layer.
     */
    constructor(name: string, scene?: Scene, options?: IThinGlowLayerOptions, dontCheckIfReady?: boolean);
    /**
     * Gets the class name of the thin glow layer
     * @returns the string with the class name of the glow layer
     */
    getClassName(): string;
    protected _importShadersAsync(): Promise<void>;
    getEffectName(): string;
    /** @internal */
    _internalShouldRender(): boolean;
    _createMergeEffect(): Effect;
    _createTextureAndPostProcesses(): void;
    private _getEffectiveBlurKernelSize;
    isReady(subMesh: SubMesh, useInstances: boolean): boolean;
    _canRenderMesh(_mesh: AbstractMesh, _material: Material): boolean;
    _internalCompose(effect: Effect): void;
    _setEmissiveTextureAndColor(mesh: Mesh, subMesh: SubMesh, material: Material): void;
    _shouldRenderMesh(mesh: Mesh): boolean;
    _addCustomEffectDefines(defines: string[]): void;
    /**
     * Add a mesh in the exclusion list to prevent it to impact or being impacted by the glow layer.
     * This will not have an effect if meshes are excluded by default (see setExcludedByDefault).
     * @param mesh The mesh to exclude from the glow layer
     */
    addExcludedMesh(mesh: Mesh): void;
    /**
     * Remove a mesh from the exclusion list to let it impact or being impacted by the glow layer.
     * This will not have an effect if meshes are excluded by default (see setExcludedByDefault).
     * @param mesh The mesh to remove
     */
    removeExcludedMesh(mesh: Mesh): void;
    /**
     * Add a mesh in the inclusion list to impact or being impacted by the glow layer.
     * @param mesh The mesh to include in the glow layer
     */
    addIncludedOnlyMesh(mesh: Mesh): void;
    /**
     * Remove a mesh from the Inclusion list to prevent it to impact or being impacted by the glow layer.
     * @param mesh The mesh to remove
     */
    removeIncludedOnlyMesh(mesh: Mesh): void;
    /**
     * Set the excluded by default option.
     * If true, all meshes will be excluded by default unless they are added to the inclusion list.
     * @param value The boolean value to set the excluded by default option to
     */
    setExcludedByDefault(value: boolean): void;
    hasMesh(mesh: AbstractMesh): boolean;
    _useMeshMaterial(mesh: AbstractMesh): boolean;
    /**
     * Add a mesh to be rendered through its own material and not with emissive only.
     * @param mesh The mesh for which we need to use its material
     */
    referenceMeshToUseItsOwnMaterial(mesh: AbstractMesh): void;
    /**
     * Remove a mesh from being rendered through its own material and not with emissive only.
     * @param mesh The mesh for which we need to not use its material
     * @param renderPassId The render pass id used when rendering the mesh
     */
    unReferenceMeshFromUsingItsOwnMaterial(mesh: AbstractMesh, renderPassId: number): void;
    /** @internal */
    _disposeMesh(mesh: Mesh): void;
}

/**
 * Base class for frame graph tasks that involve multi-target rendering.
 */
declare abstract class FrameGraphTaskMultiRenderTarget extends FrameGraphTask {
    private _outputLayerAndFaceIndices;
    private _layerAndFaceIndicesUpdated;
    /**
     * Sets the output layer and face indices for multi-target rendering.
     * @param indices The array of layer and face indices.
     */
    setOutputLayerAndFaceIndices(indices: LayerAndFaceIndex[]): void;
    protected _updateLayerAndFaceIndices(pass: FrameGraphRenderPass): void;
}

/**
 * @internal
 */
declare class ThinDepthPeelingRenderer {
    protected _scene: Scene;
    protected _engine: AbstractEngine;
    protected _depthMrts: MultiRenderTarget[];
    protected _thinTextures: ThinTexture[];
    protected _colorMrts: MultiRenderTarget[];
    protected _blendBackMrt: MultiRenderTarget;
    protected _blendBackEffectWrapper: EffectWrapper;
    protected _blendBackEffectWrapperPingPong: EffectWrapper;
    protected _finalEffectWrapper: EffectWrapper;
    protected _effectRenderer: EffectRenderer;
    protected _currentPingPongState: number;
    protected _layoutCacheFormat: boolean[][];
    protected _layoutCache: number[][];
    protected _renderPassIds: number[];
    protected _candidateSubMeshes: SmartArray<SubMesh>;
    protected _excludedSubMeshes: SmartArray<SubMesh>;
    protected _excludedMeshes: number[];
    protected static _DEPTH_CLEAR_VALUE: number;
    protected static _MIN_DEPTH: number;
    protected static _MAX_DEPTH: number;
    protected _colorCache: Color4[];
    protected _passCount: number;
    /**
     * Number of depth peeling passes. As we are using dual depth peeling, each pass two levels of transparency are processed.
     */
    get passCount(): number;
    set passCount(count: number);
    protected _useRenderPasses: boolean;
    /**
     * Instructs the renderer to use render passes. It is an optimization that makes the rendering faster for some engines (like WebGPU) but that consumes more memory, so it is disabled by default.
     */
    get useRenderPasses(): boolean;
    set useRenderPasses(usePasses: boolean);
    /**
     * Add a mesh in the exclusion list to prevent it to be handled by the depth peeling renderer
     * @param mesh The mesh to exclude from the depth peeling renderer
     */
    addExcludedMesh(mesh: AbstractMesh): void;
    /**
     * Remove a mesh from the exclusion list of the depth peeling renderer
     * @param mesh The mesh to remove
     */
    removeExcludedMesh(mesh: AbstractMesh): void;
    /** Shader language used by the renderer */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this renderer
     */
    get shaderLanguage(): ShaderLanguage;
    private _blendOutput;
    /**
     * Sets the render target wrapper we will blend the transparent objects onto
     */
    get blendOutput(): Nullable<RenderTargetWrapper>;
    set blendOutput(blendOutput: Nullable<RenderTargetWrapper>);
    /**
     * Instanciates the depth peeling renderer
     * @param scene Scene to attach to
     * @param passCount Number of depth layers to peel
     * @returns The depth peeling renderer
     */
    constructor(scene: Scene, passCount?: number);
    private _createRenderPassIds;
    private _releaseRenderPassIds;
    protected _getTextureSize(): {
        width: number;
        height: number;
    };
    protected _createTextures(): void;
    protected _disposeTextures(): void;
    protected _createEffects(finalEffectFragmentShaderName: string, finalEffectSamplerNames: string[]): void;
    /**
     * Links to the prepass renderer
     * @param _prePassRenderer The scene PrePassRenderer
     */
    setPrePassRenderer(_prePassRenderer: PrePassRenderer): void;
    /**
     * Binds depth peeling textures on an effect
     * @param effect The effect to bind textures on
     */
    bind(effect: Effect): void;
    private _renderSubMeshes;
    protected _finalCompose(writeId: number): void;
    /**
     * Checks if the depth peeling renderer is ready to render transparent meshes
     * @returns true if the depth peeling renderer is ready to render the transparent meshes
     */
    isReady(): boolean;
    protected _beforeRender(): void;
    protected _afterRender(): void;
    protected _noTransparentMeshes(): void;
    /**
     * Renders transparent submeshes with depth peeling
     * @param transparentSubMeshes List of transparent meshes to render
     * @returns The array of submeshes that could not be handled by this renderer
     */
    render(transparentSubMeshes: SmartArray<SubMesh>): SmartArray<SubMesh>;
    /**
     * Disposes the depth peeling renderer and associated resources
     */
    dispose(): void;
}

/**
 * Task used to render objects to a texture.
 */
declare class FrameGraphObjectRendererTask extends FrameGraphTaskMultiRenderTarget {
    /**
     * The target texture(s) where the objects will be rendered.
     */
    targetTexture: FrameGraphTextureHandle | FrameGraphTextureHandle[];
    /**
     * The depth attachment texture where the objects will be rendered (optional).
     */
    depthTexture?: FrameGraphTextureHandle;
    /**
     * The shadow generators used to render the objects (optional).
     */
    shadowGenerators?: FrameGraphShadowGeneratorTask[];
    private _camera;
    /**
     * Gets or sets the camera used to render the objects.
     */
    get camera(): Camera;
    set camera(camera: Camera);
    /**
     * The list of objects to render.
     */
    objectList: FrameGraphObjectList;
    /**
     * If depth testing should be enabled (default is true).
     */
    depthTest: boolean;
    /**
     * If depth writing should be enabled (default is true).
     */
    depthWrite: boolean;
    /**
     * If shadows should be disabled (default is false).
     */
    disableShadows: boolean;
    private _disableImageProcessing;
    /**
     * If image processing should be disabled (default is false).
     * false means that the default image processing configuration will be applied (the one from the scene)
     */
    get disableImageProcessing(): boolean;
    set disableImageProcessing(value: boolean);
    /**
     * Sets this property to true if this task is the main object renderer of the frame graph.
     * It will help to locate the main object renderer in the frame graph when multiple object renderers are used.
     * This is useful for the inspector to know which object renderer to use for additional rendering features like wireframe rendering or frustum light debugging.
     * It is also used to determine the main camera used by the frame graph: this is the camera used by the main object renderer.
     */
    isMainObjectRenderer: boolean;
    private _renderMeshes;
    /**
     * Defines if meshes should be rendered (default is true).
     */
    get renderMeshes(): boolean;
    set renderMeshes(value: boolean);
    private _renderDepthOnlyMeshes;
    /**
     * Defines if depth only meshes should be rendered (default is true). Always subject to the renderMeshes property, though.
     */
    get renderDepthOnlyMeshes(): boolean;
    set renderDepthOnlyMeshes(value: boolean);
    private _renderOpaqueMeshes;
    /**
     * Defines if opaque meshes should be rendered (default is true). Always subject to the renderMeshes property, though.
     */
    get renderOpaqueMeshes(): boolean;
    set renderOpaqueMeshes(value: boolean);
    private _renderAlphaTestMeshes;
    /**
     * Defines if alpha test meshes should be rendered (default is true). Always subject to the renderMeshes property, though.
     */
    get renderAlphaTestMeshes(): boolean;
    set renderAlphaTestMeshes(value: boolean);
    private _renderTransparentMeshes;
    /**
     * Defines if transparent meshes should be rendered (default is true). Always subject to the renderMeshes property, though.
     */
    get renderTransparentMeshes(): boolean;
    set renderTransparentMeshes(value: boolean);
    private _useOITForTransparentMeshes;
    /**
     * Defines if Order Independent Transparency should be used for transparent meshes (default is false).
     */
    get useOITForTransparentMeshes(): boolean;
    set useOITForTransparentMeshes(value: boolean);
    /**
     * Defines the number of passes to use for Order Independent Transparency (default is 5).
     */
    get oitPassCount(): number;
    set oitPassCount(value: number);
    private _renderParticles;
    /**
     * Defines if particles should be rendered (default is true).
     */
    get renderParticles(): boolean;
    set renderParticles(value: boolean);
    private _renderSprites;
    /**
     * Defines if sprites should be rendered (default is true).
     */
    get renderSprites(): boolean;
    set renderSprites(value: boolean);
    private _forceLayerMaskCheck;
    /**
     * Forces checking the layerMask property even if a custom list of meshes is provided (ie. if renderList is not undefined). Default is true.
     */
    get forceLayerMaskCheck(): boolean;
    set forceLayerMaskCheck(value: boolean);
    private _enableBoundingBoxRendering;
    /**
     * Enables the rendering of bounding boxes for meshes (still subject to Mesh.showBoundingBox or scene.forceShowBoundingBoxes). Default is true.
     */
    get enableBoundingBoxRendering(): boolean;
    set enableBoundingBoxRendering(value: boolean);
    private _enableOutlineRendering;
    /**
     * Enables the rendering of outlines/overlays for meshes (still subject to Mesh.renderOutline/Mesh.renderOverlay). Default is true.
     */
    get enableOutlineRendering(): boolean;
    set enableOutlineRendering(value: boolean);
    /**
     * If true, targetTexture will be resolved at the end of the render pass, if this/these texture(s) is/are MSAA (default: true)
     */
    resolveMSAAColors: boolean;
    /**
     * If true, depthTexture will be resolved at the end of the render pass, if this texture is provided and is MSAA (default: false).
     */
    resolveMSAADepth: boolean;
    /**
     * The output texture.
     * This texture will point to the same texture than the targetTexture property.
     * Note, however, that the handle itself will be different!
     */
    readonly outputTexture: FrameGraphTextureHandle;
    /**
     * The output depth attachment texture.
     * This texture will point to the same texture than the depthTexture property if it is set.
     * Note, however, that the handle itself will be different!
     */
    readonly outputDepthTexture: FrameGraphTextureHandle;
    /**
     * The object renderer used to render the objects.
     */
    get objectRenderer(): ObjectRenderer;
    get name(): string;
    set name(value: string);
    protected readonly _engine: AbstractEngine;
    protected readonly _scene: Scene;
    protected readonly _renderer: ObjectRenderer;
    protected readonly _oitRenderer: ThinDepthPeelingRenderer;
    protected _textureWidth: number;
    protected _textureHeight: number;
    protected _onBeforeRenderObservable: Nullable<Observer<number>>;
    protected _onAfterRenderObservable: Nullable<Observer<number>>;
    protected _externalObjectRenderer: boolean;
    protected _rtForOrderIndependentTransparency: FrameGraphRenderTarget;
    /**
     * Constructs a new object renderer task.
     * @param name The name of the task.
     * @param frameGraph The frame graph the task belongs to.
     * @param scene The scene the frame graph is associated with.
     * @param options The options of the object renderer.
     * @param existingObjectRenderer An existing object renderer to use (optional). If provided, the options parameter will be ignored.
     */
    constructor(name: string, frameGraph: FrameGraph, scene: Scene, options?: ObjectRendererOptions, existingObjectRenderer?: ObjectRenderer);
    isReady(): boolean;
    getClassName(): string;
    record(skipCreationOfDisabledPasses?: boolean, additionalExecute?: (context: FrameGraphRenderContext) => void): FrameGraphRenderPass;
    dispose(): void;
    protected _resolveDanglingHandles(targetTextures: FrameGraphTextureHandle[]): void;
    protected _checkParameters(): void;
    protected _checkTextureCompatibility(targetTextures: FrameGraphTextureHandle[]): boolean;
    protected _getTargetHandles(): FrameGraphTextureHandle[];
    protected _prepareRendering(context: FrameGraphRenderContext, depthEnabled: boolean): Nullable<number[]>;
    protected _setLightsForShadow(): void;
    protected _renderTransparentMeshesWithOIT(transparentSubMeshes: SmartArray<SubMesh>): void;
    protected _sceneHasClusteredLights(): boolean;
}

/**
 * Highlight layer options. This helps customizing the behaviour
 * of the highlight layer.
 */
interface IThinHighlightLayerOptions extends IThinEffectLayerOptions {
    /**
     * Multiplication factor apply to the main texture size in the first step of the blur to reduce the size
     * of the picture to blur (the smaller the faster). Default: 0.5
     */
    blurTextureSizeRatio?: number;
    /**
     * How big in texel of the blur texture is the vertical blur. Default: 1
     */
    blurVerticalSize?: number;
    /**
     * How big in texel of the blur texture is the horizontal blur. Default: 1
     */
    blurHorizontalSize?: number;
    /**
     * Should we display highlight as a solid stroke? Default: false
     */
    isStroke?: boolean;
    /**
     * Use the GLSL code generation for the shader (even on WebGPU). Default is false
     */
    forceGLSL?: boolean;
}
/**
 * Storage interface grouping all the information required for glowing a mesh.
 */
interface IHighlightLayerMesh {
    /**
     * The glowy mesh
     */
    mesh: Mesh;
    /**
     * The color of the glow
     */
    color: Color3;
    /**
     * The mesh render callback use to insert stencil information
     */
    observerHighlight: Nullable<Observer<Mesh>>;
    /**
     * The mesh render callback use to come to the default behavior
     */
    observerDefault: Nullable<Observer<Mesh>>;
    /**
     * If it exists, the emissive color of the material will be used to generate the glow.
     * Else it falls back to the current color.
     */
    glowEmissiveOnly: boolean;
}
/**
 * Storage interface grouping all the information required for an excluded mesh.
 */
interface IHighlightLayerExcludedMesh {
    /**
     * The glowy mesh
     */
    mesh: Mesh;
    /**
     * The mesh render callback use to prevent stencil use
     */
    beforeBind: Nullable<Observer<Mesh>>;
    /**
     * The mesh render callback use to restore previous stencil use
     */
    afterRender: Nullable<Observer<Mesh>>;
    /**
     * Current stencil state of the engine
     */
    stencilState: boolean;
}
/**
 * @internal
 */
declare class ThinHighlightLayer extends ThinEffectLayer {
    /**
     * Effect Name of the highlight layer.
     */
    static readonly EffectName = "HighlightLayer";
    /**
     * The neutral color used during the preparation of the glow effect.
     * This is black by default as the blend operation is a blend operation.
     */
    static NeutralColor: Color4;
    /**
     * Stencil value used for glowing meshes.
     */
    static GlowingMeshStencilReference: number;
    /**
     * Stencil value used for the other meshes in the scene.
     */
    static NormalMeshStencilReference: number;
    /**
     * Specifies whether or not the inner glow is ACTIVE in the layer.
     */
    innerGlow: boolean;
    /**
     * Specifies whether or not the outer glow is ACTIVE in the layer.
     */
    outerGlow: boolean;
    /**
     * Specifies the horizontal size of the blur.
     */
    set blurHorizontalSize(value: number);
    /**
     * Specifies the vertical size of the blur.
     */
    set blurVerticalSize(value: number);
    /**
     * Gets the horizontal size of the blur.
     */
    get blurHorizontalSize(): number;
    /**
     * Gets the vertical size of the blur.
     */
    get blurVerticalSize(): number;
    private _instanceGlowingMeshStencilReference;
    /** @internal */
    _options: Required<IThinHighlightLayerOptions>;
    private _downSamplePostprocess;
    private _horizontalBlurPostprocess;
    private _verticalBlurPostprocess;
    /** @internal */
    _meshes: Nullable<{
        [id: string]: Nullable<IHighlightLayerMesh>;
    }>;
    /** @internal */
    _excludedMeshes: Nullable<{
        [id: string]: Nullable<IHighlightLayerExcludedMesh>;
    }>;
    /** @internal */
    _mainObjectRendererRenderPassId: number;
    /**
     * Instantiates a new highlight Layer and references it to the scene..
     * @param name The name of the layer
     * @param scene The scene to use the layer in
     * @param options Sets of none mandatory options to use with the layer (see IHighlightLayerOptions for more information)
     * @param dontCheckIfReady Specifies if the layer should disable checking whether all the post processes are ready (default: false). To save performance, this should be set to true and you should call `isReady` manually before rendering to the layer.
     */
    constructor(name: string, scene?: Scene, options?: Partial<IThinHighlightLayerOptions>, dontCheckIfReady?: boolean);
    /**
     * Gets the class name of the effect layer
     * @returns the string with the class name of the effect layer
     */
    getClassName(): string;
    protected _importShadersAsync(): Promise<void>;
    getEffectName(): string;
    _numInternalDraws(): number;
    _createMergeEffect(): Effect;
    _createTextureAndPostProcesses(): void;
    needStencil(): boolean;
    isReady(subMesh: SubMesh, useInstances: boolean): boolean;
    _canRenderMesh(_mesh: AbstractMesh, _material: Material): boolean;
    _internalCompose(effect: Effect, renderIndex: number): void;
    _setEmissiveTextureAndColor(mesh: Mesh, _subMesh: SubMesh, material: Material): void;
    shouldRender(): boolean;
    _shouldRenderMesh(mesh: Mesh): boolean;
    _addCustomEffectDefines(defines: string[]): void;
    /**
     * Add a mesh in the exclusion list to prevent it to impact or being impacted by the highlight layer.
     * @param mesh The mesh to exclude from the highlight layer
     */
    addExcludedMesh(mesh: Mesh): void;
    /**
     * Remove a mesh from the exclusion list to let it impact or being impacted by the highlight layer.
     * @param mesh The mesh to highlight
     */
    removeExcludedMesh(mesh: Mesh): void;
    hasMesh(mesh: AbstractMesh): boolean;
    /**
     * Add a mesh in the highlight layer in order to make it glow with the chosen color.
     * @param mesh The mesh to highlight
     * @param color The color of the highlight
     * @param glowEmissiveOnly Extract the glow from the emissive texture
     */
    addMesh(mesh: Mesh, color: Color3, glowEmissiveOnly?: boolean): void;
    /**
     * Remove a mesh from the highlight layer in order to make it stop glowing.
     * @param mesh The mesh to highlight
     */
    removeMesh(mesh: Mesh): void;
    /**
     * Remove all the meshes currently referenced in the highlight layer
     */
    removeAllMeshes(): void;
    private _defaultStencilReference;
    _disposeMesh(mesh: Mesh): void;
    dispose(): void;
}

/**
 * This represents a depth renderer in Babylon.
 * A depth renderer will render to it's depth map every frame which can be displayed or used in post processing
 */
declare class DepthRenderer {
    private _scene;
    private _depthMap;
    private readonly _storeNonLinearDepth;
    private readonly _storeCameraSpaceZ;
    /** Shader language used by the material */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this material.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Force all the depth renderer to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /** Color used to clear the depth texture. Default: (1,0,0,1) */
    clearColor: Color4;
    /** Get if the depth renderer is using packed depth or not */
    readonly isPacked: boolean;
    private _camera;
    /** Enable or disable the depth renderer. When disabled, the depth texture is not updated */
    enabled: boolean;
    /** Force writing the transparent objects into the depth map */
    forceDepthWriteTransparentMeshes: boolean;
    /**
     * Specifies that the depth renderer will only be used within
     * the camera it is created for.
     * This can help forcing its rendering during the camera processing.
     */
    useOnlyInActiveCamera: boolean;
    /** If true, reverse the culling of materials before writing to the depth texture.
     * So, basically, when "true", back facing instead of front facing faces are rasterized into the texture
     */
    reverseCulling: boolean;
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    /**
     * Sets a specific material to be used to render a mesh/a list of meshes by the depth renderer
     * @param mesh mesh or array of meshes
     * @param material material to use by the depth render when rendering the mesh(es). If undefined is passed, the specific material created by the depth renderer will be used.
     */
    setMaterialForRendering(mesh: AbstractMesh | AbstractMesh[], material?: Material): void;
    /**
     * Instantiates a depth renderer
     * @param scene The scene the renderer belongs to
     * @param type The texture type of the depth map (default: Engine.TEXTURETYPE_FLOAT)
     * @param camera The camera to be used to render the depth map (default: scene's active camera)
     * @param storeNonLinearDepth Defines whether the depth is stored linearly like in Babylon Shadows or directly like glFragCoord.z
     * @param samplingMode The sampling mode to be used with the render target (Linear, Nearest...) (default: TRILINEAR_SAMPLINGMODE)
     * @param storeCameraSpaceZ Defines whether the depth stored is the Z coordinate in camera space. If true, storeNonLinearDepth has no effect. (Default: false)
     * @param name Name of the render target (default: DepthRenderer)
     * @param existingRenderTargetTexture An existing render target texture to use (default: undefined). If not provided, a new render target texture will be created.
     */
    constructor(scene: Scene, type?: number, camera?: Nullable<Camera>, storeNonLinearDepth?: boolean, samplingMode?: number, storeCameraSpaceZ?: boolean, name?: string, existingRenderTargetTexture?: RenderTargetTexture);
    private _shadersLoaded;
    private _initShaderSourceAsync;
    /**
     * Creates the depth rendering effect and checks if the effect is ready.
     * @param subMesh The submesh to be used to render the depth map of
     * @param useInstances If multiple world instances should be used
     * @returns if the depth renderer is ready to render the depth map
     */
    isReady(subMesh: SubMesh, useInstances: boolean): boolean;
    /**
     * Gets the texture which the depth map will be written to.
     * @returns The depth map texture
     */
    getDepthMap(): RenderTargetTexture;
    /**
     * Disposes of the depth renderer.
     */
    dispose(): void;
}

/**
 * Task used to generate shadows from a list of objects.
 */
declare class FrameGraphShadowGeneratorTask extends FrameGraphTask {
    /**
     * The object list that generates shadows.
     */
    objectList: FrameGraphObjectList;
    private _light;
    /**
     * The light to generate shadows from.
     */
    get light(): IShadowLight;
    set light(value: IShadowLight);
    private _camera;
    /**
     * Gets or sets the camera used to generate the shadow generator.
     */
    get camera(): Camera;
    set camera(camera: Camera);
    private _mapSize;
    /**
     * The size of the shadow map.
     */
    get mapSize(): number;
    set mapSize(value: number);
    private _useFloat32TextureType;
    /**
     * If true, the shadow map will use a 32 bits float texture type (else, 16 bits float is used if supported).
     */
    get useFloat32TextureType(): boolean;
    set useFloat32TextureType(value: boolean);
    private _useRedTextureFormat;
    /**
     * If true, the shadow map will use a red texture format (else, a RGBA format is used).
     */
    get useRedTextureFormat(): boolean;
    set useRedTextureFormat(value: boolean);
    private _bias;
    /**
     * The bias to apply to the shadow map.
     */
    get bias(): number;
    set bias(value: number);
    private _normalBias;
    /**
     * The normal bias to apply to the shadow map.
     */
    get normalBias(): number;
    set normalBias(value: number);
    private _darkness;
    /**
     * The darkness of the shadows.
     */
    get darkness(): number;
    set darkness(value: number);
    private _transparencyShadow;
    /**
     * Gets or sets the ability to have transparent shadow
     */
    get transparencyShadow(): boolean;
    set transparencyShadow(value: boolean);
    private _enableSoftTransparentShadow;
    /**
     * Enables or disables shadows with varying strength based on the transparency
     */
    get enableSoftTransparentShadow(): boolean;
    set enableSoftTransparentShadow(value: boolean);
    private _useOpacityTextureForTransparentShadow;
    /**
     * If this is true, use the opacity texture's alpha channel for transparent shadows instead of the diffuse one
     */
    get useOpacityTextureForTransparentShadow(): boolean;
    set useOpacityTextureForTransparentShadow(value: boolean);
    private _filter;
    /**
     * The filter to apply to the shadow map.
     */
    get filter(): number;
    set filter(value: number);
    private _filteringQuality;
    /**
     * The filtering quality to apply to the filter.
     */
    get filteringQuality(): number;
    set filteringQuality(value: number);
    /**
     * The shadow generator.
     */
    readonly shadowGenerator: ShadowGenerator;
    /**
     * The shadow map texture.
     */
    readonly outputTexture: FrameGraphTextureHandle;
    protected _shadowGenerator: ShadowGenerator | undefined;
    protected _createShadowGenerator(): void;
    protected _setupShadowGenerator(): void;
    isReady(): boolean;
    /**
     * Creates a new shadow generator task.
     * @param name The name of the task.
     * @param frameGraph The frame graph the task belongs to.
     */
    constructor(name: string, frameGraph: FrameGraph);
    getClassName(): string;
    record(): void;
    dispose(): void;
}

/**
 * Structure used by the frame graph to reference objects.
 */
declare class FrameGraphObjectList {
    /**
     * The meshes in the object list.
     */
    meshes: Nullable<AbstractMesh[]>;
    /**
     * The particle systems in the object list.
     */
    particleSystems: Nullable<IParticleSystem[]>;
}

/**
 * Frame graph context used render passes.
 */
declare class FrameGraphRenderContext extends FrameGraphContext {
    private readonly _effectRenderer;
    private readonly _effectRendererBack;
    private _currentRenderTarget;
    private _renderTargetIsBound;
    private readonly _copyTexture;
    private readonly _copyDepthTexture;
    private static _IsObjectRenderer;
    /** @internal */
    constructor(engine: AbstractEngine, textureManager: FrameGraphTextureManager, scene: Scene);
    /**
     * Checks whether a texture handle points to the backbuffer's color or depth texture
     * @param handle The handle to check
     * @returns True if the handle points to the backbuffer's color or depth texture, otherwise false
     */
    isBackbuffer(handle: FrameGraphTextureHandle): boolean;
    /**
     * Checks whether a texture handle points to the backbuffer's color texture
     * @param handle The handle to check
     * @returns True if the handle points to the backbuffer's color texture, otherwise false
     */
    isBackbufferColor(handle: FrameGraphTextureHandle): boolean;
    /**
     * Checks whether a texture handle points to the backbuffer's depth texture
     * @param handle The handle to check
     * @returns True if the handle points to the backbuffer's depth texture, otherwise false
     */
    isBackbufferDepthStencil(handle: FrameGraphTextureHandle): boolean;
    /**
     * Creates a (frame graph) render target wrapper
     * Note that renderTargets or renderTargetDepth can be undefined, but not both at the same time!
     * @param name Name of the render target wrapper
     * @param renderTargets Render target handles (textures) to use
     * @param renderTargetDepth Render target depth handle (texture) to use
     * @param depthReadOnly If true, the depth buffer will be read-only
     * @param stencilReadOnly If true, the stencil buffer will be read-only
     * @returns The created render target wrapper
     */
    createRenderTarget(name: string, renderTargets?: FrameGraphTextureHandle | FrameGraphTextureHandle[], renderTargetDepth?: FrameGraphTextureHandle, depthReadOnly?: boolean, stencilReadOnly?: boolean): FrameGraphRenderTarget;
    /**
     * Clears the current render buffer or the current render target (if any is set up)
     * @param color Defines the color to use
     * @param backBuffer Defines if the back buffer must be cleared
     * @param depth Defines if the depth buffer must be cleared
     * @param stencil Defines if the stencil buffer must be cleared
     * @param stencilClearValue Defines the value to use to clear the stencil buffer (default is 0)
     */
    clear(color: Nullable<IColor4Like>, backBuffer: boolean, depth: boolean, stencil?: boolean, stencilClearValue?: number): void;
    /**
     * Clears the color attachments of the current render target
     * @param color Defines the color to use
     * @param attachments The attachments to clear
     */
    clearColorAttachments(color: Nullable<IColor4Like>, attachments: number[]): void;
    /**
     * Clears all attachments (color(s) + depth/stencil) of the current render target
     * @param color Defines the color to use
     * @param attachments The attachments to clear
     * @param backBuffer Defines if the back buffer must be cleared
     * @param depth Defines if the depth buffer must be cleared
     * @param stencil Defines if the stencil buffer must be cleared
     * @param stencilClearValue Defines the value to use to clear the stencil buffer (default is 0)
     */
    clearAttachments(color: Nullable<IColor4Like>, attachments: number[], backBuffer: boolean, depth: boolean, stencil?: boolean, stencilClearValue?: number): void;
    /**
     * Binds the attachments to the current render target
     * @param attachments The attachments to bind
     */
    bindAttachments(attachments: number[]): void;
    /**
     * Generates mipmaps for the current render target
     * @param handle Optional handle of the texture to generate mipmaps for (if not provided, will generate mipmaps for all textures in the current render target)
     */
    generateMipMaps(handle?: FrameGraphTextureHandle): void;
    /**
     * Sets the texture sampling mode for a given texture handle
     * @param handle Handle of the texture to set the sampling mode for
     * @param samplingMode Sampling mode to set
     */
    setTextureSamplingMode(handle: FrameGraphTextureHandle, samplingMode: number): void;
    /**
     * Binds a texture handle to a given effect (resolves the handle to a texture and binds it to the effect)
     * @param effect The effect to bind the texture to
     * @param name The name of the texture in the effect
     * @param handle The handle of the texture to bind
     */
    bindTextureHandle(effect: Effect, name: string, handle: FrameGraphTextureHandle): void;
    /**
     * Applies a full-screen effect to the current render target
     * @param drawWrapper The draw wrapper containing the effect to apply
     * @param customBindings The custom bindings to use when applying the effect (optional)
     * @param stencilState The stencil state to use when applying the effect (optional)
     * @param disableColorWrite If true, color write will be disabled when applying the effect (optional)
     * @param drawBackFace If true, the fullscreen quad will be drawn as a back face (in CW - optional)
     * @param depthTest If true, depth testing will be enabled when applying the effect (default is false)
     * @param noViewport If true, the current viewport will be left unchanged (optional). If false or undefined, the viewport will be set to the full render target size.
     * @returns True if the effect was applied, otherwise false (effect not ready)
     */
    applyFullScreenEffect(drawWrapper: DrawWrapper, customBindings?: () => void, stencilState?: IStencilState | IStencilStateProperties, disableColorWrite?: boolean, drawBackFace?: boolean, depthTest?: boolean, noViewport?: boolean): boolean;
    /**
     * Copies a texture to the current render target
     * @param sourceTexture The source texture to copy from
     * @param forceCopyToBackbuffer If true, the copy will be done to the back buffer regardless of the current render target
     * @param noViewport If true, the current viewport will be left unchanged (optional). If false or undefined, the viewport will be set to the full render target size.
     * @param lodLevel The LOD level to use when copying the texture (default: 0).
     */
    copyTexture(sourceTexture: FrameGraphTextureHandle, forceCopyToBackbuffer?: boolean, noViewport?: boolean, lodLevel?: number): void;
    /**
     * Renders a RenderTargetTexture or a layer
     * @param object The RenderTargetTexture/Layer to render
     * @param viewportWidth The width of the viewport (optional for Layer, but mandatory for ObjectRenderer)
     * @param viewportHeight The height of the viewport (optional for Layer, but mandatory for ObjectRenderer)
     * @param restoreDefaultFramebuffer If true, the default framebuffer will be restored after rendering (default: false)
     */
    render(object: Layer | ObjectRenderer | UtilityLayerRenderer, viewportWidth?: number, viewportHeight?: number, restoreDefaultFramebuffer?: boolean): void;
    /**
     * Binds a render target texture so that upcoming draw calls will render to it
     * Note: it is a lazy operation, so the render target will only be bound when needed. This way, it is possible to call
     *   this method several times with different render targets without incurring the cost of binding if no draw calls are made
     * @param renderTarget The handle of the render target texture to bind (default: undefined, meaning "back buffer"). Pass an array for MRT rendering.
     * @param applyImmediately If true, the render target will be applied immediately (otherwise it will be applied at first use). Default is false (delayed application).
     */
    bindRenderTarget(renderTarget?: FrameGraphRenderTarget, applyImmediately?: boolean): void;
    /**
     * Restores the default framebuffer (back buffer) as the current render target
     */
    restoreDefaultFramebuffer(): void;
    /** @internal */
    _applyRenderTarget(): void;
    /** @internal */
    _isReady(): boolean;
    /** @internal */
    _dispose(): void;
}

/**
 * Represents a texture handle in the frame graph.
 */
type FrameGraphTextureHandle = number;
/**
 * Options used to describe a texture to be created in the frame graph.
 */
type FrameGraphTextureOptions = {
    /** Specifies if mipmaps must be created for the textures (default: false) */
    createMipMaps?: boolean;
    /** Defines sample count (default: 1) */
    samples?: number;
    /**
     * Define the type of the textures (of Constants.TEXTURE_2D, .TEXTURE_2D_ARRAY, .TEXTURE_CUBE_MAP, .TEXTURE_CUBE_MAP_ARRAY, .TEXTURE_3D).
     */
    targetTypes?: number[];
    /**
     * Define the number of layers of the textures (if applicable, given the corresponding targetType) (for Constants.TEXTURE_3D, .TEXTURE_2D_ARRAY, and .TEXTURE_CUBE_MAP_ARRAY)
     */
    layerCounts?: number[];
    /** Defines the type of the texture channels (UNSIGNED_BYTE, FLOAT, etc.) */
    types?: number[];
    /** Defines the format of the textures (RED, RG, RGB, RGBA, ALPHA...) */
    formats?: number[];
    /** Defines if sRGB format should be used for each of texture */
    useSRGBBuffers?: boolean[];
    /** Defines the creation flags of the textures (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg) */
    creationFlags?: number[];
    /** Defines the names of the textures (used for debugging purpose) */
    labels?: string[];
};
/**
 * Options used to create a texture / list of textures in the frame graph.
 */
type FrameGraphTextureCreationOptions = {
    /** Size of the textures. If sizeIsPercentage is true, these are percentages relative to the screen size (100 = 100%) */
    size: TextureSize;
    /** Options used to create the textures */
    options: FrameGraphTextureOptions;
    /** If true, indicates that "size" is percentages relative to the screen size */
    sizeIsPercentage: boolean;
    /** Indicates that the texture is a history texture (default: false) */
    isHistoryTexture?: boolean;
};
/**
 * Represents a texture description in the frame graph.
 * This is basically the same thing than FrameGraphTextureCreationOptions, but the size is never in percentage and always in pixels.
 */
type FrameGraphTextureDescription = {
    /** Size of the texture */
    size: {
        width: number;
        height: number;
    };
    /** Options used to create the texture */
    options: FrameGraphTextureOptions;
};
/**
 * Defines a pass in the frame graph.
 */
interface IFrameGraphPass {
    /**
     * The name of the pass.
     */
    name: string;
    /**
     * Whether the pass is disabled.
     */
    disabled: boolean;
    /**
     * Initializes the pass.
     * This function is called once before the first execution of the pass.
     * @param func The function to initialize the pass.
     */
    setInitializeFunc(func: (context: FrameGraphContext) => void): void;
    /**
     * Sets the function to execute when the pass is executed
     * @param func The function to execute when the pass is executed
     */
    setExecuteFunc(func: (context: FrameGraphContext) => void): void;
    /** @internal */
    _initialize(): void;
    /** @internal */
    _execute(): void;
    /** @internal */
    _isValid(): Nullable<string>;
    /** @internal */
    _dispose(): void;
}

/**
 * Configuration needed for prepass-capable materials
 */
declare class PrePassConfiguration {
    /**
     * Previous world matrices of meshes carrying this material
     * Used for computing velocity
     */
    previousWorldMatrices: {
        [index: number]: Matrix;
    };
    /**
     * Previous view project matrix
     * Used for computing velocity
     */
    previousViewProjection: Matrix;
    /**
     * Current view projection matrix
     * Used for computing velocity
     */
    currentViewProjection: Matrix;
    /**
     * Previous bones of meshes carrying this material
     * Used for computing velocity
     */
    previousBones: {
        [index: number]: Float32Array;
    };
    private _lastUpdateFrameId;
    /**
     * Add the required uniforms to the current list.
     * @param uniforms defines the current uniform list.
     */
    static AddUniforms(uniforms: string[]): void;
    /**
     * Add the required samplers to the current list.
     * @param samplers defines the current sampler list.
     */
    static AddSamplers(samplers: string[]): void;
    /**
     * Binds the material data.
     * @param effect defines the effect to update
     * @param scene defines the scene the material belongs to.
     * @param mesh The mesh
     * @param world World matrix of this mesh
     * @param isFrozen Is the material frozen
     */
    bindForSubMesh(effect: Effect, scene: Scene, mesh: Mesh, world: Matrix, isFrozen: boolean): void;
}

/**
 * Options to be used when creating a FresnelParameters.
 */
type IFresnelParametersCreationOptions = {
    /**
     * Define the color used on edges (grazing angle)
     */
    leftColor?: Color3;
    /**
     * Define the color used on center
     */
    rightColor?: Color3;
    /**
     * Define bias applied to computed fresnel term
     */
    bias?: number;
    /**
     * Defined the power exponent applied to fresnel term
     */
    power?: number;
    /**
     * Define if the fresnel effect is enable or not.
     */
    isEnabled?: boolean;
};
/**
 * Serialized format for FresnelParameters.
 */
type IFresnelParametersSerialized = {
    /**
     * Define the color used on edges (grazing angle) [as an array]
     */
    leftColor: number[];
    /**
     * Define the color used on center [as an array]
     */
    rightColor: number[];
    /**
     * Define bias applied to computed fresnel term
     */
    bias: number;
    /**
     * Defined the power exponent applied to fresnel term
     */
    power?: number;
    /**
     * Define if the fresnel effect is enable or not.
     */
    isEnabled: boolean;
};
/**
 * This represents all the required information to add a fresnel effect on a material:
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/fresnelParameters
 */
declare class FresnelParameters {
    private _isEnabled;
    /**
     * Define if the fresnel effect is enable or not.
     */
    get isEnabled(): boolean;
    set isEnabled(value: boolean);
    /**
     * Define the color used on edges (grazing angle)
     */
    leftColor: Color3;
    /**
     * Define the color used on center
     */
    rightColor: Color3;
    /**
     * Define bias applied to computed fresnel term
     */
    bias: number;
    /**
     * Defined the power exponent applied to fresnel term
     */
    power: number;
    /**
     * Creates a new FresnelParameters object.
     *
     * @param options provide your own settings to optionally to override defaults
     */
    constructor(options?: IFresnelParametersCreationOptions);
    /**
     * Clones the current fresnel and its values
     * @returns a clone fresnel configuration
     */
    clone(): FresnelParameters;
    /**
     * Determines equality between FresnelParameters objects
     * @param otherFresnelParameters defines the second operand
     * @returns true if the power, bias, leftColor, rightColor and isEnabled values are equal to the given ones
     */
    equals(otherFresnelParameters: DeepImmutable<FresnelParameters>): boolean;
    /**
     * Serializes the current fresnel parameters to a JSON representation.
     * @returns the JSON serialization
     */
    serialize(): IFresnelParametersSerialized;
    /**
     * Parse a JSON object and deserialize it to a new Fresnel parameter object.
     * @param parsedFresnelParameters Define the JSON representation
     * @returns the parsed parameters
     */
    static Parse(parsedFresnelParameters: IFresnelParametersSerialized): FresnelParameters;
}

declare module "./material" {
    interface Material {
        /**
         * Plugin manager for this material
         */
        pluginManager?: MaterialPluginManager;
    }
}
/**
 * Class that manages the plugins of a material
 * @since 5.0
 */
declare class MaterialPluginManager {
    /** Map a plugin class name to a #define name (used in the vertex/fragment shaders as a marker of the plugin usage) */
    private static _MaterialPluginClassToMainDefine;
    private static _MaterialPluginCounter;
    protected _material: Material;
    protected _scene: Scene;
    protected _engine: AbstractEngine;
    /** @internal */
    _plugins: MaterialPluginBase[];
    protected _activePlugins: MaterialPluginBase[];
    protected _activePluginsForExtraEvents: MaterialPluginBase[];
    protected _codeInjectionPoints: {
        [shaderType: string]: {
            [codeName: string]: boolean;
        };
    };
    protected _defineNamesFromPlugins?: {
        [name: string]: {
            type: string;
            default: any;
        };
    };
    protected _uboDeclaration: string;
    protected _vertexDeclaration: string;
    protected _fragmentDeclaration: string;
    protected _uniformList: string[];
    protected _samplerList: string[];
    protected _uboList: string[];
    /**
     * Creates a new instance of the plugin manager
     * @param material material that this manager will manage the plugins for
     */
    constructor(material: Material);
    /**
     * @internal
     */
    _addPlugin(plugin: MaterialPluginBase): boolean;
    /**
     * @internal
     */
    _activatePlugin(plugin: MaterialPluginBase): void;
    /**
     * Gets a plugin from the list of plugins managed by this manager
     * @param name name of the plugin
     * @returns the plugin if found, else null
     */
    getPlugin<T = MaterialPluginBase>(name: string): Nullable<T>;
    protected _handlePluginEventIsReadyForSubMesh(eventData: MaterialPluginIsReadyForSubMesh): void;
    protected _handlePluginEventPrepareDefinesBeforeAttributes(eventData: MaterialPluginPrepareDefines): void;
    protected _handlePluginEventPrepareDefines(eventData: MaterialPluginPrepareDefines): void;
    protected _handlePluginEventHardBindForSubMesh(eventData: MaterialPluginHardBindForSubMesh): void;
    protected _handlePluginEventBindForSubMesh(eventData: MaterialPluginBindForSubMesh): void;
    protected _handlePluginEventHasRenderTargetTextures(eventData: MaterialPluginHasRenderTargetTextures): void;
    protected _handlePluginEventFillRenderTargetTextures(eventData: MaterialPluginFillRenderTargetTextures): void;
    protected _handlePluginEvent(id: number, info: MaterialPluginGetActiveTextures | MaterialPluginGetAnimatables | MaterialPluginHasTexture | MaterialPluginDisposed | MaterialPluginGetDefineNames | MaterialPluginPrepareEffect | MaterialPluginPrepareUniformBuffer): void;
    protected _collectPointNames(shaderType: string, customCode: Nullable<{
        [pointName: string]: string;
    }> | undefined): void;
    protected _injectCustomCode(eventData: MaterialPluginPrepareEffect, existingCallback?: (shaderType: string, code: string) => string): ShaderCustomProcessingFunction;
}

/**
 * Base class for material plugins.
 * @since 5.0
 */
declare class MaterialPluginBase {
    /**
     * Defines the name of the plugin
     */
    name: string;
    /**
     * Defines the priority of the plugin. Lower numbers run first.
     */
    priority: number;
    /**
     * Indicates that any #include directive in the plugin code must be replaced by the corresponding code.
     */
    resolveIncludes: boolean;
    /**
     * Indicates that this plugin should be notified for the extra events (HasRenderTargetTextures / FillRenderTargetTextures / HardBindForSubMesh)
     */
    registerForExtraEvents: boolean;
    /**
     * Specifies if the material plugin should be serialized, `true` to skip serialization
     */
    doNotSerialize: boolean;
    protected _material: Material;
    protected _pluginManager: MaterialPluginManager;
    protected _pluginDefineNames?: {
        [name: string]: any;
    };
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @param shaderLanguage The shader language to use.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(shaderLanguage: ShaderLanguage): boolean;
    protected _enable(enable: boolean): void;
    /**
     * Helper function to mark defines as being dirty.
     */
    readonly markAllDefinesAsDirty: () => void;
    /**
     * Creates a new material plugin
     * @param material parent material of the plugin
     * @param name name of the plugin
     * @param priority priority of the plugin
     * @param defines list of defines used by the plugin. The value of the property is the default value for this property
     * @param addToPluginList true to add the plugin to the list of plugins managed by the material plugin manager of the material (default: true)
     * @param enable true to enable the plugin (it is handy if the plugin does not handle properties to switch its current activation)
     * @param resolveIncludes Indicates that any #include directive in the plugin code must be replaced by the corresponding code (default: false)
     */
    constructor(material: Material, name: string, priority: number, defines?: {
        [key: string]: any;
    }, addToPluginList?: boolean, enable?: boolean, resolveIncludes?: boolean);
    /**
     * Gets the current class name useful for serialization or dynamic coding.
     * @returns The class name.
     */
    getClassName(): string;
    /**
     * Specifies that the submesh is ready to be used.
     * @param _defines the list of "defines" to update.
     * @param _scene defines the scene the material belongs to.
     * @param _engine the engine this scene belongs to.
     * @param _subMesh the submesh to check for readiness
     * @returns - boolean indicating that the submesh is ready or not.
     */
    isReadyForSubMesh(_defines: MaterialDefines, _scene: Scene, _engine: AbstractEngine, _subMesh: SubMesh): boolean;
    /**
     * Binds the material data (this function is called even if mustRebind() returns false)
     * @param _uniformBuffer defines the Uniform buffer to fill in.
     * @param _scene defines the scene the material belongs to.
     * @param _engine defines the engine the material belongs to.
     * @param _subMesh the submesh to bind data for
     */
    hardBindForSubMesh(_uniformBuffer: UniformBuffer, _scene: Scene, _engine: AbstractEngine, _subMesh: SubMesh): void;
    /**
     * Binds the material data.
     * @param _uniformBuffer defines the Uniform buffer to fill in.
     * @param _scene defines the scene the material belongs to.
     * @param _engine the engine this scene belongs to.
     * @param _subMesh the submesh to bind data for
     */
    bindForSubMesh(_uniformBuffer: UniformBuffer, _scene: Scene, _engine: AbstractEngine, _subMesh: SubMesh): void;
    /**
     * Disposes the resources of the material.
     * @param _forceDisposeTextures - Forces the disposal of all textures.
     */
    dispose(_forceDisposeTextures?: boolean): void;
    /**
     * Returns a list of custom shader code fragments to customize the shader.
     * @param _shaderType "vertex" or "fragment"
     * @param _shaderLanguage The shader language to use.
     * @returns null if no code to be added, or a list of pointName =\> code.
     * Note that `pointName` can also be a regular expression if it starts with a `!`.
     * In that case, the string found by the regular expression (if any) will be
     * replaced by the code provided.
     */
    getCustomCode(_shaderType: string, _shaderLanguage?: ShaderLanguage): Nullable<{
        [pointName: string]: string;
    }>;
    /**
     * Collects all defines.
     * @param defines The object to append to.
     */
    collectDefines(defines: {
        [name: string]: {
            type: string;
            default: any;
        };
    }): void;
    /**
     * Sets the defines for the next rendering. Called before PrepareDefinesForAttributes is called.
     * @param _defines the list of "defines" to update.
     * @param _scene defines the scene to the material belongs to.
     * @param _mesh the mesh being rendered
     */
    prepareDefinesBeforeAttributes(_defines: MaterialDefines, _scene: Scene, _mesh: AbstractMesh): void;
    /**
     * Sets the defines for the next rendering
     * @param _defines the list of "defines" to update.
     * @param _scene defines the scene to the material belongs to.
     * @param _mesh the mesh being rendered
     */
    prepareDefines(_defines: MaterialDefines, _scene: Scene, _mesh: AbstractMesh): void;
    /**
     * Checks to see if a texture is used in the material.
     * @param _texture - Base texture to use.
     * @returns - Boolean specifying if a texture is used in the material.
     */
    hasTexture(_texture: BaseTexture): boolean;
    /**
     * Gets a boolean indicating that current material needs to register RTT
     * @returns true if this uses a render target otherwise false.
     */
    hasRenderTargetTextures(): boolean;
    /**
     * Fills the list of render target textures.
     * @param _renderTargets the list of render targets to update
     */
    fillRenderTargetTextures(_renderTargets: SmartArray<RenderTargetTexture>): void;
    /**
     * Returns an array of the actively used textures.
     * @param _activeTextures Array of BaseTextures
     */
    getActiveTextures(_activeTextures: BaseTexture[]): void;
    /**
     * Returns the animatable textures.
     * @param _animatables Array of animatable textures.
     */
    getAnimatables(_animatables: IAnimatable[]): void;
    /**
     * Add fallbacks to the effect fallbacks list.
     * @param defines defines the Base texture to use.
     * @param fallbacks defines the current fallback list.
     * @param currentRank defines the current fallback rank.
     * @returns the new fallback rank.
     */
    addFallbacks(defines: MaterialDefines, fallbacks: EffectFallbacks, currentRank: number): number;
    /**
     * Gets the samplers used by the plugin.
     * @param _samplers list that the sampler names should be added to.
     */
    getSamplers(_samplers: string[]): void;
    /**
     * Gets the attributes used by the plugin.
     * @param _attributes list that the attribute names should be added to.
     * @param _scene the scene that the material belongs to.
     * @param _mesh the mesh being rendered.
     */
    getAttributes(_attributes: string[], _scene: Scene, _mesh: AbstractMesh): void;
    /**
     * Gets the uniform buffers names added by the plugin.
     * @param _ubos list that the ubo names should be added to.
     */
    getUniformBuffersNames(_ubos: string[]): void;
    /**
     * Gets the description of the uniforms to add to the ubo (if engine supports ubos) or to inject directly in the vertex/fragment shaders (if engine does not support ubos)
     * @param _shaderLanguage The shader language to use.
     * @returns the description of the uniforms
     */
    getUniforms(_shaderLanguage?: ShaderLanguage): {
        ubo?: Array<{
            name: string;
            size?: number;
            type?: string;
            arraySize?: number;
        }>;
        vertex?: string;
        fragment?: string;
        externalUniforms?: string[];
    };
    /**
     * Makes a duplicate of the current configuration into another one.
     * @param plugin define the config where to copy the info
     */
    copyTo(plugin: MaterialPluginBase): void;
    /**
     * Serializes this plugin configuration.
     * @returns - An object with the serialized config.
     */
    serialize(): any;
    /**
     * Parses a plugin configuration from a serialized object.
     * @param source - Serialized object.
     * @param scene Defines the scene we are parsing for
     * @param rootUrl Defines the rootUrl to load from
     */
    parse(source: any, scene: Scene, rootUrl: string): void;
}

/**
 * @internal
 */
declare class MaterialBRDFDefines extends MaterialDefines {
    BRDF_V_HEIGHT_CORRELATED: boolean;
    MS_BRDF_ENERGY_CONSERVATION: boolean;
    SPHERICAL_HARMONICS: boolean;
    SPECULAR_GLOSSINESS_ENERGY_CONSERVATION: boolean;
    MIX_IBL_RADIANCE_WITH_IRRADIANCE: boolean;
    LEGACY_SPECULAR_ENERGY_CONSERVATION: boolean;
    BASE_DIFFUSE_MODEL: number;
    DIELECTRIC_SPECULAR_MODEL: number;
    CONDUCTOR_SPECULAR_MODEL: number;
}
/**
 * Plugin that implements the BRDF component of the PBR material
 */
declare class PBRBRDFConfiguration extends MaterialPluginBase {
    /**
     * Default value used for the energy conservation.
     * This should only be changed to adapt to the type of texture in scene.environmentBRDFTexture.
     */
    static DEFAULT_USE_ENERGY_CONSERVATION: boolean;
    /**
     * Default value used for the Smith Visibility Height Correlated mode.
     * This should only be changed to adapt to the type of texture in scene.environmentBRDFTexture.
     */
    static DEFAULT_USE_SMITH_VISIBILITY_HEIGHT_CORRELATED: boolean;
    /**
     * Default value used for the IBL diffuse part.
     * This can help switching back to the polynomials mode globally which is a tiny bit
     * less GPU intensive at the drawback of a lower quality.
     */
    static DEFAULT_USE_SPHERICAL_HARMONICS: boolean;
    /**
     * Default value used for activating energy conservation for the specular workflow.
     * If activated, the albedo color is multiplied with (1. - maxChannel(specular color)).
     * If deactivated, a material is only physically plausible, when (albedo color + specular color) < 1.
     */
    static DEFAULT_USE_SPECULAR_GLOSSINESS_INPUT_ENERGY_CONSERVATION: boolean;
    /**
     * Default value for whether IBL irradiance is used to augment rough radiance.
     * If activated, irradiance is blended into the radiance contribution when the material is rough.
     * This better approximates raytracing results for rough surfaces.
     */
    static DEFAULT_MIX_IBL_RADIANCE_WITH_IRRADIANCE: boolean;
    /**
     * Default value for whether the legacy specular energy conservation is used.
     */
    static DEFAULT_USE_LEGACY_SPECULAR_ENERGY_CONSERVATION: boolean;
    /**
     * Defines the default diffuse model used by the material.
     */
    static DEFAULT_DIFFUSE_MODEL: number;
    /**
     * Defines the default dielectric specular model used by the material.
     */
    static DEFAULT_DIELECTRIC_SPECULAR_MODEL: number;
    /**
     * Defines the default conductor specular model used by the material.
     */
    static DEFAULT_CONDUCTOR_SPECULAR_MODEL: number;
    private _useEnergyConservation;
    /**
     * Defines if the material uses energy conservation.
     */
    useEnergyConservation: boolean;
    private _useSmithVisibilityHeightCorrelated;
    /**
     * LEGACY Mode set to false
     * Defines if the material uses height smith correlated visibility term.
     * If you intent to not use our default BRDF, you need to load a separate BRDF Texture for the PBR
     * You can either load https://assets.babylonjs.com/environments/uncorrelatedBRDF.png
     * or https://assets.babylonjs.com/environments/uncorrelatedBRDF.dds to have more precision
     * Not relying on height correlated will also disable energy conservation.
     */
    useSmithVisibilityHeightCorrelated: boolean;
    private _useSphericalHarmonics;
    /**
     * LEGACY Mode set to false
     * Defines if the material uses spherical harmonics vs spherical polynomials for the
     * diffuse part of the IBL.
     * The harmonics despite a tiny bigger cost has been proven to provide closer results
     * to the ground truth.
     */
    useSphericalHarmonics: boolean;
    private _useSpecularGlossinessInputEnergyConservation;
    /**
     * Defines if the material uses energy conservation, when the specular workflow is active.
     * If activated, the albedo color is multiplied with (1. - maxChannel(specular color)).
     * If deactivated, a material is only physically plausible, when (albedo color + specular color) < 1.
     * In the deactivated case, the material author has to ensure energy conservation, for a physically plausible rendering.
     */
    useSpecularGlossinessInputEnergyConservation: boolean;
    private _mixIblRadianceWithIrradiance;
    /**
     * Defines if IBL irradiance is used to augment rough radiance.
     * If activated, irradiance is blended into the radiance contribution when the material is rough.
     * This better approximates raytracing results for rough surfaces.
     */
    mixIblRadianceWithIrradiance: boolean;
    private _useLegacySpecularEnergyConservation;
    /**
     * Defines if the legacy specular energy conservation is used.
     * If activated, the specular color is multiplied with (1. - maxChannel(albedo color)).
     */
    useLegacySpecularEnergyConservation: boolean;
    private _baseDiffuseModel;
    /**
     * Defines the base diffuse roughness model of the material.
     */
    baseDiffuseModel: number;
    private _dielectricSpecularModel;
    /**
     * The material model to use for specular lighting of dielectric materials.
     */
    dielectricSpecularModel: number;
    private _conductorSpecularModel;
    /**
     * The material model to use for specular lighting.
     */
    conductorSpecularModel: number;
    /** @internal */
    private _internalMarkAllSubMeshesAsMiscDirty;
    /** @internal */
    _markAllSubMeshesAsMiscDirty(): void;
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(): boolean;
    constructor(material: PBRBaseMaterial, addToPluginList?: boolean);
    prepareDefines(defines: MaterialBRDFDefines): void;
    getClassName(): string;
}

declare module "./baseTexture" {
    interface BaseTexture {
        /**
         * Get the polynomial representation of the texture data.
         * This is mainly use as a fast way to recover IBL Diffuse irradiance data.
         * @see https://learnopengl.com/PBR/IBL/Diffuse-irradiance
         */
        sphericalPolynomial: Nullable<SphericalPolynomial>;
        /**
         * Force recomputation of spherical polynomials.
         * Can be useful if you generate a cubemap multiple times (from a probe for eg) and you need the proper polynomials each time
         */
        forceSphericalPolynomialsRecompute(): void;
    }
}

/**
 * @internal
 */
declare class MaterialClearCoatDefines extends MaterialDefines {
    CLEARCOAT: boolean;
    CLEARCOAT_DEFAULTIOR: boolean;
    CLEARCOAT_TEXTURE: boolean;
    CLEARCOAT_TEXTURE_ROUGHNESS: boolean;
    CLEARCOAT_TEXTUREDIRECTUV: number;
    CLEARCOAT_TEXTURE_ROUGHNESSDIRECTUV: number;
    CLEARCOAT_BUMP: boolean;
    CLEARCOAT_BUMPDIRECTUV: number;
    CLEARCOAT_USE_ROUGHNESS_FROM_MAINTEXTURE: boolean;
    CLEARCOAT_REMAP_F0: boolean;
    CLEARCOAT_TINT: boolean;
    CLEARCOAT_TINT_TEXTURE: boolean;
    CLEARCOAT_TINT_TEXTUREDIRECTUV: number;
    CLEARCOAT_TINT_GAMMATEXTURE: boolean;
}
/**
 * Plugin that implements the clear coat component of the PBR material
 */
declare class PBRClearCoatConfiguration extends MaterialPluginBase {
    protected _material: PBRBaseMaterial;
    /**
     * This defaults to 1.5 corresponding to a 0.04 f0 or a 4% reflectance at normal incidence
     * The default fits with a polyurethane material.
     * @internal
     */
    static readonly _DefaultIndexOfRefraction = 1.5;
    private _isEnabled;
    /**
     * Defines if the clear coat is enabled in the material.
     */
    isEnabled: boolean;
    /**
     * Defines the clear coat layer strength (between 0 and 1) it defaults to 1.
     */
    intensity: number;
    /**
     * Defines the clear coat layer roughness.
     */
    roughness: number;
    private _indexOfRefraction;
    /**
     * Defines the index of refraction of the clear coat.
     * This defaults to 1.5 corresponding to a 0.04 f0 or a 4% reflectance at normal incidence
     * The default fits with a polyurethane material.
     * Changing the default value is more performance intensive.
     */
    indexOfRefraction: number;
    private _texture;
    /**
     * Stores the clear coat values in a texture (red channel is intensity and green channel is roughness)
     * If useRoughnessFromMainTexture is false, the green channel of texture is not used and the green channel of textureRoughness is used instead
     * if textureRoughness is not empty, else no texture roughness is used
     */
    texture: Nullable<BaseTexture>;
    private _useRoughnessFromMainTexture;
    /**
     * Indicates that the green channel of the texture property will be used for roughness (default: true)
     * If false, the green channel from textureRoughness is used for roughness
     */
    useRoughnessFromMainTexture: boolean;
    private _textureRoughness;
    /**
     * Stores the clear coat roughness in a texture (green channel)
     * Not used if useRoughnessFromMainTexture is true
     */
    textureRoughness: Nullable<BaseTexture>;
    private _remapF0OnInterfaceChange;
    /**
     * Defines if the F0 value should be remapped to account for the interface change in the material.
     */
    remapF0OnInterfaceChange: boolean;
    private _bumpTexture;
    /**
     * Define the clear coat specific bump texture.
     */
    bumpTexture: Nullable<BaseTexture>;
    private _isTintEnabled;
    /**
     * Defines if the clear coat tint is enabled in the material.
     */
    isTintEnabled: boolean;
    /**
     * Defines the clear coat tint of the material.
     * This is only use if tint is enabled
     */
    tintColor: Color3;
    /**
     * Defines the distance at which the tint color should be found in the
     * clear coat media.
     * This is only use if tint is enabled
     */
    tintColorAtDistance: number;
    /**
     * Defines the clear coat layer thickness.
     * This is only use if tint is enabled
     */
    tintThickness: number;
    private _tintTexture;
    /**
     * Stores the clear tint values in a texture.
     * rgb is tint
     * a is a thickness factor
     */
    tintTexture: Nullable<BaseTexture>;
    /** @internal */
    private _internalMarkAllSubMeshesAsTexturesDirty;
    /** @internal */
    _markAllSubMeshesAsTexturesDirty(): void;
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(): boolean;
    constructor(material: PBRBaseMaterial, addToPluginList?: boolean);
    isReadyForSubMesh(defines: MaterialClearCoatDefines, scene: Scene, engine: Engine): boolean;
    prepareDefinesBeforeAttributes(defines: MaterialClearCoatDefines, scene: Scene): void;
    bindForSubMesh(uniformBuffer: UniformBuffer, scene: Scene, engine: Engine, subMesh: SubMesh): void;
    hasTexture(texture: BaseTexture): boolean;
    getActiveTextures(activeTextures: BaseTexture[]): void;
    getAnimatables(animatables: IAnimatable[]): void;
    dispose(forceDisposeTextures?: boolean): void;
    getClassName(): string;
    addFallbacks(defines: MaterialClearCoatDefines, fallbacks: EffectFallbacks, currentRank: number): number;
    getSamplers(samplers: string[]): void;
    getUniforms(): {
        ubo?: Array<{
            name: string;
            size: number;
            type: string;
        }>;
        vertex?: string;
        fragment?: string;
    };
}

/**
 * @internal
 */
declare class MaterialIridescenceDefines extends MaterialDefines {
    IRIDESCENCE: boolean;
    IRIDESCENCE_TEXTURE: boolean;
    IRIDESCENCE_TEXTUREDIRECTUV: number;
    IRIDESCENCE_THICKNESS_TEXTURE: boolean;
    IRIDESCENCE_THICKNESS_TEXTUREDIRECTUV: number;
}
/**
 * Plugin that implements the iridescence (thin film) component of the PBR material
 */
declare class PBRIridescenceConfiguration extends MaterialPluginBase {
    protected _material: PBRBaseMaterial;
    /**
     * The default minimum thickness of the thin-film layer given in nanometers (nm).
     * Defaults to 100 nm.
     * @internal
     */
    static readonly _DefaultMinimumThickness = 100;
    /**
     * The default maximum thickness of the thin-film layer given in nanometers (nm).
     * Defaults to 400 nm.
     * @internal
     */
    static readonly _DefaultMaximumThickness = 400;
    /**
     * The default index of refraction of the thin-film layer.
     * Defaults to 1.3
     * @internal
     */
    static readonly _DefaultIndexOfRefraction = 1.3;
    private _isEnabled;
    /**
     * Defines if the iridescence is enabled in the material.
     */
    isEnabled: boolean;
    /**
     * Defines the iridescence layer strength (between 0 and 1) it defaults to 1.
     */
    intensity: number;
    /**
     * Defines the minimum thickness of the thin-film layer given in nanometers (nm).
     */
    minimumThickness: number;
    /**
     * Defines the maximum thickness of the thin-film layer given in nanometers (nm). This will be the thickness used if not thickness texture has been set.
     */
    maximumThickness: number;
    /**
     * Defines the maximum thickness of the thin-film layer given in nanometers (nm).
     */
    indexOfRefraction: number;
    private _texture;
    /**
     * Stores the iridescence intensity in a texture (red channel)
     */
    texture: Nullable<BaseTexture>;
    private _thicknessTexture;
    /**
     * Stores the iridescence thickness in a texture (green channel)
     */
    thicknessTexture: Nullable<BaseTexture>;
    /** @internal */
    private _internalMarkAllSubMeshesAsTexturesDirty;
    /** @internal */
    _markAllSubMeshesAsTexturesDirty(): void;
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(): boolean;
    constructor(material: PBRBaseMaterial, addToPluginList?: boolean);
    isReadyForSubMesh(defines: MaterialIridescenceDefines, scene: Scene): boolean;
    prepareDefinesBeforeAttributes(defines: MaterialIridescenceDefines, scene: Scene): void;
    bindForSubMesh(uniformBuffer: UniformBuffer, scene: Scene): void;
    hasTexture(texture: BaseTexture): boolean;
    getActiveTextures(activeTextures: BaseTexture[]): void;
    getAnimatables(animatables: IAnimatable[]): void;
    dispose(forceDisposeTextures?: boolean): void;
    getClassName(): string;
    addFallbacks(defines: MaterialIridescenceDefines, fallbacks: EffectFallbacks, currentRank: number): number;
    getSamplers(samplers: string[]): void;
    getUniforms(): {
        ubo?: Array<{
            name: string;
            size: number;
            type: string;
        }>;
        vertex?: string;
        fragment?: string;
    };
}

/**
 * @internal
 */
declare class MaterialAnisotropicDefines extends MaterialDefines {
    ANISOTROPIC: boolean;
    ANISOTROPIC_TEXTURE: boolean;
    ANISOTROPIC_TEXTUREDIRECTUV: number;
    ANISOTROPIC_LEGACY: boolean;
    MAINUV1: boolean;
}
/**
 * Plugin that implements the anisotropic component of the PBR material
 */
declare class PBRAnisotropicConfiguration extends MaterialPluginBase {
    private _isEnabled;
    /**
     * Defines if the anisotropy is enabled in the material.
     */
    isEnabled: boolean;
    /**
     * Defines the anisotropy strength (between 0 and 1) it defaults to 1.
     */
    intensity: number;
    /**
     * Defines if the effect is along the tangents, bitangents or in between.
     * By default, the effect is "stretching" the highlights along the tangents.
     */
    direction: Vector2;
    /**
     * Sets the anisotropy direction as an angle.
     */
    set angle(value: number);
    /**
     * Gets the anisotropy angle value in radians.
     * @returns the anisotropy angle value in radians.
     */
    get angle(): number;
    private _texture;
    /**
     * Stores the anisotropy values in a texture.
     * rg is direction (like normal from -1 to 1)
     * b is a intensity
     */
    texture: Nullable<BaseTexture>;
    private _legacy;
    /**
     * Defines if the anisotropy is in legacy mode for backwards compatibility before 6.4.0.
     */
    legacy: boolean;
    /** @internal */
    private _internalMarkAllSubMeshesAsTexturesDirty;
    /** @internal */
    _markAllSubMeshesAsTexturesDirty(): void;
    /** @internal */
    private _internalMarkAllSubMeshesAsMiscDirty;
    /** @internal */
    _markAllSubMeshesAsMiscDirty(): void;
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(): boolean;
    constructor(material: PBRBaseMaterial, addToPluginList?: boolean);
    isReadyForSubMesh(defines: MaterialAnisotropicDefines, scene: Scene): boolean;
    prepareDefinesBeforeAttributes(defines: MaterialAnisotropicDefines, scene: Scene, mesh: AbstractMesh): void;
    bindForSubMesh(uniformBuffer: UniformBuffer, scene: Scene): void;
    hasTexture(texture: BaseTexture): boolean;
    getActiveTextures(activeTextures: BaseTexture[]): void;
    getAnimatables(animatables: IAnimatable[]): void;
    dispose(forceDisposeTextures?: boolean): void;
    getClassName(): string;
    addFallbacks(defines: MaterialAnisotropicDefines, fallbacks: EffectFallbacks, currentRank: number): number;
    getSamplers(samplers: string[]): void;
    getUniforms(): {
        ubo?: Array<{
            name: string;
            size: number;
            type: string;
        }>;
        vertex?: string;
        fragment?: string;
    };
    /**
     * Parses a anisotropy Configuration from a serialized object.
     * @param source - Serialized object.
     * @param scene Defines the scene we are parsing for
     * @param rootUrl Defines the rootUrl to load from
     */
    parse(source: any, scene: Scene, rootUrl: string): void;
}

/**
 * @internal
 */
declare class MaterialSheenDefines extends MaterialDefines {
    SHEEN: boolean;
    SHEEN_TEXTURE: boolean;
    SHEEN_GAMMATEXTURE: boolean;
    SHEEN_TEXTURE_ROUGHNESS: boolean;
    SHEEN_TEXTUREDIRECTUV: number;
    SHEEN_TEXTURE_ROUGHNESSDIRECTUV: number;
    SHEEN_LINKWITHALBEDO: boolean;
    SHEEN_ROUGHNESS: boolean;
    SHEEN_ALBEDOSCALING: boolean;
    SHEEN_USE_ROUGHNESS_FROM_MAINTEXTURE: boolean;
}
/**
 * Plugin that implements the sheen component of the PBR material.
 */
declare class PBRSheenConfiguration extends MaterialPluginBase {
    private _isEnabled;
    /**
     * Defines if the material uses sheen.
     */
    isEnabled: boolean;
    private _linkSheenWithAlbedo;
    /**
     * Defines if the sheen is linked to the sheen color.
     */
    linkSheenWithAlbedo: boolean;
    /**
     * Defines the sheen intensity.
     */
    intensity: number;
    /**
     * Defines the sheen color.
     */
    color: Color3;
    private _texture;
    /**
     * Stores the sheen tint values in a texture.
     * rgb is tint
     * a is a intensity or roughness if the roughness property has been defined and useRoughnessFromTexture is true (in that case, textureRoughness won't be used)
     * If the roughness property has been defined and useRoughnessFromTexture is false then the alpha channel is not used to modulate roughness
     */
    texture: Nullable<BaseTexture>;
    private _useRoughnessFromMainTexture;
    /**
     * Indicates that the alpha channel of the texture property will be used for roughness.
     * Has no effect if the roughness (and texture!) property is not defined
     */
    useRoughnessFromMainTexture: boolean;
    private _roughness;
    /**
     * Defines the sheen roughness.
     * It is not taken into account if linkSheenWithAlbedo is true.
     * To stay backward compatible, material roughness is used instead if sheen roughness = null
     */
    roughness: Nullable<number>;
    private _textureRoughness;
    /**
     * Stores the sheen roughness in a texture.
     * alpha channel is the roughness. This texture won't be used if the texture property is not empty and useRoughnessFromTexture is true
     */
    textureRoughness: Nullable<BaseTexture>;
    private _albedoScaling;
    /**
     * If true, the sheen effect is layered above the base BRDF with the albedo-scaling technique.
     * It allows the strength of the sheen effect to not depend on the base color of the material,
     * making it easier to setup and tweak the effect
     */
    albedoScaling: boolean;
    /** @internal */
    private _internalMarkAllSubMeshesAsTexturesDirty;
    /** @internal */
    _markAllSubMeshesAsTexturesDirty(): void;
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(): boolean;
    constructor(material: PBRBaseMaterial, addToPluginList?: boolean);
    isReadyForSubMesh(defines: MaterialSheenDefines, scene: Scene): boolean;
    prepareDefinesBeforeAttributes(defines: MaterialSheenDefines, scene: Scene): void;
    bindForSubMesh(uniformBuffer: UniformBuffer, scene: Scene, engine: Engine, subMesh: SubMesh): void;
    hasTexture(texture: BaseTexture): boolean;
    getActiveTextures(activeTextures: BaseTexture[]): void;
    getAnimatables(animatables: IAnimatable[]): void;
    dispose(forceDisposeTextures?: boolean): void;
    getClassName(): string;
    addFallbacks(defines: MaterialSheenDefines, fallbacks: EffectFallbacks, currentRank: number): number;
    getSamplers(samplers: string[]): void;
    getUniforms(): {
        ubo?: Array<{
            name: string;
            size: number;
            type: string;
        }>;
        vertex?: string;
        fragment?: string;
    };
}

/**
 * @internal
 */
declare class MaterialSubSurfaceDefines extends MaterialDefines {
    SUBSURFACE: boolean;
    SS_REFRACTION: boolean;
    SS_REFRACTION_USE_INTENSITY_FROM_THICKNESS: boolean;
    SS_TRANSLUCENCY: boolean;
    SS_TRANSLUCENCY_USE_INTENSITY_FROM_THICKNESS: boolean;
    SS_SCATTERING: boolean;
    SS_DISPERSION: boolean;
    SS_THICKNESSANDMASK_TEXTURE: boolean;
    SS_THICKNESSANDMASK_TEXTUREDIRECTUV: number;
    SS_HAS_THICKNESS: boolean;
    SS_REFRACTIONINTENSITY_TEXTURE: boolean;
    SS_REFRACTIONINTENSITY_TEXTUREDIRECTUV: number;
    SS_TRANSLUCENCYINTENSITY_TEXTURE: boolean;
    SS_TRANSLUCENCYINTENSITY_TEXTUREDIRECTUV: number;
    SS_TRANSLUCENCYCOLOR_TEXTURE: boolean;
    SS_TRANSLUCENCYCOLOR_TEXTUREDIRECTUV: number;
    SS_TRANSLUCENCYCOLOR_TEXTURE_GAMMA: boolean;
    SS_REFRACTIONMAP_3D: boolean;
    SS_REFRACTIONMAP_OPPOSITEZ: boolean;
    SS_LODINREFRACTIONALPHA: boolean;
    SS_GAMMAREFRACTION: boolean;
    SS_RGBDREFRACTION: boolean;
    SS_LINEARSPECULARREFRACTION: boolean;
    SS_LINKREFRACTIONTOTRANSPARENCY: boolean;
    SS_ALBEDOFORREFRACTIONTINT: boolean;
    SS_ALBEDOFORTRANSLUCENCYTINT: boolean;
    SS_USE_LOCAL_REFRACTIONMAP_CUBIC: boolean;
    SS_USE_THICKNESS_AS_DEPTH: boolean;
    SS_USE_GLTF_TEXTURES: boolean;
    SS_APPLY_ALBEDO_AFTER_SUBSURFACE: boolean;
    SS_TRANSLUCENCY_LEGACY: boolean;
}
/**
 * Plugin that implements the sub surface component of the PBR material
 */
declare class PBRSubSurfaceConfiguration extends MaterialPluginBase {
    /**
     * Default value used for applyAlbedoAfterSubSurface.
     *
     * This property only exists for backward compatibility reasons.
     * Set it to true if your rendering in 8.0+ is different from that in 7 when you use sub-surface properties (transmission, refraction, etc.). Default is false.
     * Note however that the PBR calculation is wrong when this property is set to true, so only use it if you want to mimic the 7.0 behavior.
     */
    static DEFAULT_APPLY_ALBEDO_AFTERSUBSURFACE: boolean;
    /**
     * Default value used for legacyTranslucency.
     *
     * This property only exists for backward compatibility reasons.
     * Set it to true if your rendering in 8.0+ is different from that in 7 when you use sub-surface translucency. Default is false.
     */
    static DEFAULT_LEGACY_TRANSLUCENCY: boolean;
    protected _material: PBRBaseMaterial;
    private _isRefractionEnabled;
    /**
     * Defines if the refraction is enabled in the material.
     */
    isRefractionEnabled: boolean;
    private _isTranslucencyEnabled;
    /**
     * Defines if the translucency is enabled in the material.
     */
    isTranslucencyEnabled: boolean;
    private _isDispersionEnabled;
    /**
     * Defines if dispersion is enabled in the material.
     */
    isDispersionEnabled: boolean;
    private _isScatteringEnabled;
    /**
     * Defines if the sub surface scattering is enabled in the material.
     */
    isScatteringEnabled: boolean;
    private _scatteringDiffusionProfileIndex;
    /**
     * Diffusion profile for subsurface scattering.
     * Useful for better scattering in the skins or foliages.
     */
    get scatteringDiffusionProfile(): Nullable<Color3>;
    set scatteringDiffusionProfile(c: Nullable<Color3>);
    /**
     * Defines the refraction intensity of the material.
     * The refraction when enabled replaces the Diffuse part of the material.
     * The intensity helps transitioning between diffuse and refraction.
     */
    refractionIntensity: number;
    /**
     * Defines the translucency intensity of the material.
     * When translucency has been enabled, this defines how much of the "translucency"
     * is added to the diffuse part of the material.
     */
    translucencyIntensity: number;
    private _useAlbedoToTintRefraction;
    /**
     * When enabled, transparent surfaces will be tinted with the albedo colour (independent of thickness)
     */
    useAlbedoToTintRefraction: boolean;
    private _useAlbedoToTintTranslucency;
    /**
     * When enabled, translucent surfaces will be tinted with the albedo colour (independent of thickness)
     */
    useAlbedoToTintTranslucency: boolean;
    private _thicknessTexture;
    /**
     * Stores the average thickness of a mesh in a texture (The texture is holding the values linearly).
     * The red (or green if useGltfStyleTextures=true) channel of the texture should contain the thickness remapped between 0 and 1.
     * 0 would mean minimumThickness
     * 1 would mean maximumThickness
     * The other channels might be use as a mask to vary the different effects intensity.
     */
    thicknessTexture: Nullable<BaseTexture>;
    private _refractionTexture;
    /**
     * Defines the texture to use for refraction.
     */
    refractionTexture: Nullable<BaseTexture>;
    /** @internal */
    _indexOfRefraction: number;
    /**
     * Index of refraction of the material base layer.
     * https://en.wikipedia.org/wiki/List_of_refractive_indices
     *
     * This does not only impact refraction but also the Base F0 of Dielectric Materials.
     *
     * From dielectric fresnel rules: F0 = square((iorT - iorI) / (iorT + iorI))
     */
    indexOfRefraction: number;
    private _volumeIndexOfRefraction;
    /**
     * Index of refraction of the material's volume.
     * https://en.wikipedia.org/wiki/List_of_refractive_indices
     *
     * This ONLY impacts refraction. If not provided or given a non-valid value,
     * the volume will use the same IOR as the surface.
     */
    get volumeIndexOfRefraction(): number;
    set volumeIndexOfRefraction(value: number);
    private _invertRefractionY;
    /**
     * Controls if refraction needs to be inverted on Y. This could be useful for procedural texture.
     */
    invertRefractionY: boolean;
    /** @internal */
    _linkRefractionWithTransparency: boolean;
    /**
     * This parameters will make the material used its opacity to control how much it is refracting against not.
     * Materials half opaque for instance using refraction could benefit from this control.
     */
    linkRefractionWithTransparency: boolean;
    /**
     * Defines the minimum thickness stored in the thickness map.
     * If no thickness map is defined, this value will be used to simulate thickness.
     */
    minimumThickness: number;
    /**
     * Defines the maximum thickness stored in the thickness map.
     */
    maximumThickness: number;
    /**
     * Defines that the thickness should be used as a measure of the depth volume.
     */
    useThicknessAsDepth: boolean;
    /**
     * Defines the volume tint of the material.
     * This is used for both translucency and scattering.
     */
    tintColor: Color3;
    /**
     * Defines the distance at which the tint color should be found in the media.
     * This is used for refraction only.
     */
    tintColorAtDistance: number;
    /**
     * Defines the Abbe number for the volume.
     */
    dispersion: number;
    /**
     * Defines how far each channel transmit through the media.
     * It is defined as a color to simplify it selection.
     */
    diffusionDistance: Color3;
    private _useMaskFromThicknessTexture;
    /**
     * Stores the intensity of the different subsurface effects in the thickness texture.
     * Note that if refractionIntensityTexture and/or translucencyIntensityTexture is provided it takes precedence over thicknessTexture + useMaskFromThicknessTexture
     * * the green (red if useGltfStyleTextures = true) channel is the refraction intensity.
     * * the blue (alpha if useGltfStyleTextures = true) channel is the translucency intensity.
     */
    useMaskFromThicknessTexture: boolean;
    private _refractionIntensityTexture;
    /**
     * Stores the intensity of the refraction. If provided, it takes precedence over thicknessTexture + useMaskFromThicknessTexture
     * * the green (red if useGltfStyleTextures = true) channel is the refraction intensity.
     */
    refractionIntensityTexture: Nullable<BaseTexture>;
    private _translucencyIntensityTexture;
    /**
     * Stores the intensity of the translucency. If provided, it takes precedence over thicknessTexture + useMaskFromThicknessTexture
     * * the blue (alpha if useGltfStyleTextures = true) channel is the translucency intensity.
     */
    translucencyIntensityTexture: Nullable<BaseTexture>;
    /**
     * Defines the translucency tint of the material.
     * If not set, the tint color will be used instead.
     */
    translucencyColor: Nullable<Color3>;
    private _translucencyColorTexture;
    /**
     * Defines the translucency tint color of the material as a texture.
     * This is multiplied against the translucency color to add variety and realism to the material.
     * If translucencyColor is not set, the tint color will be used instead.
     */
    translucencyColorTexture: Nullable<BaseTexture>;
    private _useGltfStyleTextures;
    /**
     * Use channels layout used by glTF:
     * * thicknessTexture: the green (instead of red) channel is the thickness
     * * thicknessTexture/refractionIntensityTexture: the red (instead of green) channel is the refraction intensity
     * * thicknessTexture/translucencyIntensityTexture: the alpha (instead of blue) channel is the translucency intensity
     */
    useGltfStyleTextures: boolean;
    /**
     * This property only exists for backward compatibility reasons.
     * Set it to true if your rendering in 8.0+ is different from that in 7 when you use sub-surface properties (transmission, refraction, etc.). Default is false.
     * Note however that the PBR calculation is wrong when this property is set to true, so only use it if you want to mimic the 7.0 behavior.
     */
    applyAlbedoAfterSubSurface: boolean;
    /**
     * This property only exists for backward compatibility reasons.
     * Set it to true if your rendering in 8.0+ is different from that in 7 when you use sub-surface translucency. Default is false.
     */
    legacyTranslucency: boolean;
    /**
     * Keeping for backward compatibility... Should not be used anymore. It has been replaced by
     * the property with the correct spelling.
     * @see legacyTranslucency
     */
    get legacyTransluceny(): boolean;
    set legacyTransluceny(value: boolean);
    private _scene;
    /** @internal */
    private _internalMarkAllSubMeshesAsTexturesDirty;
    private _internalMarkScenePrePassDirty;
    /** @internal */
    _markAllSubMeshesAsTexturesDirty(): void;
    /** @internal */
    _markScenePrePassDirty(): void;
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(): boolean;
    constructor(material: PBRBaseMaterial, addToPluginList?: boolean);
    isReadyForSubMesh(defines: MaterialSubSurfaceDefines, scene: Scene): boolean;
    prepareDefinesBeforeAttributes(defines: MaterialSubSurfaceDefines, scene: Scene): void;
    /**
     * Binds the material data (this function is called even if mustRebind() returns false)
     * @param uniformBuffer defines the Uniform buffer to fill in.
     * @param scene defines the scene the material belongs to.
     * @param engine defines the engine the material belongs to.
     * @param subMesh the submesh to bind data for
     */
    hardBindForSubMesh(uniformBuffer: UniformBuffer, scene: Scene, engine: Engine, subMesh: SubMesh): void;
    bindForSubMesh(uniformBuffer: UniformBuffer, scene: Scene, engine: Engine, subMesh: SubMesh): void;
    /**
     * Returns the texture used for refraction or null if none is used.
     * @param scene defines the scene the material belongs to.
     * @returns - Refraction texture if present.  If no refraction texture and refraction
     * is linked with transparency, returns environment texture.  Otherwise, returns null.
     */
    private _getRefractionTexture;
    /**
     * Returns true if alpha blending should be disabled.
     */
    get disableAlphaBlending(): boolean;
    /**
     * Fills the list of render target textures.
     * @param renderTargets the list of render targets to update
     */
    fillRenderTargetTextures(renderTargets: SmartArray<RenderTargetTexture>): void;
    hasTexture(texture: BaseTexture): boolean;
    hasRenderTargetTextures(): boolean;
    getActiveTextures(activeTextures: BaseTexture[]): void;
    getAnimatables(animatables: IAnimatable[]): void;
    dispose(forceDisposeTextures?: boolean): void;
    getClassName(): string;
    addFallbacks(defines: MaterialSubSurfaceDefines, fallbacks: EffectFallbacks, currentRank: number): number;
    getSamplers(samplers: string[]): void;
    getUniforms(): {
        ubo?: Array<{
            name: string;
            size: number;
            type: string;
        }>;
        vertex?: string;
        fragment?: string;
    };
}

declare const PBRBaseMaterialBase_base: {
    new (...args: any[]): {
        _imageProcessingConfiguration: ImageProcessingConfiguration;
        get imageProcessingConfiguration(): ImageProcessingConfiguration;
        set imageProcessingConfiguration(value: ImageProcessingConfiguration);
        _imageProcessingObserver: Nullable<Observer<ImageProcessingConfiguration>>;
        _attachImageProcessingConfiguration(configuration: Nullable<ImageProcessingConfiguration>): void;
        get cameraColorCurvesEnabled(): boolean;
        set cameraColorCurvesEnabled(value: boolean);
        get cameraColorGradingEnabled(): boolean;
        set cameraColorGradingEnabled(value: boolean);
        get cameraToneMappingEnabled(): boolean;
        set cameraToneMappingEnabled(value: boolean);
        get cameraExposure(): number;
        set cameraExposure(value: number);
        get cameraContrast(): number;
        set cameraContrast(value: number);
        get cameraColorGradingTexture(): Nullable<BaseTexture>;
        set cameraColorGradingTexture(value: Nullable<BaseTexture>);
        get cameraColorCurves(): Nullable<ColorCurves>;
        set cameraColorCurves(value: Nullable<ColorCurves>);
    };
} & typeof PushMaterial;
declare class PBRBaseMaterialBase extends PBRBaseMaterialBase_base {
}
/**
 * The Physically based material base class of BJS.
 *
 * This offers the main features of a standard PBR material.
 * For more information, please refer to the documentation :
 * https://doc.babylonjs.com/features/featuresDeepDive/materials/using/introToPBR
 * @see [WebGL](https://playground.babylonjs.com/#CGHTSM#1)
 * @see [WebGPU](https://playground.babylonjs.com/#CGHTSM#2)
 */
declare abstract class PBRBaseMaterial extends PBRBaseMaterialBase {
    /**
     * PBRMaterialTransparencyMode: No transparency mode, Alpha channel is not use.
     */
    static readonly PBRMATERIAL_OPAQUE = 0;
    /**
     * PBRMaterialTransparencyMode: Alpha Test mode, pixel are discarded below a certain threshold defined by the alpha cutoff value.
     */
    static readonly PBRMATERIAL_ALPHATEST = 1;
    /**
     * PBRMaterialTransparencyMode: Pixels are blended (according to the alpha mode) with the already drawn pixels in the current frame buffer.
     */
    static readonly PBRMATERIAL_ALPHABLEND = 2;
    /**
     * PBRMaterialTransparencyMode: Pixels are blended (according to the alpha mode) with the already drawn pixels in the current frame buffer.
     * They are also discarded below the alpha cutoff threshold to improve performances.
     */
    static readonly PBRMATERIAL_ALPHATESTANDBLEND = 3;
    /**
     * Defines the default value of how much AO map is occluding the analytical lights
     * (point spot...).
     */
    static DEFAULT_AO_ON_ANALYTICAL_LIGHTS: number;
    /**
     * PBRMaterialLightFalloff Physical: light is falling off following the inverse squared distance law.
     */
    static readonly LIGHTFALLOFF_PHYSICAL = 0;
    /**
     * PBRMaterialLightFalloff gltf: light is falling off as described in the gltf moving to PBR document
     * to enhance interoperability with other engines.
     */
    static readonly LIGHTFALLOFF_GLTF = 1;
    /**
     * PBRMaterialLightFalloff Standard: light is falling off like in the standard material
     * to enhance interoperability with other materials.
     */
    static readonly LIGHTFALLOFF_STANDARD = 2;
    /**
     * Force all the PBR materials to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * Intensity of the direct lights e.g. the four lights available in your scene.
     * This impacts both the direct diffuse and specular highlights.
     * @internal
     */
    _directIntensity: number;
    /**
     * Intensity of the emissive part of the material.
     * This helps controlling the emissive effect without modifying the emissive color.
     * @internal
     */
    _emissiveIntensity: number;
    /**
     * Intensity of the environment e.g. how much the environment will light the object
     * either through harmonics for rough material or through the reflection for shiny ones.
     * @internal
     */
    _environmentIntensity: number;
    /**
     * This is a special control allowing the reduction of the specular highlights coming from the
     * four lights of the scene. Those highlights may not be needed in full environment lighting.
     * @internal
     */
    _specularIntensity: number;
    /**
     * This stores the direct, emissive, environment, and specular light intensities into a Vector4.
     */
    private _lightingInfos;
    /**
     * Debug Control allowing disabling the bump map on this material.
     * @internal
     */
    _disableBumpMap: boolean;
    /**
     * AKA Diffuse Texture in standard nomenclature.
     * @internal
     */
    _albedoTexture: Nullable<BaseTexture>;
    /**
     * Base Weight texture (multiplier to the diffuse and metal lobes).
     * @internal
     */
    _baseWeightTexture: Nullable<BaseTexture>;
    /**
     * Base Diffuse Roughness texture (roughness of the diffuse lobe).
     * @internal
     */
    _baseDiffuseRoughnessTexture: Nullable<BaseTexture>;
    /**
     * AKA Occlusion Texture in other nomenclature.
     * @internal
     */
    _ambientTexture: Nullable<BaseTexture>;
    /**
     * AKA Occlusion Texture Intensity in other nomenclature.
     * @internal
     */
    _ambientTextureStrength: number;
    /**
     * Defines how much the AO map is occluding the analytical lights (point spot...).
     * 1 means it completely occludes it
     * 0 mean it has no impact
     * @internal
     */
    _ambientTextureImpactOnAnalyticalLights: number;
    /**
     * Stores the alpha values in a texture.
     * @internal
     */
    _opacityTexture: Nullable<BaseTexture>;
    /**
     * Stores the reflection values in a texture.
     * @internal
     */
    _reflectionTexture: Nullable<BaseTexture>;
    /**
     * Stores the emissive values in a texture.
     * @internal
     */
    _emissiveTexture: Nullable<BaseTexture>;
    /**
     * AKA Specular texture in other nomenclature.
     * @internal
     */
    _reflectivityTexture: Nullable<BaseTexture>;
    /**
     * Used to switch from specular/glossiness to metallic/roughness workflow.
     * @internal
     */
    _metallicTexture: Nullable<BaseTexture>;
    /**
     * Specifies the metallic scalar of the metallic/roughness workflow.
     * Can also be used to scale the metalness values of the metallic texture.
     * @internal
     */
    _metallic: Nullable<number>;
    /**
     * Specifies the roughness scalar of the metallic/roughness workflow.
     * Can also be used to scale the roughness values of the metallic texture.
     * @internal
     */
    _roughness: Nullable<number>;
    /**
     * In metallic workflow, specifies an F0 factor to help configuring the material F0.
     * By default the indexOfrefraction is used to compute F0;
     *
     * This is used as a factor against the default reflectance at normal incidence to tweak it.
     *
     * F0 = defaultF0 * metallicF0Factor * metallicReflectanceColor;
     * F90 = metallicReflectanceColor;
     * @internal
     */
    _metallicF0Factor: number;
    /**
     * In metallic workflow, specifies an F0 color.
     * By default the F90 is always 1;
     *
     * Please note that this factor is also used as a factor against the default reflectance at normal incidence.
     *
     * F0 = defaultF0_from_IOR * metallicF0Factor * metallicReflectanceColor
     * F90 = metallicF0Factor;
     * @internal
     */
    _metallicReflectanceColor: Color3;
    /**
     * Specifies that only the A channel from _metallicReflectanceTexture should be used.
     * If false, both RGB and A channels will be used
     * @internal
     */
    _useOnlyMetallicFromMetallicReflectanceTexture: boolean;
    /**
     * Defines to store metallicReflectanceColor in RGB and metallicF0Factor in A
     * This is multiply against the scalar values defined in the material.
     * @internal
     */
    _metallicReflectanceTexture: Nullable<BaseTexture>;
    /**
     * Defines to store reflectanceColor in RGB
     * This is multiplied against the scalar values defined in the material.
     * If both _reflectanceTexture and _metallicReflectanceTexture textures are provided and _useOnlyMetallicFromMetallicReflectanceTexture
     * is false, _metallicReflectanceTexture takes precedence and _reflectanceTexture is not used
     * @internal
     */
    _reflectanceTexture: Nullable<BaseTexture>;
    /**
     * Used to enable roughness/glossiness fetch from a separate channel depending on the current mode.
     * Gray Scale represents roughness in metallic mode and glossiness in specular mode.
     * @internal
     */
    _microSurfaceTexture: Nullable<BaseTexture>;
    /**
     * Stores surface normal data used to displace a mesh in a texture.
     * @internal
     */
    _bumpTexture: Nullable<BaseTexture>;
    /**
     * Stores the pre-calculated light information of a mesh in a texture.
     * @internal
     */
    _lightmapTexture: Nullable<BaseTexture>;
    /**
     * The color of a material in ambient lighting.
     * @internal
     */
    _ambientColor: Color3;
    /**
     * AKA Diffuse Color in other nomenclature.
     * @internal
     */
    _albedoColor: Color3;
    /**
     * Base Weight (multiplier to the diffuse and metal lobes).
     * @internal
     */
    _baseWeight: number;
    /**
     * Base Diffuse Roughness (roughness of the diffuse lobe).
     * Can also be used to scale the corresponding texture.
     * @internal
     */
    _baseDiffuseRoughness: Nullable<number>;
    /**
     * AKA Specular Color in other nomenclature.
     * @internal
     */
    _reflectivityColor: Color3;
    /**
     * The color applied when light is reflected from a material.
     * @internal
     */
    _reflectionColor: Color3;
    /**
     * The color applied when light is emitted from a material.
     * @internal
     */
    _emissiveColor: Color3;
    /**
     * AKA Glossiness in other nomenclature.
     * @internal
     */
    _microSurface: number;
    /**
     * Specifies that the material will use the light map as a show map.
     * @internal
     */
    _useLightmapAsShadowmap: boolean;
    /**
     * This parameters will enable/disable Horizon occlusion to prevent normal maps to look shiny when the normal
     * makes the reflect vector face the model (under horizon).
     * @internal
     */
    _useHorizonOcclusion: boolean;
    /**
     * This parameters will enable/disable radiance occlusion by preventing the radiance to lit
     * too much the area relying on ambient texture to define their ambient occlusion.
     * @internal
     */
    _useRadianceOcclusion: boolean;
    /**
     * Specifies that the alpha is coming form the albedo channel alpha channel for alpha blending.
     * @internal
     */
    _useAlphaFromAlbedoTexture: boolean;
    /**
     * Specifies that the material will keeps the specular highlights over a transparent surface (only the most luminous ones).
     * A car glass is a good example of that. When sun reflects on it you can not see what is behind.
     * @internal
     */
    _useSpecularOverAlpha: boolean;
    /**
     * Specifies if the reflectivity texture contains the glossiness information in its alpha channel.
     * @internal
     */
    _useMicroSurfaceFromReflectivityMapAlpha: boolean;
    /**
     * Specifies if the metallic texture contains the roughness information in its alpha channel.
     * @internal
     */
    _useRoughnessFromMetallicTextureAlpha: boolean;
    /**
     * Specifies if the metallic texture contains the roughness information in its green channel.
     * @internal
     */
    _useRoughnessFromMetallicTextureGreen: boolean;
    /**
     * Specifies if the metallic texture contains the metallness information in its blue channel.
     * @internal
     */
    _useMetallnessFromMetallicTextureBlue: boolean;
    /**
     * Specifies if the metallic texture contains the ambient occlusion information in its red channel.
     * @internal
     */
    _useAmbientOcclusionFromMetallicTextureRed: boolean;
    /**
     * Specifies if the ambient texture contains the ambient occlusion information in its red channel only.
     * @internal
     */
    _useAmbientInGrayScale: boolean;
    /**
     * In case the reflectivity map does not contain the microsurface information in its alpha channel,
     * The material will try to infer what glossiness each pixel should be.
     * @internal
     */
    _useAutoMicroSurfaceFromReflectivityMap: boolean;
    /**
     * Defines the  falloff type used in this material.
     * It by default is Physical.
     * @internal
     */
    _lightFalloff: number;
    /**
     * Specifies that the material will keeps the reflection highlights over a transparent surface (only the most luminous ones).
     * A car glass is a good example of that. When the street lights reflects on it you can not see what is behind.
     * @internal
     */
    _useRadianceOverAlpha: boolean;
    /**
     * Allows using an object space normal map (instead of tangent space).
     * @internal
     */
    _useObjectSpaceNormalMap: boolean;
    /**
     * Allows using the bump map in parallax mode.
     * @internal
     */
    _useParallax: boolean;
    /**
     * Allows using the bump map in parallax occlusion mode.
     * @internal
     */
    _useParallaxOcclusion: boolean;
    /**
     * Controls the scale bias of the parallax mode.
     * @internal
     */
    _parallaxScaleBias: number;
    /**
     * If sets to true, disables all the lights affecting the material.
     * @internal
     */
    _disableLighting: boolean;
    /**
     * Number of Simultaneous lights allowed on the material.
     * @internal
     */
    _maxSimultaneousLights: number;
    /**
     * If sets to true, x component of normal map value will be inverted (x = 1.0 - x).
     * @internal
     */
    _invertNormalMapX: boolean;
    /**
     * If sets to true, y component of normal map value will be inverted (y = 1.0 - y).
     * @internal
     */
    _invertNormalMapY: boolean;
    /**
     * If sets to true and backfaceCulling is false, normals will be flipped on the backside.
     * @internal
     */
    _twoSidedLighting: boolean;
    /**
     * Defines the alpha limits in alpha test mode.
     * @internal
     */
    _alphaCutOff: number;
    /**
     * A fresnel is applied to the alpha of the model to ensure grazing angles edges are not alpha tested.
     * And/Or occlude the blended part. (alpha is converted to gamma to compute the fresnel)
     * @internal
     */
    _useAlphaFresnel: boolean;
    /**
     * A fresnel is applied to the alpha of the model to ensure grazing angles edges are not alpha tested.
     * And/Or occlude the blended part. (alpha stays linear to compute the fresnel)
     * @internal
     */
    _useLinearAlphaFresnel: boolean;
    /**
     * Specifies the environment BRDF texture used to compute the scale and offset roughness values
     * from cos theta and roughness:
     * http://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf
     * @internal
     */
    _environmentBRDFTexture: Nullable<BaseTexture>;
    /**
     * Force the shader to compute irradiance in the fragment shader in order to take bump in account.
     * @internal
     */
    _forceIrradianceInFragment: boolean;
    private _realTimeFiltering;
    /**
     * Enables realtime filtering on the texture.
     */
    get realTimeFiltering(): boolean;
    set realTimeFiltering(b: boolean);
    private _realTimeFilteringQuality;
    /**
     * Quality switch for realtime filtering
     */
    get realTimeFilteringQuality(): number;
    set realTimeFilteringQuality(n: number);
    /**
     * Can this material render to several textures at once
     */
    get canRenderToMRT(): boolean;
    /**
     * Force normal to face away from face.
     * @internal
     */
    _forceNormalForward: boolean;
    /**
     * Enables specular anti aliasing in the PBR shader.
     * It will both interacts on the Geometry for analytical and IBL lighting.
     * It also prefilter the roughness map based on the bump values.
     * @internal
     */
    _enableSpecularAntiAliasing: boolean;
    /**
     * Stores the available render targets.
     */
    private _renderTargets;
    /**
     * Sets the global ambient color for the material used in lighting calculations.
     */
    private _globalAmbientColor;
    /**
     * If set to true, no lighting calculations will be applied.
     * @internal
     */
    _unlit: boolean;
    /**
     * If sets to true, the decal map will be applied after the detail map. Else, it is applied before (default: false)
     */
    private _applyDecalMapAfterDetailMap;
    private _debugMode;
    private _shadersLoaded;
    private _breakShaderLoadedCheck;
    /**
     * @internal
     * This is reserved for the inspector.
     * Defines the material debug mode.
     * It helps seeing only some components of the material while troubleshooting.
     */
    debugMode: number;
    /**
     * @internal
     * This is reserved for the inspector.
     * Specify from where on screen the debug mode should start.
     * The value goes from -1 (full screen) to 1 (not visible)
     * It helps with side by side comparison against the final render
     * This defaults to -1
     */
    debugLimit: number;
    /**
     * @internal
     * This is reserved for the inspector.
     * As the default viewing range might not be enough (if the ambient is really small for instance)
     * You can use the factor to better multiply the final value.
     */
    debugFactor: number;
    /**
     * Defines the clear coat layer parameters for the material.
     */
    readonly clearCoat: PBRClearCoatConfiguration;
    /**
     * Defines the iridescence layer parameters for the material.
     */
    readonly iridescence: PBRIridescenceConfiguration;
    /**
     * Defines the anisotropic parameters for the material.
     */
    readonly anisotropy: PBRAnisotropicConfiguration;
    /**
     * Defines the BRDF parameters for the material.
     */
    readonly brdf: PBRBRDFConfiguration;
    /**
     * Defines the Sheen parameters for the material.
     */
    readonly sheen: PBRSheenConfiguration;
    /**
     * Defines the SubSurface parameters for the material.
     */
    readonly subSurface: PBRSubSurfaceConfiguration;
    /**
     * Defines additional PrePass parameters for the material.
     */
    readonly prePassConfiguration: PrePassConfiguration;
    /**
     * Defines the detail map parameters for the material.
     */
    readonly detailMap: DetailMapConfiguration;
    protected _cacheHasRenderTargetTextures: boolean;
    /**
     * Instantiates a new PBRMaterial instance.
     *
     * @param name The material name
     * @param scene The scene the material will be use in.
     * @param forceGLSL Use the GLSL code generation for the shader (even on WebGPU). Default is false
     */
    constructor(name: string, scene?: Scene, forceGLSL?: boolean);
    /**
     * Gets a boolean indicating that current material needs to register RTT
     */
    get hasRenderTargetTextures(): boolean;
    /**
     * Can this material render to prepass
     */
    get isPrePassCapable(): boolean;
    /**
     * @returns the name of the material class.
     */
    getClassName(): string;
    /**
     * Returns true if alpha blending should be disabled.
     */
    protected get _disableAlphaBlending(): boolean;
    /**
     * @returns whether or not this material should be rendered in alpha blend mode.
     */
    needAlphaBlending(): boolean;
    /**
     * @returns whether or not this material should be rendered in alpha test mode.
     */
    needAlphaTesting(): boolean;
    /**
     * @returns whether or not the alpha value of the albedo texture should be used for alpha blending.
     */
    protected _shouldUseAlphaFromAlbedoTexture(): boolean;
    /**
     * @returns whether or not there is a usable alpha channel for transparency.
     */
    protected _hasAlphaChannel(): boolean;
    /**
     * @returns the texture used for the alpha test.
     */
    getAlphaTestTexture(): Nullable<BaseTexture>;
    /**
     * Specifies that the submesh is ready to be used.
     * @param mesh - BJS mesh.
     * @param subMesh - A submesh of the BJS mesh.  Used to check if it is ready.
     * @param useInstances - Specifies that instances should be used.
     * @returns - boolean indicating that the submesh is ready or not.
     */
    isReadyForSubMesh(mesh: AbstractMesh, subMesh: SubMesh, useInstances?: boolean): boolean;
    /**
     * Specifies if the material uses metallic roughness workflow.
     * @returns boolean specifying if the material uses metallic roughness workflow.
     */
    isMetallicWorkflow(): boolean;
    private _prepareEffect;
    private _prepareDefines;
    /**
     * Force shader compilation
     * @param mesh - Define the mesh we want to force the compilation for
     * @param onCompiled - Define a callback triggered when the compilation completes
     * @param options - Define the options used to create the compilation
     */
    forceCompilation(mesh: AbstractMesh, onCompiled?: (material: Material) => void, options?: Partial<IMaterialCompilationOptions>): void;
    /**
     * Initializes the uniform buffer layout for the shader.
     */
    buildUniformLayout(): void;
    /**
     * Binds the submesh data.
     * @param world - The world matrix.
     * @param mesh - The BJS mesh.
     * @param subMesh - A submesh of the BJS mesh.
     */
    bindForSubMesh(world: Matrix, mesh: Mesh, subMesh: SubMesh): void;
    /**
     * Returns the animatable textures.
     * If material have animatable metallic texture, then reflectivity texture will not be returned, even if it has animations.
     * @returns - Array of animatable textures.
     */
    getAnimatables(): IAnimatable[];
    /**
     * Returns the texture used for reflections.
     * @returns - Reflection texture if present.  Otherwise, returns the environment texture.
     */
    private _getReflectionTexture;
    /**
     * Returns an array of the actively used textures.
     * @returns - Array of BaseTextures
     */
    getActiveTextures(): BaseTexture[];
    /**
     * Checks to see if a texture is used in the material.
     * @param texture - Base texture to use.
     * @returns - Boolean specifying if a texture is used in the material.
     */
    hasTexture(texture: BaseTexture): boolean;
    /**
     * Sets the required values to the prepass renderer.
     * It can't be sets when subsurface scattering of this material is disabled.
     * When scene have ability to enable subsurface prepass effect, it will enable.
     * @returns - If prepass is enabled or not.
     */
    setPrePassRenderer(): boolean;
    /**
     * Disposes the resources of the material.
     * @param forceDisposeEffect - Forces the disposal of effects.
     * @param forceDisposeTextures - Forces the disposal of all textures.
     */
    dispose(forceDisposeEffect?: boolean, forceDisposeTextures?: boolean): void;
}

/**
 * @internal
 */
declare class MaterialDetailMapDefines extends MaterialDefines {
    DETAIL: boolean;
    DETAILDIRECTUV: number;
    DETAIL_NORMALBLENDMETHOD: number;
}
/**
 * Plugin that implements the detail map component of a material
 *
 * Inspired from:
 *   Unity: https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@9.0/manual/Mask-Map-and-Detail-Map.html and https://docs.unity3d.com/Manual/StandardShaderMaterialParameterDetail.html
 *   Unreal: https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/HowTo/DetailTexturing/index.html
 *   Cryengine: https://docs.cryengine.com/display/SDKDOC2/Detail+Maps
 */
declare class DetailMapConfiguration extends MaterialPluginBase {
    private _texture;
    /**
     * The detail texture of the material.
     */
    texture: Nullable<BaseTexture>;
    /**
     * Defines how strongly the detail diffuse/albedo channel is blended with the regular diffuse/albedo texture
     * Bigger values mean stronger blending
     */
    diffuseBlendLevel: number;
    /**
     * Defines how strongly the detail roughness channel is blended with the regular roughness value
     * Bigger values mean stronger blending. Only used with PBR materials
     */
    roughnessBlendLevel: number;
    /**
     * Defines how strong the bump effect from the detail map is
     * Bigger values mean stronger effect
     */
    bumpLevel: number;
    private _normalBlendMethod;
    /**
     * The method used to blend the bump and detail normals together
     */
    normalBlendMethod: number;
    private _isEnabled;
    /**
     * Enable or disable the detail map on this material
     */
    isEnabled: boolean;
    /** @internal */
    private _internalMarkAllSubMeshesAsTexturesDirty;
    /** @internal */
    _markAllSubMeshesAsTexturesDirty(): void;
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(): boolean;
    constructor(material: PBRBaseMaterial | StandardMaterial, addToPluginList?: boolean);
    isReadyForSubMesh(defines: MaterialDetailMapDefines, scene: Scene, engine: AbstractEngine): boolean;
    prepareDefines(defines: MaterialDetailMapDefines, scene: Scene): void;
    bindForSubMesh(uniformBuffer: UniformBuffer, scene: Scene): void;
    hasTexture(texture: BaseTexture): boolean;
    getActiveTextures(activeTextures: BaseTexture[]): void;
    getAnimatables(animatables: IAnimatable[]): void;
    dispose(forceDisposeTextures?: boolean): void;
    getClassName(): string;
    getSamplers(samplers: string[]): void;
    getUniforms(): {
        ubo?: Array<{
            name: string;
            size: number;
            type: string;
        }>;
        vertex?: string;
        fragment?: string;
    };
}

declare const StandardMaterialBase_base: {
    new (...args: any[]): {
        _imageProcessingConfiguration: ImageProcessingConfiguration;
        get imageProcessingConfiguration(): ImageProcessingConfiguration;
        set imageProcessingConfiguration(value: ImageProcessingConfiguration);
        _imageProcessingObserver: Nullable<Observer<ImageProcessingConfiguration>>;
        _attachImageProcessingConfiguration(configuration: Nullable<ImageProcessingConfiguration>): void;
        get cameraColorCurvesEnabled(): boolean;
        set cameraColorCurvesEnabled(value: boolean);
        get cameraColorGradingEnabled(): boolean;
        set cameraColorGradingEnabled(value: boolean);
        get cameraToneMappingEnabled(): boolean;
        set cameraToneMappingEnabled(value: boolean);
        get cameraExposure(): number;
        set cameraExposure(value: number);
        get cameraContrast(): number;
        set cameraContrast(value: number);
        get cameraColorGradingTexture(): Nullable<BaseTexture>;
        set cameraColorGradingTexture(value: Nullable<BaseTexture>);
        get cameraColorCurves(): Nullable<ColorCurves>;
        set cameraColorCurves(value: Nullable<ColorCurves>);
    };
} & typeof PushMaterial;
declare class StandardMaterialBase extends StandardMaterialBase_base {
}
/**
 * This is the default material used in Babylon. It is the best trade off between quality
 * and performances.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction
 */
declare class StandardMaterial extends StandardMaterialBase {
    /**
     * Force all the standard materials to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    private _diffuseTexture;
    /**
     * The basic texture of the material as viewed under a light.
     */
    diffuseTexture: Nullable<BaseTexture>;
    private _ambientTexture;
    /**
     * AKA Occlusion Texture in other nomenclature, it helps adding baked shadows into your material.
     */
    ambientTexture: Nullable<BaseTexture>;
    private _opacityTexture;
    /**
     * Define the transparency of the material from a texture.
     * The final alpha value can be read either from the red channel (if texture.getAlphaFromRGB is false)
     * or from the luminance or the current texel (if texture.getAlphaFromRGB is true)
     */
    opacityTexture: Nullable<BaseTexture>;
    private _reflectionTexture;
    /**
     * Define the texture used to display the reflection.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#how-to-obtain-reflections-and-refractions
     */
    reflectionTexture: Nullable<BaseTexture>;
    private _emissiveTexture;
    /**
     * Define texture of the material as if self lit.
     * This will be mixed in the final result even in the absence of light.
     */
    emissiveTexture: Nullable<BaseTexture>;
    private _specularTexture;
    /**
     * Define how the color and intensity of the highlight given by the light in the material.
     */
    specularTexture: Nullable<BaseTexture>;
    private _bumpTexture;
    /**
     * Bump mapping is a technique to simulate bump and dents on a rendered surface.
     * These are made by creating a normal map from an image. The means to do this can be found on the web, a search for 'normal map generator' will bring up free and paid for methods of doing this.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/moreMaterials#bump-map
     */
    bumpTexture: Nullable<BaseTexture>;
    private _lightmapTexture;
    /**
     * Complex lighting can be computationally expensive to compute at runtime.
     * To save on computation, lightmaps may be used to store calculated lighting in a texture which will be applied to a given mesh.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction#lightmaps
     */
    lightmapTexture: Nullable<BaseTexture>;
    private _refractionTexture;
    /**
     * Define the texture used to display the refraction.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#how-to-obtain-reflections-and-refractions
     */
    refractionTexture: Nullable<BaseTexture>;
    /**
     * The color of the material lit by the environmental background lighting.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction#ambient-color-example
     */
    ambientColor: Color3;
    /**
     * The basic color of the material as viewed under a light.
     */
    diffuseColor: Color3;
    /**
     * Define how the color and intensity of the highlight given by the light in the material.
     */
    specularColor: Color3;
    /**
     * Define the color of the material as if self lit.
     * This will be mixed in the final result even in the absence of light.
     */
    emissiveColor: Color3;
    /**
     * Defines how sharp are the highlights in the material.
     * The bigger the value the sharper giving a more glossy feeling to the result.
     * Reversely, the smaller the value the blurrier giving a more rough feeling to the result.
     */
    specularPower: number;
    private _useAlphaFromDiffuseTexture;
    /**
     * Does the transparency come from the diffuse texture alpha channel.
     */
    useAlphaFromDiffuseTexture: boolean;
    private _useEmissiveAsIllumination;
    /**
     * If true, the emissive value is added into the end result, otherwise it is multiplied in.
     */
    useEmissiveAsIllumination: boolean;
    private _linkEmissiveWithDiffuse;
    /**
     * If true, some kind of energy conservation will prevent the end result to be more than 1 by reducing
     * the emissive level when the final color is close to one.
     */
    linkEmissiveWithDiffuse: boolean;
    private _useSpecularOverAlpha;
    /**
     * Specifies that the material will keep the specular highlights over a transparent surface (only the most luminous ones).
     * A car glass is a good exemple of that. When sun reflects on it you can not see what is behind.
     */
    useSpecularOverAlpha: boolean;
    private _useReflectionOverAlpha;
    /**
     * Specifies that the material will keeps the reflection highlights over a transparent surface (only the most luminous ones).
     * A car glass is a good exemple of that. When the street lights reflects on it you can not see what is behind.
     */
    useReflectionOverAlpha: boolean;
    private _disableLighting;
    /**
     * Does lights from the scene impacts this material.
     * It can be a nice trick for performance to disable lighting on a fully emissive material.
     */
    disableLighting: boolean;
    private _useObjectSpaceNormalMap;
    /**
     * Allows using an object space normal map (instead of tangent space).
     */
    useObjectSpaceNormalMap: boolean;
    private _useParallax;
    /**
     * Is parallax enabled or not.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/parallaxMapping
     */
    useParallax: boolean;
    private _useParallaxOcclusion;
    /**
     * Is parallax occlusion enabled or not.
     * If true, the outcome is way more realistic than traditional Parallax but you can expect a performance hit that worthes consideration.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/parallaxMapping
     */
    useParallaxOcclusion: boolean;
    /**
     * Apply a scaling factor that determine which "depth" the height map should reprensent. A value between 0.05 and 0.1 is reasonnable in Parallax, you can reach 0.2 using Parallax Occlusion.
     */
    parallaxScaleBias: number;
    private _roughness;
    /**
     * Helps to define how blurry the reflections should appears in the material.
     */
    roughness: number;
    /**
     * In case of refraction, define the value of the index of refraction.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#how-to-obtain-reflections-and-refractions
     */
    indexOfRefraction: number;
    /**
     * Invert the refraction texture alongside the y axis.
     * It can be useful with procedural textures or probe for instance.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/reflectionTexture#how-to-obtain-reflections-and-refractions
     */
    invertRefractionY: boolean;
    /**
     * Defines the alpha limits in alpha test mode.
     */
    alphaCutOff: number;
    private _useLightmapAsShadowmap;
    /**
     * In case of light mapping, define whether the map contains light or shadow informations.
     */
    useLightmapAsShadowmap: boolean;
    private _diffuseFresnelParameters;
    /**
     * Define the diffuse fresnel parameters of the material.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/fresnelParameters
     */
    diffuseFresnelParameters: FresnelParameters;
    private _opacityFresnelParameters;
    /**
     * Define the opacity fresnel parameters of the material.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/fresnelParameters
     */
    opacityFresnelParameters: FresnelParameters;
    private _reflectionFresnelParameters;
    /**
     * Define the reflection fresnel parameters of the material.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/fresnelParameters
     */
    reflectionFresnelParameters: FresnelParameters;
    private _refractionFresnelParameters;
    /**
     * Define the refraction fresnel parameters of the material.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/fresnelParameters
     */
    refractionFresnelParameters: FresnelParameters;
    private _emissiveFresnelParameters;
    /**
     * Define the emissive fresnel parameters of the material.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/fresnelParameters
     */
    emissiveFresnelParameters: FresnelParameters;
    private _useReflectionFresnelFromSpecular;
    /**
     * If true automatically deducts the fresnels values from the material specularity.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/fresnelParameters
     */
    useReflectionFresnelFromSpecular: boolean;
    private _useGlossinessFromSpecularMapAlpha;
    /**
     * Defines if the glossiness/roughness of the material should be read from the specular map alpha channel
     */
    useGlossinessFromSpecularMapAlpha: boolean;
    private _maxSimultaneousLights;
    /**
     * Defines the maximum number of lights that can be used in the material
     */
    maxSimultaneousLights: number;
    private _invertNormalMapX;
    /**
     * If sets to true, x component of normal map value will invert (x = 1.0 - x).
     */
    invertNormalMapX: boolean;
    private _invertNormalMapY;
    /**
     * If sets to true, y component of normal map value will invert (y = 1.0 - y).
     */
    invertNormalMapY: boolean;
    private _twoSidedLighting;
    /**
     * If sets to true and backfaceCulling is false, normals will be flipped on the backside.
     */
    twoSidedLighting: boolean;
    private _applyDecalMapAfterDetailMap;
    /**
     * If sets to true, the decal map will be applied after the detail map. Else, it is applied before (default: false)
     */
    applyDecalMapAfterDetailMap: boolean;
    private _shadersLoaded;
    /**
     * Defines additional PrePass parameters for the material.
     */
    readonly prePassConfiguration: PrePassConfiguration;
    /**
     * Can this material render to prepass
     */
    get isPrePassCapable(): boolean;
    /**
     * Can this material render to several textures at once
     */
    get canRenderToMRT(): boolean;
    /**
     * Defines the detail map parameters for the material.
     */
    readonly detailMap: DetailMapConfiguration;
    protected _renderTargets: SmartArray<RenderTargetTexture>;
    protected _globalAmbientColor: Color3;
    protected _cacheHasRenderTargetTextures: boolean;
    /**
     * Instantiates a new standard material.
     * This is the default material used in Babylon. It is the best trade off between quality
     * and performances.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction
     * @param name Define the name of the material in the scene
     * @param scene Define the scene the material belong to
     * @param forceGLSL Use the GLSL code generation for the shader (even on WebGPU). Default is false
     */
    constructor(name: string, scene?: Scene, forceGLSL?: boolean);
    /**
     * Gets a boolean indicating that current material needs to register RTT
     */
    get hasRenderTargetTextures(): boolean;
    /**
     * Gets the current class name of the material e.g. "StandardMaterial"
     * Mainly use in serialization.
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Specifies if the material will require alpha blending
     * @returns a boolean specifying if alpha blending is needed
     */
    needAlphaBlending(): boolean;
    /**
     * Specifies if this material should be rendered in alpha test mode
     * @returns a boolean specifying if an alpha test is needed.
     */
    needAlphaTesting(): boolean;
    /**
     * @returns whether or not the alpha value of the diffuse texture should be used for alpha blending.
     */
    protected _shouldUseAlphaFromDiffuseTexture(): boolean;
    /**
     * @returns whether or not there is a usable alpha channel for transparency.
     */
    protected _hasAlphaChannel(): boolean;
    /**
     * Get the texture used for alpha test purpose.
     * @returns the diffuse texture in case of the standard material.
     */
    getAlphaTestTexture(): Nullable<BaseTexture>;
    /**
     * Get if the submesh is ready to be used and all its information available.
     * Child classes can use it to update shaders
     * @param mesh defines the mesh to check
     * @param subMesh defines which submesh to check
     * @param useInstances specifies that instances should be used
     * @returns a boolean indicating that the submesh is ready or not
     */
    isReadyForSubMesh(mesh: AbstractMesh, subMesh: SubMesh, useInstances?: boolean): boolean;
    /**
     * Builds the material UBO layouts.
     * Used internally during the effect preparation.
     */
    buildUniformLayout(): void;
    /**
     * Binds the submesh to this material by preparing the effect and shader to draw
     * @param world defines the world transformation matrix
     * @param mesh defines the mesh containing the submesh
     * @param subMesh defines the submesh to bind the material to
     */
    bindForSubMesh(world: Matrix, mesh: Mesh, subMesh: SubMesh): void;
    /**
     * Get the list of animatables in the material.
     * @returns the list of animatables object used in the material
     */
    getAnimatables(): IAnimatable[];
    /**
     * Gets the active textures from the material
     * @returns an array of textures
     */
    getActiveTextures(): BaseTexture[];
    /**
     * Specifies if the material uses a texture
     * @param texture defines the texture to check against the material
     * @returns a boolean specifying if the material uses the texture
     */
    hasTexture(texture: BaseTexture): boolean;
    /**
     * Disposes the material
     * @param forceDisposeEffect specifies if effects should be forcefully disposed
     * @param forceDisposeTextures specifies if textures should be forcefully disposed
     */
    dispose(forceDisposeEffect?: boolean, forceDisposeTextures?: boolean): void;
    /**
     * Makes a duplicate of the material, and gives it a new name
     * @param name defines the new name for the duplicated material
     * @param cloneTexturesOnlyOnce - if a texture is used in more than one channel (e.g diffuse and opacity), only clone it once and reuse it on the other channels. Default false.
     * @param rootUrl defines the root URL to use to load textures
     * @returns the cloned material
     */
    clone(name: string, cloneTexturesOnlyOnce?: boolean, rootUrl?: string): StandardMaterial;
    /**
     * Creates a standard material from parsed material data
     * @param source defines the JSON representation of the material
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a new standard material
     */
    static Parse(source: any, scene: Scene, rootUrl: string): StandardMaterial;
    /**
     * Are diffuse textures enabled in the application.
     */
    static get DiffuseTextureEnabled(): boolean;
    static set DiffuseTextureEnabled(value: boolean);
    /**
     * Are detail textures enabled in the application.
     */
    static get DetailTextureEnabled(): boolean;
    static set DetailTextureEnabled(value: boolean);
    /**
     * Are ambient textures enabled in the application.
     */
    static get AmbientTextureEnabled(): boolean;
    static set AmbientTextureEnabled(value: boolean);
    /**
     * Are opacity textures enabled in the application.
     */
    static get OpacityTextureEnabled(): boolean;
    static set OpacityTextureEnabled(value: boolean);
    /**
     * Are reflection textures enabled in the application.
     */
    static get ReflectionTextureEnabled(): boolean;
    static set ReflectionTextureEnabled(value: boolean);
    /**
     * Are emissive textures enabled in the application.
     */
    static get EmissiveTextureEnabled(): boolean;
    static set EmissiveTextureEnabled(value: boolean);
    /**
     * Are specular textures enabled in the application.
     */
    static get SpecularTextureEnabled(): boolean;
    static set SpecularTextureEnabled(value: boolean);
    /**
     * Are bump textures enabled in the application.
     */
    static get BumpTextureEnabled(): boolean;
    static set BumpTextureEnabled(value: boolean);
    /**
     * Are lightmap textures enabled in the application.
     */
    static get LightmapTextureEnabled(): boolean;
    static set LightmapTextureEnabled(value: boolean);
    /**
     * Are refraction textures enabled in the application.
     */
    static get RefractionTextureEnabled(): boolean;
    static set RefractionTextureEnabled(value: boolean);
    /**
     * Are color grading textures enabled in the application.
     */
    static get ColorGradingTextureEnabled(): boolean;
    static set ColorGradingTextureEnabled(value: boolean);
    /**
     * Are fresnels enabled in the application.
     */
    static get FresnelEnabled(): boolean;
    static set FresnelEnabled(value: boolean);
}

/**
 * Represents the different options available during the creation of
 * a Environment helper.
 *
 * This can control the default ground, skybox and image processing setup of your scene.
 */
interface IEnvironmentHelperOptions {
    /**
     * Specifies whether or not to create a ground.
     * True by default.
     */
    createGround: boolean;
    /**
     * Specifies the ground size.
     * 15 by default.
     */
    groundSize: number;
    /**
     * The texture used on the ground for the main color.
     * Comes from the BabylonJS CDN by default.
     *
     * Remarks: Can be either a texture or a url.
     */
    groundTexture: string | BaseTexture;
    /**
     * The color mixed in the ground texture by default.
     * BabylonJS clearColor by default.
     */
    groundColor: Color3;
    /**
     * Specifies the ground opacity.
     * 1 by default.
     */
    groundOpacity: number;
    /**
     * Enables the ground to receive shadows.
     * True by default.
     */
    enableGroundShadow: boolean;
    /**
     * Helps preventing the shadow to be fully black on the ground.
     * 0.5 by default.
     */
    groundShadowLevel: number;
    /**
     * Creates a mirror texture attach to the ground.
     * false by default.
     */
    enableGroundMirror: boolean;
    /**
     * Specifies the ground mirror size ratio.
     * 0.3 by default as the default kernel is 64.
     */
    groundMirrorSizeRatio: number;
    /**
     * Specifies the ground mirror blur kernel size.
     * 64 by default.
     */
    groundMirrorBlurKernel: number;
    /**
     * Specifies the ground mirror visibility amount.
     * 1 by default
     */
    groundMirrorAmount: number;
    /**
     * Specifies the ground mirror reflectance weight.
     * This uses the standard weight of the background material to setup the fresnel effect
     * of the mirror.
     * 1 by default.
     */
    groundMirrorFresnelWeight: number;
    /**
     * Specifies the ground mirror Falloff distance.
     * This can helps reducing the size of the reflection.
     * 0 by Default.
     */
    groundMirrorFallOffDistance: number;
    /**
     * Specifies the ground mirror texture type.
     * Unsigned Int by Default.
     */
    groundMirrorTextureType: number;
    /**
     * Specifies a bias applied to the ground vertical position to prevent z-fighting with
     * the shown objects.
     */
    groundYBias: number;
    /**
     * Specifies whether or not to create a skybox.
     * True by default.
     */
    createSkybox: boolean;
    /**
     * Specifies the skybox size.
     * 20 by default.
     */
    skyboxSize: number;
    /**
     * The texture used on the skybox for the main color.
     * Comes from the BabylonJS CDN by default.
     *
     * Remarks: Can be either a texture or a url.
     */
    skyboxTexture: string | BaseTexture;
    /**
     * The color mixed in the skybox texture by default.
     * BabylonJS clearColor by default.
     */
    skyboxColor: Color3;
    /**
     * The background rotation around the Y axis of the scene.
     * This helps aligning the key lights of your scene with the background.
     * 0 by default.
     */
    backgroundYRotation: number;
    /**
     * Compute automatically the size of the elements to best fit with the scene.
     */
    sizeAuto: boolean;
    /**
     * Default position of the rootMesh if autoSize is not true.
     */
    rootPosition: Vector3;
    /**
     * Sets up the image processing in the scene.
     * true by default.
     */
    setupImageProcessing: boolean;
    /**
     * The texture used as your environment texture in the scene.
     * Comes from the BabylonJS CDN by default and in use if setupImageProcessing is true.
     *
     * Remarks: Can be either a texture or a url.
     */
    environmentTexture: string | BaseTexture;
    /**
     * The value of the exposure to apply to the scene.
     * 0.6 by default if setupImageProcessing is true.
     */
    cameraExposure: number;
    /**
     * The value of the contrast to apply to the scene.
     * 1.6 by default if setupImageProcessing is true.
     */
    cameraContrast: number;
    /**
     * Specifies whether or not tonemapping should be enabled in the scene.
     * true by default if setupImageProcessing is true.
     */
    toneMappingEnabled: boolean;
}
/**
 * The EnvironmentHelper class can be used to add a fully featured non-expensive background to your scene.
 * It includes by default a skybox and a ground relying on the BackgroundMaterial.
 * It also helps with the default setup of your ImageProcessingConfiguration.
 */
declare class EnvironmentHelper {
    /**
     * Default ground texture URL.
     */
    private static _GroundTextureCDNUrl;
    /**
     * Default skybox texture URL.
     */
    private static _SkyboxTextureCDNUrl;
    /**
     * Default environment texture URL.
     */
    private static _EnvironmentTextureCDNUrl;
    /**
     * Creates the default options for the helper.
     * @param scene The scene the environment helper belongs to.
     * @returns default options for the helper.
     */
    private static _GetDefaultOptions;
    private _rootMesh;
    /**
     * Gets the root mesh created by the helper.
     */
    get rootMesh(): Mesh;
    private _skybox;
    /**
     * Gets the skybox created by the helper.
     */
    get skybox(): Nullable<Mesh>;
    private _skyboxTexture;
    /**
     * Gets the skybox texture created by the helper.
     */
    get skyboxTexture(): Nullable<BaseTexture>;
    private _skyboxMaterial;
    /**
     * Gets the skybox material created by the helper.
     */
    get skyboxMaterial(): Nullable<BackgroundMaterial>;
    private _ground;
    /**
     * Gets the ground mesh created by the helper.
     */
    get ground(): Nullable<Mesh>;
    private _groundTexture;
    /**
     * Gets the ground texture created by the helper.
     */
    get groundTexture(): Nullable<BaseTexture>;
    private _groundMirror;
    /**
     * Gets the ground mirror created by the helper.
     */
    get groundMirror(): Nullable<MirrorTexture>;
    /**
     * Gets the ground mirror render list to helps pushing the meshes
     * you wish in the ground reflection.
     */
    get groundMirrorRenderList(): Nullable<AbstractMesh[]>;
    private _groundMaterial;
    /**
     * Gets the ground material created by the helper.
     */
    get groundMaterial(): Nullable<BackgroundMaterial>;
    /**
     * Stores the creation options.
     */
    private readonly _scene;
    private _options;
    /**
     * This observable will be notified with any error during the creation of the environment,
     * mainly texture creation errors.
     */
    onErrorObservable: Observable<{
        message?: string;
        exception?: any;
    }>;
    /**
     * constructor
     * @param options Defines the options we want to customize the helper
     * @param scene The scene to add the material to
     */
    constructor(options: Partial<IEnvironmentHelperOptions>, scene: Scene);
    /**
     * Updates the environment according to the new options
     * @param options options to configure the helper (IEnvironmentHelperOptions)
     */
    updateOptions(options: Partial<IEnvironmentHelperOptions>): void;
    /**
     * Sets the primary color of all the available elements.
     * @param color the main color to affect to the ground and the background
     */
    setMainColor(color: Color3): void;
    /**
     * Setup the image processing according to the specified options.
     */
    private _setupImageProcessing;
    /**
     * Setup the environment texture according to the specified options.
     */
    private _setupEnvironmentTexture;
    /**
     * Setup the background according to the specified options.
     */
    private _setupBackground;
    /**
     * Get the scene sizes according to the setup.
     * @returns the different ground and skybox sizes.
     */
    private _getSceneSize;
    /**
     * Setup the ground according to the specified options.
     * @param sceneSize
     */
    private _setupGround;
    /**
     * Setup the ground material according to the specified options.
     */
    private _setupGroundMaterial;
    /**
     * Setup the ground diffuse texture according to the specified options.
     */
    private _setupGroundDiffuseTexture;
    /**
     * Setup the ground mirror texture according to the specified options.
     * @param sceneSize
     */
    private _setupGroundMirrorTexture;
    /**
     * Setup the ground to receive the mirror texture.
     */
    private _setupMirrorInGroundMaterial;
    /**
     * Setup the skybox according to the specified options.
     * @param sceneSize
     */
    private _setupSkybox;
    /**
     * Setup the skybox material according to the specified options.
     */
    private _setupSkyboxMaterial;
    /**
     * Setup the skybox reflection texture according to the specified options.
     */
    private _setupSkyboxReflectionTexture;
    private _errorHandler;
    /**
     * Dispose all the elements created by the Helper.
     */
    dispose(): void;
}

/**
 * This represents the required contract to create a new type of texture loader.
 */
interface IInternalTextureLoader {
    /**
     * Defines whether the loader supports cascade loading the different faces.
     */
    supportCascades: boolean;
    /**
     * Uploads the cube texture data to the WebGL texture. It has already been bound.
     * @param data contains the texture data
     * @param texture defines the BabylonJS internal texture
     * @param createPolynomials will be true if polynomials have been requested
     * @param onLoad defines the callback to trigger once the texture is ready
     * @param onError defines the callback to trigger in case of error
     * @param options options to be passed to the loader
     */
    loadCubeData(data: ArrayBufferView | ArrayBufferView[], texture: InternalTexture, createPolynomials: boolean, onLoad: Nullable<(data?: any) => void>, onError: Nullable<(message?: string, exception?: any) => void>, options?: any): void;
    /**
     * Uploads the 2D texture data to the WebGL texture. It has already been bound once in the callback.
     * @param data contains the texture data
     * @param texture defines the BabylonJS internal texture
     * @param callback defines the method to call once ready to upload
     * @param options options to be passed to the loader
     */
    loadData(data: ArrayBufferView, texture: InternalTexture, callback: (width: number, height: number, loadMipmap: boolean, isCompressed: boolean, done: () => void, loadFailed?: boolean) => void, options?: any): void;
}

declare module "../scene" {
    interface Scene {
        /**
         * Creates a default light for the scene.
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/fastBuildWorld#create-default-light
         * @param replace has the default false, when true replaces the existing lights in the scene with a hemispheric light
         */
        createDefaultLight(replace?: boolean): void;
        /**
         * Creates a default camera for the scene.
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/fastBuildWorld#create-default-camera
         * @param createArcRotateCamera has the default false which creates a free camera, when true creates an arc rotate camera
         * @param replace has default false, when true replaces the active camera in the scene
         * @param attachCameraControls has default false, when true attaches camera controls to the canvas.
         */
        createDefaultCamera(createArcRotateCamera?: boolean, replace?: boolean, attachCameraControls?: boolean): void;
        /**
         * Creates a default camera and a default light.
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/fastBuildWorld#create-default-camera-or-light
         * @param createArcRotateCamera has the default false which creates a free camera, when true creates an arc rotate camera
         * @param replace has the default false, when true replaces the active camera/light in the scene
         * @param attachCameraControls has the default false, when true attaches camera controls to the canvas.
         */
        createDefaultCameraOrLight(createArcRotateCamera?: boolean, replace?: boolean, attachCameraControls?: boolean): void;
        /**
         * Creates a new sky box
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/fastBuildWorld#create-default-skybox
         * @param environmentTexture defines the texture to use as environment texture
         * @param pbr has default false which requires the StandardMaterial to be used, when true PBRMaterial must be used
         * @param scale defines the overall scale of the skybox
         * @param blur is only available when pbr is true, default is 0, no blur, maximum value is 1
         * @param setGlobalEnvTexture has default true indicating that scene.environmentTexture must match the current skybox texture
         * @returns a new mesh holding the sky box
         */
        createDefaultSkybox(environmentTexture?: BaseTexture, pbr?: boolean, scale?: number, blur?: number, setGlobalEnvTexture?: boolean): Nullable<Mesh>;
        /**
         * Creates a new environment
         * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/fastBuildWorld#create-default-environment
         * @param options defines the options you can use to configure the environment
         * @returns the new EnvironmentHelper
         */
        createDefaultEnvironment(options?: Partial<IEnvironmentHelperOptions>): Nullable<EnvironmentHelper>;
        /**
         * Creates a new VREXperienceHelper
         * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/webVRHelper
         * @param webVROptions defines the options used to create the new VREXperienceHelper
         * @deprecated Please use createDefaultXRExperienceAsync instead
         * @returns a new VREXperienceHelper
         */
        createDefaultVRExperience(webVROptions?: VRExperienceHelperOptions): VRExperienceHelper;
        /**
         * Creates a new WebXRDefaultExperience
         * @see https://doc.babylonjs.com/features/featuresDeepDive/webXR/introToWebXR
         * @param options experience options
         * @returns a promise for a new WebXRDefaultExperience
         */
        createDefaultXRExperienceAsync(options?: WebXRDefaultExperienceOptions): Promise<WebXRDefaultExperience>;
    }
}

declare module "../scene" {
    interface Scene {
        /**
         * Return the first glow layer of the scene with a given name.
         * @param name The name of the glow layer to look for.
         * @returns The glow layer if found otherwise null.
         */
        getGlowLayerByName(name: string): Nullable<GlowLayer>;
    }
}
/**
 * Glow layer options. This helps customizing the behaviour
 * of the glow layer.
 */
interface IGlowLayerOptions extends IThinGlowLayerOptions {
    /**
     * Enable MSAA by choosing the number of samples. Default: 1
     */
    mainTextureSamples?: number;
    /**
     * Whether or not to generate a stencil buffer. Default: false
     */
    generateStencilBuffer?: boolean;
}
/**
 * The glow layer Helps adding a glow effect around the emissive parts of a mesh.
 *
 * Once instantiated in a scene, by default, all the emissive meshes will glow.
 *
 * Documentation: https://doc.babylonjs.com/features/featuresDeepDive/mesh/glowLayer
 */
declare class GlowLayer extends EffectLayer {
    /**
     * Effect Name of the layer.
     */
    static get EffectName(): string;
    /**
     * The default blur kernel size used for the glow.
     */
    static DefaultBlurKernelSize: number;
    /**
     * The default texture size ratio used for the glow.
     */
    static DefaultTextureRatio: number;
    /**
     * Sets the kernel size of the blur.
     */
    set blurKernelSize(value: number);
    /**
     * Gets the kernel size of the blur.
     */
    get blurKernelSize(): number;
    /**
     * Sets the glow intensity.
     */
    set intensity(value: number);
    /**
     * Gets the glow intensity.
     */
    get intensity(): number;
    protected _options: IGlowLayerOptions;
    protected readonly _thinEffectLayer: ThinGlowLayer;
    private _horizontalBlurPostprocess1;
    private _verticalBlurPostprocess1;
    private _horizontalBlurPostprocess2;
    private _verticalBlurPostprocess2;
    private _blurTexture1;
    private _blurTexture2;
    private _postProcesses1;
    private _postProcesses2;
    /**
     * Callback used to let the user override the color selection on a per mesh basis
     */
    get customEmissiveColorSelector(): (mesh: Mesh, subMesh: SubMesh, material: Material, result: Color4) => void;
    set customEmissiveColorSelector(value: (mesh: Mesh, subMesh: SubMesh, material: Material, result: Color4) => void);
    /**
     * Callback used to let the user override the texture selection on a per mesh basis
     */
    get customEmissiveTextureSelector(): (mesh: Mesh, subMesh: SubMesh, material: Material) => Texture;
    set customEmissiveTextureSelector(value: (mesh: Mesh, subMesh: SubMesh, material: Material) => Texture);
    /**
     * Instantiates a new glow Layer and references it to the scene.
     * @param name The name of the layer
     * @param scene The scene to use the layer in
     * @param options Sets of none mandatory options to use with the layer (see IGlowLayerOptions for more information)
     */
    constructor(name: string, scene?: Scene, options?: Partial<IGlowLayerOptions>);
    /**
     * Get the effect name of the layer.
     * @returns The effect name
     */
    getEffectName(): string;
    /**
     * @internal
     * Create the merge effect. This is the shader use to blit the information back
     * to the main canvas at the end of the scene rendering.
     */
    protected _createMergeEffect(): Effect;
    /**
     * Creates the render target textures and post processes used in the glow layer.
     */
    protected _createTextureAndPostProcesses(): void;
    /**
     * Checks for the readiness of the element composing the layer.
     * @param subMesh the mesh to check for
     * @param useInstances specify whether or not to use instances to render the mesh
     * @returns true if ready otherwise, false
     */
    isReady(subMesh: SubMesh, useInstances: boolean): boolean;
    /**
     * @returns whether or not the layer needs stencil enabled during the mesh rendering.
     */
    needStencil(): boolean;
    /**
     * Returns true if the mesh can be rendered, otherwise false.
     * @param mesh The mesh to render
     * @param material The material used on the mesh
     * @returns true if it can be rendered otherwise false
     */
    protected _canRenderMesh(mesh: AbstractMesh, material: Material): boolean;
    /**
     * Implementation specific of rendering the generating effect on the main canvas.
     * @param effect The effect used to render through
     */
    protected _internalRender(effect: Effect): void;
    /**
     * Sets the required values for both the emissive texture and and the main color.
     * @param mesh
     * @param subMesh
     * @param material
     */
    protected _setEmissiveTextureAndColor(mesh: Mesh, subMesh: SubMesh, material: Material): void;
    /**
     * Returns true if the mesh should render, otherwise false.
     * @param mesh The mesh to render
     * @returns true if it should render otherwise false
     */
    protected _shouldRenderMesh(mesh: Mesh): boolean;
    /**
     * Adds specific effects defines.
     * @param defines The defines to add specifics to.
     */
    protected _addCustomEffectDefines(defines: string[]): void;
    /**
     * Add a mesh in the exclusion list to prevent it to impact or being impacted by the glow layer.
     * This will not have an effect if meshes are excluded by default (see setExcludedByDefault).
     * @param mesh The mesh to exclude from the glow layer
     */
    addExcludedMesh(mesh: Mesh): void;
    /**
     * Remove a mesh from the exclusion list to let it impact or being impacted by the glow layer.
     * This will not have an effect if meshes are excluded by default (see setExcludedByDefault).
     * @param mesh The mesh to remove
     */
    removeExcludedMesh(mesh: Mesh): void;
    /**
     * Add a mesh in the inclusion list to impact or being impacted by the glow layer.
     * @param mesh The mesh to include in the glow layer
     */
    addIncludedOnlyMesh(mesh: Mesh): void;
    /**
     * Remove a mesh from the Inclusion list to prevent it to impact or being impacted by the glow layer.
     * @param mesh The mesh to remove
     */
    removeIncludedOnlyMesh(mesh: Mesh): void;
    /**
     * Set the excluded by default option.
     * If true, all meshes will be excluded by default unless they are added to the inclusion list.
     * @param value The boolean value to set the excluded by default option to
     */
    setExcludedByDefault(value: boolean): void;
    /**
     * Determine if a given mesh will be used in the glow layer
     * @param mesh The mesh to test
     * @returns true if the mesh will be highlighted by the current glow layer
     */
    hasMesh(mesh: AbstractMesh): boolean;
    /**
     * Defines whether the current material of the mesh should be use to render the effect.
     * @param mesh defines the current mesh to render
     * @returns true if the material of the mesh should be use to render the effect
     */
    protected _useMeshMaterial(mesh: AbstractMesh): boolean;
    /**
     * Add a mesh to be rendered through its own material and not with emissive only.
     * @param mesh The mesh for which we need to use its material
     */
    referenceMeshToUseItsOwnMaterial(mesh: AbstractMesh): void;
    /**
     * Remove a mesh from being rendered through its own material and not with emissive only.
     * @param mesh The mesh for which we need to not use its material
     */
    unReferenceMeshFromUsingItsOwnMaterial(mesh: AbstractMesh): void;
    /**
     * Free any resources and references associated to a mesh.
     * Internal use
     * @param mesh The mesh to free.
     * @internal
     */
    _disposeMesh(mesh: Mesh): void;
    /**
     * Gets the class name of the effect layer
     * @returns the string with the class name of the effect layer
     */
    getClassName(): string;
    /**
     * Serializes this glow layer
     * @returns a serialized glow layer object
     */
    serialize(): any;
    /**
     * Creates a Glow Layer from parsed glow layer data
     * @param parsedGlowLayer defines glow layer data
     * @param scene defines the current scene
     * @param rootUrl defines the root URL containing the glow layer information
     * @returns a parsed Glow Layer
     */
    static Parse(parsedGlowLayer: any, scene: Scene, rootUrl: string): GlowLayer;
}

declare module "../scene" {
    interface Scene {
        /**
         * Return a the first highlight layer of the scene with a given name.
         * @param name The name of the highlight layer to look for.
         * @returns The highlight layer if found otherwise null.
         */
        getHighlightLayerByName(name: string): Nullable<HighlightLayer>;
    }
}
/**
 * Highlight layer options. This helps customizing the behaviour
 * of the highlight layer.
 */
interface IHighlightLayerOptions extends IThinHighlightLayerOptions {
}
/**
 * The highlight layer Helps adding a glow effect around a mesh.
 *
 * Once instantiated in a scene, simply use the addMesh or removeMesh method to add or remove
 * glowy meshes to your scene.
 *
 * !!! THIS REQUIRES AN ACTIVE STENCIL BUFFER ON THE CANVAS !!!
 */
declare class HighlightLayer extends EffectLayer {
    /**
     * Effect Name of the highlight layer.
     */
    static readonly EffectName = "HighlightLayer";
    /**
     * The neutral color used during the preparation of the glow effect.
     * This is black by default as the blend operation is a blend operation.
     */
    static get NeutralColor(): Color4;
    static set NeutralColor(value: Color4);
    /**
     * Specifies whether or not the inner glow is ACTIVE in the layer.
     */
    get innerGlow(): boolean;
    set innerGlow(value: boolean);
    /**
     * Specifies whether or not the outer glow is ACTIVE in the layer.
     */
    get outerGlow(): boolean;
    set outerGlow(value: boolean);
    /**
     * Specifies the horizontal size of the blur.
     */
    set blurHorizontalSize(value: number);
    /**
     * Specifies the vertical size of the blur.
     */
    set blurVerticalSize(value: number);
    /**
     * Gets the horizontal size of the blur.
     */
    get blurHorizontalSize(): number;
    /**
     * Gets the vertical size of the blur.
     */
    get blurVerticalSize(): number;
    /**
     * An event triggered when the highlight layer is being blurred.
     */
    onBeforeBlurObservable: Observable<HighlightLayer>;
    /**
     * An event triggered when the highlight layer has been blurred.
     */
    onAfterBlurObservable: Observable<HighlightLayer>;
    private _options;
    protected readonly _thinEffectLayer: ThinHighlightLayer;
    private _downSamplePostprocess;
    private _horizontalBlurPostprocess;
    private _verticalBlurPostprocess;
    private _blurTexture;
    /**
     * Instantiates a new highlight Layer and references it to the scene..
     * @param name The name of the layer
     * @param scene The scene to use the layer in
     * @param options Sets of none mandatory options to use with the layer (see IHighlightLayerOptions for more information)
     */
    constructor(name: string, scene?: Scene, options?: Partial<IHighlightLayerOptions>);
    /**
     * Get the effect name of the layer.
     * @returns The effect name
     */
    getEffectName(): string;
    protected _numInternalDraws(): number;
    /**
     * Create the merge effect. This is the shader use to blit the information back
     * to the main canvas at the end of the scene rendering.
     * @returns The effect created
     */
    protected _createMergeEffect(): Effect;
    /**
     * Creates the render target textures and post processes used in the highlight layer.
     */
    protected _createTextureAndPostProcesses(): void;
    /**
     * @returns whether or not the layer needs stencil enabled during the mesh rendering.
     */
    needStencil(): boolean;
    /**
     * Checks for the readiness of the element composing the layer.
     * @param subMesh the mesh to check for
     * @param useInstances specify whether or not to use instances to render the mesh
     * @returns true if ready otherwise, false
     */
    isReady(subMesh: SubMesh, useInstances: boolean): boolean;
    /**
     * Implementation specific of rendering the generating effect on the main canvas.
     * @param effect The effect used to render through
     * @param renderIndex
     */
    protected _internalRender(effect: Effect, renderIndex: number): void;
    /**
     * @returns true if the layer contains information to display, otherwise false.
     */
    shouldRender(): boolean;
    /**
     * Returns true if the mesh should render, otherwise false.
     * @param mesh The mesh to render
     * @returns true if it should render otherwise false
     */
    protected _shouldRenderMesh(mesh: Mesh): boolean;
    /**
     * Returns true if the mesh can be rendered, otherwise false.
     * @param mesh The mesh to render
     * @param material The material used on the mesh
     * @returns true if it can be rendered otherwise false
     */
    protected _canRenderMesh(mesh: AbstractMesh, material: Material): boolean;
    /**
     * Adds specific effects defines.
     * @param defines The defines to add specifics to.
     */
    protected _addCustomEffectDefines(defines: string[]): void;
    /**
     * Sets the required values for both the emissive texture and and the main color.
     * @param mesh
     * @param subMesh
     * @param material
     */
    protected _setEmissiveTextureAndColor(mesh: Mesh, subMesh: SubMesh, material: Material): void;
    /**
     * Add a mesh in the exclusion list to prevent it to impact or being impacted by the highlight layer.
     * @param mesh The mesh to exclude from the highlight layer
     */
    addExcludedMesh(mesh: Mesh): void;
    /**
     * Remove a mesh from the exclusion list to let it impact or being impacted by the highlight layer.
     * @param mesh The mesh to highlight
     */
    removeExcludedMesh(mesh: Mesh): void;
    /**
     * Determine if a given mesh will be highlighted by the current HighlightLayer
     * @param mesh mesh to test
     * @returns true if the mesh will be highlighted by the current HighlightLayer
     */
    hasMesh(mesh: AbstractMesh): boolean;
    /**
     * Add a mesh in the highlight layer in order to make it glow with the chosen color.
     * @param mesh The mesh to highlight
     * @param color The color of the highlight
     * @param glowEmissiveOnly Extract the glow from the emissive texture
     */
    addMesh(mesh: Mesh, color: Color3, glowEmissiveOnly?: boolean): void;
    /**
     * Remove a mesh from the highlight layer in order to make it stop glowing.
     * @param mesh The mesh to highlight
     */
    removeMesh(mesh: Mesh): void;
    /**
     * Remove all the meshes currently referenced in the highlight layer
     */
    removeAllMeshes(): void;
    /**
     * Free any resources and references associated to a mesh.
     * Internal use
     * @param mesh The mesh to free.
     * @internal
     */
    _disposeMesh(mesh: Mesh): void;
    /**
     * Gets the class name of the effect layer
     * @returns the string with the class name of the effect layer
     */
    getClassName(): string;
    /**
     * Serializes this Highlight layer
     * @returns a serialized Highlight layer object
     */
    serialize(): any;
    /**
     * Creates a Highlight layer from parsed Highlight layer data
     * @param parsedHightlightLayer defines the Highlight layer data
     * @param scene defines the current scene
     * @param rootUrl defines the root URL containing the Highlight layer information
     * @returns a parsed Highlight layer
     */
    static Parse(parsedHightlightLayer: any, scene: Scene, rootUrl: string): HighlightLayer;
}

declare module "../scene" {
    interface Scene {
        /**
         * Removes the given lens flare system from this scene.
         * @param toRemove The lens flare system to remove
         * @returns The index of the removed lens flare system
         */
        removeLensFlareSystem(toRemove: LensFlareSystem): number;
        /**
         * Adds the given lens flare system to this scene
         * @param newLensFlareSystem The lens flare system to add
         */
        addLensFlareSystem(newLensFlareSystem: LensFlareSystem): void;
        /**
         * Gets a lens flare system using its name
         * @param name defines the name to look for
         * @returns the lens flare system or null if not found
         */
        getLensFlareSystemByName(name: string): Nullable<LensFlareSystem>;
        /**
         * Gets a lens flare system using its Id
         * @param id defines the Id to look for
         * @returns the lens flare system or null if not found
         * @deprecated Please use getLensFlareSystemById instead
         */
        getLensFlareSystemByID(id: string): Nullable<LensFlareSystem>;
        /**
         * Gets a lens flare system using its Id
         * @param id defines the Id to look for
         * @returns the lens flare system or null if not found
         */
        getLensFlareSystemById(id: string): Nullable<LensFlareSystem>;
    }
}

/**
 * Linearly transformed cosine textures that are used in the Area Lights shaders.
 */
type ILTCTextures = {
    /**
     * Linearly transformed cosine texture BRDF Approximation.
     */
    LTC1: BaseTexture;
    /**
     * Linearly transformed cosine texture Fresnel Approximation.
     */
    LTC2: BaseTexture;
};

declare module "../scene" {
    interface Scene {
        /**
         * @internal
         */
        _ltcTextures?: ILTCTextures;
    }
}

declare module "./mesh" {
    interface Mesh {
        /**
         * Gets or sets a boolean defining if we want picking to pick thin instances as well
         */
        thinInstanceEnablePicking: boolean;
        /**
         * Indicates that a buffer created as static should be recreated if the buffer is updated (by calling thinInstanceSetMatrixAt or thinInstanceSetAttributeAt, for eg.)
         * If this flag is false (the default behavior), a buffer created as "static" won't show any update done to it, and will stay the same as it was created.
         * Note however that recreating a buffer each time there's a change will have some performance cost, that's why it is set to false by default.
         * You should set this flag to true only if your static buffers should change infrequently. If they change frequently, you should create your buffers as "dynamic" instead.
         */
        thinInstanceAllowAutomaticStaticBufferRecreation: boolean;
        /**
         * Creates a new thin instance
         * @param matrix the matrix or array of matrices (position, rotation, scale) of the thin instance(s) to create
         * @param refresh true to refresh the underlying gpu buffer (default: true). If you do multiple calls to this method in a row, set refresh to true only for the last call to save performance
         * @returns the thin instance index number. If you pass an array of matrices, other instance indexes are index+1, index+2, etc
         */
        thinInstanceAdd(matrix: DeepImmutableObject<Matrix> | Array<DeepImmutableObject<Matrix>>, refresh?: boolean): number;
        /**
         * Adds the transformation (matrix) of the current mesh as a thin instance
         * @param refresh true to refresh the underlying gpu buffer (default: true). If you do multiple calls to this method in a row, set refresh to true only for the last call to save performance
         * @returns the thin instance index number
         */
        thinInstanceAddSelf(refresh?: boolean): number;
        /**
         * Registers a custom attribute to be used with thin instances
         * @param kind name of the attribute
         * @param stride size in floats of the attribute
         */
        thinInstanceRegisterAttribute(kind: string, stride: number): void;
        /**
         * Sets the matrix of a thin instance
         * @param index index of the thin instance
         * @param matrix matrix to set
         * @param refresh true to refresh the underlying gpu buffer (default: true). If you do multiple calls to this method in a row, set refresh to true only for the last call to save performance
         */
        thinInstanceSetMatrixAt(index: number, matrix: DeepImmutableObject<Matrix>, refresh?: boolean): void;
        /**
         * Sets the value of a custom attribute for a thin instance
         * @param kind name of the attribute
         * @param index index of the thin instance
         * @param value value to set
         * @param refresh true to refresh the underlying gpu buffer (default: true). If you do multiple calls to this method in a row, set refresh to true only for the last call to save performance
         */
        thinInstanceSetAttributeAt(kind: string, index: number, value: Array<number>, refresh?: boolean): void;
        /**
         * Gets / sets the number of thin instances to display. Note that you can't set a number higher than what the underlying buffer can handle.
         */
        thinInstanceCount: number;
        /**
         * Sets a buffer to be used with thin instances. This method is a faster way to setup multiple instances than calling thinInstanceAdd repeatedly
         * @param kind name of the attribute. Use "matrix" to setup the buffer of matrices
         * @param buffer buffer to set
         * @param stride size in floats of each value of the buffer
         * @param staticBuffer indicates that the buffer is static, so that you won't change it after it is set (better performances - true by default)
         */
        thinInstanceSetBuffer(kind: string, buffer: Nullable<Float32Array>, stride?: number, staticBuffer?: boolean): void;
        /**
         * Gets the list of world matrices
         * @returns an array containing all the world matrices from the thin instances
         */
        thinInstanceGetWorldMatrices(): Matrix[];
        /**
         * Synchronize the gpu buffers with a thin instance buffer. Call this method if you update later on the buffers passed to thinInstanceSetBuffer
         * @param kind name of the attribute to update. Use "matrix" to update the buffer of matrices
         */
        thinInstanceBufferUpdated(kind: string): void;
        /**
         * Applies a partial update to a buffer directly on the GPU
         * Note that the buffer located on the CPU is NOT updated! It's up to you to update it (or not) with the same data you pass to this method
         * @param kind name of the attribute to update. Use "matrix" to update the buffer of matrices
         * @param data the data to set in the GPU buffer
         * @param offset the offset in the GPU buffer where to update the data
         */
        thinInstancePartialBufferUpdate(kind: string, data: Float32Array, offset: number): void;
        /**
         * Refreshes the bounding info, taking into account all the thin instances defined
         * @param forceRefreshParentInfo true to force recomputing the mesh bounding info and use it to compute the aggregated bounding info
         * @param applySkeleton defines whether to apply the skeleton before computing the bounding info
         * @param applyMorph  defines whether to apply the morph target before computing the bounding info
         */
        thinInstanceRefreshBoundingInfo(forceRefreshParentInfo?: boolean, applySkeleton?: boolean, applyMorph?: boolean): void;
        /** @internal */
        _thinInstanceInitializeUserStorage(): void;
        /** @internal */
        _thinInstanceUpdateBufferSize(kind: string, numInstances?: number): void;
        /** @internal */
        _thinInstanceCreateMatrixBuffer(kind: string, buffer: Nullable<Float32Array>, staticBuffer: boolean): Buffer$1;
        /** @internal */
        _thinInstanceRecreateBuffer(kind: string, staticBuffer?: boolean): void;
        /** @internal */
        _userThinInstanceBuffersStorage: {
            data: {
                [key: string]: Float32Array;
            };
            sizes: {
                [key: string]: number;
            };
            vertexBuffers: {
                [key: string]: Nullable<VertexBuffer>;
            };
            strides: {
                [key: string]: number;
            };
        };
    }
}

declare module "../scene" {
    interface Scene {
        /** @internal */
        _meshUVSpaceRendererShader: Nullable<ShaderMaterial>;
        /** @internal */
        _meshUVSpaceRendererMaskShader: Nullable<ShaderMaterial>;
    }
}
/**
 * Options for the MeshUVSpaceRenderer
 * @since 5.49.1
 */
interface IMeshUVSpaceRendererOptions {
    /**
     * Width of the texture. Default: 1024
     */
    width?: number;
    /**
     * Height of the texture. Default: 1024
     */
    height?: number;
    /**
     * Type of the texture. Default: Constants.TEXTURETYPE_UNSIGNED_BYTE
     */
    textureType?: number;
    /**
     * Generate mip maps. Default: true
     */
    generateMipMaps?: boolean;
    /**
     * Optimize UV allocation. Default: true
     * If you plan to use the texture as a decal map and rotate / offset the texture, you should set this to false
     */
    optimizeUVAllocation?: boolean;
    /**
     * If true, a post processing effect will be applied to the texture to fix seams. Default: false
     */
    uvEdgeBlending?: boolean;
}
/**
 * Class used to render in the mesh UV space
 * @since 5.49.1
 */
declare class MeshUVSpaceRenderer {
    private _mesh;
    private _scene;
    private _options;
    private _textureCreatedInternally;
    private _configureUserCreatedTexture;
    private _maskTexture;
    private _finalPostProcess;
    private _shadersLoaded;
    private _isDisposed;
    private static _GetShader;
    private static _GetMaskShader;
    private static _IsRenderTargetTexture;
    /**
     * Clear color of the texture
     */
    clearColor: Color4;
    /**
     * Target texture used for rendering
     * If you don't set the property, a RenderTargetTexture will be created internally given the options provided to the constructor.
     * If you provide a RenderTargetTexture, it will be used directly.
     */
    texture: Nullable<Texture>;
    /** Shader language used by the material */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this material.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Creates a new MeshUVSpaceRenderer
     * @param mesh The mesh used for the source UV space
     * @param scene The scene the mesh belongs to
     * @param options The options to use when creating the texture
     */
    constructor(mesh: AbstractMesh, scene: Scene, options?: IMeshUVSpaceRendererOptions);
    private _initShaderSourceAsync;
    /**
     * Checks if the texture is ready to be used
     * @returns true if the texture is ready to be used
     */
    isReady(): boolean;
    /**
     * Projects and renders a texture in the mesh UV space
     * @param texture The texture
     * @param position The position of the center of projection (world space coordinates)
     * @param normal The direction of the projection (world space coordinates)
     * @param size The size of the projection
     * @param angle The rotation angle around the direction of the projection (default: 0)
     * @param checkIsReady If true, it will check if the texture is ready before rendering (default: true). If the texture is not ready, a new attempt will be scheduled in 16ms
     */
    renderTexture(texture: BaseTexture, position: Vector3, normal: Vector3, size: Vector3, angle?: number, checkIsReady?: boolean): void;
    /**
     * Clears the texture map
     */
    clear(): void;
    /**
     * Disposes of the resources
     */
    dispose(): void;
    private _configureUserCreatedRTT;
    private _createDiffuseRTT;
    private _createMaskTexture;
    private _createPostProcess;
    private _createRenderTargetTexture;
    private _createProjectionMatrix;
}

declare module "./abstractMesh" {
    interface AbstractMesh {
        /** @internal */
        _decalMap: Nullable<MeshUVSpaceRenderer>;
        /**
         * Gets or sets the decal map for this mesh
         */
        decalMap: Nullable<MeshUVSpaceRenderer>;
    }
}

/**
 * Expected simplification settings.
 * Quality should be between 0 and 1 (1 being 100%, 0 being 0%)
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/simplifyingMeshes
 */
interface ISimplificationSettings {
    /**
     * Gets or sets the expected quality
     */
    quality: number;
    /**
     * Gets or sets the distance when this optimized version should be used
     */
    distance: number;
    /**
     * Gets an already optimized mesh
     */
    optimizeMesh?: boolean | undefined;
}
/**
 * Interface used to define a simplification task
 */
interface ISimplificationTask {
    /**
     * Array of settings
     */
    settings: Array<ISimplificationSettings>;
    /**
     * Simplification type
     */
    simplificationType: SimplificationType;
    /**
     * Mesh to simplify
     */
    mesh: Mesh;
    /**
     * Callback called on success
     */
    successCallback?: () => void;
    /**
     * Defines if parallel processing can be used
     */
    parallelProcessing: boolean;
}
/**
 * Queue used to order the simplification tasks
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/simplifyingMeshes
 */
declare class SimplificationQueue {
    private _simplificationArray;
    /**
     * Gets a boolean indicating that the process is still running
     */
    running: boolean;
    /**
     * Creates a new queue
     */
    constructor();
    /**
     * Adds a new simplification task
     * @param task defines a task to add
     */
    addTask(task: ISimplificationTask): void;
    /**
     * Execute next task
     */
    executeNext(): void;
    /**
     * Execute a simplification task
     * @param task defines the task to run
     */
    runSimplification(task: ISimplificationTask): void;
    private _getSimplifier;
}
/**
 * The implemented types of simplification
 * At the moment only Quadratic Error Decimation is implemented
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/simplifyingMeshes
 */
declare const enum SimplificationType {
    /** Quadratic error decimation */
    QUADRATIC = 0
}

declare module "../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _simplificationQueue: SimplificationQueue;
        /**
         * Gets or sets the simplification queue attached to the scene
         * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/simplifyingMeshes
         */
        simplificationQueue: SimplificationQueue;
    }
}
declare module "../Meshes/mesh" {
    interface Mesh {
        /**
         * Simplify the mesh according to the given array of settings.
         * Function will return immediately and will simplify async
         * @param settings a collection of simplification settings
         * @param parallelProcessing should all levels calculate parallel or one after the other
         * @param simplificationType the type of simplification to run
         * @param successCallback optional success callback to be called after the simplification finished processing all settings
         * @returns the current mesh
         */
        simplify(settings: Array<ISimplificationSettings>, parallelProcessing?: boolean, simplificationType?: SimplificationType, successCallback?: (mesh?: Mesh, submeshIndex?: number) => void): Mesh;
    }
}

declare module "./observable" {
    interface Observable<T> {
        /**
         * Calling this will execute each callback, expecting it to be a promise or return a value.
         * If at any point in the chain one function fails, the promise will fail and the execution will not continue.
         * This is useful when a chain of events (sometimes async events) is needed to initialize a certain object
         * and it is crucial that all callbacks will be executed.
         * The order of the callbacks is kept, callbacks are not executed parallel.
         *
         * @param eventData The data to be sent to each callback
         * @param mask is used to filter observers defaults to -1
         * @param target defines the callback target (see EventState)
         * @param currentTarget defines he current object in the bubbling phase
         * @param userInfo defines any user info to send to observers
         * @returns {Promise<T>} will return a Promise than resolves when all callbacks executed successfully.
         */
        notifyObserversWithPromise(eventData: T, mask?: number, target?: any, currentTarget?: any, userInfo?: any): Promise<T>;
    }
}

/**
 * A class acting as a dynamic float32array used in the performance viewer
 */
declare class DynamicFloat32Array {
    private _view;
    private _itemLength;
    /**
     * Creates a new DynamicFloat32Array with the desired item capacity.
     * @param itemCapacity The initial item capacity you would like to set for the array.
     */
    constructor(itemCapacity: number);
    /**
     * The number of items currently in the array.
     */
    get itemLength(): number;
    /**
     * Gets value at index, NaN if no such index exists.
     * @param index the index to get the value at.
     * @returns the value at the index provided.
     */
    at(index: number): number;
    /**
     * Gets a view of the original array from start to end (exclusive of end).
     * @param start starting index.
     * @param end ending index.
     * @returns a subarray of the original array.
     */
    subarray(start: number, end: number): Float32Array;
    /**
     * Pushes items to the end of the array.
     * @param item The item to push into the array.
     */
    push(item: number): void;
    /**
     * Grows the array by the growth factor when necessary.
     */
    private _growArray;
}

/**
 * Defines the shape of a collection of datasets that our graphing service uses for drawing purposes.
 */
interface IPerfDatasets {
    /**
     * The ids of our dataset.
     */
    ids: string[];
    /**
     * The data to be processed by the performance graph. Each slice will be of the form of [timestamp, numberOfPoints, value1, value2...]
     */
    data: DynamicFloat32Array;
    /**
     * A list of starting indices for each slice of data collected. Used for fast access of an arbitrary slice inside the data array.
     */
    startingIndices: DynamicFloat32Array;
}
/**
 * Defines the shape of a the metadata the graphing service uses for drawing purposes.
 */
interface IPerfMetadata {
    /**
     * The color of the line to be drawn.
     */
    color?: string;
    /**
     * Specifies if data should be hidden, falsey by default.
     */
    hidden?: boolean;
    /**
     * Specifies the category of the data
     */
    category?: string;
}
/**
 * Defines the shape of a custom user registered event.
 */
interface IPerfCustomEvent {
    /**
     * The name of the event.
     */
    name: string;
    /**
     * The value for the event, if set we will use it as the value, otherwise we will count the number of occurrences.
     */
    value?: number;
}

/**
 * PostProcessManager is used to manage one or more post processes or post process pipelines
 * See https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/usePostProcesses
 */
declare class PostProcessManager {
    private _scene;
    private _indexBuffer;
    private _vertexBuffers;
    /**
     * Creates a new instance PostProcess
     * @param scene The scene that the post process is associated with.
     */
    constructor(scene: Scene);
    private _prepareBuffers;
    private _buildIndexBuffer;
    onBeforeRenderObservable: Observable<PostProcessManager>;
    /**
     * Rebuilds the vertex buffers of the manager.
     * @internal
     */
    _rebuild(): void;
    /**
     * Prepares a frame to be run through a post process.
     * @param sourceTexture The input texture to the post processes. (default: null)
     * @param postProcesses An array of post processes to be run. (default: null)
     * @returns True if the post processes were able to be run.
     * @internal
     */
    _prepareFrame(sourceTexture?: Nullable<InternalTexture>, postProcesses?: Nullable<PostProcess[]>): boolean;
    /**
     * Manually render a set of post processes to a texture.
     * Please note, the frame buffer won't be unbound after the call in case you have more render to do.
     * @param postProcesses An array of post processes to be run.
     * @param targetTexture The render target wrapper to render to.
     * @param forceFullscreenViewport force gl.viewport to be full screen eg. 0,0,textureWidth,textureHeight
     * @param faceIndex defines the face to render to if a cubemap is defined as the target
     * @param lodLevel defines which lod of the texture to render to
     * @param doNotBindFrambuffer If set to true, assumes that the framebuffer has been bound previously
     * @param numPostsProcesses The number of post processes to render. Defaults to the length of the postProcesses array.
     */
    directRender(postProcesses: PostProcess[], targetTexture?: Nullable<RenderTargetWrapper>, forceFullscreenViewport?: boolean, faceIndex?: number, lodLevel?: number, doNotBindFrambuffer?: boolean, numPostsProcesses?: number): void;
    /**
     * Finalize the result of the output of the postprocesses.
     * @param doNotPresent If true the result will not be displayed to the screen.
     * @param targetTexture The render target wrapper to render to.
     * @param faceIndex The index of the face to bind the target texture to.
     * @param postProcesses The array of post processes to render.
     * @param forceFullscreenViewport force gl.viewport to be full screen eg. 0,0,textureWidth,textureHeight (default: false)
     * @internal
     */
    _finalizeFrame(doNotPresent?: boolean, targetTexture?: RenderTargetWrapper, faceIndex?: number, postProcesses?: Array<PostProcess>, forceFullscreenViewport?: boolean): void;
    /**
     * Disposes of the post process manager.
     */
    dispose(): void;
}

/**
 * Defines the general structure of what is necessary for a collection strategy.
 */
interface IPerfViewerCollectionStrategy {
    /**
     * The id of the strategy.
     */
    id: string;
    /**
     * Function which gets the data for the strategy.
     */
    getData: () => number;
    /**
     * Function which does any necessary cleanup. Called when performanceViewerCollector.dispose() is called.
     */
    dispose: () => void;
}
/**
 * Initializer callback for a strategy
 */
type PerfStrategyInitialization = (scene: Scene) => IPerfViewerCollectionStrategy;

/**
 * Callback strategy and optional category for data collection
 */
interface IPerformanceViewerStrategyParameter {
    /**
     * The strategy for collecting data. Available strategies are located on the PerfCollectionStrategy class
     */
    strategyCallback: PerfStrategyInitialization;
    /**
     * Category for displaying this strategy on the viewer. Can be undefined or an empty string, in which case the strategy will be displayed on top
     */
    category?: string;
    /**
     * Starts hidden
     */
    hidden?: boolean;
}
/**
 * The collector class handles the collection and storage of data into the appropriate array.
 * The collector also handles notifying any observers of any updates.
 */
declare class PerformanceViewerCollector {
    private _scene;
    private _datasetMeta;
    private _strategies;
    private _startingTimestamp;
    private _hasLoadedData;
    private _isStarted;
    private readonly _customEventObservable;
    private readonly _eventRestoreSet;
    /**
     * Datastructure containing the collected datasets. Warning: you should not modify the values in here, data will be of the form [timestamp, numberOfPoints, value1, value2..., timestamp, etc...]
     */
    readonly datasets: IPerfDatasets;
    /**
     * An observable you can attach to get deltas in the dataset. Subscribing to this will increase memory consumption slightly, and may hurt performance due to increased garbage collection needed.
     * Updates of slices will be of the form [timestamp, numberOfPoints, value1, value2...].
     */
    readonly datasetObservable: Observable<number[]>;
    /**
     * An observable you can attach to get the most updated map of metadatas.
     */
    readonly metadataObservable: Observable<Map<string, IPerfMetadata>>;
    /**
     * The offset for when actual data values start appearing inside a slice.
     */
    static get SliceDataOffset(): number;
    /**
     * The offset for the value of the number of points inside a slice.
     */
    static get NumberOfPointsOffset(): number;
    /**
     * Handles the creation of a performance viewer collector.
     * @param _scene the scene to collect on.
     * @param _enabledStrategyCallbacks the list of data to collect with callbacks for initialization purposes.
     */
    constructor(_scene: Scene, _enabledStrategyCallbacks?: IPerformanceViewerStrategyParameter[]);
    /**
     * Registers a custom string event which will be callable via sendEvent. This method returns an event object which will contain the id of the event.
     * The user can set a value optionally, which will be used in the sendEvent method. If the value is set, we will record this value at the end of each frame,
     * if not we will increment our counter and record the value of the counter at the end of each frame. The value recorded is 0 if no sendEvent method is called, within a frame.
     * @param name The name of the event to register
     * @param forceUpdate if the code should force add an event, and replace the last one.
     * @param category the category for that event
     * @returns The event registered, used in sendEvent
     */
    registerEvent(name: string, forceUpdate?: boolean, category?: string): IPerfCustomEvent | undefined;
    /**
     * Lets the perf collector handle an event, occurences or event value depending on if the event.value params is set.
     * @param event the event to handle an occurence for
     */
    sendEvent(event: IPerfCustomEvent): void;
    /**
     * This event restores all custom string events if necessary.
     */
    private _restoreStringEvents;
    /**
     * This method adds additional collection strategies for data collection purposes.
     * @param strategyCallbacks the list of data to collect with callbacks.
     */
    addCollectionStrategies(...strategyCallbacks: IPerformanceViewerStrategyParameter[]): void;
    /**
     * Gets a 6 character hexcode representing the colour from a passed in string.
     * @param id the string to get a hex code for.
     * @returns a hexcode hashed from the id.
     */
    private _getHexColorFromId;
    /**
     * Collects data for every dataset by using the appropriate strategy. This is called every frame.
     * This method will then notify all observers with the latest slice.
     */
    private _collectDataAtFrame;
    /**
     * Collects and then sends the latest slice to any observers by using the appropriate strategy when the user wants.
     * The slice will be of the form [timestamp, numberOfPoints, value1, value2...]
     * This method does not add onto the collected data accessible via the datasets variable.
     */
    getCurrentSlice(): void;
    /**
     * Updates a property for a dataset's metadata with the value provided.
     * @param id the id of the dataset which needs its metadata updated.
     * @param prop the property to update.
     * @param value the value to update the property with.
     */
    updateMetadata<T extends keyof IPerfMetadata>(id: string, prop: T, value: IPerfMetadata[T]): void;
    /**
     * Completely clear, data, ids, and strategies saved to this performance collector.
     * @param preserveStringEventsRestore if it should preserve the string events, by default will clear string events registered when called.
     */
    clear(preserveStringEventsRestore?: boolean): void;
    /**
     * Accessor which lets the caller know if the performance collector has data loaded from a file or not!
     * Call clear() to reset this value.
     * @returns true if the data is loaded from a file, false otherwise.
     */
    get hasLoadedData(): boolean;
    /**
     * Given a string containing file data, this function parses the file data into the datasets object.
     * It returns a boolean to indicate if this object was successfully loaded with the data.
     * @param data string content representing the file data.
     * @param keepDatasetMeta if it should use reuse the existing dataset metadata
     * @returns true if the data was successfully loaded, false otherwise.
     */
    loadFromFileData(data: string, keepDatasetMeta?: boolean): boolean;
    /**
     * Exports the datasets inside of the collector to a csv.
     */
    exportDataToCsv(): void;
    /**
     * Starts the realtime collection of data.
     * @param shouldPreserve optional boolean param, if set will preserve the dataset between calls of start.
     */
    start(shouldPreserve?: boolean): void;
    /**
     * Stops the collection of data.
     */
    stop(): void;
    /**
     * Returns if the perf collector has been started or not.
     */
    get isStarted(): boolean;
    /**
     * Disposes of the object
     */
    dispose(): void;
}

declare module "./observable" {
    interface Observable<T> {
        /**
         * Internal observable-based coroutine scheduler instance.
         */
        _coroutineScheduler?: CoroutineScheduler<void>;
        /**
         * Internal disposal method for observable-based coroutine scheduler instance.
         */
        _coroutineSchedulerDispose?: () => void;
        /**
         * Runs a coroutine asynchronously on this observable
         * @param coroutine the iterator resulting from having started the coroutine
         * @returns a promise which will be resolved when the coroutine finishes or rejected if the coroutine is cancelled
         */
        runCoroutineAsync(coroutine: AsyncCoroutine<void>): Promise<void>;
        /**
         * Cancels all coroutines currently running on this observable
         */
        cancelAllCoroutines(): void;
    }
}

declare module "../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Create an effect to use with particle systems.
         * Please note that some parameters like animation sheets or not being billboard are not supported in this configuration, except if you pass
         * the particle system for which you want to create a custom effect in the last parameter
         * @param fragmentName defines the base name of the effect (The name of file without .fragment.fx)
         * @param uniformsNames defines a list of attribute names
         * @param samplers defines an array of string used to represent textures
         * @param defines defines the string containing the defines to use to compile the shaders
         * @param fallbacks defines the list of potential fallbacks to use if shader compilation fails
         * @param onCompiled defines a function to call when the effect creation is successful
         * @param onError defines a function to call when the effect creation has failed
         * @param particleSystem the particle system you want to create the effect for
         * @param shaderLanguage defines the shader language to use
         * @param vertexName defines the vertex base name of the effect (The name of file without .vertex.fx)
         * @returns the new Effect
         */
        createEffectForParticles(fragmentName: string, uniformsNames: string[], samplers: string[], defines: string, fallbacks?: EffectFallbacks, onCompiled?: (effect: Effect) => void, onError?: (effect: Effect, errors: string) => void, particleSystem?: IParticleSystem, shaderLanguage?: ShaderLanguage, vertexName?: string): Effect;
    }
}
declare module "../Meshes/mesh" {
    interface Mesh {
        /**
         * Returns an array populated with IParticleSystem objects whose the mesh is the emitter
         * @returns an array of IParticleSystem
         */
        getEmittedParticleSystems(): IParticleSystem[];
        /**
         * Returns an array populated with IParticleSystem objects whose the mesh or its children are the emitter
         * @returns an array of IParticleSystem
         */
        getHierarchyEmittedParticleSystems(): IParticleSystem[];
    }
}

/**
 * Interface used to define a physics engine
 * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
 */
interface IPhysicsEngine {
    /**
     * Gets the gravity vector used by the simulation
     */
    gravity: Vector3;
    getPluginVersion(): number;
    /**
     * Sets the gravity vector used by the simulation
     * @param gravity defines the gravity vector to use
     */
    setGravity(gravity: Vector3): void;
    /**
     * Set the time step of the physics engine.
     * Default is 1/60.
     * To slow it down, enter 1/600 for example.
     * To speed it up, 1/30
     * @param newTimeStep the new timestep to apply to this world.
     */
    setTimeStep(newTimeStep: number): void;
    /**
     * Get the time step of the physics engine.
     * @returns the current time step
     */
    getTimeStep(): number;
    /**
     * Set the sub time step of the physics engine.
     * Default is 0 meaning there is no sub steps
     * To increase physics resolution precision, set a small value (like 1 ms)
     * @param subTimeStep defines the new sub timestep used for physics resolution.
     */
    setSubTimeStep(subTimeStep: number): void;
    /**
     * Get the sub time step of the physics engine.
     * @returns the current sub time step
     */
    getSubTimeStep(): number;
    /**
     * Release all resources
     */
    dispose(): void;
    /**
     * Gets the name of the current physics plugin
     * @returns the name of the plugin
     */
    getPhysicsPluginName(): string;
    /**
     * Gets the current plugin used to run the simulation
     * @returns current plugin
     */
    getPhysicsPlugin(): IPhysicsEnginePlugin | IPhysicsEnginePluginV2 | null;
    /**
     * Does a raycast in the physics world
     * @param from when should the ray start?
     * @param to when should the ray end?
     * @returns PhysicsRaycastResult
     */
    raycast(from: Vector3, to: Vector3, query?: IRaycastQuery): PhysicsRaycastResult;
    /**
     * Called by the scene. No need to call it.
     * @param delta defines the timespan between frames
     */
    _step(delta: number): void;
}

declare module "../../Meshes/abstractMesh" {
    interface AbstractMesh {
        /** @internal */
        _physicsImpostor: Nullable<PhysicsImpostor>;
        /**
         * Gets or sets impostor used for physic simulation
         * @see https://doc.babylonjs.com/features/featuresDeepDive/physics
         */
        physicsImpostor: Nullable<PhysicsImpostor>;
        /**
         * Gets the current physics impostor
         * @see https://doc.babylonjs.com/features/featuresDeepDive/physics
         * @returns a physics impostor or null
         */
        getPhysicsImpostor(): Nullable<PhysicsImpostor>;
        /** Apply a physic impulse to the mesh
         * @param force defines the force to apply
         * @param contactPoint defines where to apply the force
         * @returns the current mesh
         * @see https://doc.babylonjs.com/features/featuresDeepDive/physics/usingPhysicsEngine
         */
        applyImpulse(force: Vector3, contactPoint: Vector3): AbstractMesh;
        /**
         * Creates a physic joint between two meshes
         * @param otherMesh defines the other mesh to use
         * @param pivot1 defines the pivot to use on this mesh
         * @param pivot2 defines the pivot to use on the other mesh
         * @param options defines additional options (can be plugin dependent)
         * @returns the current mesh
         * @see https://www.babylonjs-playground.com/#0BS5U0#0
         */
        setPhysicsLinkWith(otherMesh: Mesh, pivot1: Vector3, pivot2: Vector3, options?: any): AbstractMesh;
        /** @internal */
        _disposePhysicsObserver: Nullable<Observer<Node>>;
    }
}

declare module "../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _physicsEngine: Nullable<IPhysicsEngine>;
        /** @internal */
        _physicsTimeAccumulator: number;
        /**
         * Gets the current physics engine
         * @returns a IPhysicsEngine or null if none attached
         */
        getPhysicsEngine(): Nullable<IPhysicsEngine>;
        /**
         * Enables physics to the current scene
         * @param gravity defines the scene's gravity for the physics engine. defaults to real earth gravity : (0, -9.81, 0)
         * @param plugin defines the physics engine to be used. defaults to CannonJS.
         * @returns a boolean indicating if the physics engine was initialized
         */
        enablePhysics(gravity?: Nullable<Vector3>, plugin?: IPhysicsEnginePlugin | IPhysicsEnginePluginV2): boolean;
        /**
         * Disables and disposes the physics engine associated with the scene
         */
        disablePhysicsEngine(): void;
        /**
         * Gets a boolean indicating if there is an active physics engine
         * @returns a boolean indicating if there is an active physics engine
         */
        isPhysicsEnabled(): boolean;
        /**
         * Deletes a physics compound impostor
         * @param compound defines the compound to delete
         */
        deleteCompoundImpostor(compound: any): void;
        /**
         * An event triggered when physic simulation is about to be run
         */
        onBeforePhysicsObservable: Observable<Scene>;
        /**
         * An event triggered when physic simulation has been done
         */
        onAfterPhysicsObservable: Observable<Scene>;
    }
}

declare module "../../Meshes/transformNode" {
    interface TransformNode {
        /** @internal */
        _physicsBody: Nullable<PhysicsBody>;
        /**
         * @see
         */
        physicsBody: Nullable<PhysicsBody>;
        /**
         *
         */
        getPhysicsBody(): Nullable<PhysicsBody>;
        /** Apply a physic impulse to the mesh
         * @param force defines the force to apply
         * @param contactPoint defines where to apply the force
         * @returns the current mesh
         */
        applyImpulse(force: Vector3, contactPoint: Vector3): TransformNode;
        /** Apply a physic angular impulse to the mesh
         * @param angularImpulse defines the torque to apply
         * @returns the current mesh
         */
        applyAngularImpulse(angularImpulse: Vector3): TransformNode;
        /** Apply a physic torque to the mesh
         * @param torque defines the torque to apply
         * @returns the current mesh
         */
        applyTorque(torque: Vector3): TransformNode;
        /** @internal */
        _disposePhysicsObserver: Nullable<Observer<Node>>;
    }
}

/**
 * This represents a set of one or more post processes in Babylon.
 * A post process can be used to apply a shader to a texture after it is rendered.
 * @example https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/postProcessRenderPipeline
 */
declare class PostProcessRenderEffect {
    private _postProcesses;
    private _getPostProcesses;
    private _singleInstance;
    private _cameras;
    private _indicesForCamera;
    /**
     * Name of the effect
     * @internal
     */
    _name: string;
    /**
     * Instantiates a post process render effect.
     * A post process can be used to apply a shader to a texture after it is rendered.
     * @param engine The engine the effect is tied to
     * @param name The name of the effect
     * @param getPostProcesses A function that returns a set of post processes which the effect will run in order to be run.
     * @param singleInstance False if this post process can be run on multiple cameras. (default: true)
     */
    constructor(engine: AbstractEngine, name: string, getPostProcesses: () => Nullable<PostProcess | Array<PostProcess>>, singleInstance?: boolean);
    /**
     * Checks if all the post processes in the effect are supported.
     */
    get isSupported(): boolean;
    /**
     * Updates the current state of the effect
     * @internal
     */
    _update(): void;
    /**
     * Attaches the effect on cameras
     * @param cameras The camera to attach to.
     * @internal
     */
    _attachCameras(cameras: Camera): void;
    /**
     * Attaches the effect on cameras
     * @param cameras The camera to attach to.
     * @internal
     */
    _attachCameras(cameras: Camera[]): void;
    /**
     * Detaches the effect on cameras
     * @param cameras The camera to detach from.
     * @internal
     */
    _detachCameras(cameras: Camera): void;
    /**
     * Detaches the effect on cameras
     * @param cameras The camera to detach from.
     * @internal
     */
    _detachCameras(cameras: Camera[]): void;
    /**
     * Enables the effect on given cameras
     * @param cameras The camera to enable.
     * @internal
     */
    _enable(cameras: Camera): void;
    /**
     * Enables the effect on given cameras
     * @param cameras The camera to enable.
     * @internal
     */
    _enable(cameras: Nullable<Camera[]>): void;
    /**
     * Disables the effect on the given cameras
     * @param cameras The camera to disable.
     * @internal
     */
    _disable(cameras: Camera): void;
    /**
     * Disables the effect on the given cameras
     * @param cameras The camera to disable.
     * @internal
     */
    _disable(cameras: Nullable<Camera[]>): void;
    /**
     * Gets a list of the post processes contained in the effect.
     * @param camera The camera to get the post processes on.
     * @returns The list of the post processes in the effect.
     */
    getPostProcesses(camera?: Camera): Nullable<Array<PostProcess>>;
}

/** @internal */
interface ISavedTransformationMatrix {
    world: Matrix;
    viewProjection: Matrix;
}
/**
 * This renderer is helpful to fill one of the render target with a geometry buffer.
 */
declare class GeometryBufferRenderer {
    /**
     * Force all the standard materials to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static ForceGLSL: boolean;
    /**
     * Constant used to retrieve the depth texture index in the G-Buffer textures array
     * using getIndex(GeometryBufferRenderer.DEPTH_TEXTURE_INDEX)
     */
    static readonly DEPTH_TEXTURE_TYPE = 0;
    /**
     * Constant used to retrieve the normal texture index in the G-Buffer textures array
     * using getIndex(GeometryBufferRenderer.NORMAL_TEXTURE_INDEX)
     */
    static readonly NORMAL_TEXTURE_TYPE = 1;
    /**
     * Constant used to retrieve the position texture index in the G-Buffer textures array
     * using getIndex(GeometryBufferRenderer.POSITION_TEXTURE_INDEX)
     */
    static readonly POSITION_TEXTURE_TYPE = 2;
    /**
     * Constant used to retrieve the velocity texture index in the G-Buffer textures array
     * using getIndex(GeometryBufferRenderer.VELOCITY_TEXTURE_INDEX)
     */
    static readonly VELOCITY_TEXTURE_TYPE = 3;
    /**
     * Constant used to retrieve the reflectivity texture index in the G-Buffer textures array
     * using the getIndex(GeometryBufferRenderer.REFLECTIVITY_TEXTURE_TYPE)
     */
    static readonly REFLECTIVITY_TEXTURE_TYPE = 4;
    /**
     * Constant used to retrieve the screen-space depth texture index in the G-Buffer textures array
     * using getIndex(GeometryBufferRenderer.SCREENSPACE_DEPTH_TEXTURE_TYPE)
     */
    static readonly SCREENSPACE_DEPTH_TEXTURE_TYPE = 5;
    /**
     * Constant used to retrieve the linear velocity texture index in the G-Buffer textures array
     * using getIndex(GeometryBufferRenderer.VELOCITY_LINEAR_TEXTURE_TYPE)
     */
    static readonly VELOCITY_LINEAR_TEXTURE_TYPE = 6;
    /**
     * Dictionary used to store the previous transformation matrices of each rendered mesh
     * in order to compute objects velocities when enableVelocity is set to "true"
     * @internal
     */
    _previousTransformationMatrices: {
        [index: number]: ISavedTransformationMatrix;
    };
    /**
     * Dictionary used to store the previous bones transformation matrices of each rendered mesh
     * in order to compute objects velocities when enableVelocity is set to "true"
     * @internal
     */
    _previousBonesTransformationMatrices: {
        [index: number]: Float32Array;
    };
    /**
     * Array used to store the ignored skinned meshes while computing velocity map (typically used by the motion blur post-process).
     * Avoids computing bones velocities and computes only mesh's velocity itself (position, rotation, scaling).
     */
    excludedSkinnedMeshesFromVelocity: AbstractMesh[];
    /** Gets or sets a boolean indicating if transparent meshes should be rendered */
    renderTransparentMeshes: boolean;
    /**
     * Gets or sets a boolean indicating if normals should be generated in world space (default: false, meaning normals are generated in view space)
     */
    generateNormalsInWorldSpace: boolean;
    private _normalsAreUnsigned;
    /**
     * Gets a boolean indicating if normals are encoded in the [0,1] range in the render target. If true, you should do `normal = normal_rt * 2.0 - 1.0` to get the right normal
     */
    get normalsAreUnsigned(): boolean;
    private _scene;
    private _resizeObserver;
    private _multiRenderTarget;
    private _textureTypesAndFormats;
    private _ratioOrDimensions;
    private _enableDepth;
    private _enableNormal;
    private _enablePosition;
    private _enableVelocity;
    private _enableVelocityLinear;
    private _enableReflectivity;
    private _enableScreenspaceDepth;
    private _depthFormat;
    private _clearColor;
    private _clearDepthColor;
    private _positionIndex;
    private _velocityIndex;
    private _velocityLinearIndex;
    private _reflectivityIndex;
    private _depthIndex;
    private _normalIndex;
    private _screenspaceDepthIndex;
    private _linkedWithPrePass;
    private _prePassRenderer;
    private _attachmentsFromPrePass;
    private _useUbo;
    protected _cachedDefines: string;
    /**
     * @internal
     * Sets up internal structures to share outputs with PrePassRenderer
     * This method should only be called by the PrePassRenderer itself
     */
    _linkPrePassRenderer(prePassRenderer: PrePassRenderer): void;
    /**
     * @internal
     * Separates internal structures from PrePassRenderer so the geometry buffer can now operate by itself.
     * This method should only be called by the PrePassRenderer itself
     */
    _unlinkPrePassRenderer(): void;
    /**
     * @internal
     * Resets the geometry buffer layout
     */
    _resetLayout(): void;
    /**
     * @internal
     * Replaces a texture in the geometry buffer renderer
     * Useful when linking textures of the prepass renderer
     */
    _forceTextureType(geometryBufferType: number, index: number): void;
    /**
     * @internal
     * Sets texture attachments
     * Useful when linking textures of the prepass renderer
     */
    _setAttachments(attachments: number[]): void;
    /**
     * @internal
     * Replaces the first texture which is hard coded as a depth texture in the geometry buffer
     * Useful when linking textures of the prepass renderer
     */
    _linkInternalTexture(internalTexture: InternalTexture): void;
    /**
     * Gets the render list (meshes to be rendered) used in the G buffer.
     */
    get renderList(): Nullable<AbstractMesh[]>;
    /**
     * Set the render list (meshes to be rendered) used in the G buffer.
     */
    set renderList(meshes: Nullable<AbstractMesh[]>);
    /**
     * Gets whether or not G buffer are supported by the running hardware.
     * This requires draw buffer supports
     */
    get isSupported(): boolean;
    /**
     * Returns the index of the given texture type in the G-Buffer textures array
     * @param textureType The texture type constant. For example GeometryBufferRenderer.POSITION_TEXTURE_INDEX
     * @returns the index of the given texture type in the G-Buffer textures array
     */
    getTextureIndex(textureType: number): number;
    /**
     * @returns a boolean indicating if object's depths are enabled for the G buffer.
     */
    get enableDepth(): boolean;
    /**
     * Sets whether or not object's depths are enabled for the G buffer.
     */
    set enableDepth(enable: boolean);
    /**
     * @returns a boolean indicating if object's normals are enabled for the G buffer.
     */
    get enableNormal(): boolean;
    /**
     * Sets whether or not object's normals are enabled for the G buffer.
     */
    set enableNormal(enable: boolean);
    /**
     * @returns a boolean indicating if objects positions are enabled for the G buffer.
     */
    get enablePosition(): boolean;
    /**
     * Sets whether or not objects positions are enabled for the G buffer.
     */
    set enablePosition(enable: boolean);
    /**
     * @returns a boolean indicating if objects velocities are enabled for the G buffer.
     */
    get enableVelocity(): boolean;
    /**
     * Sets whether or not objects velocities are enabled for the G buffer.
     */
    set enableVelocity(enable: boolean);
    /**
     * @returns a boolean indicating if object's linear velocities are enabled for the G buffer.
     */
    get enableVelocityLinear(): boolean;
    /**
     * Sets whether or not object's linear velocities are enabled for the G buffer.
     */
    set enableVelocityLinear(enable: boolean);
    /**
     * Gets a boolean indicating if objects reflectivity are enabled in the G buffer.
     */
    get enableReflectivity(): boolean;
    /**
     * Sets whether or not objects reflectivity are enabled for the G buffer.
     * For Metallic-Roughness workflow with ORM texture, we assume that ORM texture is defined according to the default layout:
     * pbr.useRoughnessFromMetallicTextureAlpha = false;
     * pbr.useRoughnessFromMetallicTextureGreen = true;
     * pbr.useMetallnessFromMetallicTextureBlue = true;
     */
    set enableReflectivity(enable: boolean);
    /**
     * Sets whether or not objects screenspace depth are enabled for the G buffer.
     */
    get enableScreenspaceDepth(): boolean;
    set enableScreenspaceDepth(enable: boolean);
    /**
     * If set to true (default: false), the depth texture will be cleared with the depth value corresponding to the far plane (1 in normal mode, 0 in reverse depth buffer mode)
     * If set to false, the depth texture is always cleared with 0.
     */
    useSpecificClearForDepthTexture: boolean;
    /**
     * Gets the scene associated with the buffer.
     */
    get scene(): Scene;
    /**
     * Gets the ratio used by the buffer during its creation.
     * How big is the buffer related to the main canvas.
     */
    get ratio(): number;
    /** Shader language used by the material */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this material.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    /**
     * Creates a new G Buffer for the scene
     * @param scene The scene the buffer belongs to
     * @param ratioOrDimensions How big is the buffer related to the main canvas (default: 1). You can also directly pass a width and height for the generated textures
     * @param depthFormat Format of the depth texture (default: Constants.TEXTUREFORMAT_DEPTH16)
     * @param textureTypesAndFormats The types and formats of textures to create as render targets. If not provided, all textures will be RGBA and float or half float, depending on the engine capabilities.
     */
    constructor(scene: Scene, ratioOrDimensions?: number | {
        width: number;
        height: number;
    }, depthFormat?: number, textureTypesAndFormats?: {
        [key: number]: {
            textureType: number;
            textureFormat: number;
        };
    });
    private _shadersLoaded;
    private _initShaderSourceAsync;
    /**
     * Checks whether everything is ready to render a submesh to the G buffer.
     * @param subMesh the submesh to check readiness for
     * @param useInstances is the mesh drawn using instance or not
     * @returns true if ready otherwise false
     */
    isReady(subMesh: SubMesh, useInstances: boolean): boolean;
    /**
     * Gets the current underlying G Buffer.
     * @returns the buffer
     */
    getGBuffer(): MultiRenderTarget;
    /**
     * Gets the number of samples used to render the buffer (anti aliasing).
     */
    get samples(): number;
    /**
     * Sets the number of samples used to render the buffer (anti aliasing).
     */
    set samples(value: number);
    /**
     * Disposes the renderer and frees up associated resources.
     */
    dispose(): void;
    private _assignRenderTargetIndices;
    protected _createRenderTargets(): void;
    private _copyBonesTransformationMatrices;
}

declare module "../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _geometryBufferRenderer: Nullable<GeometryBufferRenderer>;
        /**
         * Gets or Sets the current geometry buffer associated to the scene.
         */
        geometryBufferRenderer: Nullable<GeometryBufferRenderer>;
        /**
         * Enables a GeometryBufferRender and associates it with the scene
         * @param ratioOrDimensions defines the scaling ratio to apply to the renderer (1 by default which means same resolution). You can also directly pass a width and height for the generated textures
         * @param depthFormat Format of the depth texture (default: Constants.TEXTUREFORMAT_DEPTH16)
         * @param textureTypesAndFormats The types and formats of textures to create as render targets. If not provided, all textures will be RGBA and float or half float, depending on the engine capabilities.
         * @returns the GeometryBufferRenderer
         */
        enableGeometryBufferRenderer(ratioOrDimensions?: number | {
            width: number;
            height: number;
        }, depthFormat?: number, textureTypesAndFormats?: {
            [key: number]: {
                textureType: number;
                textureFormat: number;
            };
        }): Nullable<GeometryBufferRenderer>;
        /**
         * Disables the GeometryBufferRender associated with the scene
         */
        disableGeometryBufferRenderer(): void;
    }
}

/**
 * PostProcessRenderPipeline
 * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/postProcessRenderPipeline
 */
declare class PostProcessRenderPipeline {
    private _engine;
    protected _renderEffects: {
        [key: string]: PostProcessRenderEffect;
    };
    protected _renderEffectsForIsolatedPass: PostProcessRenderEffect[];
    /**
     * List of inspectable custom properties (used by the Inspector)
     * @see https://doc.babylonjs.com/toolsAndResources/inspector#extensibility
     */
    inspectableCustomProperties: IInspectable[];
    /**
     * @internal
     */
    protected _cameras: Camera[];
    /** @internal */
    _name: string;
    /**
     * Gets pipeline name
     */
    get name(): string;
    /**
     * Gets the unique id of the post process rendering pipeline
     */
    readonly uniqueId: number;
    /** Gets the list of attached cameras */
    get cameras(): Camera[];
    /**
     * Gets the active engine
     */
    get engine(): AbstractEngine;
    /**
     * Initializes a PostProcessRenderPipeline
     * @param _engine engine to add the pipeline to
     * @param name name of the pipeline
     */
    constructor(_engine: AbstractEngine, name: string);
    /**
     * Gets the class name
     * @returns "PostProcessRenderPipeline"
     */
    getClassName(): string;
    /**
     * If all the render effects in the pipeline are supported
     */
    get isSupported(): boolean;
    /**
     * Adds an effect to the pipeline
     * @param renderEffect the effect to add
     */
    addEffect(renderEffect: PostProcessRenderEffect): void;
    /** @internal */
    _rebuild(): void;
    /** @internal */
    _enableEffect(renderEffectName: string, cameras: Camera): void;
    /** @internal */
    _enableEffect(renderEffectName: string, cameras: Camera[]): void;
    /** @internal */
    _disableEffect(renderEffectName: string, cameras: Nullable<Camera[]>): void;
    /** @internal */
    _disableEffect(renderEffectName: string, cameras: Nullable<Camera[]>): void;
    /** @internal */
    _attachCameras(cameras: Camera, unique: boolean): void;
    /** @internal */
    _attachCameras(cameras: Camera[], unique: boolean): void;
    /** @internal */
    _detachCameras(cameras: Camera): void;
    /** @internal */
    _detachCameras(cameras: Nullable<Camera[]>): void;
    /** @internal */
    _update(): void;
    /** @internal */
    _reset(): void;
    protected _enableMSAAOnFirstPostProcess(sampleCount: number): boolean;
    /**
     * Ensures that all post processes in the pipeline are the correct size according to the
     * the viewport's required size
     */
    protected _adaptPostProcessesToViewPort(): void;
    /**
     * Sets the required values to the prepass renderer.
     * @param prePassRenderer defines the prepass renderer to setup.
     * @returns true if the pre pass is needed.
     */
    setPrePassRenderer(prePassRenderer: PrePassRenderer): boolean;
    /**
     * Disposes of the pipeline
     */
    dispose(): void;
}

/**
 * PostProcessRenderPipelineManager class
 * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/postProcessRenderPipeline
 */
declare class PostProcessRenderPipelineManager {
    private readonly _renderPipelines;
    private readonly _onNewPipelineAddedObservable;
    private readonly _onPipelineRemovedObservable;
    /**
     * Initializes a PostProcessRenderPipelineManager
     * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/postProcessRenderPipeline
     */
    constructor();
    /**
     * An event triggered when a pipeline is added to the manager
     */
    get onNewPipelineAddedObservable(): IReadonlyObservable<PostProcessRenderPipeline>;
    /**
     * An event triggered when a pipeline is removed from the manager
     */
    get onPipelineRemovedObservable(): IReadonlyObservable<PostProcessRenderPipeline>;
    /**
     * Gets the list of supported render pipelines
     */
    get supportedPipelines(): PostProcessRenderPipeline[];
    /**
     * Adds a pipeline to the manager
     * @param renderPipeline The pipeline to add
     */
    addPipeline(renderPipeline: PostProcessRenderPipeline): void;
    /**
     * Remove the pipeline from the manager
     * @param renderPipelineName the name of the pipeline to remove
     */
    removePipeline(renderPipelineName: string): void;
    /**
     * Attaches a camera to the pipeline
     * @param renderPipelineName The name of the pipeline to attach to
     * @param cameras the camera to attach
     * @param unique if the camera can be attached multiple times to the pipeline
     */
    attachCamerasToRenderPipeline(renderPipelineName: string, cameras: Camera[] | Camera, unique?: boolean): void;
    /**
     * Detaches a camera from the pipeline
     * @param renderPipelineName The name of the pipeline to detach from
     * @param cameras the camera to detach
     */
    detachCamerasFromRenderPipeline(renderPipelineName: string, cameras: Camera[] | Camera): void;
    /**
     * Enables an effect by name on a pipeline
     * @param renderPipelineName the name of the pipeline to enable the effect in
     * @param renderEffectName the name of the effect to enable
     * @param cameras the cameras that the effect should be enabled on
     */
    enableEffectInPipeline(renderPipelineName: string, renderEffectName: string, cameras: Camera[] | Camera): void;
    /**
     * Disables an effect by name on a pipeline
     * @param renderPipelineName the name of the pipeline to disable the effect in
     * @param renderEffectName the name of the effect to disable
     * @param cameras the cameras that the effect should be disabled on
     */
    disableEffectInPipeline(renderPipelineName: string, renderEffectName: string, cameras: Camera[] | Camera): void;
    /**
     * Updates the state of all contained render pipelines and disposes of any non supported pipelines
     */
    update(): void;
    /** @internal */
    _rebuild(): void;
    /**
     * Disposes of the manager and pipelines
     */
    dispose(): void;
}

declare module "../../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _postProcessRenderPipelineManager: PostProcessRenderPipelineManager;
        /**
         * Gets the postprocess render pipeline manager
         * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/postProcessRenderPipeline
         * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/defaultRenderingPipeline
         */
        readonly postProcessRenderPipelineManager: PostProcessRenderPipelineManager;
    }
}

declare module "../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _boundingBoxRenderer: BoundingBoxRenderer;
        /** @internal (Backing field) */
        _forceShowBoundingBoxes: boolean;
        /**
         * Gets or sets a boolean indicating if all bounding boxes must be rendered
         */
        forceShowBoundingBoxes: boolean;
        /**
         * Gets the bounding box renderer associated with the scene
         * @returns a BoundingBoxRenderer
         */
        getBoundingBoxRenderer(): BoundingBoxRenderer;
    }
}
declare module "../Meshes/abstractMesh" {
    interface AbstractMesh {
        /** @internal (Backing field) */
        _showBoundingBox: boolean;
        /**
         * Gets or sets a boolean indicating if the bounding box must be rendered as well (false by default)
         */
        showBoundingBox: boolean;
    }
}
/**
 * Component responsible of rendering the bounding box of the meshes in a scene.
 * This is usually used through the mesh.showBoundingBox or the scene.forceShowBoundingBoxes properties
 */
declare class BoundingBoxRenderer implements ISceneComponent {
    /**
     * The component name helpful to identify the component in the list of scene components.
     */
    readonly name = "BoundingBoxRenderer";
    /**
     * The scene the component belongs to.
     */
    scene: Scene;
    /**
     * Color of the bounding box lines placed in front of an object
     */
    frontColor: Color3;
    /**
     * Color of the bounding box lines placed behind an object
     */
    backColor: Color3;
    /**
     * Defines if the renderer should show the back lines or not
     */
    showBackLines: boolean;
    /**
     * Observable raised before rendering a bounding box
     * When {@link BoundingBoxRenderer.useInstances} enabled,
     * this would only be triggered once for one rendering, instead of once every bounding box.
     * Events would be triggered with a dummy box to keep backwards compatibility,
     * the passed bounding box has no meaning and should be ignored.
     */
    onBeforeBoxRenderingObservable: Observable<BoundingBox>;
    /**
     * Observable raised after rendering a bounding box
     * When {@link BoundingBoxRenderer.useInstances} enabled,
     * this would only be triggered once for one rendering, instead of once every bounding box.
     * Events would be triggered with a dummy box to keep backwards compatibility,
     * the passed bounding box has no meaning and should be ignored.
     */
    onAfterBoxRenderingObservable: Observable<BoundingBox>;
    /**
     * Observable raised after resources are created
     */
    onResourcesReadyObservable: Observable<BoundingBoxRenderer>;
    /**
     * When false, no bounding boxes will be rendered
     */
    enabled: boolean;
    /** Shader language used by the renderer */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this renderer.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * @internal
     */
    renderList: SmartArray<BoundingBox>;
    private _colorShader;
    private _colorShaderForOcclusionQuery;
    private _vertexBuffers;
    private _indexBuffer;
    private _fillIndexBuffer;
    private _fillIndexData;
    private _uniformBufferFront;
    private _uniformBufferBack;
    private _renderPassIdForOcclusionQuery;
    /**
     * Internal buffer for instanced rendering
     */
    private _matrixBuffer;
    private _matrices;
    /**
     * Internal state of whether instanced rendering enabled
     */
    protected _useInstances: boolean;
    /** @internal */
    _drawWrapperFront: Nullable<DrawWrapper>;
    /** @internal */
    _drawWrapperBack: Nullable<DrawWrapper>;
    /**
     * Instantiates a new bounding box renderer in a scene.
     * @param scene the scene the  renderer renders in
     */
    constructor(scene: Scene);
    private _buildUniformLayout;
    /**
     * Registers the component in a given scene
     */
    register(): void;
    /**
     * Checks if the renderer is ready asynchronously.
     * @param timeStep Time step in ms between retries (default is 16)
     * @param maxTimeout Maximum time in ms to wait for the graph to be ready (default is 30000)
     * @returns The promise that resolves when the renderer is ready
     */
    whenReadyAsync(timeStep?: number, maxTimeout?: number): Promise<void>;
    /** @internal */
    _evaluateSubMesh(mesh: AbstractMesh, subMesh: SubMesh): void;
    /** @internal */
    _preActiveMesh(mesh: AbstractMesh): void;
    private _prepareResources;
    private _createIndexBuffer;
    /**
     * Rebuilds the elements related to this component in case of
     * context lost for instance.
     */
    rebuild(): void;
    /**
     * @internal
     */
    reset(): void;
    /**
     * Render the bounding boxes of a specific rendering group
     * @param renderingGroupId defines the rendering group to render
     */
    render(renderingGroupId: number): void;
    private _createWrappersForBoundingBox;
    /**
     * In case of occlusion queries, we can render the occlusion bounding box through this method
     * @param mesh Define the mesh to render the occlusion bounding box for
     */
    renderOcclusionBoundingBox(mesh: AbstractMesh): void;
    /**
     * Sets whether to use instanced rendering.
     * When not enabled, BoundingBoxRenderer renders in a loop,
     * calling engine.drawElementsType for each bounding box in renderList,
     * making every bounding box 1 or 2 draw call.
     * When enabled, it collects bounding boxes to render,
     * and render all boxes in 1 or 2 draw call.
     * This could make the rendering with many bounding boxes much faster than not enabled,
     * but could result in a difference in rendering result if
     * {@link BoundingBoxRenderer.showBackLines} enabled,
     * because drawing the black/white part of each box one after the other
     * can be different from drawing the black part of all boxes and then the white part.
     * Also, when enabled, events of {@link BoundingBoxRenderer.onBeforeBoxRenderingObservable}
     * and {@link BoundingBoxRenderer.onAfterBoxRenderingObservable} would only be triggered once
     * for one rendering, instead of once every bounding box.
     * Events would be triggered with a dummy box to keep backwards compatibility,
     * the passed bounding box has no meaning and should be ignored.
     * @param val whether to use instanced rendering
     */
    set useInstances(val: boolean);
    get useInstances(): boolean;
    /**
     * Instanced render the bounding boxes of a specific rendering group
     * @param renderingGroupId defines the rendering group to render
     */
    private _renderInstanced;
    /**
     * Creates buffer for instanced rendering
     * @param buffer buffer to set
     */
    private _createInstanceBuffer;
    /**
     * Clean up buffers for instanced rendering
     */
    private _cleanupInstanceBuffer;
    /**
     * Clean up resources for instanced rendering
     */
    private _cleanupInstances;
    /**
     * Dispose and release the resources attached to this renderer.
     */
    dispose(): void;
}

declare module "../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _depthRenderer: {
            [id: string]: DepthRenderer;
        };
        /**
         * Creates a depth renderer a given camera which contains a depth map which can be used for post processing.
         * @param camera The camera to create the depth renderer on (default: scene's active camera)
         * @param storeNonLinearDepth Defines whether the depth is stored linearly like in Babylon Shadows or directly like glFragCoord.z
         * @param force32bitsFloat Forces 32 bits float when supported (else 16 bits float is prioritized over 32 bits float if supported)
         * @param samplingMode The sampling mode to be used with the render target (Linear, Nearest...)
         * @param storeCameraSpaceZ Defines whether the depth stored is the Z coordinate in camera space. If true, storeNonLinearDepth has no effect. (Default: false)
         * @param existingRenderTargetTexture An existing render target texture to use (default: undefined). If not provided, a new render target texture will be created.
         * @returns the created depth renderer
         */
        enableDepthRenderer(camera?: Nullable<Camera>, storeNonLinearDepth?: boolean, force32bitsFloat?: boolean, samplingMode?: number, storeCameraSpaceZ?: boolean, existingRenderTargetTexture?: RenderTargetTexture): DepthRenderer;
        /**
         * Disables a depth renderer for a given camera
         * @param camera The camera to disable the depth renderer on (default: scene's active camera)
         */
        disableDepthRenderer(camera?: Nullable<Camera>): void;
    }
}

declare module "../scene" {
    interface Scene {
        /**
         * The depth peeling renderer
         */
        depthPeelingRenderer: Nullable<ThinDepthPeelingRenderer>;
        /** @internal (Backing field) */
        _depthPeelingRenderer: Nullable<ThinDepthPeelingRenderer>;
        /**
         * Flag to indicate if we want to use order independent transparency, despite the performance hit
         */
        useOrderIndependentTransparency: boolean;
        /** @internal */
        _useOrderIndependentTransparency: boolean;
    }
}

/**
 * Build cdf maps to be used for IBL importance sampling.
 */
declare class IblCdfGenerator {
    private _scene;
    private _engine;
    private _cdfyPT;
    private _cdfxPT;
    private _icdfPT;
    private _scaledLuminancePT;
    private _dominantDirectionPT;
    private _iblSource;
    private _dummyTexture;
    private _cachedDominantDirection;
    /**
     * Returns whether the CDF renderer is supported by the current engine
     */
    get isSupported(): boolean;
    /**
     * Gets the IBL source texture being used by the CDF renderer
     */
    get iblSource(): Nullable<BaseTexture>;
    /**
     * Sets the IBL source texture to be used by the CDF renderer.
     * This will trigger recreation of the CDF assets.
     */
    set iblSource(source: Nullable<BaseTexture>);
    private _recreateAssetsFromNewIbl;
    /**
     * Return the cumulative distribution function (CDF) texture
     * @returns Return the cumulative distribution function (CDF) texture
     */
    getIcdfTexture(): Texture;
    /** Enable the debug view for this pass */
    debugEnabled: boolean;
    private _debugPass;
    private _debugSizeParams;
    /**
     * Sets params that control the position and scaling of the debug display on the screen.
     * @param x Screen X offset of the debug display (0-1)
     * @param y Screen Y offset of the debug display (0-1)
     * @param widthScale X scale of the debug display (0-1)
     * @param heightScale Y scale of the debug display (0-1)
     */
    setDebugDisplayParams(x: number, y: number, widthScale: number, heightScale: number): void;
    /**
     * The name of the debug pass post process
     */
    get debugPassName(): string;
    private _debugPassName;
    /**
     * Gets the debug pass post process
     * @returns The post process
     */
    getDebugPassPP(): PostProcess;
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    /**
     * Instanciates the CDF renderer
     * @param sceneOrEngine Scene to attach to
     * @returns The CDF renderer
     */
    constructor(sceneOrEngine: Nullable<Scene | AbstractEngine>);
    /**
     * Observable that triggers when the CDF renderer is ready
     */
    onGeneratedObservable: Observable<void>;
    private _createTextures;
    private _disposeTextures;
    private _createDebugPass;
    /**
     * Checks if the CDF renderer is ready
     * @returns true if the CDF renderer is ready
     */
    isReady(): boolean | null;
    /**
     * Explicitly trigger generation of CDF maps when they are ready to render.
     * @returns Promise that resolves when the CDF maps are rendered.
     */
    renderWhenReady(): Promise<void>;
    /**
     * Finds the average direction of the highest intensity areas of the IBL source
     * @returns Async promise that resolves to the dominant direction of the IBL source
     */
    findDominantDirection(): Promise<Vector3>;
    /**
     * Disposes the CDF renderer and associated resources
     */
    dispose(): void;
    private static _IsScene;
}

declare module "../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _iblCdfGenerator: Nullable<IblCdfGenerator>;
        /**
         * Gets or Sets the current CDF generator associated to the scene.
         * The CDF (cumulative distribution function) generator creates CDF maps
         * for a given IBL texture that can then be used for more efficient
         * importance sampling.
         */
        iblCdfGenerator: Nullable<IblCdfGenerator>;
        /**
         * Enables a IblCdfGenerator and associates it with the scene.
         * @returns the IblCdfGenerator
         */
        enableIblCdfGenerator(): Nullable<IblCdfGenerator>;
        /**
         * Disables the GeometryBufferRender associated with the scene
         */
        disableIblCdfGenerator(): void;
    }
}

declare module "../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _prePassRenderer: Nullable<PrePassRenderer>;
        /**
         * Gets or Sets the current prepass renderer associated to the scene.
         */
        prePassRenderer: Nullable<PrePassRenderer>;
        /**
         * Enables the prepass and associates it with the scene
         * @returns the PrePassRenderer
         */
        enablePrePassRenderer(): Nullable<PrePassRenderer>;
        /**
         * Disables the prepass associated with the scene
         */
        disablePrePassRenderer(): void;
    }
}
declare module "../Materials/Textures/renderTargetTexture" {
    interface RenderTargetTexture {
        /**
         * Gets or sets a boolean indicating that the prepass renderer should not be used with this render target
         */
        noPrePassRenderer: boolean;
        /** @internal */
        _prePassRenderTarget: Nullable<PrePassRenderTarget>;
    }
}

/**
 * Sub surface scattering post process
 */
declare class SubSurfaceScatteringPostProcess extends PostProcess {
    /**
     * Gets a string identifying the name of the class
     * @returns "SubSurfaceScatteringPostProcess" string
     */
    getClassName(): string;
    constructor(name: string, scene: Scene, options: number | PostProcessOptions, camera?: Nullable<Camera>, samplingMode?: number, engine?: AbstractEngine, reusable?: boolean, textureType?: number);
}

/**
 * Contains all parameters needed for the prepass to perform
 * screen space subsurface scattering
 */
declare class SubSurfaceConfiguration implements PrePassEffectConfiguration {
    /**
     * @internal
     */
    static _SceneComponentInitialization: (scene: Scene) => void;
    private _ssDiffusionS;
    private _ssFilterRadii;
    private _ssDiffusionD;
    /**
     * Post process to attach for screen space subsurface scattering
     */
    postProcess: SubSurfaceScatteringPostProcess;
    /**
     * Diffusion profile color for subsurface scattering
     */
    get ssDiffusionS(): number[];
    /**
     * Diffusion profile max color channel value for subsurface scattering
     */
    get ssDiffusionD(): number[];
    /**
     * Diffusion profile filter radius for subsurface scattering
     */
    get ssFilterRadii(): number[];
    /**
     * Is subsurface enabled
     */
    enabled: boolean;
    /**
     * Does the output of this prepass need to go through imageprocessing
     */
    needsImageProcessing: boolean;
    /**
     * Name of the configuration
     */
    name: string;
    /**
     * Diffusion profile colors for subsurface scattering
     * You can add one diffusion color using `addDiffusionProfile` on `scene.prePassRenderer`
     * See ...
     * Note that you can only store up to 5 of them
     */
    ssDiffusionProfileColors: Color3[];
    /**
     * Defines the ratio real world => scene units.
     * Used for subsurface scattering
     */
    metersPerUnit: number;
    /**
     * Textures that should be present in the MRT for this effect to work
     */
    readonly texturesRequired: number[];
    /**
     * The clear color of the render targets.
     * We need 1 for the alpha channel of the irradiance texture so that we early exit from the SSS post-process if the pixel should not be processed
     */
    clearColor: Color4;
    private _scene;
    /**
     * Builds a subsurface configuration object
     * @param scene The scene
     */
    constructor(scene: Scene);
    /**
     * Adds a new diffusion profile.
     * Useful for more realistic subsurface scattering on diverse materials.
     * @param color The color of the diffusion profile. Should be the average color of the material.
     * @returns The index of the diffusion profile for the material subsurface configuration
     */
    addDiffusionProfile(color: Color3): number;
    /**
     * Creates the sss post process
     * @returns The created post process
     */
    createPostProcess(): SubSurfaceScatteringPostProcess;
    /**
     * Deletes all diffusion profiles.
     * Note that in order to render subsurface scattering, you should have at least 1 diffusion profile.
     */
    clearAllDiffusionProfiles(): void;
    /**
     * Disposes this object
     */
    dispose(): void;
    /**
     * @internal
     * https://zero-radiance.github.io/post/sampling-diffusion/
     *
     * Importance sample the normalized diffuse reflectance profile for the computed value of 's'.
     * ------------------------------------------------------------------------------------
     * R[r, phi, s]   = s * (Exp[-r * s] + Exp[-r * s / 3]) / (8 * Pi * r)
     * PDF[r, phi, s] = r * R[r, phi, s]
     * CDF[r, s]      = 1 - 1/4 * Exp[-r * s] - 3/4 * Exp[-r * s / 3]
     * ------------------------------------------------------------------------------------
     * We importance sample the color channel with the widest scattering distance.
     */
    getDiffusionProfileParameters(color: Color3): number;
    /**
     * Performs sampling of a Normalized Burley diffusion profile in polar coordinates.
     * 'u' is the random number (the value of the CDF): [0, 1).
     * rcp(s) = 1 / ShapeParam = ScatteringDistance.
     * Returns the sampled radial distance, s.t. (u = 0 -> r = 0) and (u = 1 -> r = Inf).
     * @param u
     * @param rcpS
     * @returns The sampled radial distance
     */
    private _sampleBurleyDiffusionProfile;
}

declare module "../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _subSurfaceConfiguration: Nullable<SubSurfaceConfiguration>;
        /**
         * Gets or Sets the current prepass renderer associated to the scene.
         */
        subSurfaceConfiguration: Nullable<SubSurfaceConfiguration>;
        /**
         * Enables the subsurface effect for prepass
         * @returns the SubSurfaceConfiguration
         */
        enableSubSurfaceForPrePass(): Nullable<SubSurfaceConfiguration>;
        /**
         * Disables the subsurface effect for prepass
         */
        disableSubSurfaceForPrePass(): void;
    }
}

declare module "../scene" {
    interface Scene {
        /** @internal */
        _outlineRenderer: OutlineRenderer;
        /**
         * Gets the outline renderer associated with the scene
         * @returns a OutlineRenderer
         */
        getOutlineRenderer(): OutlineRenderer;
    }
}
declare module "../Meshes/abstractMesh" {
    interface AbstractMesh {
        /** @internal (Backing field) */
        _renderOutline: boolean;
        /**
         * Gets or sets a boolean indicating if the outline must be rendered as well
         * @see https://www.babylonjs-playground.com/#10WJ5S#3
         */
        renderOutline: boolean;
        /** @internal (Backing field) */
        _renderOverlay: boolean;
        /**
         * Gets or sets a boolean indicating if the overlay must be rendered as well
         * @see https://www.babylonjs-playground.com/#10WJ5S#2
         */
        renderOverlay: boolean;
    }
}
/**
 * This class is responsible to draw the outline/overlay of meshes.
 * It should not be used directly but through the available method on mesh.
 */
declare class OutlineRenderer implements ISceneComponent {
    /**
     * Stencil value used to avoid outline being seen within the mesh when the mesh is transparent
     */
    private static _StencilReference;
    /**
     * The name of the component. Each component must have a unique name.
     */
    name: string;
    /**
     * The scene the component belongs to.
     */
    scene: Scene;
    /**
     * Defines a zOffset default Factor to prevent zFighting between the overlay and the mesh.
     */
    zOffset: number;
    /**
     * Defines a zOffset default Unit to prevent zFighting between the overlay and the mesh.
     */
    zOffsetUnits: number;
    /**
     * Gets or sets a boolean indicating if the renderer is enabled
     */
    enabled: boolean;
    private _engine;
    private _savedDepthWrite;
    private _passIdForDrawWrapper;
    /** Shader language used by the Outline renderer. */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in the Outline renderer.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Instantiates a new outline renderer. (There could be only one per scene).
     * @param scene Defines the scene it belongs to
     */
    constructor(scene: Scene);
    /**
     * Register the component to one instance of a scene.
     */
    register(): void;
    /**
     * Rebuilds the elements related to this component in case of
     * context lost for instance.
     */
    rebuild(): void;
    /**
     * Disposes the component and the associated resources.
     */
    dispose(): void;
    /**
     * Renders the outline in the canvas.
     * @param subMesh Defines the sumesh to render
     * @param batch Defines the batch of meshes in case of instances
     * @param useOverlay Defines if the rendering is for the overlay or the outline
     * @param renderPassId Render pass id to use to render the mesh
     */
    render(subMesh: SubMesh, batch: _InstancesBatch, useOverlay?: boolean, renderPassId?: number): void;
    /**
     * Returns whether or not the outline renderer is ready for a given submesh.
     * All the dependencies e.g. submeshes, texture, effect... mus be ready
     * @param subMesh Defines the submesh to check readiness for
     * @param useInstances Defines whether wee are trying to render instances or not
     * @param renderPassId Render pass id to use to render the mesh
     * @returns true if ready otherwise false
     */
    isReady(subMesh: SubMesh, useInstances: boolean, renderPassId?: number): boolean;
    private _beforeRenderingMesh;
    private _afterRenderingMesh;
}

/**
 * Defines the base object used for fluid rendering.
 * It is based on a list of vertices (particles)
 */
declare abstract class FluidRenderingObject {
    protected _scene: Scene;
    protected _engine: AbstractEngine;
    protected _effectsAreDirty: boolean;
    protected _depthEffectWrapper: Nullable<EffectWrapper>;
    protected _thicknessEffectWrapper: Nullable<EffectWrapper>;
    /** Defines the priority of the object. Objects will be rendered in ascending order of priority */
    priority: number;
    protected _particleSize: number;
    /** Observable triggered when the size of the particle is changed */
    onParticleSizeChanged: Observable<FluidRenderingObject>;
    /** Gets or sets the size of the particle */
    get particleSize(): number;
    set particleSize(size: number);
    /** Defines the alpha value of a particle */
    particleThicknessAlpha: number;
    /** Indicates if the object uses instancing or not */
    get useInstancing(): boolean;
    private _useVelocity;
    /** Indicates if velocity of particles should be used when rendering the object. The vertex buffer set must contain a "velocity" buffer for this to work! */
    get useVelocity(): boolean;
    set useVelocity(use: boolean);
    private _hasVelocity;
    /**
     * Gets the vertex buffers
     */
    abstract get vertexBuffers(): {
        [key: string]: VertexBuffer;
    };
    /**
     * Gets the index buffer (or null if the object is using instancing)
     */
    get indexBuffer(): Nullable<DataBuffer>;
    /**
     * @returns the name of the class
     */
    getClassName(): string;
    /** Shader language used by the object */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this object
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Instantiates a fluid rendering object
     * @param scene The scene the object is part of
     * @param shaderLanguage The shader language to use
     */
    constructor(scene: Scene, shaderLanguage?: ShaderLanguage);
    protected _createEffects(): void;
    /**
     * Indicates if the object is ready to be rendered
     * @returns True if everything is ready for the object to be rendered, otherwise false
     */
    isReady(): boolean;
    /**
     * Gets the number of particles (vertices) of this object
     * @returns The number of particles
     */
    abstract get numParticles(): number;
    /**
     * Render the depth texture for this object
     */
    renderDepthTexture(): void;
    /**
     * Render the thickness texture for this object
     */
    renderThicknessTexture(): void;
    /**
     * Render the diffuse texture for this object
     */
    renderDiffuseTexture(): void;
    /**
     * Releases the resources used by the class
     */
    dispose(): void;
}

/** @internal */
declare class FluidRenderingTextures {
    protected _name: string;
    protected _scene: Scene;
    protected _camera: Nullable<Camera>;
    protected _engine: AbstractEngine;
    protected _width: number;
    protected _height: number;
    protected _blurTextureSizeX: number;
    protected _blurTextureSizeY: number;
    protected _textureType: number;
    protected _textureFormat: number;
    protected _blurTextureType: number;
    protected _blurTextureFormat: number;
    protected _useStandardBlur: boolean;
    protected _generateDepthBuffer: boolean;
    protected _samples: number;
    protected _postProcessRunningIndex: number;
    protected _rt: Nullable<RenderTargetWrapper>;
    protected _texture: Nullable<Texture>;
    protected _rtBlur: Nullable<RenderTargetWrapper>;
    protected _textureBlurred: Nullable<Texture>;
    protected _blurPostProcesses: Nullable<PostProcess[]>;
    enableBlur: boolean;
    blurSizeDivisor: number;
    blurFilterSize: number;
    private _blurNumIterations;
    get blurNumIterations(): number;
    set blurNumIterations(numIterations: number);
    blurMaxFilterSize: number;
    blurDepthScale: number;
    particleSize: number;
    onDisposeObservable: Observable<FluidRenderingTextures>;
    get renderTarget(): Nullable<RenderTargetWrapper>;
    get renderTargetBlur(): Nullable<RenderTargetWrapper>;
    get texture(): Nullable<Texture>;
    get textureBlur(): Nullable<Texture>;
    /** Shader language used by the texture */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in the texture
     */
    get shaderLanguage(): ShaderLanguage;
    constructor(name: string, scene: Scene, width: number, height: number, blurTextureSizeX: number, blurTextureSizeY: number, textureType?: number, textureFormat?: number, blurTextureType?: number, blurTextureFormat?: number, useStandardBlur?: boolean, camera?: Nullable<Camera>, generateDepthBuffer?: boolean, samples?: number, shaderLanguage?: ShaderLanguage);
    initialize(): void;
    applyBlurPostProcesses(): void;
    protected _createRenderTarget(): void;
    protected _createBlurPostProcesses(textureBlurSource: ThinTexture, textureType: number, textureFormat: number, blurSizeDivisor: number, debugName: string, useStandardBlur?: boolean): [RenderTargetWrapper, Texture, PostProcess[]];
    private _fixReusablePostProcess;
    private _getProjectedParticleConstant;
    private _getDepthThreshold;
    dispose(): void;
}

/**
 * Textures that can be displayed as a debugging tool
 */
declare const enum FluidRenderingDebug {
    DepthTexture = 0,
    DepthBlurredTexture = 1,
    ThicknessTexture = 2,
    ThicknessBlurredTexture = 3,
    DiffuseTexture = 4,
    Normals = 5,
    DiffuseRendering = 6
}
/**
 * Class used to render an object as a fluid thanks to different render target textures (depth, thickness, diffuse)
 */
declare class FluidRenderingTargetRenderer {
    protected _scene: Scene;
    protected _camera: Nullable<Camera>;
    protected _engine: AbstractEngine;
    protected _invProjectionMatrix: Matrix;
    protected _depthClearColor: Color4;
    protected _thicknessClearColor: Color4;
    protected _needInitialization: boolean;
    /**
     * Returns true if the class needs to be reinitialized (because of changes in parameterization)
     */
    get needInitialization(): boolean;
    private _generateDiffuseTexture;
    /**
     * Gets or sets a boolean indicating that the diffuse texture should be generated and used for the rendering
     */
    get generateDiffuseTexture(): boolean;
    set generateDiffuseTexture(generate: boolean);
    /**
     * Fluid color. Not used if generateDiffuseTexture is true
     */
    fluidColor: Color3;
    /**
     * Density of the fluid (positive number). The higher the value, the more opaque the fluid.
     */
    density: number;
    /**
     * Strength of the refraction (positive number, but generally between 0 and 0.3).
     */
    refractionStrength: number;
    /**
     * Strength of the fresnel effect (value between 0 and 1). Lower the value if you want to soften the specular effect
     */
    fresnelClamp: number;
    /**
     * Strength of the specular power (positive number). Increase the value to make the specular effect more concentrated
     */
    specularPower: number;
    /**
     * Minimum thickness of the particles (positive number). If useFixedThickness is true, minimumThickness is the thickness used
     */
    minimumThickness: number;
    /**
     * Direction of the light. The fluid is assumed to be lit by a directional light
     */
    dirLight: Vector3;
    private _debugFeature;
    /**
     * Gets or sets the feature (texture) to be debugged. Not used if debug is false
     */
    get debugFeature(): FluidRenderingDebug;
    set debugFeature(feature: FluidRenderingDebug);
    private _debug;
    /**
     * Gets or sets a boolean indicating if we should display a specific texture (given by debugFeature) for debugging purpose
     */
    get debug(): boolean;
    set debug(debug: boolean);
    private _environmentMap?;
    /**
     * Gets or sets the environment map used for the reflection part of the shading
     * If null, no map will be used. If undefined, the scene.environmentMap will be used (if defined)
     */
    get environmentMap(): Nullable<BaseTexture> | undefined;
    set environmentMap(map: Nullable<BaseTexture> | undefined);
    private _enableBlurDepth;
    /**
     * Gets or sets a boolean indicating that the depth texture should be blurred
     */
    get enableBlurDepth(): boolean;
    set enableBlurDepth(enable: boolean);
    private _blurDepthSizeDivisor;
    /**
     * Gets or sets the depth size divisor (positive number, generally between 1 and 4), which is used as a divisor when creating the texture used for blurring the depth
     * For eg. if blurDepthSizeDivisor=2, the texture used to blur the depth will be half the size of the depth texture
     */
    get blurDepthSizeDivisor(): number;
    set blurDepthSizeDivisor(scale: number);
    private _blurDepthFilterSize;
    /**
     * Size of the kernel used to filter the depth blur texture (positive number, generally between 1 and 20 - higher values will require more processing power from the GPU)
     */
    get blurDepthFilterSize(): number;
    set blurDepthFilterSize(filterSize: number);
    private _blurDepthNumIterations;
    /**
     * Number of blurring iterations used to generate the depth blur texture (positive number, generally between 1 and 10 - higher values will require more processing power from the GPU)
     */
    get blurDepthNumIterations(): number;
    set blurDepthNumIterations(numIterations: number);
    private _blurDepthMaxFilterSize;
    /**
     * Maximum size of the kernel used to blur the depth texture (positive number, generally between 1 and 200 - higher values will require more processing power from the GPU when the particles are larger on screen)
     */
    get blurDepthMaxFilterSize(): number;
    set blurDepthMaxFilterSize(maxFilterSize: number);
    private _blurDepthDepthScale;
    /**
     * Depth weight in the calculation when applying the bilateral blur to generate the depth blur texture (positive number, generally between 0 and 100)
     */
    get blurDepthDepthScale(): number;
    set blurDepthDepthScale(scale: number);
    private _enableBlurThickness;
    /**
     * Gets or sets a boolean indicating that the thickness texture should be blurred
     */
    get enableBlurThickness(): boolean;
    set enableBlurThickness(enable: boolean);
    private _blurThicknessSizeDivisor;
    /**
     * Gets or sets the thickness size divisor (positive number, generally between 1 and 4), which is used as a divisor when creating the texture used for blurring the thickness
     * For eg. if blurThicknessSizeDivisor=2, the texture used to blur the thickness will be half the size of the thickness texture
     */
    get blurThicknessSizeDivisor(): number;
    set blurThicknessSizeDivisor(scale: number);
    private _blurThicknessFilterSize;
    /**
     * Size of the kernel used to filter the thickness blur texture (positive number, generally between 1 and 20 - higher values will require more processing power from the GPU)
     */
    get blurThicknessFilterSize(): number;
    set blurThicknessFilterSize(filterSize: number);
    private _blurThicknessNumIterations;
    /**
     * Number of blurring iterations used to generate the thickness blur texture (positive number, generally between 1 and 10 - higher values will require more processing power from the GPU)
     */
    get blurThicknessNumIterations(): number;
    set blurThicknessNumIterations(numIterations: number);
    private _useFixedThickness;
    /**
     * Gets or sets a boolean indicating that a fixed thickness should be used instead of generating a thickness texture
     */
    get useFixedThickness(): boolean;
    set useFixedThickness(use: boolean);
    /** @internal */
    _bgDepthTexture: Nullable<InternalTexture>;
    /** @internal */
    _onUseVelocityChanged: Observable<FluidRenderingTargetRenderer>;
    private _useVelocity;
    /**
     * Gets or sets a boolean indicating that the velocity should be used when rendering the particles as a fluid.
     * Note: the vertex buffers must contain a "velocity" buffer for this to work!
     */
    get useVelocity(): boolean;
    set useVelocity(use: boolean);
    private _depthMapSize;
    /**
     * Defines the size of the depth texture.
     * If null, the texture will have the size of the screen
     */
    get depthMapSize(): Nullable<number>;
    set depthMapSize(size: Nullable<number>);
    private _thicknessMapSize;
    /**
     * Defines the size of the thickness texture.
     * If null, the texture will have the size of the screen
     */
    get thicknessMapSize(): Nullable<number>;
    set thicknessMapSize(size: Nullable<number>);
    private _diffuseMapSize;
    /**
     * Defines the size of the diffuse texture.
     * If null, the texture will have the size of the screen
     */
    get diffuseMapSize(): Nullable<number>;
    set diffuseMapSize(size: Nullable<number>);
    private _samples;
    /**
     * Gets or sets the number of samples used by MSAA
     * Note: changing this value in WebGL does not work because depth/stencil textures can't be created with MSAA (see https://github.com/BabylonJS/Babylon.js/issues/12444)
     */
    get samples(): number;
    set samples(samples: number);
    private _compositeMode;
    /**
     * If compositeMode is true (default: false), when the alpha value of the background (the scene rendered without the fluid objects) is 0, the final alpha value of the pixel will be set to the thickness value.
     * This way, it is possible to composite the fluid rendering on top of the HTML background.
     */
    get compositeMode(): boolean;
    set compositeMode(value: boolean);
    /**
     * Gets the camera used for the rendering
     */
    get camera(): Nullable<Camera>;
    /** @internal */
    _renderPostProcess: Nullable<PostProcess>;
    /** @internal */
    _depthRenderTarget: Nullable<FluidRenderingTextures>;
    /** @internal */
    _diffuseRenderTarget: Nullable<FluidRenderingTextures>;
    /** @internal */
    _thicknessRenderTarget: Nullable<FluidRenderingTextures>;
    /** Shader language used by the renderer */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this renderer
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Creates an instance of the class
     * @param scene Scene used to render the fluid object into
     * @param camera Camera used to render the fluid object. If not provided, use the active camera of the scene instead
     * @param shaderLanguage The shader language to use
     */
    constructor(scene: Scene, camera?: Camera, shaderLanguage?: ShaderLanguage);
    /** @internal */
    _initialize(): void;
    protected _setBlurParameters(renderTarget?: Nullable<FluidRenderingTextures>): void;
    protected _setBlurDepthParameters(): void;
    protected _setBlurThicknessParameters(): void;
    protected _initializeRenderTarget(renderTarget: FluidRenderingTextures): void;
    protected _createLiquidRenderingPostProcess(): void;
    /** @internal */
    _clearTargets(): void;
    /** @internal */
    _render(fluidObject: FluidRenderingObject): void;
    /**
     * Releases all the resources used by the class
     * @param onlyPostProcesses If true, releases only the resources used by the render post processes
     */
    dispose(onlyPostProcesses?: boolean): void;
}

declare module "../../scene" {
    interface Scene {
        /** @internal (Backing field) */
        _fluidRenderer: Nullable<FluidRenderer>;
        /**
         * Gets or Sets the fluid renderer associated to the scene.
         */
        fluidRenderer: Nullable<FluidRenderer>;
        /**
         * Enables the fluid renderer and associates it with the scene
         * @returns the FluidRenderer
         */
        enableFluidRenderer(): Nullable<FluidRenderer>;
        /**
         * Disables the fluid renderer associated with the scene
         */
        disableFluidRenderer(): void;
    }
}
/**
 * An object rendered as a fluid.
 * It consists of the object itself as well as the render target renderer (which is used to generate the textures (render target) needed for fluid rendering)
 */
interface IFluidRenderingRenderObject {
    /** object rendered as a fluid */
    object: FluidRenderingObject;
    /** target renderer used to render the fluid object */
    targetRenderer: FluidRenderingTargetRenderer;
}
/**
 * Class responsible for fluid rendering.
 * It is implementing the method described in https://developer.download.nvidia.com/presentations/2010/gdc/Direct3D_Effects.pdf
 */
declare class FluidRenderer {
    /** @internal */
    static _SceneComponentInitialization(scene: Scene): void;
    private _scene;
    private _engine;
    private _onEngineResizeObserver;
    private _cameras;
    /** Retrieves all the render objects managed by the class */
    readonly renderObjects: Array<IFluidRenderingRenderObject>;
    /** Retrieves all the render target renderers managed by the class */
    readonly targetRenderers: FluidRenderingTargetRenderer[];
    /** Shader language used by the renderer */
    protected _shaderLanguage: ShaderLanguage;
    /**
     * Gets the shader language used in this renderer
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Initializes the class
     * @param scene Scene in which the objects are part of
     */
    constructor(scene: Scene);
    /**
     * Reinitializes the class
     * Can be used if you change the object priority (FluidRenderingObject.priority), to make sure the objects are rendered in the right order
     */
    recreate(): void;
    /**
     * Gets the render object corresponding to a particle system (null if the particle system is not rendered as a fluid)
     * @param ps The particle system
     * @returns the render object corresponding to this particle system if any, otherwise null
     */
    getRenderObjectFromParticleSystem(ps: IParticleSystem): Nullable<IFluidRenderingRenderObject>;
    /**
     * Adds a particle system to the fluid renderer.
     * @param ps particle system
     * @param generateDiffuseTexture True if you want to generate a diffuse texture from the particle system and use it as part of the fluid rendering (default: false)
     * @param targetRenderer The target renderer used to display the particle system as a fluid. If not provided, the method will create a new one
     * @param camera The camera used by the target renderer (if the target renderer is created by the method)
     * @returns the render object corresponding to the particle system
     */
    addParticleSystem(ps: IParticleSystem, generateDiffuseTexture?: boolean, targetRenderer?: FluidRenderingTargetRenderer, camera?: Camera): IFluidRenderingRenderObject;
    /**
     * Adds a custom particle set to the fluid renderer.
     * @param buffers The list of buffers (should contain at least a "position" buffer!)
     * @param numParticles Number of particles in each buffer
     * @param generateDiffuseTexture True if you want to generate a diffuse texture from buffers and use it as part of the fluid rendering (default: false). For the texture to be generated correctly, you need a "color" buffer in the set!
     * @param targetRenderer The target renderer used to display the particle system as a fluid. If not provided, the method will create a new one
     * @param camera The camera used by the target renderer (if the target renderer is created by the method)
     * @returns the render object corresponding to the custom particle set
     */
    addCustomParticles(buffers: {
        [key: string]: FloatArray;
    }, numParticles: number, generateDiffuseTexture?: boolean, targetRenderer?: FluidRenderingTargetRenderer, camera?: Camera): IFluidRenderingRenderObject;
    /**
     * Removes a render object from the fluid renderer
     * @param renderObject the render object to remove
     * @param removeUnusedTargetRenderer True to remove/dispose of the target renderer if it's not used anymore (default: true)
     * @returns True if the render object has been found and released, else false
     */
    removeRenderObject(renderObject: IFluidRenderingRenderObject, removeUnusedTargetRenderer?: boolean): boolean;
    private _sortRenderingObjects;
    private _removeUnusedTargetRenderers;
    private _getParticleSystemIndex;
    private _initialize;
    private _setParticleSizeForRenderTargets;
    private _setUseVelocityForRenderObject;
    /** @internal */
    _prepareRendering(): void;
    /** @internal */
    _render(forCamera?: Camera): void;
    /**
     * Disposes of all the resources used by the class
     */
    dispose(): void;
}

/**
 * @internal
 **/
declare class AlphaState {
    private _supportBlendParametersPerTarget;
    _blendFunctionParameters: Nullable<number>[];
    _blendEquationParameters: Nullable<number>[];
    _blendConstants: Nullable<number>[];
    _isBlendConstantsDirty: boolean;
    _alphaBlend: any[];
    _numTargetEnabled: number;
    private _isAlphaBlendDirty;
    private _isBlendFunctionParametersDirty;
    private _isBlendEquationParametersDirty;
    /**
     * Initializes the state.
     * @param _supportBlendParametersPerTarget - Whether blend parameters per target is supported
     */
    constructor(_supportBlendParametersPerTarget: boolean);
    get isDirty(): boolean;
    get alphaBlend(): boolean;
    set alphaBlend(value: boolean);
    setAlphaBlend(value: boolean, targetIndex?: number): void;
    setAlphaBlendConstants(r: number, g: number, b: number, a: number): void;
    setAlphaBlendFunctionParameters(srcRGBFactor: number, dstRGBFactor: number, srcAlphaFactor: number, dstAlphaFactor: number, targetIndex?: number): void;
    setAlphaEquationParameters(rgbEquation: number, alphaEquation: number, targetIndex?: number): void;
    reset(): void;
    apply(gl: WebGLRenderingContext, numTargets?: number): void;
    setAlphaMode(mode: number, targetIndex: number): void;
}

/**
 * @internal
 **/
declare class DepthCullingState {
    protected _isDepthTestDirty: boolean;
    protected _isDepthMaskDirty: boolean;
    protected _isDepthFuncDirty: boolean;
    protected _isCullFaceDirty: boolean;
    protected _isCullDirty: boolean;
    protected _isZOffsetDirty: boolean;
    protected _isFrontFaceDirty: boolean;
    protected _depthTest: boolean;
    protected _depthMask: boolean;
    protected _depthFunc: Nullable<number>;
    protected _cull: Nullable<boolean>;
    protected _cullFace: Nullable<number>;
    protected _zOffset: number;
    protected _zOffsetUnits: number;
    protected _frontFace: Nullable<number>;
    /**
     * Initializes the state.
     * @param reset
     */
    constructor(reset?: boolean);
    get isDirty(): boolean;
    get zOffset(): number;
    set zOffset(value: number);
    get zOffsetUnits(): number;
    set zOffsetUnits(value: number);
    get cullFace(): Nullable<number>;
    set cullFace(value: Nullable<number>);
    get cull(): Nullable<boolean>;
    set cull(value: Nullable<boolean>);
    get depthFunc(): Nullable<number>;
    set depthFunc(value: Nullable<number>);
    get depthMask(): boolean;
    set depthMask(value: boolean);
    get depthTest(): boolean;
    set depthTest(value: boolean);
    get frontFace(): Nullable<number>;
    set frontFace(value: Nullable<number>);
    reset(): void;
    apply(gl: WebGLRenderingContext): void;
}

/**
 * @internal
 **/
declare class StencilState implements IStencilState {
    /** Passed to depthFunction or stencilFunction to specify depth or stencil tests will always pass. i.e. Pixels will be drawn in the order they are drawn */
    static readonly ALWAYS = 519;
    /** Passed to stencilOperation to specify that stencil value must be kept */
    static readonly KEEP = 7680;
    /** Passed to stencilOperation to specify that stencil value must be replaced */
    static readonly REPLACE = 7681;
    constructor();
    reset(): void;
    func: number;
    get stencilFunc(): number;
    set stencilFunc(value: number);
    backFunc: number;
    get stencilBackFunc(): number;
    set stencilBackFunc(value: number);
    funcRef: number;
    get stencilFuncRef(): number;
    set stencilFuncRef(value: number);
    funcMask: number;
    get stencilFuncMask(): number;
    set stencilFuncMask(value: number);
    opStencilFail: number;
    get stencilOpStencilFail(): number;
    set stencilOpStencilFail(value: number);
    opDepthFail: number;
    get stencilOpDepthFail(): number;
    set stencilOpDepthFail(value: number);
    opStencilDepthPass: number;
    get stencilOpStencilDepthPass(): number;
    set stencilOpStencilDepthPass(value: number);
    backOpStencilFail: number;
    get stencilBackOpStencilFail(): number;
    set stencilBackOpStencilFail(value: number);
    backOpDepthFail: number;
    get stencilBackOpDepthFail(): number;
    set stencilBackOpDepthFail(value: number);
    backOpStencilDepthPass: number;
    get stencilBackOpStencilDepthPass(): number;
    set stencilBackOpStencilDepthPass(value: number);
    mask: number;
    get stencilMask(): number;
    set stencilMask(value: number);
    enabled: boolean;
    get stencilTest(): boolean;
    set stencilTest(value: boolean);
}

/**
 * @internal
 **/
declare class StencilStateComposer {
    protected _isStencilTestDirty: boolean;
    protected _isStencilMaskDirty: boolean;
    protected _isStencilFuncDirty: boolean;
    protected _isStencilOpDirty: boolean;
    protected _enabled: boolean;
    protected _mask: number;
    protected _func: number;
    protected _funcRef: number;
    protected _funcMask: number;
    protected _opStencilFail: number;
    protected _opDepthFail: number;
    protected _opStencilDepthPass: number;
    protected _backFunc: number;
    protected _backOpStencilFail: number;
    protected _backOpDepthFail: number;
    protected _backOpStencilDepthPass: number;
    stencilGlobal: IStencilState;
    stencilMaterial: IStencilState | undefined;
    useStencilGlobalOnly: boolean;
    get isDirty(): boolean;
    get func(): number;
    set func(value: number);
    get backFunc(): number;
    set backFunc(value: number);
    get funcRef(): number;
    set funcRef(value: number);
    get funcMask(): number;
    set funcMask(value: number);
    get opStencilFail(): number;
    set opStencilFail(value: number);
    get opDepthFail(): number;
    set opDepthFail(value: number);
    get opStencilDepthPass(): number;
    set opStencilDepthPass(value: number);
    get backOpStencilFail(): number;
    set backOpStencilFail(value: number);
    get backOpDepthFail(): number;
    set backOpDepthFail(value: number);
    get backOpStencilDepthPass(): number;
    set backOpStencilDepthPass(value: number);
    get mask(): number;
    set mask(value: number);
    get enabled(): boolean;
    set enabled(value: boolean);
    constructor(reset?: boolean);
    reset(): void;
    apply(gl?: WebGLRenderingContext): void;
}

declare const BackgroundMaterialBase_base: {
    new (...args: any[]): {
        _imageProcessingConfiguration: ImageProcessingConfiguration;
        get imageProcessingConfiguration(): ImageProcessingConfiguration;
        set imageProcessingConfiguration(value: ImageProcessingConfiguration);
        _imageProcessingObserver: Nullable<Observer<ImageProcessingConfiguration>>;
        _attachImageProcessingConfiguration(configuration: Nullable<ImageProcessingConfiguration>): void;
        get cameraColorCurvesEnabled(): boolean;
        set cameraColorCurvesEnabled(value: boolean);
        get cameraColorGradingEnabled(): boolean;
        set cameraColorGradingEnabled(value: boolean);
        get cameraToneMappingEnabled(): boolean;
        set cameraToneMappingEnabled(value: boolean);
        get cameraExposure(): number;
        set cameraExposure(value: number);
        get cameraContrast(): number;
        set cameraContrast(value: number);
        get cameraColorGradingTexture(): Nullable<BaseTexture>;
        set cameraColorGradingTexture(value: Nullable<BaseTexture>);
        get cameraColorCurves(): Nullable<ColorCurves>;
        set cameraColorCurves(value: Nullable<ColorCurves>);
    };
} & typeof PushMaterial;
declare class BackgroundMaterialBase extends BackgroundMaterialBase_base {
}
/**
 * Background material used to create an efficient environment around your scene.
 * #157MGZ: simple test
 */
declare class BackgroundMaterial extends BackgroundMaterialBase {
    /**
     * Standard reflectance value at parallel view angle.
     */
    static StandardReflectance0: number;
    /**
     * Standard reflectance value at grazing angle.
     */
    static StandardReflectance90: number;
    protected _primaryColor: Color3;
    /**
     * Key light Color (multiply against the environment texture)
     */
    primaryColor: Color3;
    protected __perceptualColor: Nullable<Color3>;
    /**
     * Experimental Internal Use Only.
     *
     * Key light Color in "perceptual value" meaning the color you would like to see on screen.
     * This acts as a helper to set the primary color to a more "human friendly" value.
     * Conversion to linear space as well as exposure and tone mapping correction will be applied to keep the
     * output color as close as possible from the chosen value.
     * (This does not account for contrast color grading and color curves as they are considered post effect and not directly
     * part of lighting setup.)
     */
    get _perceptualColor(): Nullable<Color3>;
    set _perceptualColor(value: Nullable<Color3>);
    protected _primaryColorShadowLevel: float;
    /**
     * Defines the level of the shadows (dark area of the reflection map) in order to help scaling the colors.
     * The color opposite to the primary color is used at the level chosen to define what the black area would look.
     */
    get primaryColorShadowLevel(): float;
    set primaryColorShadowLevel(value: float);
    protected _primaryColorHighlightLevel: float;
    /**
     * Defines the level of the highlights (highlight area of the reflection map) in order to help scaling the colors.
     * The primary color is used at the level chosen to define what the white area would look.
     */
    get primaryColorHighlightLevel(): float;
    set primaryColorHighlightLevel(value: float);
    protected _reflectionTexture: Nullable<BaseTexture>;
    /**
     * Reflection Texture used in the material.
     * Should be author in a specific way for the best result (refer to the documentation).
     */
    reflectionTexture: Nullable<BaseTexture>;
    protected _reflectionBlur: float;
    /**
     * Reflection Texture level of blur.
     *
     * Can be use to reuse an existing HDR Texture and target a specific LOD to prevent authoring the
     * texture twice.
     */
    reflectionBlur: float;
    protected _diffuseTexture: Nullable<BaseTexture>;
    /**
     * Diffuse Texture used in the material.
     * Should be author in a specific way for the best result (refer to the documentation).
     */
    diffuseTexture: Nullable<BaseTexture>;
    protected _shadowLights: Nullable<IShadowLight[]>;
    /**
     * Specify the list of lights casting shadow on the material.
     * All scene shadow lights will be included if null.
     */
    shadowLights: Nullable<IShadowLight[]>;
    protected _shadowLevel: float;
    /**
     * Helps adjusting the shadow to a softer level if required.
     * 0 means black shadows and 1 means no shadows.
     */
    shadowLevel: float;
    protected _sceneCenter: Vector3;
    /**
     * In case of opacity Fresnel or reflection falloff, this is use as a scene center.
     * It is usually zero but might be interesting to modify according to your setup.
     */
    sceneCenter: Vector3;
    protected _opacityFresnel: boolean;
    /**
     * This helps specifying that the material is falling off to the sky box at grazing angle.
     * This helps ensuring a nice transition when the camera goes under the ground.
     */
    opacityFresnel: boolean;
    protected _reflectionFresnel: boolean;
    /**
     * This helps specifying that the material is falling off from diffuse to the reflection texture at grazing angle.
     * This helps adding a mirror texture on the ground.
     */
    reflectionFresnel: boolean;
    protected _reflectionFalloffDistance: number;
    /**
     * This helps specifying the falloff radius off the reflection texture from the sceneCenter.
     * This helps adding a nice falloff effect to the reflection if used as a mirror for instance.
     */
    reflectionFalloffDistance: number;
    protected _reflectionAmount: number;
    /**
     * This specifies the weight of the reflection against the background in case of reflection Fresnel.
     */
    reflectionAmount: number;
    protected _reflectionReflectance0: number;
    /**
     * This specifies the weight of the reflection at grazing angle.
     */
    reflectionReflectance0: number;
    protected _reflectionReflectance90: number;
    /**
     * This specifies the weight of the reflection at a perpendicular point of view.
     */
    reflectionReflectance90: number;
    /**
     * Sets the reflection reflectance fresnel values according to the default standard
     * empirically know to work well :-)
     */
    set reflectionStandardFresnelWeight(value: number);
    protected _useRGBColor: boolean;
    /**
     * Helps to directly use the maps channels instead of their level.
     */
    useRGBColor: boolean;
    protected _enableNoise: boolean;
    /**
     * This helps reducing the banding effect that could occur on the background.
     */
    enableNoise: boolean;
    /**
     * The current fov(field of view) multiplier, 0.0 - 2.0. Defaults to 1.0. Lower values "zoom in" and higher values "zoom out".
     * Best used when trying to implement visual zoom effects like fish-eye or binoculars while not adjusting camera fov.
     * Recommended to be keep at 1.0 except for special cases.
     */
    get fovMultiplier(): number;
    set fovMultiplier(value: number);
    private _fovMultiplier;
    /**
     * Enable the FOV adjustment feature controlled by fovMultiplier.
     */
    useEquirectangularFOV: boolean;
    private _maxSimultaneousLights;
    /**
     * Number of Simultaneous lights allowed on the material.
     */
    maxSimultaneousLights: int;
    private _shadowOnly;
    /**
     * Make the material only render shadows
     */
    shadowOnly: boolean;
    /**
     * Due to a bug in iOS10, video tags (which are using the background material) are in BGR and not RGB.
     * Setting this flag to true (not done automatically!) will convert it back to RGB.
     */
    switchToBGR: boolean;
    private _enableGroundProjection;
    /**
     * Enables the ground projection mode on the material.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/skybox#ground-projection
     */
    enableGroundProjection: boolean;
    /**
     * Defines the radius of the projected ground if enableGroundProjection is true.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/skybox#ground-projection
     */
    projectedGroundRadius: number;
    /**
     * Defines the height of the projected ground if enableGroundProjection is true.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/skybox#ground-projection
     */
    projectedGroundHeight: number;
    private _renderTargets;
    private _reflectionControls;
    private _white;
    private _primaryShadowColor;
    private _primaryHighlightColor;
    private _shadersLoaded;
    /**
     * Instantiates a Background Material in the given scene
     * @param name The friendly name of the material
     * @param scene The scene to add the material to
     * @param forceGLSL Use the GLSL code generation for the shader (even on WebGPU). Default is false
     */
    constructor(name: string, scene?: Scene, forceGLSL?: boolean);
    /**
     * Gets a boolean indicating that current material needs to register RTT
     */
    get hasRenderTargetTextures(): boolean;
    /**
     * The entire material has been created in order to prevent overdraw.
     * @returns false
     */
    needAlphaTesting(): boolean;
    /**
     * The entire material has been created in order to prevent overdraw.
     * @returns true if blending is enable
     */
    needAlphaBlending(): boolean;
    /**
     * Checks whether the material is ready to be rendered for a given mesh.
     * @param mesh The mesh to render
     * @param subMesh The submesh to check against
     * @param useInstances Specify wether or not the material is used with instances
     * @returns true if all the dependencies are ready (Textures, Effects...)
     */
    isReadyForSubMesh(mesh: AbstractMesh, subMesh: SubMesh, useInstances?: boolean): boolean;
    /**
     * Compute the primary color according to the chosen perceptual color.
     */
    private _computePrimaryColorFromPerceptualColor;
    /**
     * Compute the highlights and shadow colors according to their chosen levels.
     */
    private _computePrimaryColors;
    /**
     * Build the uniform buffer used in the material.
     */
    buildUniformLayout(): void;
    /**
     * Unbind the material.
     */
    unbind(): void;
    /**
     * Bind only the world matrix to the material.
     * @param world The world matrix to bind.
     */
    bindOnlyWorldMatrix(world: Matrix): void;
    /**
     * Bind the material for a dedicated submesh (every used meshes will be considered opaque).
     * @param world The world matrix to bind.
     * @param mesh the mesh to bind for.
     * @param subMesh The submesh to bind for.
     */
    bindForSubMesh(world: Matrix, mesh: Mesh, subMesh: SubMesh): void;
    /**
     * Checks to see if a texture is used in the material.
     * @param texture - Base texture to use.
     * @returns - Boolean specifying if a texture is used in the material.
     */
    hasTexture(texture: BaseTexture): boolean;
    /**
     * Dispose the material.
     * @param forceDisposeEffect Force disposal of the associated effect.
     * @param forceDisposeTextures Force disposal of the associated textures.
     */
    dispose(forceDisposeEffect?: boolean, forceDisposeTextures?: boolean): void;
    /**
     * Clones the material.
     * @param name The cloned name.
     * @returns The cloned material.
     */
    clone(name: string): BackgroundMaterial;
    /**
     * Serializes the current material to its JSON representation.
     * @returns The JSON representation.
     */
    serialize(): any;
    /**
     * Gets the class name of the material
     * @returns "BackgroundMaterial"
     */
    getClassName(): string;
    /**
     * Parse a JSON input to create back a background material.
     * @param source The JSON data to parse
     * @param scene The scene to create the parsed material in
     * @param rootUrl The root url of the assets the material depends upon
     * @returns the instantiated BackgroundMaterial.
     */
    static Parse(source: any, scene: Scene, rootUrl: string): BackgroundMaterial;
}

/**
 * Enum used to define the material modes
 */
declare enum NodeMaterialModes {
    /** Regular material */
    Material = 0,
    /** For post process */
    PostProcess = 1,
    /** For particle system */
    Particle = 2,
    /** For procedural texture */
    ProceduralTexture = 3,
    /** For gaussian splatting */
    GaussianSplatting = 4,
    /** For SFE */
    SFE = 5
}

/**
 * Block used to read a texture from a sampler
 */
declare class TextureBlock extends NodeMaterialBlock {
    private _defineName;
    private _linearDefineName;
    private _gammaDefineName;
    private _tempTextureRead;
    private _samplerName;
    private _transformedUVName;
    private _textureTransformName;
    private _textureInfoName;
    private _mainUVName;
    private _mainUVDefineName;
    private _fragmentOnly;
    private _imageSource;
    protected _texture: Nullable<Texture>;
    /**
     * Gets or sets the texture associated with the node
     */
    get texture(): Nullable<Texture>;
    set texture(texture: Nullable<Texture>);
    private static _IsPrePassTextureBlock;
    private get _isSourcePrePass();
    /**
     * Gets the sampler name associated with this texture
     */
    get samplerName(): string;
    /**
     * Gets a boolean indicating that this block is linked to an ImageSourceBlock
     */
    get hasImageSource(): boolean;
    private _convertToGammaSpace;
    /**
     * Gets or sets a boolean indicating if content needs to be converted to gamma space
     */
    set convertToGammaSpace(value: boolean);
    get convertToGammaSpace(): boolean;
    private _convertToLinearSpace;
    /**
     * Gets or sets a boolean indicating if content needs to be converted to linear space
     */
    set convertToLinearSpace(value: boolean);
    get convertToLinearSpace(): boolean;
    /**
     * Gets or sets a boolean indicating if multiplication of texture with level should be disabled
     */
    disableLevelMultiplication: boolean;
    /**
     * Create a new TextureBlock
     * @param name defines the block name
     * @param fragmentOnly
     */
    constructor(name: string, fragmentOnly?: boolean);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the uv input component
     */
    get uv(): NodeMaterialConnectionPoint;
    /**
     * Gets the source input component
     */
    get source(): NodeMaterialConnectionPoint;
    /**
     * Gets the layer input component
     */
    get layer(): NodeMaterialConnectionPoint;
    /**
     * Gets the LOD input component
     */
    get lod(): NodeMaterialConnectionPoint;
    /**
     * Gets the rgba output component
     */
    get rgba(): NodeMaterialConnectionPoint;
    /**
     * Gets the rgb output component
     */
    get rgb(): NodeMaterialConnectionPoint;
    /**
     * Gets the r output component
     */
    get r(): NodeMaterialConnectionPoint;
    /**
     * Gets the g output component
     */
    get g(): NodeMaterialConnectionPoint;
    /**
     * Gets the b output component
     */
    get b(): NodeMaterialConnectionPoint;
    /**
     * Gets the a output component
     */
    get a(): NodeMaterialConnectionPoint;
    /**
     * Gets the level output component
     */
    get level(): NodeMaterialConnectionPoint;
    private _isTiedToFragment;
    private _getEffectiveTarget;
    get target(): NodeMaterialBlockTargets;
    set target(value: NodeMaterialBlockTargets);
    autoConfigure(material: NodeMaterial, additionalFilteringInfo?: (node: NodeMaterialBlock) => boolean): void;
    initializeDefines(defines: NodeMaterialDefines): void;
    prepareDefines(defines: NodeMaterialDefines): void;
    isReady(): boolean;
    bind(effect: Effect): void;
    private get _isMixed();
    private _injectVertexCode;
    private _getUVW;
    private _samplerFunc;
    private get _samplerLodSuffix();
    private _generateTextureSample;
    private _generateTextureLookup;
    private _writeTextureRead;
    private _generateConversionCode;
    private _writeOutput;
    protected _buildBlock(state: NodeMaterialBuildState): this | undefined;
    protected _dumpPropertiesCode(): string;
    serialize(): any;
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string, urlRewriter?: (url: string) => string): void;
}

/**
 * Base block used to read a reflection texture from a sampler
 */
declare abstract class ReflectionTextureBaseBlock extends NodeMaterialBlock {
    /** @internal */
    _define3DName: string;
    /** @internal */
    _defineCubicName: string;
    /** @internal */
    _defineExplicitName: string;
    /** @internal */
    _defineProjectionName: string;
    /** @internal */
    _defineLocalCubicName: string;
    /** @internal */
    _defineSphericalName: string;
    /** @internal */
    _definePlanarName: string;
    /** @internal */
    _defineEquirectangularName: string;
    /** @internal */
    _defineMirroredEquirectangularFixedName: string;
    /** @internal */
    _defineEquirectangularFixedName: string;
    /** @internal */
    _defineSkyboxName: string;
    /** @internal */
    _defineOppositeZ: string;
    /** @internal */
    _cubeSamplerName: string;
    /** @internal */
    _2DSamplerName: string;
    /** @internal */
    _reflectionPositionName: string;
    /** @internal */
    _reflectionSizeName: string;
    protected _positionUVWName: string;
    protected _directionWname: string;
    protected _reflectionVectorName: string;
    /** @internal */
    _reflectionCoordsName: string;
    /** @internal */
    _reflectionMatrixName: string;
    protected _reflectionColorName: string;
    protected _worldPositionNameInFragmentOnlyMode: string;
    protected _texture: Nullable<BaseTexture>;
    /**
     * Gets or sets the texture associated with the node
     */
    get texture(): Nullable<BaseTexture>;
    set texture(texture: Nullable<BaseTexture>);
    /** Indicates that no code should be generated in the vertex shader. Can be useful in some specific circumstances (like when doing ray marching for eg) */
    generateOnlyFragmentCode: boolean;
    protected static _OnGenerateOnlyFragmentCodeChanged(block: NodeMaterialBlock, _propertyName: string): boolean;
    protected _onGenerateOnlyFragmentCodeChanged(): boolean;
    protected _setTarget(): void;
    /**
     * Create a new ReflectionTextureBaseBlock
     * @param name defines the block name
     */
    constructor(name: string);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the world position input component
     */
    abstract get position(): NodeMaterialConnectionPoint;
    /**
     * Gets the world position input component
     */
    abstract get worldPosition(): NodeMaterialConnectionPoint;
    /**
     * Gets the world normal input component
     */
    abstract get worldNormal(): NodeMaterialConnectionPoint;
    /**
     * Gets the world input component
     */
    abstract get world(): NodeMaterialConnectionPoint;
    /**
     * Gets the camera (or eye) position component
     */
    abstract get cameraPosition(): NodeMaterialConnectionPoint;
    /**
     * Gets the view input component
     */
    abstract get view(): NodeMaterialConnectionPoint;
    protected _getTexture(): Nullable<BaseTexture>;
    initialize(state: NodeMaterialBuildState): void;
    private _initShaderSourceAsync;
    /**
     * Auto configure the node based on the existing material
     * @param material defines the material to configure
     * @param additionalFilteringInfo defines additional info to be used when filtering inputs (we might want to skip some non relevant blocks)
     */
    autoConfigure(material: NodeMaterial, additionalFilteringInfo?: (node: NodeMaterialBlock) => boolean): void;
    prepareDefines(defines: NodeMaterialDefines): void;
    isReady(): boolean;
    bind(effect: Effect, nodeMaterial: NodeMaterial, mesh?: Mesh, _subMesh?: SubMesh): void;
    /**
     * Gets the code to inject in the vertex shader
     * @param state current state of the node material building
     * @returns the shader code
     */
    handleVertexSide(state: NodeMaterialBuildState): string;
    /**
     * Handles the inits for the fragment code path
     * @param state node material build state
     */
    handleFragmentSideInits(state: NodeMaterialBuildState): void;
    /**
     * Generates the reflection coords code for the fragment code path
     * @param state defines the build state
     * @param worldNormalVarName name of the world normal variable
     * @param worldPos name of the world position variable. If not provided, will use the world position connected to this block
     * @param onlyReflectionVector if true, generates code only for the reflection vector computation, not for the reflection coordinates
     * @param doNotEmitInvertZ if true, does not emit the invertZ code
     * @returns the shader code
     */
    handleFragmentSideCodeReflectionCoords(state: NodeMaterialBuildState, worldNormalVarName: string, worldPos?: string, onlyReflectionVector?: boolean, doNotEmitInvertZ?: boolean): string;
    /**
     * Generates the reflection color code for the fragment code path
     * @param state defines the build state
     * @param lodVarName name of the lod variable
     * @param swizzleLookupTexture swizzle to use for the final color variable
     * @returns the shader code
     */
    handleFragmentSideCodeReflectionColor(state: NodeMaterialBuildState, lodVarName?: string, swizzleLookupTexture?: string): string;
    /**
     * Generates the code corresponding to the connected output points
     * @param state node material build state
     * @param varName name of the variable to output
     * @returns the shader code
     */
    writeOutputs(state: NodeMaterialBuildState, varName: string): string;
    protected _buildBlock(state: NodeMaterialBuildState): this;
    protected _dumpPropertiesCode(): string;
    serialize(): any;
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string): void;
}

/**
 * Base block used as input for post process
 */
declare class CurrentScreenBlock extends NodeMaterialBlock {
    protected _samplerName: string;
    protected _linearDefineName: string;
    protected _gammaDefineName: string;
    protected _mainUVName: string;
    protected _tempTextureRead: string;
    protected _texture: Nullable<BaseTexture>;
    /**
     * The name of the sampler to read the screen texture from.
     */
    get samplerName(): string;
    /**
     * Gets or sets the texture associated with the node
     */
    get texture(): Nullable<BaseTexture>;
    set texture(value: Nullable<BaseTexture>);
    /**
     * Gets or sets a boolean indicating if content needs to be converted to gamma space
     */
    convertToGammaSpace: boolean;
    /**
     * Gets or sets a boolean indicating if content needs to be converted to linear space
     */
    convertToLinearSpace: boolean;
    /**
     * Create a new CurrentScreenBlock
     * @param name defines the block name
     */
    constructor(name: string);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the uv input component
     */
    get uv(): NodeMaterialConnectionPoint;
    /**
     * Gets the rgba output component
     */
    get rgba(): NodeMaterialConnectionPoint;
    /**
     * Gets the rgb output component
     */
    get rgb(): NodeMaterialConnectionPoint;
    /**
     * Gets the r output component
     */
    get r(): NodeMaterialConnectionPoint;
    /**
     * Gets the g output component
     */
    get g(): NodeMaterialConnectionPoint;
    /**
     * Gets the b output component
     */
    get b(): NodeMaterialConnectionPoint;
    /**
     * Gets the a output component
     */
    get a(): NodeMaterialConnectionPoint;
    /**
     * Initialize the block and prepare the context for build
     * @param state defines the state that will be used for the build
     */
    initialize(state: NodeMaterialBuildState): void;
    get target(): NodeMaterialBlockTargets.Fragment | NodeMaterialBlockTargets.VertexAndFragment;
    prepareDefines(defines: NodeMaterialDefines): void;
    isReady(): boolean;
    protected _getMainUvName(state: NodeMaterialBuildState): string;
    protected _injectVertexCode(state: NodeMaterialBuildState): void;
    protected _writeTextureRead(state: NodeMaterialBuildState, vertexMode?: boolean): void;
    protected _writeOutput(state: NodeMaterialBuildState, output: NodeMaterialConnectionPoint, swizzle: string, vertexMode?: boolean): void;
    protected _emitUvAndSampler(state: NodeMaterialBuildState): void;
    protected _buildBlock(state: NodeMaterialBuildState): this | undefined;
    serialize(): any;
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string): void;
}

/**
 * Block used to provide an image for a TextureBlock
 */
declare class ImageSourceBlock extends NodeMaterialBlock {
    private _samplerName;
    protected _texture: Nullable<Texture>;
    /**
     * Gets or sets the texture associated with the node
     */
    get texture(): Nullable<Texture>;
    set texture(texture: Nullable<Texture>);
    /**
     * Gets the sampler name associated with this image source
     */
    get samplerName(): string;
    /**
     * Creates a new ImageSourceBlock
     * @param name defines the block name
     */
    constructor(name: string);
    bind(effect: Effect, _nodeMaterial: NodeMaterial): void;
    isReady(): boolean;
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the output component
     */
    get source(): NodeMaterialConnectionPoint;
    /**
     * Gets the dimension component
     */
    get dimensions(): NodeMaterialConnectionPoint;
    protected _buildBlock(state: NodeMaterialBuildState): this;
    protected _dumpPropertiesCode(ignoreTexture?: boolean): string;
    serialize(ignoreTexture?: boolean): any;
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string, urlRewriter?: (url: string) => string): void;
}

/**
 * Enum defining the type of animations supported by InputBlock
 */
declare enum AnimatedInputBlockTypes {
    /** No animation */
    None = 0,
    /** Time based animation (is incremented by 0.6 each second). Will only work for floats */
    Time = 1,
    /** Time elapsed (in seconds) since the engine was initialized. Will only work for floats */
    RealTime = 2,
    MouseInfo = 3
}

/**
 * Block used to read from prepass textures
 */
declare class PrePassTextureBlock extends NodeMaterialBlock {
    private _positionSamplerName;
    private _localPositionSamplerName;
    private _depthSamplerName;
    private _screenSpaceDepthSamplerName;
    private _normalSamplerName;
    private _worldNormalSamplerName;
    /**
     * The texture associated with the node is the prepass texture
     */
    get texture(): any;
    set texture(value: any);
    /**
     * Creates a new PrePassTextureBlock
     * @param name defines the block name
     * @param target defines the target of that block (VertexAndFragment by default)
     */
    constructor(name: string, target?: NodeMaterialBlockTargets);
    /**
     * Returns the sampler name associated with the node connection point
     * @param output defines the connection point to get the associated sampler name
     * @returns
     */
    getSamplerName(output: NodeMaterialConnectionPoint): string;
    /**
     * Gets the position texture
     */
    get position(): NodeMaterialConnectionPoint;
    /**
     * Gets the local position texture
     */
    get localPosition(): NodeMaterialConnectionPoint;
    /**
     * Gets the depth texture
     */
    get depth(): NodeMaterialConnectionPoint;
    /**
     * Gets the screen depth texture
     */
    get screenDepth(): NodeMaterialConnectionPoint;
    /**
     * Gets the normal texture
     */
    get normal(): NodeMaterialConnectionPoint;
    /**
     * Gets the world normal texture
     */
    get worldNormal(): NodeMaterialConnectionPoint;
    /**
     * Gets the sampler name associated with this image source
     */
    get positionSamplerName(): string;
    /**
     * Gets the sampler name associated with this image source
     */
    get localPositionSamplerName(): string;
    /**
     * Gets the sampler name associated with this image source
     */
    get normalSamplerName(): string;
    /**
     * Gets the sampler name associated with this image source
     */
    get worldNormalSamplerName(): string;
    /**
     * Gets the sampler name associated with this image source
     */
    get depthSamplerName(): string;
    /**
     * Gets the sampler name associated with this image source
     */
    get linearDepthSamplerName(): string;
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    protected _buildBlock(state: NodeMaterialBuildState): this | undefined;
    bind(effect: Effect, nodeMaterial: NodeMaterial): void;
}

/**
 * Block used to implement the refraction part of the sub surface module of the PBR material
 */
declare class RefractionBlock extends NodeMaterialBlock {
    /** @internal */
    _define3DName: string;
    /** @internal */
    _refractionMatrixName: string;
    /** @internal */
    _defineLODRefractionAlpha: string;
    /** @internal */
    _defineLinearSpecularRefraction: string;
    /** @internal */
    _defineOppositeZ: string;
    /** @internal */
    _cubeSamplerName: string;
    /** @internal */
    _2DSamplerName: string;
    /** @internal */
    _vRefractionMicrosurfaceInfosName: string;
    /** @internal */
    _vRefractionInfosName: string;
    /** @internal */
    _vRefractionFilteringInfoName: string;
    private _scene;
    /**
     * The properties below are set by the main PBR block prior to calling methods of this class.
     * This is to avoid having to add them as inputs here whereas they are already inputs of the main block, so already known.
     * It's less burden on the user side in the editor part.
     */
    /** @internal */
    viewConnectionPoint: NodeMaterialConnectionPoint;
    /** @internal */
    indexOfRefractionConnectionPoint: NodeMaterialConnectionPoint;
    /**
     * This parameters will make the material used its opacity to control how much it is refracting against not.
     * Materials half opaque for instance using refraction could benefit from this control.
     */
    linkRefractionWithTransparency: boolean;
    /**
     * Controls if refraction needs to be inverted on Y. This could be useful for procedural texture.
     */
    invertRefractionY: boolean;
    /**
     * Controls if refraction needs to be inverted on Y. This could be useful for procedural texture.
     */
    useThicknessAsDepth: boolean;
    /**
     * Gets or sets the texture associated with the node
     */
    texture: Nullable<BaseTexture>;
    /**
     * Create a new RefractionBlock
     * @param name defines the block name
     */
    constructor(name: string);
    /**
     * Initialize the block and prepare the context for build
     * @param state defines the state that will be used for the build
     */
    initialize(state: NodeMaterialBuildState): void;
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the intensity input component
     */
    get intensity(): NodeMaterialConnectionPoint;
    /**
     * Gets the tint at distance input component
     */
    get tintAtDistance(): NodeMaterialConnectionPoint;
    /**
     * Gets the volume index of refraction input component
     */
    get volumeIndexOfRefraction(): NodeMaterialConnectionPoint;
    /**
     * Gets the view input component
     */
    get view(): NodeMaterialConnectionPoint;
    /**
     * Gets the refraction object output component
     */
    get refraction(): NodeMaterialConnectionPoint;
    /**
     * Returns true if the block has a texture
     */
    get hasTexture(): boolean;
    protected _getTexture(): Nullable<BaseTexture>;
    autoConfigure(material: NodeMaterial, additionalFilteringInfo?: (node: NodeMaterialBlock) => boolean): void;
    prepareDefines(defines: NodeMaterialDefines): void;
    isReady(): boolean;
    bind(effect: Effect, nodeMaterial: NodeMaterial, mesh?: Mesh): void;
    /**
     * Gets the main code of the block (fragment side)
     * @param state current state of the node material building
     * @returns the shader code
     */
    getCode(state: NodeMaterialBuildState): string;
    protected _buildBlock(state: NodeMaterialBuildState): this;
    protected _dumpPropertiesCode(): string;
    serialize(): any;
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string): void;
}

/**
 * Base block used for the particle texture
 */
declare class ParticleTextureBlock extends NodeMaterialBlock {
    private _samplerName;
    private _linearDefineName;
    private _gammaDefineName;
    private _tempTextureRead;
    /**
     * Gets or sets the texture associated with the node
     */
    texture: Nullable<BaseTexture>;
    /**
     * Gets or sets a boolean indicating if content needs to be converted to gamma space
     */
    convertToGammaSpace: boolean;
    /**
     * Gets or sets a boolean indicating if content needs to be converted to linear space
     */
    convertToLinearSpace: boolean;
    /**
     * Create a new ParticleTextureBlock
     * @param name defines the block name
     */
    constructor(name: string);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the uv input component
     */
    get uv(): NodeMaterialConnectionPoint;
    /**
     * Gets the rgba output component
     */
    get rgba(): NodeMaterialConnectionPoint;
    /**
     * Gets the rgb output component
     */
    get rgb(): NodeMaterialConnectionPoint;
    /**
     * Gets the r output component
     */
    get r(): NodeMaterialConnectionPoint;
    /**
     * Gets the g output component
     */
    get g(): NodeMaterialConnectionPoint;
    /**
     * Gets the b output component
     */
    get b(): NodeMaterialConnectionPoint;
    /**
     * Gets the a output component
     */
    get a(): NodeMaterialConnectionPoint;
    /**
     * Initialize the block and prepare the context for build
     * @param state defines the state that will be used for the build
     */
    initialize(state: NodeMaterialBuildState): void;
    autoConfigure(material: NodeMaterial, additionalFilteringInfo?: (node: NodeMaterialBlock) => boolean): void;
    prepareDefines(defines: NodeMaterialDefines): void;
    isReady(): boolean;
    private _writeOutput;
    protected _buildBlock(state: NodeMaterialBuildState): this | undefined;
    serialize(): any;
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string): void;
}

/**
 * Block used to read a texture with triplanar mapping (see "boxmap" in https://iquilezles.org/articles/biplanar/)
 */
declare class TriPlanarBlock extends NodeMaterialBlock {
    private _linearDefineName;
    private _gammaDefineName;
    protected _tempTextureRead: string;
    private _samplerName;
    private _textureInfoName;
    private _textureInfoName2;
    private _imageSource;
    /**
     * Project the texture(s) for a better fit to a cube
     */
    projectAsCube: boolean;
    protected _texture: Nullable<Texture>;
    /**
     * Gets or sets the texture associated with the node
     */
    get texture(): Nullable<Texture>;
    set texture(texture: Nullable<Texture>);
    /**
     * Gets the textureY associated with the node
     */
    get textureY(): Nullable<Texture>;
    /**
     * Gets the textureZ associated with the node
     */
    get textureZ(): Nullable<Texture>;
    protected _getImageSourceBlock(connectionPoint: Nullable<NodeMaterialConnectionPoint>): Nullable<ImageSourceBlock>;
    /**
     * Gets the sampler name associated with this texture
     */
    get samplerName(): string;
    /**
     * Gets the samplerY name associated with this texture
     */
    get samplerYName(): Nullable<string>;
    /**
     * Gets the samplerZ name associated with this texture
     */
    get samplerZName(): Nullable<string>;
    /**
     * Gets a boolean indicating that this block is linked to an ImageSourceBlock
     */
    get hasImageSource(): boolean;
    private _convertToGammaSpace;
    /**
     * Gets or sets a boolean indicating if content needs to be converted to gamma space
     */
    set convertToGammaSpace(value: boolean);
    get convertToGammaSpace(): boolean;
    private _convertToLinearSpace;
    /**
     * Gets or sets a boolean indicating if content needs to be converted to linear space
     */
    set convertToLinearSpace(value: boolean);
    get convertToLinearSpace(): boolean;
    /**
     * Gets or sets a boolean indicating if multiplication of texture with level should be disabled
     */
    disableLevelMultiplication: boolean;
    /**
     * Create a new TriPlanarBlock
     * @param name defines the block name
     * @param hideSourceZ defines a boolean indicating that normal Z should not be used (false by default)
     */
    constructor(name: string, hideSourceZ?: boolean);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets the position input component
     */
    get position(): NodeMaterialConnectionPoint;
    /**
     * Gets the normal input component
     */
    get normal(): NodeMaterialConnectionPoint;
    /**
     * Gets the sharpness input component
     */
    get sharpness(): NodeMaterialConnectionPoint;
    /**
     * Gets the source input component
     */
    get source(): NodeMaterialConnectionPoint;
    /**
     * Gets the sourceY input component
     */
    get sourceY(): NodeMaterialConnectionPoint;
    /**
     * Gets the sourceZ input component
     */
    get sourceZ(): Nullable<NodeMaterialConnectionPoint>;
    /**
     * Gets the rgba output component
     */
    get rgba(): NodeMaterialConnectionPoint;
    /**
     * Gets the rgb output component
     */
    get rgb(): NodeMaterialConnectionPoint;
    /**
     * Gets the r output component
     */
    get r(): NodeMaterialConnectionPoint;
    /**
     * Gets the g output component
     */
    get g(): NodeMaterialConnectionPoint;
    /**
     * Gets the b output component
     */
    get b(): NodeMaterialConnectionPoint;
    /**
     * Gets the a output component
     */
    get a(): NodeMaterialConnectionPoint;
    /**
     * Gets the level output component
     */
    get level(): NodeMaterialConnectionPoint;
    prepareDefines(defines: NodeMaterialDefines): void;
    isReady(): boolean;
    bind(effect: Effect): void;
    private _samplerFunc;
    private _generateTextureSample;
    protected _generateTextureLookup(state: NodeMaterialBuildState): void;
    private _generateConversionCode;
    private _writeOutput;
    protected _buildBlock(state: NodeMaterialBuildState): this;
    protected _dumpPropertiesCode(): string;
    serialize(): any;
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string): void;
}

/**
 * Block used to read a texture with triplanar mapping (see https://iquilezles.org/articles/biplanar/)
 */
declare class BiPlanarBlock extends TriPlanarBlock {
    /**
     * Create a new BiPlanarBlock
     * @param name defines the block name
     */
    constructor(name: string);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    private _declareLocalVarAsVec3I;
    private _getTextureGrad;
    protected _generateTextureLookup(state: NodeMaterialBuildState): void;
}

/**
 * Root class for all node material optimizers
 */
declare class NodeMaterialOptimizer {
    /**
     * Function used to optimize a NodeMaterial graph
     * @param _vertexOutputNodes defines the list of output nodes for the vertex shader
     * @param _fragmentOutputNodes defines the list of output nodes for the fragment shader
     */
    optimize(_vertexOutputNodes: NodeMaterialBlock[], _fragmentOutputNodes: NodeMaterialBlock[]): void;
}

/**
 * @internal
 */
declare class DecalMapDefines extends MaterialDefines {
    DECAL: boolean;
    DECALDIRECTUV: number;
    DECAL_SMOOTHALPHA: boolean;
    GAMMADECAL: boolean;
}
/**
 * Plugin that implements the decal map component of a material
 * @since 5.49.1
 */
declare class DecalMapConfiguration extends MaterialPluginBase {
    private _isEnabled;
    /**
     * Enables or disables the decal map on this material
     */
    isEnabled: boolean;
    private _smoothAlpha;
    /**
     * Enables or disables the smooth alpha mode on this material. Default: false.
     * When enabled, the alpha value used to blend the decal map will be the squared value and will produce a smoother result.
     */
    smoothAlpha: boolean;
    private _internalMarkAllSubMeshesAsTexturesDirty;
    /** @internal */
    _markAllSubMeshesAsTexturesDirty(): void;
    /**
     * Gets a boolean indicating that the plugin is compatible with a given shader language.
     * @returns true if the plugin is compatible with the shader language
     */
    isCompatible(): boolean;
    /**
     * Creates a new DecalMapConfiguration
     * @param material The material to attach the decal map plugin to
     * @param addToPluginList If the plugin should be added to the material plugin list
     */
    constructor(material: PBRBaseMaterial | StandardMaterial, addToPluginList?: boolean);
    isReadyForSubMesh(defines: DecalMapDefines, scene: Scene, engine: Engine, subMesh: SubMesh): boolean;
    prepareDefinesBeforeAttributes(defines: DecalMapDefines, scene: Scene, mesh: AbstractMesh): void;
    hardBindForSubMesh(uniformBuffer: UniformBuffer, scene: Scene, _engine: Engine, subMesh: SubMesh): void;
    getClassName(): string;
    getSamplers(samplers: string[]): void;
    getUniforms(): {
        ubo?: Array<{
            name: string;
            size: number;
            type: string;
        }>;
        vertex?: string;
        fragment?: string;
    };
}

declare module "./standardMaterial" {
    interface StandardMaterial {
        /** @internal */
        _decalMap: Nullable<DecalMapConfiguration>;
        /**
         * Defines the decal map parameters for the material.
         */
        decalMap: Nullable<DecalMapConfiguration>;
    }
}

declare module "./pbrBaseMaterial" {
    interface PBRBaseMaterial {
        /** @internal */
        _decalMap: Nullable<DecalMapConfiguration>;
        /**
         * Defines the decal map parameters for the material.
         */
        decalMap: Nullable<DecalMapConfiguration>;
    }
}

/**
 * Interface used to configure the node material editor
 */
interface INodeMaterialEditorOptions {
    /** Define the URL to load node editor script from */
    editorURL?: string;
    /** Additional configuration for the NME */
    nodeEditorConfig?: {
        backgroundColor?: Color4;
    };
}
declare const NodeMaterialDefinesBase_base: {
    new (...args: any[]): {
        MAINUV1: boolean;
        MAINUV2: boolean;
        MAINUV3: boolean;
        MAINUV4: boolean;
        MAINUV5: boolean;
        MAINUV6: boolean;
        UV1: boolean;
        UV2: boolean;
        UV3: boolean;
        UV4: boolean;
        UV5: boolean;
        UV6: boolean;
    };
} & typeof MaterialDefines;
declare class NodeMaterialDefinesBase extends NodeMaterialDefinesBase_base {
}
declare const NodeMaterialDefines_base: {
    new (...args: any[]): {
        IMAGEPROCESSING: boolean;
        VIGNETTE: boolean;
        VIGNETTEBLENDMODEMULTIPLY: boolean;
        VIGNETTEBLENDMODEOPAQUE: boolean;
        TONEMAPPING: number;
        CONTRAST: boolean;
        COLORCURVES: boolean;
        COLORGRADING: boolean;
        COLORGRADING3D: boolean;
        SAMPLER3DGREENDEPTH: boolean;
        SAMPLER3DBGRMAP: boolean;
        DITHER: boolean;
        IMAGEPROCESSINGPOSTPROCESS: boolean;
        SKIPFINALCOLORCLAMP: boolean;
        EXPOSURE: boolean;
    };
} & typeof NodeMaterialDefinesBase;
/** @internal */
declare class NodeMaterialDefines extends NodeMaterialDefines_base {
    /** Normal */
    NORMAL: boolean;
    /** Tangent */
    TANGENT: boolean;
    /** Vertex color */
    VERTEXCOLOR_NME: boolean;
    /** Prepass **/
    PREPASS: boolean;
    /** Prepass normal */
    PREPASS_NORMAL: boolean;
    /** Prepass normal index */
    PREPASS_NORMAL_INDEX: number;
    /** Prepass world normal */
    PREPASS_WORLD_NORMAL: boolean;
    /** Prepass world normal index */
    PREPASS_WORLD_NORMAL_INDEX: number;
    /** Prepass position */
    PREPASS_POSITION: boolean;
    /** Prepass position index */
    PREPASS_POSITION_INDEX: number;
    /** Prepass local position */
    PREPASS_LOCAL_POSITION: boolean;
    /** Prepass local position index */
    PREPASS_LOCAL_POSITION_INDEX: number;
    /** Prepass depth */
    PREPASS_DEPTH: boolean;
    /** Prepass depth index */
    PREPASS_DEPTH_INDEX: number;
    /** Clip-space depth */
    PREPASS_SCREENSPACE_DEPTH: boolean;
    /** Clip-space depth index */
    PREPASS_SCREENSPACE_DEPTH_INDEX: number;
    /** Scene MRT count */
    SCENE_MRT_COUNT: number;
    /** BONES */
    NUM_BONE_INFLUENCERS: number;
    /** Bones per mesh */
    BonesPerMesh: number;
    /** Using texture for bone storage */
    BONETEXTURE: boolean;
    /** MORPH TARGETS */
    MORPHTARGETS: boolean;
    /** Morph target position */
    MORPHTARGETS_POSITION: boolean;
    /** Morph target normal */
    MORPHTARGETS_NORMAL: boolean;
    /** Morph target tangent */
    MORPHTARGETS_TANGENT: boolean;
    /** Morph target uv */
    MORPHTARGETS_UV: boolean;
    /** Morph target uv2 */
    MORPHTARGETS_UV2: boolean;
    MORPHTARGETS_COLOR: boolean;
    /** Morph target support positions */
    MORPHTARGETTEXTURE_HASPOSITIONS: boolean;
    /** Morph target support normals */
    MORPHTARGETTEXTURE_HASNORMALS: boolean;
    /** Morph target support tangents */
    MORPHTARGETTEXTURE_HASTANGENTS: boolean;
    /** Morph target support uvs */
    MORPHTARGETTEXTURE_HASUVS: boolean;
    /** Morph target support uv2s */
    MORPHTARGETTEXTURE_HASUV2S: boolean;
    MORPHTARGETTEXTURE_HASCOLORS: boolean;
    /** Number of morph influencers */
    NUM_MORPH_INFLUENCERS: number;
    /** Using a texture to store morph target data */
    MORPHTARGETS_TEXTURE: boolean;
    /** MISC. */
    BUMPDIRECTUV: number;
    /** Camera is orthographic */
    CAMERA_ORTHOGRAPHIC: boolean;
    /** Camera is perspective */
    CAMERA_PERSPECTIVE: boolean;
    AREALIGHTSUPPORTED: boolean;
    AREALIGHTNOROUGHTNESS: boolean;
    POSITIONW_AS_VARYING: boolean;
    /**
     * Creates a new NodeMaterialDefines
     */
    constructor();
    /**
     * Set the value of a specific key
     * @param name defines the name of the key to set
     * @param value defines the value to set
     * @param markAsUnprocessedIfDirty Flag to indicate to the cache that this value needs processing
     */
    setValue(name: string, value: any, markAsUnprocessedIfDirty?: boolean): void;
}
/**
 * Class used to configure NodeMaterial
 */
interface INodeMaterialOptions {
    /**
     * Defines if blocks should emit comments
     */
    emitComments: boolean;
    /** Defines shader language to use (default to GLSL) */
    shaderLanguage: ShaderLanguage;
}
/**
 * Blocks that manage a texture
 */
type NodeMaterialTextureBlocks = TextureBlock | ReflectionTextureBaseBlock | RefractionBlock | CurrentScreenBlock | ParticleTextureBlock | ImageSourceBlock | TriPlanarBlock | BiPlanarBlock | PrePassTextureBlock;
declare const NodeMaterialBase_base: {
    new (...args: any[]): {
        _imageProcessingConfiguration: ImageProcessingConfiguration;
        get imageProcessingConfiguration(): ImageProcessingConfiguration;
        set imageProcessingConfiguration(value: ImageProcessingConfiguration);
        _imageProcessingObserver: Nullable<Observer<ImageProcessingConfiguration>>;
        _attachImageProcessingConfiguration(configuration: Nullable<ImageProcessingConfiguration>): void;
        get cameraColorCurvesEnabled(): boolean;
        set cameraColorCurvesEnabled(value: boolean);
        get cameraColorGradingEnabled(): boolean;
        set cameraColorGradingEnabled(value: boolean);
        get cameraToneMappingEnabled(): boolean;
        set cameraToneMappingEnabled(value: boolean);
        get cameraExposure(): number;
        set cameraExposure(value: number);
        get cameraContrast(): number;
        set cameraContrast(value: number);
        get cameraColorGradingTexture(): Nullable<BaseTexture>;
        set cameraColorGradingTexture(value: Nullable<BaseTexture>);
        get cameraColorCurves(): Nullable<ColorCurves>;
        set cameraColorCurves(value: Nullable<ColorCurves>);
    };
} & typeof PushMaterial;
declare class NodeMaterialBase extends NodeMaterialBase_base {
}
/**
 * Class used to create a node based material built by assembling shader blocks
 */
declare class NodeMaterial extends NodeMaterialBase {
    private static _BuildIdGenerator;
    private _options;
    private _vertexCompilationState;
    private _fragmentCompilationState;
    private _sharedData;
    private _buildId;
    private _buildWasSuccessful;
    private _cachedWorldViewMatrix;
    private _cachedWorldViewProjectionMatrix;
    private _optimizers;
    private _animationFrame;
    private _buildIsInProgress;
    /** Define the Url to load node editor script */
    static EditorURL: string;
    /** Define the Url to load snippets */
    static SnippetUrl: string;
    /** Gets or sets a boolean indicating that node materials should not deserialize textures from json / snippet content */
    static IgnoreTexturesAtLoadTime: boolean;
    /** Gets or sets a boolean indicating that render target textures can be serialized */
    static AllowSerializationOfRenderTargetTextures: boolean;
    /** Defines default shader language when no option is defined */
    static DefaultShaderLanguage: ShaderLanguage;
    /** If true, the node material will use GLSL if the engine is WebGL and WGSL if it's WebGPU. It takes priority over DefaultShaderLanguage if it's true */
    static UseNativeShaderLanguageOfEngine: boolean;
    /**
     * Checks if a block is a texture block
     * @param block The block to check
     * @returns True if the block is a texture block
     */
    static _BlockIsTextureBlock(block: NodeMaterialBlock): block is NodeMaterialTextureBlocks;
    private BJSNODEMATERIALEDITOR;
    /** Gets whether the node material is currently building */
    get buildIsInProgress(): boolean;
    /** @internal */
    _useAdditionalColor: boolean;
    set _glowModeEnabled(value: boolean);
    /** Get the inspector from bundle or global
     * @returns the global NME
     */
    private _getGlobalNodeMaterialEditor;
    /** Gets or sets the active shader language */
    get shaderLanguage(): ShaderLanguage;
    set shaderLanguage(value: ShaderLanguage);
    /**
     * Snippet ID if the material was created from the snippet server
     */
    snippetId: string;
    /**
     * Gets or sets data used by visual editor
     * @see https://nme.babylonjs.com
     */
    editorData: any;
    /**
     * Gets or sets a boolean indicating that alpha value must be ignored (This will turn alpha blending off even if an alpha value is produced by the material)
     */
    ignoreAlpha: boolean;
    /**
     * Defines the maximum number of lights that can be used in the material
     */
    maxSimultaneousLights: number;
    /**
     * Observable raised when the material is built
     */
    onBuildObservable: Observable<NodeMaterial>;
    /**
     * Observable raised when an error is detected
     */
    onBuildErrorObservable: Observable<string>;
    /**
     * Gets or sets the root nodes of the material vertex shader
     */
    _vertexOutputNodes: NodeMaterialBlock[];
    /**
     * Gets or sets the root nodes of the material fragment (pixel) shader
     */
    _fragmentOutputNodes: NodeMaterialBlock[];
    /** Gets or sets options to control the node material overall behavior */
    get options(): INodeMaterialOptions;
    set options(options: INodeMaterialOptions);
    /**
     * Gets an array of blocks that needs to be serialized even if they are not yet connected
     */
    attachedBlocks: NodeMaterialBlock[];
    /**
     * Specifies the mode of the node material
     * @internal
     */
    _mode: NodeMaterialModes;
    /**
     * Gets or sets the mode property
     */
    get mode(): NodeMaterialModes;
    set mode(value: NodeMaterialModes);
    /** Gets or sets the unique identifier used to identified the effect associated with the material */
    get buildId(): number;
    set buildId(value: number);
    /**
     * A free comment about the material
     */
    comment: string;
    /**
     * Create a new node based material
     * @param name defines the material name
     * @param scene defines the hosting scene
     * @param options defines creation option
     */
    constructor(name: string, scene?: Scene, options?: Partial<INodeMaterialOptions>);
    /**
     * Gets the current class name of the material e.g. "NodeMaterial"
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Get a block by its name
     * @param name defines the name of the block to retrieve
     * @returns the required block or null if not found
     */
    getBlockByName(name: string): NodeMaterialBlock | null;
    /**
     * Get a block using a predicate
     * @param predicate defines the predicate used to find the good candidate
     * @returns the required block or null if not found
     */
    getBlockByPredicate(predicate: (block: NodeMaterialBlock) => boolean): NodeMaterialBlock | null;
    /**
     * Get an input block using a predicate
     * @param predicate defines the predicate used to find the good candidate
     * @returns the required input block or null if not found
     */
    getInputBlockByPredicate(predicate: (block: InputBlock) => boolean): Nullable<InputBlock>;
    /**
     * Gets the list of input blocks attached to this material
     * @returns an array of InputBlocks
     */
    getInputBlocks(): InputBlock[];
    /**
     * Adds a new optimizer to the list of optimizers
     * @param optimizer defines the optimizers to add
     * @returns the current material
     */
    registerOptimizer(optimizer: NodeMaterialOptimizer): this | undefined;
    /**
     * Remove an optimizer from the list of optimizers
     * @param optimizer defines the optimizers to remove
     * @returns the current material
     */
    unregisterOptimizer(optimizer: NodeMaterialOptimizer): this | undefined;
    /**
     * Add a new block to the list of output nodes
     * @param node defines the node to add
     * @returns the current material
     */
    addOutputNode(node: NodeMaterialBlock): this;
    /**
     * Remove a block from the list of root nodes
     * @param node defines the node to remove
     * @returns the current material
     */
    removeOutputNode(node: NodeMaterialBlock): this;
    private _addVertexOutputNode;
    private _removeVertexOutputNode;
    private _addFragmentOutputNode;
    private _removeFragmentOutputNode;
    /**
     * Gets or sets a boolean indicating that alpha blending must be enabled no matter what alpha value or alpha channel of the FragmentBlock are
     */
    forceAlphaBlending: boolean;
    get _supportGlowLayer(): boolean;
    /**
     * Specifies if the material will require alpha blending
     * @returns a boolean specifying if alpha blending is needed
     */
    needAlphaBlending(): boolean;
    /**
     * Specifies if this material should be rendered in alpha test mode
     * @returns a boolean specifying if an alpha test is needed.
     */
    needAlphaTesting(): boolean;
    private _processInitializeOnLink;
    private _attachBlock;
    private _initializeBlock;
    private _resetDualBlocks;
    /**
     * Remove a block from the current node material
     * @param block defines the block to remove
     */
    removeBlock(block: NodeMaterialBlock): void;
    /**
     * Build the material and generates the inner effect
     * @param verbose defines if the build should log activity
     * @param updateBuildId defines if the internal build Id should be updated (default is true)
     * @param autoConfigure defines if the autoConfigure method should be called when initializing blocks (default is false)
     */
    build(verbose?: boolean, updateBuildId?: boolean, autoConfigure?: boolean): void;
    private _finishBuildProcess;
    /**
     * Runs an optimization phase to try to improve the shader code
     */
    optimize(): void;
    private _prepareDefinesForAttributes;
    /**
     * Can this material render to prepass
     */
    get isPrePassCapable(): boolean;
    /**
     * Outputs written to the prepass
     */
    get prePassTextureOutputs(): number[];
    /**
     * Gets the list of prepass texture required
     */
    get prePassTextureInputs(): number[];
    /**
     * Sets the required values to the prepass renderer.
     * @param prePassRenderer defines the prepass renderer to set
     * @returns true if the pre pass is needed
     */
    setPrePassRenderer(prePassRenderer: PrePassRenderer): boolean;
    /**
     * Create a post process from the material
     * @param camera The camera to apply the render pass to.
     * @param options The required width/height ratio to downsize to before computing the render pass. (Use 1.0 for full size)
     * @param samplingMode The sampling mode to be used when computing the pass. (default: 0)
     * @param engine The engine which the post process will be applied. (default: current engine)
     * @param reusable If the post process can be reused on the same frame. (default: false)
     * @param textureType Type of textures used when performing the post process. (default: 0)
     * @param textureFormat Format of textures used when performing the post process. (default: TEXTUREFORMAT_RGBA)
     * @returns the post process created
     */
    createPostProcess(camera: Nullable<Camera>, options?: number | PostProcessOptions, samplingMode?: number, engine?: AbstractEngine, reusable?: boolean, textureType?: number, textureFormat?: number): Nullable<PostProcess>;
    /**
     * Create the post process effect from the material
     * @param postProcess The post process to create the effect for
     */
    createEffectForPostProcess(postProcess: PostProcess): void;
    private _createEffectForPostProcess;
    /**
     * Create a new procedural texture based on this node material
     * @param size defines the size of the texture
     * @param scene defines the hosting scene
     * @returns the new procedural texture attached to this node material
     */
    createProceduralTexture(size: number | {
        width: number;
        height: number;
        layers?: number;
    }, scene: Scene): Nullable<ProceduralTexture>;
    private _createEffectForParticles;
    private _checkInternals;
    /**
     * Create the effect to be used as the custom effect for a particle system
     * @param particleSystem Particle system to create the effect for
     * @param onCompiled defines a function to call when the effect creation is successful
     * @param onError defines a function to call when the effect creation has failed
     */
    createEffectForParticles(particleSystem: IParticleSystem, onCompiled?: (effect: Effect) => void, onError?: (effect: Effect, errors: string) => void): void;
    /**
     * Use this material as the shadow depth wrapper of a target material
     * @param targetMaterial defines the target material
     */
    createAsShadowDepthWrapper(targetMaterial: Material): void;
    private _processDefines;
    /**
     * Get if the submesh is ready to be used and all its information available.
     * Child classes can use it to update shaders
     * @param mesh defines the mesh to check
     * @param subMesh defines which submesh to check
     * @param useInstances specifies that instances should be used
     * @returns a boolean indicating that the submesh is ready or not
     */
    isReadyForSubMesh(mesh: AbstractMesh, subMesh: SubMesh, useInstances?: boolean): boolean;
    /**
     * Get a string representing the shaders built by the current node graph
     */
    get compiledShaders(): string;
    /**
     * Get a string representing the fragment shader used by the engine for the current node graph
     * @internal
     */
    _getProcessedFragmentAsync(): Promise<string>;
    /**
     * Binds the world matrix to the material
     * @param world defines the world transformation matrix
     */
    bindOnlyWorldMatrix(world: Matrix): void;
    /**
     * Binds the submesh to this material by preparing the effect and shader to draw
     * @param world defines the world transformation matrix
     * @param mesh defines the mesh containing the submesh
     * @param subMesh defines the submesh to bind the material to
     */
    bindForSubMesh(world: Matrix, mesh: Mesh, subMesh: SubMesh): void;
    /**
     * Gets the active textures from the material
     * @returns an array of textures
     */
    getActiveTextures(): BaseTexture[];
    /**
     * Gets the list of texture blocks
     * Note that this method will only return blocks that are reachable from the final block(s) and only after the material has been built!
     * @returns an array of texture blocks
     */
    getTextureBlocks(): NodeMaterialTextureBlocks[];
    /**
     * Gets the list of all texture blocks
     * Note that this method will scan all attachedBlocks and return blocks that are texture blocks
     * @returns
     */
    getAllTextureBlocks(): NodeMaterialTextureBlocks[];
    /**
     * Specifies if the material uses a texture
     * @param texture defines the texture to check against the material
     * @returns a boolean specifying if the material uses the texture
     */
    hasTexture(texture: BaseTexture): boolean;
    /**
     * Disposes the material
     * @param forceDisposeEffect specifies if effects should be forcefully disposed
     * @param forceDisposeTextures specifies if textures should be forcefully disposed
     * @param notBoundToMesh specifies if the material that is being disposed is known to be not bound to any mesh
     */
    dispose(forceDisposeEffect?: boolean, forceDisposeTextures?: boolean, notBoundToMesh?: boolean): void;
    /** Creates the node editor window.
     * @param additionalConfig Define the configuration of the editor
     */
    private _createNodeEditor;
    /**
     * Launch the node material editor
     * @param config Define the configuration of the editor
     * @returns a promise fulfilled when the node editor is visible
     */
    edit(config?: INodeMaterialEditorOptions): Promise<void>;
    /**
     * Clear the current material
     */
    clear(): void;
    /**
     * Clear the current material and set it to a default state
     */
    setToDefault(): void;
    /**
     * Clear the current material and set it to a default state for post process
     */
    setToDefaultPostProcess(): void;
    /**
     * Clear the current material and set it to a default state for procedural texture
     */
    setToDefaultProceduralTexture(): void;
    /**
     * Clear the current material and set it to a default state for particle
     */
    setToDefaultParticle(): void;
    /**
     * Loads the current Node Material from a url pointing to a file save by the Node Material Editor
     * @deprecated Please use NodeMaterial.ParseFromFileAsync instead
     * @param url defines the url to load from
     * @param rootUrl defines the root URL for nested url in the node material
     * @returns a promise that will fulfil when the material is fully loaded
     */
    loadAsync(url: string, rootUrl?: string): Promise<NodeMaterial>;
    private _gatherBlocks;
    /**
     * Generate a string containing the code declaration required to create an equivalent of this material
     * @returns a string
     */
    generateCode(): string;
    /**
     * Serializes this material in a JSON representation
     * @param selectedBlocks defines an optional list of blocks to serialize
     * @returns the serialized material object
     */
    serialize(selectedBlocks?: NodeMaterialBlock[]): any;
    private _restoreConnections;
    /**
     * Clear the current graph and load a new one from a serialization object
     * @param source defines the JSON representation of the material
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @param merge defines whether or not the source must be merged or replace the current content
     * @param urlRewriter defines a function used to rewrite urls
     */
    parseSerializedObject(source: any, rootUrl?: string, merge?: boolean, urlRewriter?: (url: string) => string): void;
    /**
     * Clear the current graph and load a new one from a serialization object
     * @param source defines the JSON representation of the material
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @param merge defines whether or not the source must be merged or replace the current content
     * @deprecated Please use the parseSerializedObject method instead
     */
    loadFromSerialization(source: any, rootUrl?: string, merge?: boolean): void;
    /**
     * Makes a duplicate of the current material.
     * @param name defines the name to use for the new material
     * @param shareEffect defines if the clone material should share the same effect (default is false)
     * @returns the cloned material
     */
    clone(name: string, shareEffect?: boolean): NodeMaterial;
    /**
     * Awaits for all the material textures to be ready before resolving the returned promise.
     * @returns A promise that resolves when the textures are ready.
     */
    whenTexturesReadyAsync(): Promise<void[]>;
    /**
     * Creates a node material from parsed material data
     * @param source defines the JSON representation of the material
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @param shaderLanguage defines the language to use (GLSL by default)
     * @returns a new node material
     */
    static Parse(source: any, scene: Scene, rootUrl?: string, shaderLanguage?: ShaderLanguage): NodeMaterial;
    /**
     * Creates a node material from a snippet saved in a remote file
     * @param name defines the name of the material to create
     * @param url defines the url to load from
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL for nested url in the node material
     * @param skipBuild defines whether to build the node material
     * @param targetMaterial defines a material to use instead of creating a new one
     * @param urlRewriter defines a function used to rewrite urls
     * @param options defines options to be used with the node material
     * @returns a promise that will resolve to the new node material
     */
    static ParseFromFileAsync(name: string, url: string, scene: Scene, rootUrl?: string, skipBuild?: boolean, targetMaterial?: NodeMaterial, urlRewriter?: (url: string) => string, options?: Partial<INodeMaterialOptions>): Promise<NodeMaterial>;
    /**
     * Creates a node material from a snippet saved by the node material editor
     * @param snippetId defines the snippet to load
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @param nodeMaterial defines a node material to update (instead of creating a new one)
     * @param skipBuild defines whether to build the node material
     * @param waitForTextureReadyness defines whether to wait for texture readiness resolving the promise (default: false)
     * @param urlRewriter defines a function used to rewrite urls
     * @param options defines options to be used with the node material
     * @returns a promise that will resolve to the new node material
     */
    static ParseFromSnippetAsync(snippetId: string, scene?: Scene, rootUrl?: string, nodeMaterial?: NodeMaterial, skipBuild?: boolean, waitForTextureReadyness?: boolean, urlRewriter?: (url: string) => string, options?: Partial<INodeMaterialOptions>): Promise<NodeMaterial>;
    /**
     * Creates a new node material set to default basic configuration
     * @param name defines the name of the material
     * @param scene defines the hosting scene
     * @returns a new NodeMaterial
     */
    static CreateDefault(name: string, scene?: Scene): NodeMaterial;
}

declare module "../Engines/abstractEngine" {
    interface AbstractEngine {
        /**
         * Sets a texture to the context from a postprocess
         * @param channel defines the channel to use
         * @param postProcess defines the source postprocess
         * @param name name of the channel
         */
        setTextureFromPostProcess(channel: number, postProcess: Nullable<PostProcess>, name: string): void;
        /**
         * Binds the output of the passed in post process to the texture channel specified
         * @param channel The channel the texture should be bound to
         * @param postProcess The post process which's output should be bound
         * @param name name of the channel
         */
        setTextureFromPostProcessOutput(channel: number, postProcess: Nullable<PostProcess>, name: string): void;
    }
}
declare module "../Materials/effect" {
    interface Effect {
        /**
         * Sets a texture to be the input of the specified post process. (To use the output, pass in the next post process in the pipeline)
         * @param channel Name of the sampler variable.
         * @param postProcess Post process to get the input texture from.
         */
        setTextureFromPostProcess(channel: string, postProcess: Nullable<PostProcess>): void;
        /**
         * (Warning! setTextureFromPostProcessOutput may be desired instead)
         * Sets the input texture of the passed in post process to be input of this effect. (To use the output of the passed in post process use setTextureFromPostProcessOutput)
         * @param channel Name of the sampler variable.
         * @param postProcess Post process to get the output texture from.
         */
        setTextureFromPostProcessOutput(channel: string, postProcess: Nullable<PostProcess>): void;
    }
}
/**
 * Options for the PostProcess constructor
 */
type PostProcessOptions = EffectWrapperCreationOptions & {
    /**
     * The width of the texture created for this post process.
     * This parameter (and height) is only used when passing a value for the 5th parameter (options) to the PostProcess constructor function.
     * If you use a PostProcessOptions for the 3rd parameter of the constructor, size is used instead of width and height.
     */
    width?: number;
    /**
     * The height of the texture created for this post process.
     * This parameter (and width) is only used when passing a value for the 5th parameter (options) to the PostProcess constructor function.
     * If you use a PostProcessOptions for the 3rd parameter of the constructor, size is used instead of width and height.
     */
    height?: number;
    /**
     * The size of the post process texture.
     * It is either a ratio to downscale or upscale the texture create for this post process, or an object containing width and height values.
     * Default: 1
     */
    size?: number | {
        width: number;
        height: number;
    };
    /**
     * The camera that the post process will be attached to (default: null)
     */
    camera?: Nullable<Camera>;
    /**
     * The sampling mode to be used by the shader (default: Constants.TEXTURE_NEAREST_SAMPLINGMODE)
     */
    samplingMode?: number;
    /**
     * The engine to be used to render the post process (default: engine from scene)
     */
    engine?: AbstractEngine;
    /**
     * If the post process can be reused on the same frame. (default: false)
     */
    reusable?: boolean;
    /**
     * Type of the texture created for this post process (default: Constants.TEXTURETYPE_UNSIGNED_BYTE)
     */
    textureType?: number;
    /**
     * Format of the texture created for this post process (default: TEXTUREFORMAT_RGBA)
     */
    textureFormat?: number;
    /**
     * The effect wrapper instance used by the post process. If not provided, a new one will be created.
     */
    effectWrapper?: EffectWrapper;
};
/**
 * PostProcess can be used to apply a shader to a texture after it has been rendered
 * See https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/usePostProcesses
 */
declare class PostProcess {
    /**
     * Force all the postprocesses to compile to glsl even on WebGPU engines.
     * False by default. This is mostly meant for backward compatibility.
     */
    static get ForceGLSL(): boolean;
    static set ForceGLSL(force: boolean);
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /**
     * Registers a shader code processing with a post process name.
     * @param postProcessName name of the post process. Use null for the fallback shader code processing. This is the shader code processing that will be used in case no specific shader code processing has been associated to a post process name
     * @param customShaderCodeProcessing shader code processing to associate to the post process name
     */
    static RegisterShaderCodeProcessing(postProcessName: Nullable<string>, customShaderCodeProcessing?: EffectWrapperCustomShaderCodeProcessing): void;
    /**
     * Gets or sets the unique id of the post process
     */
    uniqueId: number;
    /** Name of the PostProcess. */
    get name(): string;
    set name(value: string);
    /**
     * Width of the texture to apply the post process on
     */
    width: number;
    /**
     * Height of the texture to apply the post process on
     */
    height: number;
    /**
     * Gets the node material used to create this postprocess (null if the postprocess was manually created)
     */
    nodeMaterialSource: Nullable<NodeMaterial>;
    /**
     * Internal, reference to the location where this postprocess was output to. (Typically the texture on the next postprocess in the chain)
     * @internal
     */
    _outputTexture: Nullable<RenderTargetWrapper>;
    /**
     * Sampling mode used by the shader
     */
    renderTargetSamplingMode: number;
    /**
     * Clear color to use when screen clearing
     */
    clearColor: Color4;
    /**
     * If the buffer needs to be cleared before applying the post process. (default: true)
     * Should be set to false if shader will overwrite all previous pixels.
     */
    autoClear: boolean;
    /**
     * If clearing the buffer should be forced in autoClear mode, even when alpha mode is enabled (default: false).
     * By default, the buffer will only be cleared if alpha mode is disabled (and autoClear is true).
     */
    forceAutoClearInAlphaMode: boolean;
    /**
     * Type of alpha mode to use when performing the post process (default: Engine.ALPHA_DISABLE)
     */
    get alphaMode(): number;
    set alphaMode(value: number);
    /**
     * Sets the setAlphaBlendConstants of the babylon engine
     */
    alphaConstants: Color4;
    /**
     * Animations to be used for the post processing
     */
    animations: Animation[];
    /**
     * Enable Pixel Perfect mode where texture is not scaled to be power of 2.
     * Can only be used on a single postprocess or on the last one of a chain. (default: false)
     */
    enablePixelPerfectMode: boolean;
    /**
     * Force the postprocess to be applied without taking in account viewport
     */
    forceFullscreenViewport: boolean;
    /**
     * List of inspectable custom properties (used by the Inspector)
     * @see https://doc.babylonjs.com/toolsAndResources/inspector#extensibility
     */
    inspectableCustomProperties: IInspectable[];
    /**
     * Scale mode for the post process (default: Engine.SCALEMODE_FLOOR)
     *
     * | Value | Type                                | Description |
     * | ----- | ----------------------------------- | ----------- |
     * | 1     | SCALEMODE_FLOOR                     | [engine.scalemode_floor](https://doc.babylonjs.com/api/classes/babylon.engine#scalemode_floor) |
     * | 2     | SCALEMODE_NEAREST                   | [engine.scalemode_nearest](https://doc.babylonjs.com/api/classes/babylon.engine#scalemode_nearest) |
     * | 3     | SCALEMODE_CEILING                   | [engine.scalemode_ceiling](https://doc.babylonjs.com/api/classes/babylon.engine#scalemode_ceiling) |
     *
     */
    scaleMode: number;
    /**
     * Force textures to be a power of two (default: false)
     */
    alwaysForcePOT: boolean;
    private _samples;
    /**
     * Number of sample textures (default: 1)
     */
    get samples(): number;
    set samples(n: number);
    /**
     * Modify the scale of the post process to be the same as the viewport (default: false)
     */
    adaptScaleToCurrentViewport: boolean;
    /**
     * Specifies if the post process should be serialized
     */
    doNotSerialize: boolean;
    private _camera;
    protected _scene: Scene;
    private _engine;
    protected _webGPUReady: boolean;
    private _options;
    private _reusable;
    private _renderId;
    private _textureType;
    private _textureFormat;
    /** @internal */
    private _shaderLanguage;
    /**
     * Gets the shader language type used to generate vertex and fragment source code.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * if externalTextureSamplerBinding is true, the "apply" method won't bind the textureSampler texture, it is expected to be done by the "outside" (by the onApplyObservable observer most probably).
     * counter-productive in some cases because if the texture bound by "apply" is different from the currently texture bound, (the one set by the onApplyObservable observer, for eg) some
     * internal structures (materialContext) will be dirtified, which may impact performances
     */
    externalTextureSamplerBinding: boolean;
    /**
     * Smart array of input and output textures for the post process.
     * @internal
     */
    _textures: SmartArray<RenderTargetWrapper>;
    /**
     * Smart array of input and output textures for the post process.
     * @internal
     */
    private _textureCache;
    /**
     * The index in _textures that corresponds to the output texture.
     * @internal
     */
    _currentRenderTextureInd: number;
    private _samplers;
    private _fragmentUrl;
    private _vertexUrl;
    private _parameters;
    private _uniformBuffers;
    protected _postProcessDefines: Nullable<string>;
    private _scaleRatio;
    protected _indexParameters: any;
    private _shareOutputWithPostProcess;
    private _texelSize;
    /** @internal */
    _forcedOutputTexture: Nullable<RenderTargetWrapper>;
    /**
     * Prepass configuration in case this post process needs a texture from prepass
     * @internal
     */
    _prePassEffectConfiguration: PrePassEffectConfiguration;
    /**
     * Returns the fragment url or shader name used in the post process.
     * @returns the fragment url or name in the shader store.
     */
    getEffectName(): string;
    /**
     * Executed when the effect was created
     * @returns effect that was created for this post process
     */
    onEffectCreatedObservable: Observable<Effect>;
    /**
     * An event triggered when the postprocess is activated.
     */
    onActivateObservable: Observable<Camera>;
    private _onActivateObserver;
    /**
     * A function that is added to the onActivateObservable
     */
    set onActivate(callback: Nullable<(camera: Camera) => void>);
    /**
     * An event triggered when the postprocess changes its size.
     */
    onSizeChangedObservable: Observable<PostProcess>;
    private _onSizeChangedObserver;
    /**
     * A function that is added to the onSizeChangedObservable
     */
    set onSizeChanged(callback: (postProcess: PostProcess) => void);
    /**
     * An event triggered when the postprocess applies its effect.
     */
    onApplyObservable: Observable<Effect>;
    private _onApplyObserver;
    /**
     * A function that is added to the onApplyObservable
     */
    set onApply(callback: (effect: Effect) => void);
    /**
     * An event triggered before rendering the postprocess
     */
    onBeforeRenderObservable: Observable<Effect>;
    private _onBeforeRenderObserver;
    /**
     * A function that is added to the onBeforeRenderObservable
     */
    set onBeforeRender(callback: (effect: Effect) => void);
    /**
     * An event triggered after rendering the postprocess
     */
    onAfterRenderObservable: Observable<Effect>;
    private _onAfterRenderObserver;
    /**
     * A function that is added to the onAfterRenderObservable
     */
    set onAfterRender(callback: (efect: Effect) => void);
    /**
     * An event triggered when the post-process is disposed
     */
    readonly onDisposeObservable: Observable<void>;
    /**
     * The input texture for this post process and the output texture of the previous post process. When added to a pipeline the previous post process will
     * render it's output into this texture and this texture will be used as textureSampler in the fragment shader of this post process.
     */
    get inputTexture(): RenderTargetWrapper;
    set inputTexture(value: RenderTargetWrapper);
    /**
     * Since inputTexture should always be defined, if we previously manually set `inputTexture`,
     * the only way to unset it is to use this function to restore its internal state
     */
    restoreDefaultInputTexture(): void;
    /**
     * Gets the camera which post process is applied to.
     * @returns The camera the post process is applied to.
     */
    getCamera(): Camera;
    /**
     * Gets the texel size of the postprocess.
     * See https://en.wikipedia.org/wiki/Texel_(graphics)
     */
    get texelSize(): Vector2;
    protected readonly _effectWrapper: EffectWrapper;
    protected readonly _useExistingThinPostProcess: boolean;
    /**
     * Creates a new instance PostProcess
     * @param name The name of the PostProcess.
     * @param fragmentUrl The url of the fragment shader to be used.
     * @param options The options to be used when constructing the post process.
     */
    constructor(name: string, fragmentUrl: string, options?: PostProcessOptions);
    /**
     * Creates a new instance PostProcess
     * @param name The name of the PostProcess.
     * @param fragmentUrl The url of the fragment shader to be used.
     * @param parameters Array of the names of uniform non-sampler2D variables that will be passed to the shader.
     * @param samplers Array of the names of uniform sampler2D variables that will be passed to the shader.
     * @param options The required width/height ratio to downsize to before computing the render pass. (Use 1.0 for full size)
     * @param camera The camera to apply the render pass to.
     * @param samplingMode The sampling mode to be used when computing the pass. (default: 0)
     * @param engine The engine which the post process will be applied. (default: current engine)
     * @param reusable If the post process can be reused on the same frame. (default: false)
     * @param defines String of defines that will be set when running the fragment shader. (default: null)
     * @param textureType Type of textures used when performing the post process. (default: 0)
     * @param vertexUrl The url of the vertex shader to be used. (default: "postprocess")
     * @param indexParameters The index parameters to be used for babylons include syntax "#include<kernelBlurVaryingDeclaration>[0..varyingCount]". (default: undefined) See usage in babylon.blurPostProcess.ts and kernelBlur.vertex.fx
     * @param blockCompilation If the shader should not be compiled immediatly. (default: false)
     * @param textureFormat Format of textures used when performing the post process. (default: TEXTUREFORMAT_RGBA)
     * @param shaderLanguage The shader language of the shader. (default: GLSL)
     * @param extraInitializations Defines additional code to call to prepare the shader code
     */
    constructor(name: string, fragmentUrl: string, parameters: Nullable<string[]>, samplers: Nullable<string[]>, options: number | PostProcessOptions, camera: Nullable<Camera>, samplingMode?: number, engine?: AbstractEngine, reusable?: boolean, defines?: Nullable<string>, textureType?: number, vertexUrl?: string, indexParameters?: any, blockCompilation?: boolean, textureFormat?: number, shaderLanguage?: ShaderLanguage, extraInitializations?: (useWebGPU: boolean, list: Promise<any>[]) => void);
    protected _gatherImports(useWebGPU: boolean | undefined, list: Promise<any>[]): void;
    /**
     * Gets a string identifying the name of the class
     * @returns "PostProcess" string
     */
    getClassName(): string;
    /**
     * Gets the engine which this post process belongs to.
     * @returns The engine the post process was enabled with.
     */
    getEngine(): AbstractEngine;
    /**
     * The effect that is created when initializing the post process.
     * @returns The created effect corresponding to the postprocess.
     */
    getEffect(): Effect;
    /**
     * To avoid multiple redundant textures for multiple post process, the output the output texture for this post process can be shared with another.
     * @param postProcess The post process to share the output with.
     * @returns This post process.
     */
    shareOutputWith(postProcess: PostProcess): PostProcess;
    /**
     * Reverses the effect of calling shareOutputWith and returns the post process back to its original state.
     * This should be called if the post process that shares output with this post process is disabled/disposed.
     */
    useOwnOutput(): void;
    /**
     * Updates the effect with the current post process compile time values and recompiles the shader.
     * @param defines Define statements that should be added at the beginning of the shader. (default: null)
     * @param uniforms Set of uniform variables that will be passed to the shader. (default: null)
     * @param samplers Set of Texture2D variables that will be passed to the shader. (default: null)
     * @param indexParameters The index parameters to be used for babylons include syntax "#include<kernelBlurVaryingDeclaration>[0..varyingCount]". (default: undefined) See usage in babylon.blurPostProcess.ts and kernelBlur.vertex.fx
     * @param onCompiled Called when the shader has been compiled.
     * @param onError Called if there is an error when compiling a shader.
     * @param vertexUrl The url of the vertex shader to be used (default: the one given at construction time)
     * @param fragmentUrl The url of the fragment shader to be used (default: the one given at construction time)
     */
    updateEffect(defines?: Nullable<string>, uniforms?: Nullable<string[]>, samplers?: Nullable<string[]>, indexParameters?: any, onCompiled?: (effect: Effect) => void, onError?: (effect: Effect, errors: string) => void, vertexUrl?: string, fragmentUrl?: string): void;
    /**
     * The post process is reusable if it can be used multiple times within one frame.
     * @returns If the post process is reusable
     */
    isReusable(): boolean;
    /** invalidate frameBuffer to hint the postprocess to create a depth buffer */
    markTextureDirty(): void;
    private _createRenderTargetTexture;
    private _flushTextureCache;
    /**
     * Resizes the post-process texture
     * @param width Width of the texture
     * @param height Height of the texture
     * @param camera The camera this post-process is applied to. Pass null if the post-process is used outside the context of a camera post-process chain (default: null)
     * @param needMipMaps True if mip maps need to be generated after render (default: false)
     * @param forceDepthStencil True to force post-process texture creation with stencil depth and buffer (default: false)
     */
    resize(width: number, height: number, camera?: Nullable<Camera>, needMipMaps?: boolean, forceDepthStencil?: boolean): void;
    private _getTarget;
    /**
     * Activates the post process by intializing the textures to be used when executed. Notifies onActivateObservable.
     * When this post process is used in a pipeline, this is call will bind the input texture of this post process to the output of the previous.
     * @param cameraOrScene The camera that will be used in the post process. This camera will be used when calling onActivateObservable. You can also pass the scene if no camera is available.
     * @param sourceTexture The source texture to be inspected to get the width and height if not specified in the post process constructor. (default: null)
     * @param forceDepthStencil If true, a depth and stencil buffer will be generated. (default: false)
     * @returns The render target wrapper that was bound to be written to.
     */
    activate(cameraOrScene: Nullable<Camera> | Scene, sourceTexture?: Nullable<InternalTexture>, forceDepthStencil?: boolean): RenderTargetWrapper;
    /**
     * If the post process is supported.
     */
    get isSupported(): boolean;
    /**
     * The aspect ratio of the output texture.
     */
    get aspectRatio(): number;
    /**
     * Get a value indicating if the post-process is ready to be used
     * @returns true if the post-process is ready (shader is compiled)
     */
    isReady(): boolean;
    /**
     * Binds all textures and uniforms to the shader, this will be run on every pass.
     * @returns the effect corresponding to this post process. Null if not compiled or not ready.
     */
    apply(): Nullable<Effect>;
    private _disposeTextures;
    private _disposeTextureCache;
    /**
     * Sets the required values to the prepass renderer.
     * @param prePassRenderer defines the prepass renderer to setup.
     * @returns true if the pre pass is needed.
     */
    setPrePassRenderer(prePassRenderer: PrePassRenderer): boolean;
    /**
     * Disposes the post process.
     * @param camera The camera to dispose the post process on.
     */
    dispose(camera?: Camera): void;
    /**
     * Serializes the post process to a JSON object
     * @returns the JSON object
     */
    serialize(): any;
    /**
     * Clones this post process
     * @returns a new post process similar to this one
     */
    clone(): Nullable<PostProcess>;
    /**
     * Creates a material from parsed material data
     * @param parsedPostProcess defines parsed post process data
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures
     * @returns a new post process
     */
    static Parse(parsedPostProcess: any, scene: Scene, rootUrl: string): Nullable<PostProcess>;
    /**
     * @internal
     */
    static _Parse(parsedPostProcess: any, targetCamera: Nullable<Camera>, scene: Nullable<Scene>, rootUrl: string): Nullable<PostProcess>;
}

/**
 * Interface used to define options for the Audio Engine
 * @since 5.0.0
 */
interface IAudioEngineOptions {
    /**
     * Specifies an existing Audio Context for the audio engine
     * @deprecated Please use AudioEngineV2 instead
     */
    audioContext?: AudioContext;
    /**
     * Specifies a destination node for the audio engine
     * @deprecated Please use AudioEngineV2 instead
     */
    audioDestination?: AudioDestinationNode | MediaStreamAudioDestinationNode;
}

/**
 * Defines the interface used by objects working like Scene
 * @internal
 */
interface ISceneLike {
    /** Add pending data  (to load) */
    addPendingData(data: any): void;
    /** Remove pending data */
    removePendingData(data: any): void;
    /** Offline provider */
    offlineProvider: IOfflineProvider;
}
/** Interface defining initialization parameters for AbstractEngine class */
interface AbstractEngineOptions {
    /**
     * Defines if the engine should no exceed a specified device ratio
     * @see https://developer.mozilla.org/en-US/docs/Web/API/Window/devicePixelRatio
     */
    limitDeviceRatio?: number;
    /**
     * Defines if webaudio should be initialized as well
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic
     */
    audioEngine?: boolean;
    /**
     * Specifies options for the audio engine
     */
    audioEngineOptions?: IAudioEngineOptions;
    /**
     * Defines if animations should run using a deterministic lock step
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
     */
    deterministicLockstep?: boolean;
    /** Defines the maximum steps to use with deterministic lock step mode */
    lockstepMaxSteps?: number;
    /** Defines the seconds between each deterministic lock step */
    timeStep?: number;
    /**
     * Defines that engine should ignore context lost events
     * If this event happens when this parameter is true, you will have to reload the page to restore rendering
     */
    doNotHandleContextLost?: boolean;
    /**
     * Defines that engine should ignore modifying touch action attribute and style
     * If not handle, you might need to set it up on your side for expected touch devices behavior.
     */
    doNotHandleTouchAction?: boolean;
    /**
     * Make the matrix computations to be performed in 64 bits instead of 32 bits. False by default.
     * Note that setting useLargeWorldRendering will also set high precision matrices
     */
    useHighPrecisionMatrix?: boolean;
    /**
     * @experimental
     * LargeWorldRendering helps avoid floating point imprecision of rendering large worlds by
     * 1. Forcing highPrecisionMatrices (matrix computations in 64 bits instead of 32)
     * 2. Enabling floatingOriginMode in all scenes -- offsetting position-related uniform and attribute values before passing to shader so that active camera is centered at origin and world is offset by active camera position
     *
     * NOTE that if this mode is set during engineCreation, all scenes will have floatingOrigin offset and you do not need to send floatingOriginMode option to each scene creation.
     * If you'd like to have only specific scenes using the offset logic, you can set the flag on those scenes directly -- however, to achieve proper large world rendering, you must also set the useHighPrecisionMatrix option on engine.
     */
    readonly useLargeWorldRendering?: boolean;
    /**
     * Defines whether to adapt to the device's viewport characteristics (default: false)
     */
    adaptToDeviceRatio?: boolean;
    /**
     * Defines whether MSAA is enabled on the canvas.
     */
    antialias?: boolean;
    /**
     * Defines whether the stencil buffer should be enabled.
     */
    stencil?: boolean;
    /**
     * Defines whether the canvas should be created in "premultiplied" mode (if false, the canvas is created in the "opaque" mode) (true by default)
     */
    premultipliedAlpha?: boolean;
    /**
     * True if the more expensive but exact conversions should be used for transforming colors to and from linear space within shaders.
     * Otherwise, the default is to use a cheaper approximation.
     */
    useExactSrgbConversions?: boolean;
}
/**
 * Information about the current host
 */
interface HostInformation {
    /**
     * Defines if the current host is a mobile
     */
    isMobile: boolean;
}
type PrepareTextureProcessFunction = (width: number, height: number, img: HTMLImageElement | ImageBitmap | {
    width: number;
    height: number;
}, extension: string, texture: InternalTexture, continuationCallback: () => void) => boolean;
type PrepareTextureFunction = (texture: InternalTexture, extension: string, scene: Nullable<ISceneLike>, img: HTMLImageElement | ImageBitmap | {
    width: number;
    height: number;
}, invertY: boolean, noMipmap: boolean, isCompressed: boolean, processFunction: PrepareTextureProcessFunction, samplingMode: number) => void;
/**
 * The parent class for specialized engines (WebGL, WebGPU)
 */
declare abstract class AbstractEngine {
    /** @internal */
    protected _colorWrite: boolean;
    /** @internal */
    protected _colorWriteChanged: boolean;
    /** @internal */
    _depthCullingState: DepthCullingState;
    /** @internal */
    protected _stencilStateComposer: StencilStateComposer;
    /** @internal */
    _stencilState: StencilState;
    /** @internal */
    _alphaState: AlphaState;
    /** @internal */
    _alphaMode: any[];
    /** @internal */
    _alphaEquation: any[];
    protected _activeRequests: IFileRequest[];
    /** @internal */
    _badOS: boolean;
    /** @internal */
    _badDesktopOS: boolean;
    /** @internal */
    _videoTextureSupported: boolean;
    protected _compatibilityMode: boolean;
    /** @internal */
    _pointerLockRequested: boolean;
    /** @internal */
    _loadingScreen: ILoadingScreen;
    /** @internal */
    _renderingCanvas: Nullable<HTMLCanvasElement>;
    /** @internal */
    _internalTexturesCache: InternalTexture[];
    protected _currentEffect: Nullable<Effect>;
    /** @internal */
    protected _cachedVertexBuffers: any;
    /** @internal */
    protected _cachedIndexBuffer: Nullable<DataBuffer>;
    /** @internal */
    protected _cachedEffectForVertexBuffers: Nullable<Effect>;
    /** @internal */
    _currentRenderTarget: Nullable<RenderTargetWrapper>;
    /** @internal */
    _caps: EngineCapabilities;
    /** @internal */
    protected _cachedViewport: Nullable<IViewportLike>;
    /** @internal */
    _currentDrawContext: IDrawContext;
    /** @internal */
    _currentMaterialContext: IMaterialContext;
    /** @internal */
    protected _boundTexturesCache: {
        [key: string]: Nullable<InternalTexture>;
    };
    /** @internal */
    protected _activeChannel: number;
    /** @internal */
    protected _currentTextureChannel: number;
    /** @internal */
    protected _viewportCached: {
        x: number;
        y: number;
        z: number;
        w: number;
    };
    /** @internal */
    protected _isWebGPU: boolean;
    /** @internal */
    _enableGPUDebugMarkers: boolean;
    /** @internal */
    _onFocus: () => void;
    /** @internal */
    _onBlur: () => void;
    /** @internal */
    _onCanvasPointerOut: (event: PointerEvent) => void;
    /** @internal */
    _onCanvasBlur: () => void;
    /** @internal */
    _onCanvasFocus: () => void;
    /** @internal */
    _onCanvasContextMenu: (evt: Event) => void;
    /** @internal */
    _onFullscreenChange: () => void;
    /**
     * Observable event triggered each time the canvas loses focus
     */
    onCanvasBlurObservable: Observable<AbstractEngine>;
    /**
     * Observable event triggered each time the canvas gains focus
     */
    onCanvasFocusObservable: Observable<AbstractEngine>;
    /**
     * Event raised when a new scene is created
     */
    onNewSceneAddedObservable: Observable<Scene>;
    /**
     * Observable event triggered each time the rendering canvas is resized
     */
    onResizeObservable: Observable<AbstractEngine>;
    /**
     * Observable event triggered each time the canvas receives pointerout event
     */
    onCanvasPointerOutObservable: Observable<PointerEvent>;
    /**
     * Observable event triggered each time an effect compilation fails
     */
    onEffectErrorObservable: Observable<{
        effect: Effect;
        errors: string;
    }>;
    /**
     * Turn this value on if you want to pause FPS computation when in background
     */
    disablePerformanceMonitorInBackground: boolean;
    /**
     * Gets or sets a boolean indicating that vertex array object must be disabled even if they are supported
     */
    disableVertexArrayObjects: boolean;
    /** @internal */
    protected _frameId: number;
    /**
     * Gets the current frame id
     */
    get frameId(): number;
    /**
     * Gets a boolean indicating if the engine runs in WebGPU or not.
     */
    get isWebGPU(): boolean;
    protected _shaderProcessor: Nullable<IShaderProcessor>;
    /**
     * @internal
     */
    _getShaderProcessor(_shaderLanguage: ShaderLanguage): Nullable<IShaderProcessor>;
    /**
     * @internal
     */
    _resetAlphaMode(): void;
    /**
     * Gets a boolean indicating if all created effects are ready
     * @returns true if all effects are ready
     */
    abstract areAllEffectsReady(): boolean;
    /**
     * @internal
     */
    abstract _executeWhenRenderingStateIsCompiled(pipelineContext: IPipelineContext, action: () => void): void;
    /**
     * @internal
     */
    abstract _setTexture(channel: number, texture: Nullable<ThinTexture>, isPartOfTextureArray?: boolean, depthStencilTexture?: boolean, name?: string): boolean;
    /**
     * Sets a texture to the according uniform.
     * @param channel The texture channel
     * @param unused unused parameter
     * @param texture The texture to apply
     * @param name The name of the uniform in the effect
     */
    abstract setTexture(channel: number, unused: Nullable<WebGLUniformLocation>, texture: Nullable<ThinTexture>, name: string): void;
    /**
     * Binds an effect to the webGL context
     * @param effect defines the effect to bind
     */
    abstract bindSamplers(effect: Effect): void;
    /**
     * @internal
     */
    abstract _bindTexture(channel: number, texture: Nullable<InternalTexture>, name: string): void;
    /**
     * @internal
     */
    abstract _deletePipelineContext(pipelineContext: IPipelineContext): void;
    /**
     * @internal
     */
    abstract _preparePipelineContextAsync(pipelineContext: IPipelineContext, vertexSourceCode: string, fragmentSourceCode: string, createAsRaw: boolean, rawVertexSourceCode: string, rawFragmentSourceCode: string, rebuildRebind: any, defines: Nullable<string>, transformFeedbackVaryings: Nullable<string[]>, key: string, onReady: () => void): void;
    /** @internal */
    protected _shaderPlatformName: string;
    /**
     * Gets the shader platform name used by the effects.
     */
    get shaderPlatformName(): string;
    /**
     * Gets information about the current host
     */
    hostInformation: HostInformation;
    /**
     * Gets a boolean indicating if the engine is currently rendering in fullscreen mode
     */
    isFullscreen: boolean;
    /**
     * Gets or sets a boolean to enable/disable IndexedDB support and avoid XHR on .manifest
     **/
    enableOfflineSupport: boolean;
    /**
     * Gets or sets a boolean to enable/disable checking manifest if IndexedDB support is enabled (js will always consider the database is up to date)
     **/
    disableManifestCheck: boolean;
    /**
     * Gets or sets a boolean to enable/disable the context menu (right-click) from appearing on the main canvas
     */
    disableContextMenu: boolean;
    /**
     * Gets or sets the current render pass id
     */
    currentRenderPassId: number;
    /**
     * Gets a boolean indicating if the pointer is currently locked
     */
    isPointerLock: boolean;
    /**
     * Gets the list of created postprocesses
     */
    postProcesses: PostProcess[];
    /** Gets or sets the tab index to set to the rendering canvas. 1 is the minimum value to set to be able to capture keyboard events */
    canvasTabIndex: number;
    /** @internal */
    protected _onContextLost: (evt: Event) => void;
    /** @internal */
    protected _onContextRestored: (evt: Event) => void;
    /** @internal */
    protected _contextWasLost: boolean;
    private _emptyTexture;
    private _emptyCubeTexture;
    private _emptyTexture3D;
    private _emptyTexture2DArray;
    protected _clearEmptyResources(): void;
    abstract wipeCaches(bruteForce?: boolean): void;
    private _useReverseDepthBuffer;
    /**
     * Gets or sets a boolean indicating if depth buffer should be reverse, going from far to near.
     * This can provide greater z depth for distant objects.
     */
    get useReverseDepthBuffer(): boolean;
    set useReverseDepthBuffer(useReverse: boolean);
    /**
     * Enable or disable color writing
     * @param enable defines the state to set
     */
    setColorWrite(enable: boolean): void;
    /**
     * Gets a boolean indicating if color writing is enabled
     * @returns the current color writing state
     */
    getColorWrite(): boolean;
    /**
     * Gets the depth culling state manager
     */
    get depthCullingState(): DepthCullingState;
    /**
     * Gets the alpha state manager
     */
    get alphaState(): AlphaState;
    /**
     * Gets the stencil state manager
     */
    get stencilState(): StencilState;
    /**
     * Gets the stencil state composer
     */
    get stencilStateComposer(): StencilStateComposer;
    /**
     * Indicates if the z range in NDC space is 0..1 (value: true) or -1..1 (value: false)
     */
    readonly isNDCHalfZRange: boolean;
    /**
     * Indicates that the origin of the texture/framebuffer space is the bottom left corner. If false, the origin is top left
     */
    readonly hasOriginBottomLeft: boolean;
    /**
     * Gets a boolean indicating if the exact sRGB conversions or faster approximations are used for converting to and from linear space.
     */
    readonly useExactSrgbConversions: boolean;
    /** @internal */
    _getGlobalDefines(defines?: {
        [key: string]: string;
    }): string | undefined;
    /** @internal */
    _renderTargetWrapperCache: RenderTargetWrapper[];
    /** @internal */
    protected _compiledEffects: {
        [key: string]: Effect;
    };
    private _rebuildInternalTextures;
    private _rebuildRenderTargetWrappers;
    private _rebuildEffects;
    protected _rebuildGraphicsResources(): void;
    protected _flagContextRestored(): void;
    protected _restoreEngineAfterContextLost(initEngine: () => void): void;
    /** @internal */
    protected _isDisposed: boolean;
    /** Gets a boolean indicating if the engine was disposed */
    get isDisposed(): boolean;
    /**
     * Gets the list of created scenes
     */
    scenes: Scene[];
    /** @internal */
    _virtualScenes: Scene[];
    /** @internal */
    _features: EngineFeatures;
    /**
     * Enables or disables the snapshot rendering mode
     * Note that the WebGL engine does not support snapshot rendering so setting the value won't have any effect for this engine
     */
    get snapshotRendering(): boolean;
    set snapshotRendering(activate: boolean);
    /**
     * Gets or sets the snapshot rendering mode
     */
    get snapshotRenderingMode(): number;
    set snapshotRenderingMode(mode: number);
    /**
     * Observable event triggered before each texture is initialized
     */
    onBeforeTextureInitObservable: Observable<Texture>;
    /**
     * Gets or sets a boolean indicating if the engine must keep rendering even if the window is not in foreground
     */
    renderEvenInBackground: boolean;
    /**
     * Gets or sets a boolean indicating that cache can be kept between frames
     */
    preventCacheWipeBetweenFrames: boolean;
    /**
     * Returns the string "AbstractEngine"
     * @returns "AbstractEngine"
     */
    getClassName(): string;
    /**
     * Gets the default empty texture
     */
    get emptyTexture(): InternalTexture;
    /**
     * Gets the default empty 3D texture
     */
    get emptyTexture3D(): InternalTexture;
    /**
     * Gets the default empty 2D array texture
     */
    get emptyTexture2DArray(): InternalTexture;
    /**
     * Gets the default empty cube texture
     */
    get emptyCubeTexture(): InternalTexture;
    /** @internal */
    _frameHandler: number;
    /** @internal */
    protected _activeRenderLoops: (() => void)[];
    /**
     * Gets the list of current active render loop functions
     * @returns a read only array with the current render loop functions
     */
    get activeRenderLoops(): ReadonlyArray<() => void>;
    /**
     * stop executing a render loop function and remove it from the execution array
     * @param renderFunction defines the function to be removed. If not provided all functions will be removed.
     */
    stopRenderLoop(renderFunction?: () => void): void;
    protected _cancelFrame(): void;
    /** @internal */
    _windowIsBackground: boolean;
    /**
     * Begin a new frame
     */
    beginFrame(): void;
    /**
     * End the current frame
     */
    endFrame(): void;
    /**
     * Gets the performance monitor attached to this engine
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#engineinstrumentation
     */
    abstract get performanceMonitor(): PerformanceMonitor;
    /** @internal */
    _boundRenderFunction: any;
    protected _maxFPS: number | undefined;
    protected _minFrameTime: number;
    protected _lastFrameTime: number;
    protected _renderAccumulator: number;
    /**
     * Skip frame rendering but keep the frame heartbeat (begin/end frame).
     * This is useful if you need all the plumbing but not the rendering work.
     * (for instance when capturing a screenshot where you do not want to mix rendering to the screen and to the screenshot)
     */
    skipFrameRender: boolean;
    /** Gets or sets max frame per second allowed. Will return undefined if not capped */
    get maxFPS(): number | undefined;
    set maxFPS(value: number | undefined);
    protected _isOverFrameTime(timestamp?: number): boolean;
    protected _processFrame(timestamp?: number): void;
    /** @internal */
    _renderLoop(timestamp: number | undefined): void;
    /** @internal */
    _renderFrame(): void;
    /** @internal */
    _renderViews(): boolean;
    /**
     * Can be used to override the current requestAnimationFrame requester.
     * @internal
     */
    protected _queueNewFrame(bindedRenderFunction: any, requester?: any): number;
    /**
     * Register and execute a render loop. The engine can have more than one render function
     * @param renderFunction defines the function to continuously execute
     */
    runRenderLoop(renderFunction: () => void): void;
    /**
     * Gets a boolean indicating if depth testing is enabled
     * @returns the current state
     */
    getDepthBuffer(): boolean;
    /**
     * Enable or disable depth buffering
     * @param enable defines the state to set
     */
    setDepthBuffer(enable: boolean): void;
    /**
     * Set the z offset Factor to apply to current rendering
     * @param value defines the offset to apply
     */
    setZOffset(value: number): void;
    /**
     * Gets the current value of the zOffset Factor
     * @returns the current zOffset Factor state
     */
    getZOffset(): number;
    /**
     * Set the z offset Units to apply to current rendering
     * @param value defines the offset to apply
     */
    setZOffsetUnits(value: number): void;
    /**
     * Gets the current value of the zOffset Units
     * @returns the current zOffset Units state
     */
    getZOffsetUnits(): number;
    /**
     * Gets host window
     * @returns the host window object
     */
    getHostWindow(): Nullable<Window>;
    /**
     * (WebGPU only) True (default) to be in compatibility mode, meaning rendering all existing scenes without artifacts (same rendering than WebGL).
     * Setting the property to false will improve performances but may not work in some scenes if some precautions are not taken.
     * See https://doc.babylonjs.com/setup/support/webGPU/webGPUOptimization/webGPUNonCompatibilityMode for more details
     */
    get compatibilityMode(): boolean;
    set compatibilityMode(mode: boolean);
    /**
     * Observable raised when the engine is about to compile a shader
     */
    onBeforeShaderCompilationObservable: Observable<AbstractEngine>;
    /**
     * Observable raised when the engine has just compiled a shader
     */
    onAfterShaderCompilationObservable: Observable<AbstractEngine>;
    /**
     * Observable raised when the engine begins a new frame
     */
    onBeginFrameObservable: Observable<AbstractEngine>;
    /**
     * Observable raised when the engine ends the current frame (requires a render loop, e.g. 'engine.runRenderLoop(...)')
     */
    onEndFrameObservable: Observable<AbstractEngine>;
    protected _rebuildTextures(): void;
    /**
     * @internal
     */
    abstract _getRGBABufferInternalSizedFormat(type: number, format?: number, useSRGBBuffer?: boolean): number;
    /** @internal */
    abstract _getUnpackAlignement(): number;
    /**
     * @internal
     */
    abstract _uploadCompressedDataToTextureDirectly(texture: InternalTexture, internalFormat: number, width: number, height: number, data: ArrayBufferView, faceIndex: number, lod?: number): void;
    /**
     * @internal
     */
    abstract _bindTextureDirectly(target: number, texture: Nullable<InternalTexture>, forTextureDataUpdate?: boolean, force?: boolean): boolean;
    /**
     * @internal
     */
    abstract _uploadDataToTextureDirectly(texture: InternalTexture, imageData: ArrayBufferView, faceIndex?: number, lod?: number, babylonInternalFormat?: number, useTextureWidthAndHeight?: boolean): void;
    /** @internal */
    abstract _unpackFlipY(value: boolean): void;
    /**
     * Reads pixels from the current frame buffer. Please note that this function can be slow
     * @param x defines the x coordinate of the rectangle where pixels must be read
     * @param y defines the y coordinate of the rectangle where pixels must be read
     * @param width defines the width of the rectangle where pixels must be read
     * @param height defines the height of the rectangle where pixels must be read
     * @param hasAlpha defines whether the output should have alpha or not (defaults to true)
     * @param flushRenderer true to flush the renderer from the pending commands before reading the pixels
     * @returns a ArrayBufferView promise (Uint8Array) containing RGBA colors
     */
    abstract readPixels(x: number, y: number, width: number, height: number, hasAlpha?: boolean, flushRenderer?: boolean): Promise<ArrayBufferView>;
    /**
     * Generates mipmaps for a texture
     * @param texture The texture to generate the mipmaps for
     */
    abstract generateMipmaps(texture: InternalTexture): void;
    /**
     * Force a flush (ie. a flush of all waiting commands)
     */
    abstract flushFramebuffer(): void;
    /** @internal */
    abstract _currentFrameBufferIsDefaultFrameBuffer(): boolean;
    /**
     * Creates an internal texture without binding it to a framebuffer
     * @internal
     * @param size defines the size of the texture
     * @param options defines the options used to create the texture
     * @param delayGPUTextureCreation true to delay the texture creation the first time it is really needed. false to create it right away
     * @param source source type of the texture
     * @returns a new internal texture
     */
    abstract _createInternalTexture(size: TextureSize, options: boolean | InternalTextureCreationOptions, delayGPUTextureCreation?: boolean, source?: InternalTextureSource): InternalTexture;
    /** @internal */
    abstract applyStates(): void;
    /**
     * Binds the frame buffer to the specified texture.
     * @param texture The render target wrapper to render to
     * @param faceIndex The face of the texture to render to in case of cube texture
     * @param requiredWidth The width of the target to render to
     * @param requiredHeight The height of the target to render to
     * @param forceFullscreenViewport Forces the viewport to be the entire texture/screen if true
     * @param lodLevel defines the lod level to bind to the frame buffer
     * @param layer defines the 2d array index to bind to frame buffer to
     */
    abstract bindFramebuffer(texture: RenderTargetWrapper, faceIndex?: number, requiredWidth?: number, requiredHeight?: number, forceFullscreenViewport?: boolean, lodLevel?: number, layer?: number): void;
    /**
     * Update the sampling mode of a given texture
     * @param texture defines the texture to update
     * @param wrapU defines the texture wrap mode of the u coordinates
     * @param wrapV defines the texture wrap mode of the v coordinates
     * @param wrapR defines the texture wrap mode of the r coordinates
     */
    abstract updateTextureWrappingMode(texture: InternalTexture, wrapU: Nullable<number>, wrapV?: Nullable<number>, wrapR?: Nullable<number>): void;
    /**
     * Unbind the current render target and bind the default framebuffer
     */
    abstract restoreDefaultFramebuffer(): void;
    /**
     * Draw a list of indexed primitives
     * @param fillMode defines the primitive to use
     * @param indexStart defines the starting index
     * @param indexCount defines the number of index to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    abstract drawElementsType(fillMode: number, indexStart: number, indexCount: number, instancesCount?: number): void;
    /**
     * Unbind the current render target texture from the webGL context
     * @param texture defines the render target wrapper to unbind
     * @param disableGenerateMipMaps defines a boolean indicating that mipmaps must not be generated
     * @param onBeforeUnbind defines a function which will be called before the effective unbind
     */
    abstract unBindFramebuffer(texture: RenderTargetWrapper, disableGenerateMipMaps?: boolean, onBeforeUnbind?: () => void): void;
    /**
     * Generates mipmaps for the texture of the (single) render target
     * @param texture The render target containing the texture to generate the mipmaps for
     */
    abstract generateMipMapsFramebuffer(texture: RenderTargetWrapper): void;
    /**
     * Resolves the MSAA texture of the (single) render target into its non-MSAA version.
     * Note that if "texture" is not a MSAA render target, no resolve is performed.
     * @param texture The render target texture containing the MSAA texture to resolve
     */
    abstract resolveFramebuffer(texture: RenderTargetWrapper): void;
    /**Gets driver info if available */
    abstract extractDriverInfo(): string;
    /**
     * Bind a list of vertex buffers to the webGL context
     * @param vertexBuffers defines the list of vertex buffers to bind
     * @param indexBuffer defines the index buffer to bind
     * @param effect defines the effect associated with the vertex buffers
     * @param overrideVertexBuffers defines optional list of avertex buffers that overrides the entries in vertexBuffers
     */
    abstract bindBuffers(vertexBuffers: {
        [key: string]: Nullable<VertexBuffer>;
    }, indexBuffer: Nullable<DataBuffer>, effect: Effect, overrideVertexBuffers?: {
        [kind: string]: Nullable<VertexBuffer>;
    }): void;
    /**
     * @internal
     */
    _releaseRenderTargetWrapper(rtWrapper: RenderTargetWrapper): void;
    /**
     * Activates an effect, making it the current one (i.e. the one used for rendering)
     * @param effect defines the effect to activate
     */
    abstract enableEffect(effect: Nullable<Effect | DrawWrapper>): void;
    /**
     * Sets the type of faces to cull
     * @param cullBackFaces true to cull back faces, false to cull front faces (if culling is enabled)
     * @param force defines if states must be applied even if cache is up to date
     */
    abstract setStateCullFaceType(cullBackFaces?: boolean, force?: boolean): void;
    /**
     * Set various states to the webGL context
     * @param culling defines culling state: true to enable culling, false to disable it
     * @param zOffset defines the value to apply to zOffset (0 by default)
     * @param force defines if states must be applied even if cache is up to date
     * @param reverseSide defines if culling must be reversed (CCW if false, CW if true)
     * @param cullBackFaces true to cull back faces, false to cull front faces (if culling is enabled)
     * @param stencil stencil states to set
     * @param zOffsetUnits defines the value to apply to zOffsetUnits (0 by default)
     */
    abstract setState(culling: boolean, zOffset?: number, force?: boolean, reverseSide?: boolean, cullBackFaces?: boolean, stencil?: IStencilState | IStencilStateProperties, zOffsetUnits?: number): void;
    /**
     * Creates a new material context
     * @returns the new context
     */
    abstract createMaterialContext(): IMaterialContext | undefined;
    /**
     * Creates a new draw context
     * @returns the new context
     */
    abstract createDrawContext(): IDrawContext | undefined;
    /**
     * Create a new effect (used to store vertex/fragment shaders)
     * @param baseName defines the base name of the effect (The name of file without .fragment.fx or .vertex.fx)
     * @param attributesNamesOrOptions defines either a list of attribute names or an IEffectCreationOptions object
     * @param uniformsNamesOrEngine defines either a list of uniform names or the engine to use
     * @param samplers defines an array of string used to represent textures
     * @param defines defines the string containing the defines to use to compile the shaders
     * @param fallbacks defines the list of potential fallbacks to use if shader compilation fails
     * @param onCompiled defines a function to call when the effect creation is successful
     * @param onError defines a function to call when the effect creation has failed
     * @param indexParameters defines an object containing the index values to use to compile shaders (like the maximum number of simultaneous lights)
     * @param shaderLanguage the language the shader is written in (default: GLSL)
     * @param extraInitializationsAsync additional async code to run before preparing the effect
     * @returns the new Effect
     */
    abstract createEffect(baseName: string | (IShaderPath & {
        vertexToken?: string;
        fragmentToken?: string;
    }), attributesNamesOrOptions: string[] | IEffectCreationOptions, uniformsNamesOrEngine: string[] | AbstractEngine, samplers?: string[], defines?: string, fallbacks?: EffectFallbacks, onCompiled?: Nullable<(effect: Effect) => void>, onError?: Nullable<(effect: Effect, errors: string) => void>, indexParameters?: any, shaderLanguage?: ShaderLanguage, extraInitializationsAsync?: () => Promise<void>): Effect;
    /**
     * Clear the current render buffer or the current render target (if any is set up)
     * @param color defines the color to use
     * @param backBuffer defines if the back buffer must be cleared
     * @param depth defines if the depth buffer must be cleared
     * @param stencil defines if the stencil buffer must be cleared
     * @param stencilClearValue defines the value to use to clear the stencil buffer
     */
    abstract clear(color: Nullable<IColor4Like>, backBuffer: boolean, depth: boolean, stencil?: boolean, stencilClearValue?: number): void;
    /**
     * Gets a boolean indicating that only power of 2 textures are supported
     * Please note that you can still use non power of 2 textures but in this case the engine will forcefully convert them
     */
    abstract get needPOTTextures(): boolean;
    /**
     * Creates a new index buffer
     * @param indices defines the content of the index buffer
     * @param _updatable defines if the index buffer must be updatable
     * @param label defines the label of the buffer (for debug purpose)
     * @returns a new buffer
     */
    abstract createIndexBuffer(indices: IndicesArray, _updatable?: boolean, label?: string): DataBuffer;
    /**
     * Draw a list of unindexed primitives
     * @param fillMode defines the primitive to use
     * @param verticesStart defines the index of first vertex to draw
     * @param verticesCount defines the count of vertices to draw
     * @param instancesCount defines the number of instances to draw (if instantiation is enabled)
     */
    abstract drawArraysType(fillMode: number, verticesStart: number, verticesCount: number, instancesCount?: number): void;
    /**
     * Force the engine to release all cached effects.
     * This means that next effect compilation will have to be done completely even if a similar effect was already compiled
     */
    abstract releaseEffects(): void;
    /**
     * @internal
     */
    abstract _viewport(x: number, y: number, width: number, height: number): void;
    /**
     * Gets the current viewport
     */
    get currentViewport(): Nullable<IViewportLike>;
    /**
     * Set the WebGL's viewport
     * @param viewport defines the viewport element to be used
     * @param requiredWidth defines the width required for rendering. If not provided the rendering canvas' width is used
     * @param requiredHeight defines the height required for rendering. If not provided the rendering canvas' height is used
     */
    setViewport(viewport: IViewportLike, requiredWidth?: number, requiredHeight?: number): void;
    /**
     * Update the sampling mode of a given texture
     * @param samplingMode defines the required sampling mode
     * @param texture defines the texture to update
     * @param generateMipMaps defines whether to generate mipmaps for the texture
     */
    abstract updateTextureSamplingMode(samplingMode: number, texture: InternalTexture, generateMipMaps?: boolean): void;
    /**
     * Sets an array of texture to the webGL context
     * @param channel defines the channel where the texture array must be set
     * @param uniform defines the associated uniform location
     * @param textures defines the array of textures to bind
     * @param name name of the channel
     */
    abstract setTextureArray(channel: number, uniform: Nullable<WebGLUniformLocation>, textures: ThinTexture[], name: string): void;
    /** @internal */
    _transformTextureUrl: Nullable<(url: string) => string>;
    /**
     * Unbind all instance attributes
     */
    abstract unbindInstanceAttributes(): void;
    /**
     * @internal
     */
    abstract _getUseSRGBBuffer(useSRGBBuffer: boolean, noMipmap: boolean): boolean;
    /**
     * Create an image to use with canvas
     * @returns IImage interface
     */
    createCanvasImage(): IImage;
    /**
     * Create a 2D path to use with canvas
     * @returns IPath2D interface
     * @param d SVG path string
     */
    createCanvasPath2D(d?: string): IPath2D;
    /**
     * Returns a string describing the current engine
     */
    get description(): string;
    protected _createTextureBase(url: Nullable<string>, noMipmap: boolean, invertY: boolean, scene: Nullable<ISceneLike>, samplingMode: number | undefined, onLoad: Nullable<(texture: InternalTexture) => void> | undefined, onError: Nullable<(message: string, exception: any) => void> | undefined, prepareTexture: PrepareTextureFunction, prepareTextureProcess: PrepareTextureProcessFunction, buffer?: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>, fallback?: Nullable<InternalTexture>, format?: Nullable<number>, forcedExtension?: Nullable<string>, mimeType?: string, loaderOptions?: any, useSRGBBuffer?: boolean): InternalTexture;
    /**
     * Creates a new pipeline context
     * @param shaderProcessingContext defines the shader processing context used during the processing if available
     * @returns the new pipeline
     */
    abstract createPipelineContext(shaderProcessingContext: Nullable<_IShaderProcessingContext>): IPipelineContext;
    /**
     * Inline functions in shader code that are marked to be inlined
     * @param code code to inline
     * @returns inlined code
     */
    abstract inlineShaderCode(code: string): string;
    /**
     * Gets a boolean indicating that the engine supports uniform buffers
     */
    abstract get supportsUniformBuffers(): boolean;
    /**
     * Returns the version of the engine
     */
    abstract get version(): number;
    /**
     * @internal
     */
    abstract _releaseEffect(effect: Effect): void;
    /**
     * Bind a buffer to the current draw context
     * @param buffer defines the buffer to bind
     * @param _location not used in WebGPU
     * @param name Name of the uniform variable to bind
     */
    abstract bindUniformBufferBase(buffer: DataBuffer, _location: number, name: string): void;
    /**
     * Bind a specific block at a given index in a specific shader program
     * @param pipelineContext defines the pipeline context to use
     * @param blockName defines the block name
     * @param index defines the index where to bind the block
     */
    abstract bindUniformBlock(pipelineContext: IPipelineContext, blockName: string, index: number): void;
    /** @internal */
    _uniformBuffers: UniformBuffer[];
    /** @internal */
    _storageBuffers: StorageBuffer[];
    protected _rebuildBuffers(): void;
    protected _highPrecisionShadersAllowed: boolean;
    /** @internal */
    get _shouldUseHighPrecisionShader(): boolean;
    /**
     * @internal
     */
    abstract _getShaderProcessingContext(shaderLanguage: ShaderLanguage, pureMode: boolean): Nullable<_IShaderProcessingContext>;
    /**
     * Gets host document
     * @returns the host document object
     */
    getHostDocument(): Nullable<Document>;
    /**
     * Observable signaled when a context lost event is raised
     */
    onContextLostObservable: Observable<AbstractEngine>;
    /**
     * Observable signaled when a context restored event is raised
     */
    onContextRestoredObservable: Observable<AbstractEngine>;
    /**
     * Gets the list of loaded textures
     * @returns an array containing all loaded textures
     */
    getLoadedTexturesCache(): InternalTexture[];
    /**
     * Clears the list of texture accessible through engine.
     * This can help preventing texture load conflict due to name collision.
     */
    clearInternalTexturesCache(): void;
    /**
     * @internal
     */
    abstract _releaseTexture(texture: InternalTexture): void;
    /**
     * Gets the object containing all engine capabilities
     * @returns the EngineCapabilities object
     */
    getCaps(): EngineCapabilities;
    /**
     * Reset the texture cache to empty state
     */
    resetTextureCache(): void;
    /** @internal */
    protected _name: string;
    /**
     * Gets or sets the name of the engine
     */
    get name(): string;
    set name(value: string);
    /**
     * Returns the current npm package of the sdk
     */
    static get NpmPackage(): string;
    /**
     * Returns the current version of the framework
     */
    static get Version(): string;
    /**
     * The time (in milliseconds elapsed since the current page has been loaded) when the engine was initialized
     */
    readonly startTime: number;
    /** @internal */
    protected _audioContext: Nullable<AudioContext>;
    /** @internal */
    protected _audioDestination: Nullable<AudioDestinationNode | MediaStreamAudioDestinationNode>;
    /**
     * Gets the HTML canvas attached with the current webGL context
     * @returns a HTML canvas
     */
    getRenderingCanvas(): Nullable<HTMLCanvasElement>;
    /**
     * Gets the audio context specified in engine initialization options
     * @deprecated please use AudioEngineV2 instead
     * @returns an Audio Context
     */
    getAudioContext(): Nullable<AudioContext>;
    /**
     * Gets the audio destination specified in engine initialization options
     * @deprecated please use AudioEngineV2 instead
     * @returns an audio destination node
     */
    getAudioDestination(): Nullable<AudioDestinationNode | MediaStreamAudioDestinationNode>;
    /**
     * Defines whether the engine has been created with the premultipliedAlpha option on or not.
     */
    premultipliedAlpha: boolean;
    /**
     * If set to true zooming in and out in the browser will rescale the hardware-scaling correctly.
     */
    adaptToDeviceRatio: boolean;
    /** @internal */
    protected _lastDevicePixelRatio: number;
    /** @internal */
    _hardwareScalingLevel: number;
    /**
     * Defines the hardware scaling level.
     * By default the hardware scaling level is computed from the window device ratio.
     * if level = 1 then the engine will render at the exact resolution of the canvas. If level = 0.5 then the engine will render at twice the size of the canvas.
     * @param level defines the level to use
     */
    setHardwareScalingLevel(level: number): void;
    /**
     * Gets the current hardware scaling level.
     * By default the hardware scaling level is computed from the window device ratio.
     * if level = 1 then the engine will render at the exact resolution of the canvas. If level = 0.5 then the engine will render at twice the size of the canvas.
     * @returns a number indicating the current hardware scaling level
     */
    getHardwareScalingLevel(): number;
    /** @internal */
    _doNotHandleContextLost: boolean;
    /**
     * Gets or sets a boolean indicating if resources should be retained to be able to handle context lost events
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#handling-webgl-context-lost
     */
    get doNotHandleContextLost(): boolean;
    set doNotHandleContextLost(value: boolean);
    /** @internal */
    protected _isStencilEnable: boolean;
    /**
     * Returns true if the stencil buffer has been enabled through the creation option of the context.
     */
    get isStencilEnable(): boolean;
    /** @internal */
    protected _creationOptions: AbstractEngineOptions;
    /**
     * Gets the options used for engine creation
     * NOTE that modifying the object after engine creation will have no effect
     * @returns EngineOptions object
     */
    getCreationOptions(): AbstractEngineOptions;
    /**
     * Creates a new engine
     * @param antialias defines whether anti-aliasing should be enabled. If undefined, it means that the underlying engine is free to enable it or not
     * @param options defines further options to be sent to the creation context
     * @param adaptToDeviceRatio defines whether to adapt to the device's viewport characteristics (default: false)
     */
    constructor(antialias: boolean | undefined, options: AbstractEngineOptions, adaptToDeviceRatio?: boolean);
    /**
     * Resize the view according to the canvas' size
     * @param forceSetSize true to force setting the sizes of the underlying canvas
     */
    resize(forceSetSize?: boolean): void;
    /**
     * Force a specific size of the canvas
     * @param width defines the new canvas' width
     * @param height defines the new canvas' height
     * @param forceSetSize true to force setting the sizes of the underlying canvas
     * @returns true if the size was changed
     */
    setSize(width: number, height: number, forceSetSize?: boolean): boolean;
    /**
     * @internal
     */
    abstract _releaseBuffer(buffer: DataBuffer): boolean;
    /**
     * Create a dynamic uniform buffer
     * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
     * @param elements defines the content of the uniform buffer
     * @param label defines a name for the buffer (for debugging purpose)
     * @returns the webGL uniform buffer
     */
    abstract createDynamicUniformBuffer(elements: FloatArray, label?: string): DataBuffer;
    /**
     * Create an uniform buffer
     * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
     * @param elements defines the content of the uniform buffer
     * @param label defines a name for the buffer (for debugging purpose)
     * @returns the webGL uniform buffer
     */
    abstract createUniformBuffer(elements: FloatArray, label?: string): DataBuffer;
    /**
     * Update an existing uniform buffer
     * @see https://doc.babylonjs.com/setup/support/webGL2#uniform-buffer-objets
     * @param uniformBuffer defines the target uniform buffer
     * @param elements defines the content to update
     * @param offset defines the offset in the uniform buffer where update should start
     * @param count defines the size of the data to update
     */
    abstract updateUniformBuffer(uniformBuffer: DataBuffer, elements: FloatArray, offset?: number, count?: number): void;
    /**
     * Creates a dynamic vertex buffer
     * @param data the data for the dynamic vertex buffer
     * @param _label defines the label of the buffer (for debug purpose)
     * @returns the new WebGL dynamic buffer
     */
    abstract createDynamicVertexBuffer(data: DataArray | number, _label?: string): DataBuffer;
    /**
     * Creates a vertex buffer
     * @param data the data or size for the vertex buffer
     * @param _updatable whether the buffer should be created as updatable
     * @param _label defines the label of the buffer (for debug purpose)
     * @returns the new WebGL static buffer
     */
    abstract createVertexBuffer(data: DataArray | number, _updatable?: boolean, _label?: string): DataBuffer;
    /**
     * Update the dimensions of a texture
     * @param texture texture to update
     * @param width new width of the texture
     * @param height new height of the texture
     * @param depth new depth of the texture
     */
    abstract updateTextureDimensions(texture: InternalTexture, width: number, height: number, depth: number): void;
    /**
     * Usually called from Texture.ts.
     * Passed information to create a WebGLTexture
     * @param url defines a value which contains one of the following:
     * * A conventional http URL, e.g. 'http://...' or 'file://...'
     * * A base64 string of in-line texture data, e.g. 'data:image/jpg;base64,/...'
     * * An indicator that data being passed using the buffer parameter, e.g. 'data:mytexture.jpg'
     * @param noMipmap defines a boolean indicating that no mipmaps shall be generated.  Ignored for compressed textures.  They must be in the file
     * @param invertY when true, image is flipped when loaded.  You probably want true. Certain compressed textures may invert this if their default is inverted (eg. ktx)
     * @param scene needed for loading to the correct scene
     * @param samplingMode mode with should be used sample / access the texture (Default: Texture.TRILINEAR_SAMPLINGMODE)
     * @param onLoad optional callback to be called upon successful completion
     * @param onError optional callback to be called upon failure
     * @param buffer a source of a file previously fetched as either a base64 string, an ArrayBuffer (compressed or image format), HTMLImageElement (image format), or a Blob
     * @param fallback an internal argument in case the function must be called again, due to etc1 not having alpha capabilities
     * @param format internal format.  Default: RGB when extension is '.jpg' else RGBA.  Ignored for compressed textures
     * @param forcedExtension defines the extension to use to pick the right loader
     * @param mimeType defines an optional mime type
     * @param loaderOptions options to be passed to the loader
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
     * @returns a InternalTexture for assignment back into BABYLON.Texture
     */
    abstract createTexture(url: Nullable<string>, noMipmap: boolean, invertY: boolean, scene: Nullable<ISceneLike>, samplingMode?: number, onLoad?: Nullable<(texture: InternalTexture) => void>, onError?: Nullable<(message: string, exception: any) => void>, buffer?: Nullable<string | ArrayBuffer | ArrayBufferView | HTMLImageElement | Blob | ImageBitmap>, fallback?: Nullable<InternalTexture>, format?: Nullable<number>, forcedExtension?: Nullable<string>, mimeType?: string, loaderOptions?: any, creationFlags?: number, useSRGBBuffer?: boolean): InternalTexture;
    /**
     * Creates a raw texture
     * @param data defines the data to store in the texture
     * @param width defines the width of the texture
     * @param height defines the height of the texture
     * @param format defines the format of the data
     * @param generateMipMaps defines if the engine should generate the mip levels
     * @param invertY defines if data must be stored with Y axis inverted
     * @param samplingMode defines the required sampling mode (Texture.NEAREST_SAMPLINGMODE by default)
     * @param compression defines the compression used (null by default)
     * @param type defines the type fo the data (Engine.TEXTURETYPE_UNSIGNED_BYTE by default)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param useSRGBBuffer defines if the texture must be loaded in a sRGB GPU buffer (if supported by the GPU).
     * @param mipLevelCount defines the number of mip levels to allocate for the texture
     * @returns the raw texture inside an InternalTexture
     */
    createRawTexture(data: Nullable<ArrayBufferView>, width: number, height: number, format: number, generateMipMaps: boolean, invertY: boolean, samplingMode: number, compression?: Nullable<string>, type?: number, creationFlags?: number, useSRGBBuffer?: boolean, mipLevelCount?: number): InternalTexture;
    /**
     * Creates a new raw 3D texture
     * @param data defines the data used to create the texture
     * @param width defines the width of the texture
     * @param height defines the height of the texture
     * @param depth defines the depth of the texture
     * @param format defines the format of the texture
     * @param generateMipMaps defines if the engine must generate mip levels
     * @param invertY defines if data must be stored with Y axis inverted
     * @param samplingMode defines the required sampling mode (like Texture.NEAREST_SAMPLINGMODE)
     * @param compression defines the compressed used (can be null)
     * @param textureType defines the compressed used (can be null)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @returns a new raw 3D texture (stored in an InternalTexture)
     */
    createRawTexture3D(data: Nullable<ArrayBufferView>, width: number, height: number, depth: number, format: number, generateMipMaps: boolean, invertY: boolean, samplingMode: number, compression?: Nullable<string>, textureType?: number, creationFlags?: number): InternalTexture;
    /**
     * Creates a new raw 2D array texture
     * @param data defines the data used to create the texture
     * @param width defines the width of the texture
     * @param height defines the height of the texture
     * @param depth defines the number of layers of the texture
     * @param format defines the format of the texture
     * @param generateMipMaps defines if the engine must generate mip levels
     * @param invertY defines if data must be stored with Y axis inverted
     * @param samplingMode defines the required sampling mode (like Texture.NEAREST_SAMPLINGMODE)
     * @param compression defines the compressed used (can be null)
     * @param textureType defines the compressed used (can be null)
     * @param creationFlags specific flags to use when creating the texture (Constants.TEXTURE_CREATIONFLAG_STORAGE for storage textures, for eg)
     * @param mipLevelCount defines the number of mip levels to allocate for the texture
     * @returns a new raw 2D array texture (stored in an InternalTexture)
     */
    createRawTexture2DArray(data: Nullable<ArrayBufferView>, width: number, height: number, depth: number, format: number, generateMipMaps: boolean, invertY: boolean, samplingMode: number, compression?: Nullable<string>, textureType?: number, creationFlags?: number, mipLevelCount?: number): InternalTexture;
    /**
     * Gets or sets a boolean indicating if back faces must be culled. If false, front faces are culled instead (true by default)
     * If non null, this takes precedence over the value from the material
     */
    cullBackFaces: Nullable<boolean>;
    /**
     * Gets the current render width
     * @param useScreen defines if screen size must be used (or the current render target if any)
     * @returns a number defining the current render width
     */
    abstract getRenderWidth(useScreen?: boolean): number;
    /**
     * Gets the current render height
     * @param useScreen defines if screen size must be used (or the current render target if any)
     * @returns a number defining the current render height
     */
    abstract getRenderHeight(useScreen?: boolean): number;
    /**
     * Shared initialization across engines types.
     * @param canvas The canvas associated with this instance of the engine.
     */
    protected _sharedInit(canvas: HTMLCanvasElement): void;
    private _checkForMobile;
    protected _setupMobileChecks(): void;
    /** @internal */
    static _RenderPassIdCounter: number;
    /** @internal */
    _renderPassNames: string[];
    /** @internal */
    abstract _createHardwareTexture(): IHardwareTextureWrapper;
    /**
     * creates and returns a new video element
     * @param constraints video constraints
     * @returns video element
     */
    createVideoElement(constraints: MediaTrackConstraints): any;
    protected _fps: number;
    protected _deltaTime: number;
    /** @internal */
    _drawCalls: PerfCounter;
    /**
     * @internal
     */
    _reportDrawCall(numDrawCalls?: number): void;
    /**
     * Gets the current framerate
     * @returns a number representing the framerate
     */
    getFps(): number;
    /**
     * Gets the time spent between current and previous frame
     * @returns a number representing the delta time in ms
     */
    getDeltaTime(): number;
    /** @internal */
    _deterministicLockstep: boolean;
    /** @internal */
    _lockstepMaxSteps: number;
    /** @internal */
    _timeStep: number;
    /**
     * Gets a boolean indicating that the engine is running in deterministic lock step mode
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
     * @returns true if engine is in deterministic lock step mode
     */
    isDeterministicLockStep(): boolean;
    /**
     * Gets the max steps when engine is running in deterministic lock step
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
     * @returns the max steps
     */
    getLockstepMaxSteps(): number;
    /**
     * Returns the time in ms between steps when using deterministic lock step.
     * @returns time step in (ms)
     */
    getTimeStep(): number;
    /**
     * Engine abstraction for loading and creating an image bitmap from a given source string.
     * @param imageSource source to load the image from.
     * @param options An object that sets options for the image's extraction.
     */
    _createImageBitmapFromSource(imageSource: string, options?: ImageBitmapOptions): Promise<ImageBitmap>;
    /**
     * Engine abstraction for createImageBitmap
     * @param image source for image
     * @param options An object that sets options for the image's extraction.
     * @returns ImageBitmap
     */
    createImageBitmap(image: ImageBitmapSource, options?: ImageBitmapOptions): Promise<ImageBitmap>;
    /**
     * Resize an image and returns the image data as an uint8array
     * @param image image to resize
     * @param bufferWidth destination buffer width
     * @param bufferHeight destination buffer height
     */
    resizeImageBitmap(image: HTMLImageElement | ImageBitmap, bufferWidth: number, bufferHeight: number): Uint8Array;
    /**
     * Get the current error code of the webGL context
     * @returns the error code
     */
    abstract getError(): number;
    /**
     * Get Font size information
     * @param font font name
     */
    getFontOffset(font: string): {
        ascent: number;
        height: number;
        descent: number;
    };
    protected static _CreateCanvas(width: number, height: number): ICanvas;
    /**
     * Create a canvas. This method is overridden by other engines
     * @param width width
     * @param height height
     * @returns ICanvas interface
     */
    createCanvas(width: number, height: number): ICanvas;
    /**
     * Loads an image as an HTMLImageElement.
     * @param input url string, ArrayBuffer, or Blob to load
     * @param onLoad callback called when the image successfully loads
     * @param onError callback called when the image fails to load
     * @param offlineProvider offline provider for caching
     * @param mimeType optional mime type
     * @param imageBitmapOptions optional the options to use when creating an ImageBitmap
     * @param engine the engine instance to use
     * @returns the HTMLImageElement of the loaded image
     * @internal
     */
    static _FileToolsLoadImage(input: string | ArrayBuffer | ArrayBufferView | Blob, onLoad: (img: HTMLImageElement | ImageBitmap) => void, onError: (message?: string, exception?: any) => void, offlineProvider: Nullable<IOfflineProvider>, mimeType?: string, imageBitmapOptions?: ImageBitmapOptions, engine?: AbstractEngine): Nullable<HTMLImageElement>;
    /**
     * @internal
     */
    _loadFile(url: string, onSuccess: (data: string | ArrayBuffer, responseURL?: string) => void, onProgress?: (data: any) => void, offlineProvider?: Nullable<IOfflineProvider>, useArrayBuffer?: boolean, onError?: (request?: IWebRequest, exception?: any) => void): IFileRequest;
    /**
     * Loads a file from a url
     * @param url url to load
     * @param onSuccess callback called when the file successfully loads
     * @param onProgress callback called while file is loading (if the server supports this mode)
     * @param offlineProvider defines the offline provider for caching
     * @param useArrayBuffer defines a boolean indicating that date must be returned as ArrayBuffer
     * @param onError callback called when the file fails to load
     * @returns a file request object
     * @internal
     */
    static _FileToolsLoadFile(url: string, onSuccess: (data: string | ArrayBuffer, responseURL?: string) => void, onProgress?: (ev: ProgressEvent) => void, offlineProvider?: IOfflineProvider, useArrayBuffer?: boolean, onError?: (request?: WebRequest, exception?: LoadFileError) => void): IFileRequest;
    /**
     * An event triggered when the engine is disposed.
     */
    readonly onDisposeObservable: Observable<AbstractEngine>;
    /**
     * An event triggered when a global cleanup of all effects is required
     */
    readonly onReleaseEffectsObservable: Observable<AbstractEngine>;
    /**
     * Dispose and release all associated resources
     */
    dispose(): void;
    /**
     * Method called to create the default rescale post process on each engine.
     */
    static _RescalePostProcessFactory: Nullable<(engine: AbstractEngine) => PostProcess>;
    /**
     * Method called to create the default loading screen.
     * This can be overridden in your own app.
     * @param canvas The rendering canvas element
     */
    static DefaultLoadingScreenFactory(canvas: HTMLCanvasElement): ILoadingScreen;
    /**
     * Gets the audio engine
     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic
     * @deprecated please use AudioEngineV2 instead
     */
    static audioEngine: Nullable<IAudioEngine>;
    /**
     * Default AudioEngine factory responsible of creating the Audio Engine.
     * By default, this will create a BabylonJS Audio Engine if the workload has been embedded.
     * @deprecated please use AudioEngineV2 instead
     */
    static AudioEngineFactory: (hostElement: Nullable<HTMLElement>, audioContext: Nullable<AudioContext>, audioDestination: Nullable<AudioDestinationNode | MediaStreamAudioDestinationNode>) => IAudioEngine;
    /**
     * Default offline support factory responsible of creating a tool used to store data locally.
     * By default, this will create a Database object if the workload has been embedded.
     */
    static OfflineProviderFactory: (urlToScene: string, callbackManifestChecked: (checked: boolean) => any, disableManifestCheck: boolean) => IOfflineProvider;
    /**
     * Will flag all materials in all scenes in all engines as dirty to trigger new shader compilation
     * @param flag defines which part of the materials must be marked as dirty
     * @param predicate defines a predicate used to filter which materials should be affected
     */
    static MarkAllMaterialsAsDirty(flag: number, predicate?: (mat: Material) => boolean): void;
    /**
     * Gets or sets the epsilon value used by collision engine
     */
    static CollisionsEpsilon: number;
    /**
     * Queue a new function into the requested animation frame pool (ie. this function will be executed by the browser (or the javascript engine) for the next frame)
     * @param func - the function to be called
     * @param requester - the object that will request the next frame. Falls back to window.
     * @returns frame number
     */
    static QueueNewFrame: (func: () => void, requester?: any) => number;
    /**
     * @internal
     * Function used to get the correct texture loader for a specific extension.
     * @param extension defines the file extension of the file being loaded
     * @param mimeType defines the optional mime type of the file being loaded
     * @returns the IInternalTextureLoader or null if it wasn't found
     */
    static GetCompatibleTextureLoader(_extension: string, _mimeType?: string): Nullable<Promise<IInternalTextureLoader>>;
}

/**
 * Define an interface for a node to indicate it's info for accessibility.
 * By default, Node type doesn't imply accessibility info unless this tag is assigned. Whereas GUI controls already indicate accessibility info, but one can override the info using this tag.
 */
interface IAccessibilityTag {
    /**
     * A string as alt text of the node, describing what the node is/does, for accessibility purpose.
     */
    description?: string;
    /**
     * Customize the event of the accessible object.
     * This will be applied on the generated HTML twin node.
     */
    eventHandler?: {
        [key in keyof HTMLElementEventMap]: (e?: Event) => void;
    };
    /**
     * ARIA roles and attributes to customize accessibility support.
     * If you use BabylonJS's accessibility html twin renderer, and want to override the default behavior (not suggested), this can be your way.
     * Learn more about ARIA: https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA
     */
    role?: AcceptedRole;
    aria?: {
        [key in AcceptedARIA]: any;
    };
}
type AcceptedRole = "toolbar" | "tooltip" | "feed" | "math" | "presentation" | "none" | "note" | "application" | "article" | "cell" | "columnheader" | "definition" | "directory" | "document" | "figure" | "group" | "heading" | "img" | "list" | "listitem" | "meter" | "row" | "rowgroup" | "rowheader" | "separator" | "table" | "term" | "scrollbar" | "searchbox" | "slider" | "spinbutton" | "switch" | "tab" | "tabpanel" | "treeitem" | "combobox" | "menu" | "menubar" | "tablist" | "tree" | "treegrid" | "banner" | "complementary" | "contentinfo" | "form" | "main" | "navigation" | "region" | "search" | "alert" | "log" | "marquee" | "status" | "timer" | "alertdialog" | "dialog";
type AcceptedARIA = "aria-autocomplete" | "aria-checked" | "aria-disabled" | "aria-errormessage" | "aria-expanded" | "aria-haspopup" | "aria-hidden" | "aria-invalid" | "aria-label" | "aria-level" | "aria-modal" | "aria-multiline" | "aria-multiselectable" | "aria-orientation" | "aria-placeholder" | "aria-pressed" | "aria-readonly" | "aria-required" | "aria-selected" | "aria-sort" | "aria-valuemax" | "aria-valuemin" | "aria-valuenow" | "aria-valuetext" | "aria-busy" | "aria-live" | "aria-relevant" | "aria-atomic" | "aria-dropeffect" | "aria-grabbed" | "aria-activedescendant" | "aria-colcount" | "aria-colindex" | "aria-colspan" | "aria-controls" | "aria-describedby" | "aria-description" | "aria-details" | "aria-flowto" | "aria-labelledby" | "aria-owns" | "aria-posinset" | "aria-rowcount" | "aria-rowindex" | "aria-rowspan" | "aria-setsize";

/**
 * Defines how a node can be built from a string name.
 */
type NodeConstructor = (name: string, scene: Scene, options?: any) => () => Node;
/**
 * Node is the basic class for all scene objects (Mesh, Light, Camera.)
 */
declare class Node implements IBehaviorAware<Node> {
    protected _isDirty: boolean;
    /**
     * @internal
     */
    static _AnimationRangeFactory: (_name: string, _from: number, _to: number) => AnimationRange;
    private static _NodeConstructors;
    /**
     * Add a new node constructor
     * @param type defines the type name of the node to construct
     * @param constructorFunc defines the constructor function
     */
    static AddNodeConstructor(type: string, constructorFunc: NodeConstructor): void;
    /**
     * Returns a node constructor based on type name
     * @param type defines the type name
     * @param name defines the new node name
     * @param scene defines the hosting scene
     * @param options defines optional options to transmit to constructors
     * @returns the new constructor or null
     */
    static Construct(type: string, name: string, scene: Scene, options?: any): Nullable<() => Node>;
    private _nodeDataStorage;
    /**
     * Gets or sets the name of the node
     */
    name: string;
    /**
     * Gets or sets the id of the node
     */
    id: string;
    /**
     * Gets or sets the unique id of the node
     */
    uniqueId: number;
    /**
     * Gets or sets a string used to store user defined state for the node
     */
    state: string;
    /**
     * Gets or sets an object used to store user defined information for the node
     */
    metadata: any;
    /** @internal */
    _internalMetadata: any;
    /**
     * For internal use only. Please do not use.
     */
    reservedDataStore: any;
    /**
     * List of inspectable custom properties (used by the Inspector)
     * @see https://doc.babylonjs.com/toolsAndResources/inspector#extensibility
     */
    inspectableCustomProperties: IInspectable[];
    /**
     * Gets or sets the accessibility tag to describe the node for accessibility purpose.
     */
    set accessibilityTag(value: Nullable<IAccessibilityTag>);
    get accessibilityTag(): Nullable<IAccessibilityTag>;
    protected _accessibilityTag: Nullable<IAccessibilityTag>;
    /**
     * Observable fired when an accessibility tag is changed
     */
    onAccessibilityTagChangedObservable: Observable<Nullable<IAccessibilityTag>>;
    /**
     * Gets or sets a boolean used to define if the node must be serialized
     */
    get doNotSerialize(): boolean;
    set doNotSerialize(value: boolean);
    /** @internal */
    _parentContainer: Nullable<IAssetContainer>;
    /**
     * Gets a list of Animations associated with the node
     */
    animations: Animation[];
    protected _ranges: {
        [name: string]: Nullable<AnimationRange>;
    };
    /**
     * Callback raised when the node is ready to be used
     */
    onReady: Nullable<(node: Node) => void>;
    /** @internal */
    _currentRenderId: number;
    private _parentUpdateId;
    /** @internal */
    _childUpdateId: number;
    /** @internal */
    _waitingParentId: Nullable<string>;
    /** @internal */
    _waitingParentInstanceIndex: Nullable<string>;
    /** @internal */
    _waitingParsedUniqueId: Nullable<number>;
    /** @internal */
    _scene: Scene;
    /** @internal */
    _cache: any;
    protected _parentNode: Nullable<Node>;
    /** @internal */
    protected _children: Nullable<Node[]>;
    /** @internal */
    _worldMatrix: Matrix;
    /** @internal */
    _worldMatrixDeterminant: number;
    /** @internal */
    _worldMatrixDeterminantIsDirty: boolean;
    /**
     * Gets a boolean indicating if the node has been disposed
     * @returns true if the node was disposed
     */
    isDisposed(): boolean;
    /**
     * Gets or sets the parent of the node (without keeping the current position in the scene)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/parent_pivot/parent
     */
    set parent(parent: Nullable<Node>);
    get parent(): Nullable<Node>;
    /**
     * If set to true, this node, when renderable, will only be visible if its parent(s) are also visible.
     * @default false
     */
    get inheritVisibility(): boolean;
    set inheritVisibility(value: boolean);
    /**
     * Gets or sets a boolean indicating whether this node is visible, either this node itself when it is renderable or its renderable child nodes when `inheritVisibility` is true.
     * @default true
     */
    get isVisible(): boolean;
    set isVisible(value: boolean);
    /**
     * @internal
     */
    _serializeAsParent(serializationObject: any): void;
    /** @internal */
    _addToSceneRootNodes(): void;
    /** @internal */
    _removeFromSceneRootNodes(): void;
    private _animationPropertiesOverride;
    /**
     * Gets or sets the animation properties override
     */
    get animationPropertiesOverride(): Nullable<AnimationPropertiesOverride>;
    set animationPropertiesOverride(value: Nullable<AnimationPropertiesOverride>);
    /**
     * Gets a string identifying the name of the class
     * @returns "Node" string
     */
    getClassName(): string;
    /** @internal */
    readonly _isNode = true;
    /**
     * An event triggered when the mesh is disposed
     */
    onDisposeObservable: Observable<Node>;
    private _onDisposeObserver;
    /**
     * Sets a callback that will be raised when the node will be disposed
     */
    set onDispose(callback: () => void);
    /**
     * An event triggered when the enabled state of the node changes
     */
    get onEnabledStateChangedObservable(): Observable<boolean>;
    /**
     * An event triggered when the node is cloned
     */
    get onClonedObservable(): Observable<Node>;
    /**
     * Creates a new Node
     * @param name the name and id to be given to this node
     * @param scene the scene this node will be added to
     * @param isPure indicates this Node is just a Node, and not a derived class like Mesh or Camera
     */
    constructor(name: string, scene?: Nullable<Scene>, isPure?: boolean);
    /**
     * Gets the scene of the node
     * @returns a scene
     */
    getScene(): Scene;
    /**
     * Gets the engine of the node
     * @returns a Engine
     */
    getEngine(): AbstractEngine;
    private _behaviors;
    /**
     * Attach a behavior to the node
     * @see https://doc.babylonjs.com/features/featuresDeepDive/behaviors
     * @param behavior defines the behavior to attach
     * @param attachImmediately defines that the behavior must be attached even if the scene is still loading
     * @returns the current Node
     */
    addBehavior(behavior: Behavior<Node>, attachImmediately?: boolean): Node;
    /**
     * Remove an attached behavior
     * @see https://doc.babylonjs.com/features/featuresDeepDive/behaviors
     * @param behavior defines the behavior to attach
     * @returns the current Node
     */
    removeBehavior(behavior: Behavior<Node>): Node;
    /**
     * Gets the list of attached behaviors
     * @see https://doc.babylonjs.com/features/featuresDeepDive/behaviors
     */
    get behaviors(): Behavior<Node>[];
    /**
     * Gets an attached behavior by name
     * @param name defines the name of the behavior to look for
     * @see https://doc.babylonjs.com/features/featuresDeepDive/behaviors
     * @returns null if behavior was not found else the requested behavior
     */
    getBehaviorByName(name: string): Nullable<Behavior<Node>>;
    /**
     * Returns the latest update of the World matrix
     * @returns a Matrix
     */
    getWorldMatrix(): Matrix;
    /** @internal */
    _getWorldMatrixDeterminant(): number;
    /**
     * Returns directly the latest state of the mesh World matrix.
     * A Matrix is returned.
     */
    get worldMatrixFromCache(): Matrix;
    /** @internal */
    _initCache(): void;
    /**
     * @internal
     */
    updateCache(force?: boolean): void;
    /**
     * @internal
     */
    _getActionManagerForTrigger(trigger?: number, _initialCall?: boolean): Nullable<AbstractActionManager>;
    /**
     * @internal
     */
    _updateCache(_ignoreParentClass?: boolean): void;
    /** @internal */
    _isSynchronized(): boolean;
    /** @internal */
    _markSyncedWithParent(): void;
    /** @internal */
    isSynchronizedWithParent(): boolean;
    /** @internal */
    isSynchronized(): boolean;
    /**
     * Is this node ready to be used/rendered
     * @param _completeCheck defines if a complete check (including materials and lights) has to be done (false by default)
     * @returns true if the node is ready
     */
    isReady(_completeCheck?: boolean): boolean;
    /**
     * Flag the  node as dirty (Forcing it to update everything)
     * @param _property helps children apply precise "dirtyfication"
     * @returns this node
     */
    markAsDirty(_property?: string): Node;
    /**
     * Is this node enabled?
     * If the node has a parent, all ancestors will be checked and false will be returned if any are false (not enabled), otherwise will return true
     * @param checkAncestors indicates if this method should check the ancestors. The default is to check the ancestors. If set to false, the method will return the value of this node without checking ancestors
     * @returns whether this node (and its parent) is enabled
     */
    isEnabled(checkAncestors?: boolean): boolean;
    /** @internal */
    protected _syncParentEnabledState(): void;
    /**
     * Set the enabled state of this node
     * @param value defines the new enabled state
     */
    setEnabled(value: boolean): void;
    /**
     * Is this node a descendant of the given node?
     * The function will iterate up the hierarchy until the ancestor was found or no more parents defined
     * @param ancestor defines the parent node to inspect
     * @returns a boolean indicating if this node is a descendant of the given node
     */
    isDescendantOf(ancestor: Node): boolean;
    /**
     * @internal
     */
    _getDescendants(results: Node[], directDescendantsOnly?: boolean, predicate?: (node: Node) => boolean): void;
    /**
     * Will return all nodes that have this node as ascendant
     * @param directDescendantsOnly defines if true only direct descendants of 'this' will be considered, if false direct and also indirect (children of children, an so on in a recursive manner) descendants of 'this' will be considered
     * @param predicate defines an optional predicate that will be called on every evaluated child, the predicate must return true for a given child to be part of the result, otherwise it will be ignored
     * @returns all children nodes of all types
     */
    getDescendants<T extends Node>(directDescendantsOnly?: boolean, predicate?: (node: Node) => node is T): T[];
    /**
     * Will return all nodes that have this node as ascendant
     * @param directDescendantsOnly defines if true only direct descendants of 'this' will be considered, if false direct and also indirect (children of children, an so on in a recursive manner) descendants of 'this' will be considered
     * @param predicate defines an optional predicate that will be called on every evaluated child, the predicate must return true for a given child to be part of the result, otherwise it will be ignored
     * @returns all children nodes of all types
     */
    getDescendants(directDescendantsOnly?: boolean, predicate?: (node: Node) => boolean): Node[];
    /**
     * Get all child-meshes of this node
     * @param directDescendantsOnly defines if true only direct descendants of 'this' will be considered, if false direct and also indirect (children of children, an so on in a recursive manner) descendants of 'this' will be considered (Default: false)
     * @param predicate defines an optional predicate that will be called on every evaluated child, the predicate must return true for a given child to be part of the result, otherwise it will be ignored
     * @returns an array of AbstractMesh
     */
    getChildMeshes<T extends AbstractMesh>(directDescendantsOnly?: boolean, predicate?: (node: Node) => node is T): T[];
    /**
     * Get all child-meshes of this node
     * @param directDescendantsOnly defines if true only direct descendants of 'this' will be considered, if false direct and also indirect (children of children, an so on in a recursive manner) descendants of 'this' will be considered (Default: false)
     * @param predicate defines an optional predicate that will be called on every evaluated child, the predicate must return true for a given child to be part of the result, otherwise it will be ignored
     * @returns an array of AbstractMesh
     */
    getChildMeshes(directDescendantsOnly?: boolean, predicate?: (node: Node) => boolean): AbstractMesh[];
    /**
     * Get all direct children of this node
     * @param predicate defines an optional predicate that will be called on every evaluated child, the predicate must return true for a given child to be part of the result, otherwise it will be ignored
     * @param directDescendantsOnly defines if true only direct descendants of 'this' will be considered, if false direct and also indirect (children of children, an so on in a recursive manner) descendants of 'this' will be considered (Default: true)
     * @returns an array of Node
     */
    getChildren<T extends Node>(predicate?: (node: Node) => node is T, directDescendantsOnly?: boolean): T[];
    /**
     * Get all direct children of this node
     * @param predicate defines an optional predicate that will be called on every evaluated child, the predicate must return true for a given child to be part of the result, otherwise it will be ignored
     * @param directDescendantsOnly defines if true only direct descendants of 'this' will be considered, if false direct and also indirect (children of children, an so on in a recursive manner) descendants of 'this' will be considered (Default: true)
     * @returns an array of Node
     */
    getChildren(predicate?: (node: Node) => boolean, directDescendantsOnly?: boolean): Node[];
    /**
     * @internal
     */
    _setReady(state: boolean): void;
    /**
     * Get an animation by name
     * @param name defines the name of the animation to look for
     * @returns null if not found else the requested animation
     */
    getAnimationByName(name: string): Nullable<Animation>;
    /**
     * Creates an animation range for this node
     * @param name defines the name of the range
     * @param from defines the starting key
     * @param to defines the end key
     */
    createAnimationRange(name: string, from: number, to: number): void;
    /**
     * Delete a specific animation range
     * @param name defines the name of the range to delete
     * @param deleteFrames defines if animation frames from the range must be deleted as well
     */
    deleteAnimationRange(name: string, deleteFrames?: boolean): void;
    /**
     * Get an animation range by name
     * @param name defines the name of the animation range to look for
     * @returns null if not found else the requested animation range
     */
    getAnimationRange(name: string): Nullable<AnimationRange>;
    /**
     * Clone the current node
     * @param name Name of the new clone
     * @param newParent New parent for the clone
     * @param doNotCloneChildren Do not clone children hierarchy
     * @returns the new transform node
     */
    clone(name: string, newParent: Nullable<Node>, doNotCloneChildren?: boolean): Nullable<Node>;
    /**
     * Gets the list of all animation ranges defined on this node
     * @returns an array
     */
    getAnimationRanges(): Nullable<AnimationRange>[];
    /**
     * Will start the animation sequence
     * @param name defines the range frames for animation sequence
     * @param loop defines if the animation should loop (false by default)
     * @param speedRatio defines the speed factor in which to run the animation (1 by default)
     * @param onAnimationEnd defines a function to be executed when the animation ended (undefined by default)
     * @returns the object created for this animation. If range does not exist, it will return null
     */
    beginAnimation(name: string, loop?: boolean, speedRatio?: number, onAnimationEnd?: () => void): Nullable<Animatable>;
    /**
     * Serialize animation ranges into a JSON compatible object
     * @returns serialization object
     */
    serializeAnimationRanges(): any;
    /**
     * Computes the world matrix of the node
     * @param _force defines if the cache version should be invalidated forcing the world matrix to be created from scratch
     * @returns the world matrix
     */
    computeWorldMatrix(_force?: boolean): Matrix;
    /**
     * Releases resources associated with this node.
     * @param doNotRecurse Set to true to not recurse into each children (recurse into each children by default)
     * @param disposeMaterialAndTextures Set to true to also dispose referenced materials and textures (false by default)
     */
    dispose(doNotRecurse?: boolean, disposeMaterialAndTextures?: boolean): void;
    /**
     * Parse animation range data from a serialization object and store them into a given node
     * @param node defines where to store the animation ranges
     * @param parsedNode defines the serialization object to read data from
     * @param _scene defines the hosting scene
     */
    static ParseAnimationRanges(node: Node, parsedNode: any, _scene: Scene): void;
    /**
     * Return the minimum and maximum world vectors of the entire hierarchy under current node
     * @param includeDescendants Include bounding info from descendants as well (true by default)
     * @param predicate defines a callback function that can be customize to filter what meshes should be included in the list used to compute the bounding vectors
     * @returns the new bounding vectors
     */
    getHierarchyBoundingVectors(includeDescendants?: boolean, predicate?: Nullable<(abstractMesh: AbstractMesh) => boolean>): {
        min: Vector3;
        max: Vector3;
    };
}

/**
 * Oblique projection values
 */
interface IObliqueParams {
    /** The angle of the plane */
    angle: number;
    /** The length of the plane */
    length: number;
    /** The offset of the plane */
    offset: number;
}
/**
 * This is the base class of all the camera used in the application.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras
 */
declare class Camera extends Node {
    /**
     * @internal
     */
    static _CreateDefaultParsedCamera: (name: string, scene: Scene) => Camera;
    /**
     * This is the default projection mode used by the cameras.
     * It helps recreating a feeling of perspective and better appreciate depth.
     * This is the best way to simulate real life cameras.
     */
    static readonly PERSPECTIVE_CAMERA = 0;
    /**
     * This helps creating camera with an orthographic mode.
     * Orthographic is commonly used in engineering as a means to produce object specifications that communicate dimensions unambiguously, each line of 1 unit length (cm, meter..whatever) will appear to have the same length everywhere on the drawing. This allows the drafter to dimension only a subset of lines and let the reader know that other lines of that length on the drawing are also that length in reality. Every parallel line in the drawing is also parallel in the object.
     */
    static readonly ORTHOGRAPHIC_CAMERA = 1;
    /**
     * This is the default FOV mode for perspective cameras.
     * This setting aligns the upper and lower bounds of the viewport to the upper and lower bounds of the camera frustum.
     */
    static readonly FOVMODE_VERTICAL_FIXED = 0;
    /**
     * This setting aligns the left and right bounds of the viewport to the left and right bounds of the camera frustum.
     */
    static readonly FOVMODE_HORIZONTAL_FIXED = 1;
    /**
     * This specifies there is no need for a camera rig.
     * Basically only one eye is rendered corresponding to the camera.
     */
    static readonly RIG_MODE_NONE = 0;
    /**
     * Simulates a camera Rig with one blue eye and one red eye.
     * This can be use with 3d blue and red glasses.
     */
    static readonly RIG_MODE_STEREOSCOPIC_ANAGLYPH = 10;
    /**
     * Defines that both eyes of the camera will be rendered side by side with a parallel target.
     */
    static readonly RIG_MODE_STEREOSCOPIC_SIDEBYSIDE_PARALLEL = 11;
    /**
     * Defines that both eyes of the camera will be rendered side by side with a none parallel target.
     */
    static readonly RIG_MODE_STEREOSCOPIC_SIDEBYSIDE_CROSSEYED = 12;
    /**
     * Defines that both eyes of the camera will be rendered over under each other.
     */
    static readonly RIG_MODE_STEREOSCOPIC_OVERUNDER = 13;
    /**
     * Defines that both eyes of the camera will be rendered on successive lines interlaced for passive 3d monitors.
     */
    static readonly RIG_MODE_STEREOSCOPIC_INTERLACED = 14;
    /**
     * Defines that both eyes of the camera should be renderered in a VR mode (carbox).
     */
    static readonly RIG_MODE_VR = 20;
    /**
     * Custom rig mode allowing rig cameras to be populated manually with any number of cameras
     */
    static readonly RIG_MODE_CUSTOM = 22;
    /**
     * Defines if by default attaching controls should prevent the default javascript event to continue.
     */
    static ForceAttachControlToAlwaysPreventDefault: boolean;
    /**
     * Define the input manager associated with the camera.
     */
    inputs: CameraInputsManager<Camera>;
    /** @internal */
    _position: Vector3;
    /**
     * Define the current local position of the camera in the scene
     */
    get position(): Vector3;
    set position(newPosition: Vector3);
    protected _upVector: Vector3;
    /**
     * The vector the camera should consider as up.
     * (default is Vector3(0, 1, 0) aka Vector3.Up())
     */
    set upVector(vec: Vector3);
    get upVector(): Vector3;
    /**
     * Object containing oblique projection values (only used with ORTHOGRAPHIC_CAMERA)
     */
    oblique: Nullable<IObliqueParams>;
    /**
     * The screen area in scene units squared
     */
    get screenArea(): number;
    private _orthoLeft;
    /**
     * Define the current limit on the left side for an orthographic camera
     * In scene unit
     */
    set orthoLeft(value: Nullable<number>);
    get orthoLeft(): Nullable<number>;
    private _orthoRight;
    /**
     * Define the current limit on the right side for an orthographic camera
     * In scene unit
     */
    set orthoRight(value: Nullable<number>);
    get orthoRight(): Nullable<number>;
    private _orthoBottom;
    /**
     * Define the current limit on the bottom side for an orthographic camera
     * In scene unit
     */
    set orthoBottom(value: Nullable<number>);
    get orthoBottom(): Nullable<number>;
    private _orthoTop;
    /**
     * Define the current limit on the top side for an orthographic camera
     * In scene unit
     */
    set orthoTop(value: Nullable<number>);
    get orthoTop(): Nullable<number>;
    /**
     * Field Of View is set in Radians. (default is 0.8)
     */
    fov: number;
    /**
     * Sets the camera's field of view in radians based on the focal length and sensor size.
     * @param value the focal length of the camera in mm.
     * @param sensorSize the sensor width size of the camera in mm. (default is 36mm, which is a full frame sensor)
     */
    setFocalLength(value: number, sensorSize?: number): void;
    /**
     * Projection plane tilt around the X axis (horizontal), set in Radians. (default is 0)
     * Can be used to make vertical lines in world space actually vertical on the screen.
     * See https://forum.babylonjs.com/t/add-vertical-shift-to-3ds-max-exporter-babylon-cameras/17480
     */
    projectionPlaneTilt: number;
    /**
     * Define the minimum distance the camera can see from.
     * This is important to note that the depth buffer are not infinite and the closer it starts
     * the more your scene might encounter depth fighting issue.
     */
    minZ: number;
    /**
     * Define the maximum distance the camera can see to.  (default is 10000)
     * This is important to note that the depth buffer are not infinite and the further it end
     * the more your scene might encounter depth fighting issue.
     */
    maxZ: number;
    /**
     * Define the default inertia of the camera.
     * This helps giving a smooth feeling to the camera movement.
     */
    inertia: number;
    private _mode;
    /**
     * Define the mode of the camera (Camera.PERSPECTIVE_CAMERA or Camera.ORTHOGRAPHIC_CAMERA)
     */
    set mode(mode: number);
    get mode(): number;
    /**
     * Define whether the camera is intermediate.
     * This is useful to not present the output directly to the screen in case of rig without post process for instance
     */
    isIntermediate: boolean;
    /**
     * Define the viewport of the camera.
     * This correspond to the portion of the screen the camera will render to in normalized 0 to 1 unit.
     */
    viewport: Viewport;
    /**
     * Restricts the camera to viewing objects with the same layerMask.
     * A camera with a layerMask of 1 will render mesh.layerMask & camera.layerMask!== 0
     */
    layerMask: number;
    /**
     * fovMode sets the camera frustum bounds to the viewport bounds. (default is FOVMODE_VERTICAL_FIXED)
     */
    fovMode: number;
    /**
     * Rig mode of the camera.
     * This is useful to create the camera with two "eyes" instead of one to create VR or stereoscopic scenes.
     * This is normally controlled byt the camera themselves as internal use.
     */
    cameraRigMode: number;
    /**
     * Defines the distance between both "eyes" in case of a RIG
     */
    interaxialDistance: number;
    /**
     * Defines if stereoscopic rendering is done side by side or over under.
     */
    isStereoscopicSideBySide: boolean;
    /**
     * Ignores camera maxZ when computing the projection matrix (ie. use 0 instead of maxZ), meaning objects won't be culled by the far plane
     */
    ignoreCameraMaxZ: boolean;
    /**
     * Defines the list of custom render target which are rendered to and then used as the input to this camera's render. Eg. display another camera view on a TV in the main scene
     * This is pretty helpful if you wish to make a camera render to a texture you could reuse somewhere
     * else in the scene. (Eg. security camera)
     *
     * To change the final output target of the camera, camera.outputRenderTarget should be used instead (eg. webXR renders to a render target corresponding to an HMD)
     */
    customRenderTargets: RenderTargetTexture[];
    /**
     * When set, the camera will render to this render target instead of the default canvas
     *
     * If the desire is to use the output of a camera as a texture in the scene consider using camera.customRenderTargets instead
     */
    outputRenderTarget: Nullable<RenderTargetTexture>;
    /**
     * Observable triggered when the camera view matrix has changed.
     * Beware of reentrance! Some methods like Camera.getViewMatrix and Camera.getWorldMatrix can trigger the onViewMatrixChangedObservable
     * observable, so using them inside an observer will require additional logic to avoid a stack overflow error.
     */
    onViewMatrixChangedObservable: Observable<Camera>;
    /**
     * Observable triggered when the camera Projection matrix has changed.
     */
    onProjectionMatrixChangedObservable: Observable<Camera>;
    /**
     * Observable triggered when the inputs have been processed.
     */
    onAfterCheckInputsObservable: Observable<Camera>;
    /**
     * Observable triggered when reset has been called and applied to the camera.
     */
    onRestoreStateObservable: Observable<Camera>;
    /**
     * Is this camera a part of a rig system?
     */
    isRigCamera: boolean;
    /**
     * If isRigCamera set to true this will be set with the parent camera.
     * The parent camera is not (!) necessarily the .parent of this camera (like in the case of XR)
     */
    rigParent?: Camera;
    /**
     * Render pass id used by the camera to render into the main framebuffer
     */
    renderPassId: number;
    private _hasMoved;
    /**
     * Gets a flag indicating that the camera has moved in some way since the last call to Camera.update()
     */
    get hasMoved(): boolean;
    /** @internal */
    _cameraRigParams: any;
    /** @internal */
    _rigCameras: Camera[];
    /** @internal */
    _rigPostProcess: Nullable<PostProcess>;
    /** @internal */
    _skipRendering: boolean;
    /** @internal */
    _projectionMatrix: Matrix;
    /** @internal */
    _postProcesses: Nullable<PostProcess>[];
    /** @internal */
    _activeMeshes: SmartArray<AbstractMesh>;
    protected _globalPosition: Vector3;
    /** @internal */
    _computedViewMatrix: Matrix;
    private _doNotComputeProjectionMatrix;
    private _transformMatrix;
    /** @internal */
    _frustumPlanes: Plane[];
    private _refreshFrustumPlanes;
    private _storedFov;
    private _stateStored;
    private _absoluteRotation;
    /**
     * Instantiates a new camera object.
     * This should not be used directly but through the inherited cameras: ArcRotate, Free...
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras
     * @param name Defines the name of the camera in the scene
     * @param position Defines the position of the camera
     * @param scene Defines the scene the camera belongs too
     * @param setActiveOnSceneIfNoneActive Defines if the camera should be set as active after creation if no other camera have been defined in the scene
     */
    constructor(name: string, position: Vector3, scene?: Scene, setActiveOnSceneIfNoneActive?: boolean);
    /**
     * Store current camera state (fov, position, etc..)
     * @returns the camera
     */
    storeState(): Camera;
    /**
     * Returns true if a state has been stored by calling storeState method.
     * @returns true if state has been stored.
     */
    hasStateStored(): boolean;
    /**
     * Restores the camera state values if it has been stored. You must call storeState() first
     * @returns true if restored and false otherwise
     */
    protected _restoreStateValues(): boolean;
    /**
     * Restored camera state. You must call storeState() first.
     * @returns true if restored and false otherwise
     */
    restoreState(): boolean;
    /**
     * Gets the class name of the camera.
     * @returns the class name
     */
    getClassName(): string;
    /** @internal */
    readonly _isCamera = true;
    /**
     * Gets a string representation of the camera useful for debug purpose.
     * @param fullDetails Defines that a more verbose level of logging is required
     * @returns the string representation
     */
    toString(fullDetails?: boolean): string;
    /**
     * Automatically tilts the projection plane, using `projectionPlaneTilt`, to correct the perspective effect on vertical lines.
     */
    applyVerticalCorrection(): void;
    /**
     * Gets the current world space position of the camera.
     */
    get globalPosition(): Vector3;
    /**
     * Gets the list of active meshes this frame (meshes no culled or excluded by lod s in the frame)
     * @returns the active meshe list
     */
    getActiveMeshes(): SmartArray<AbstractMesh>;
    /**
     * Check whether a mesh is part of the current active mesh list of the camera
     * @param mesh Defines the mesh to check
     * @returns true if active, false otherwise
     */
    isActiveMesh(mesh: Mesh): boolean;
    /**
     * Is this camera ready to be used/rendered
     * @param completeCheck defines if a complete check (including post processes) has to be done (false by default)
     * @returns true if the camera is ready
     */
    isReady(completeCheck?: boolean): boolean;
    /** @internal */
    _initCache(): void;
    /**
     * @internal
     */
    _updateCache(ignoreParentClass?: boolean): void;
    /** @internal */
    _isSynchronized(): boolean;
    /** @internal */
    _isSynchronizedViewMatrix(): boolean;
    /** @internal */
    _isSynchronizedProjectionMatrix(): boolean;
    /**
     * Attach the input controls to a specific dom element to get the input from.
     * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     */
    attachControl(noPreventDefault?: boolean): void;
    /**
     * Attach the input controls to a specific dom element to get the input from.
     * @param ignored defines an ignored parameter kept for backward compatibility.
     * @param noPreventDefault Defines whether event caught by the controls should call preventdefault() (https://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault)
     * BACK COMPAT SIGNATURE ONLY.
     */
    attachControl(ignored: any, noPreventDefault?: boolean): void;
    /**
     * Detach the current controls from the specified dom element.
     */
    detachControl(): void;
    /**
     * Detach the current controls from the specified dom element.
     * @param ignored defines an ignored parameter kept for backward compatibility.
     */
    detachControl(ignored?: any): void;
    /**
     * Update the camera state according to the different inputs gathered during the frame.
     */
    update(): void;
    /** @internal */
    _checkInputs(): void;
    /** @internal */
    get rigCameras(): Camera[];
    /**
     * Gets the post process used by the rig cameras
     */
    get rigPostProcess(): Nullable<PostProcess>;
    /**
     * Internal, gets the first post process.
     * @returns the first post process to be run on this camera.
     */
    _getFirstPostProcess(): Nullable<PostProcess>;
    private _cascadePostProcessesToRigCams;
    /**
     * Attach a post process to the camera.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/usePostProcesses#attach-postprocess
     * @param postProcess The post process to attach to the camera
     * @param insertAt The position of the post process in case several of them are in use in the scene
     * @returns the position the post process has been inserted at
     */
    attachPostProcess(postProcess: PostProcess, insertAt?: Nullable<number>): number;
    /**
     * Detach a post process to the camera.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/usePostProcesses#attach-postprocess
     * @param postProcess The post process to detach from the camera
     */
    detachPostProcess(postProcess: PostProcess): void;
    /**
     * Gets the current world matrix of the camera
     * @returns the world matrix
     */
    getWorldMatrix(): Matrix;
    /** @internal */
    _getViewMatrix(): Matrix;
    /**
     * Gets the current view matrix of the camera.
     * @param force forces the camera to recompute the matrix without looking at the cached state
     * @returns the view matrix
     */
    getViewMatrix(force?: boolean): Matrix;
    /**
     * Freeze the projection matrix.
     * It will prevent the cache check of the camera projection compute and can speed up perf
     * if no parameter of the camera are meant to change
     * @param projection Defines manually a projection if necessary
     */
    freezeProjectionMatrix(projection?: Matrix): void;
    /**
     * Unfreeze the projection matrix if it has previously been freezed by freezeProjectionMatrix.
     */
    unfreezeProjectionMatrix(): void;
    /**
     * Gets the current projection matrix of the camera.
     * @param force forces the camera to recompute the matrix without looking at the cached state
     * @returns the projection matrix
     */
    getProjectionMatrix(force?: boolean): Matrix;
    /**
     * Gets the transformation matrix (ie. the multiplication of view by projection matrices)
     * @returns a Matrix
     */
    getTransformationMatrix(): Matrix;
    private _computeObliqueDistance;
    /** @internal */
    _updateFrustumPlanes(): void;
    /**
     * Checks if a cullable object (mesh...) is in the camera frustum
     * This checks the bounding box center. See isCompletelyInFrustum for a full bounding check
     * @param target The object to check
     * @param checkRigCameras If the rig cameras should be checked (eg. with VR camera both eyes should be checked) (Default: false)
     * @returns true if the object is in frustum otherwise false
     */
    isInFrustum(target: ICullable, checkRigCameras?: boolean): boolean;
    /**
     * Checks if a cullable object (mesh...) is in the camera frustum
     * Unlike isInFrustum this checks the full bounding box
     * @param target The object to check
     * @returns true if the object is in frustum otherwise false
     */
    isCompletelyInFrustum(target: ICullable): boolean;
    /**
     * Gets a ray in the forward direction from the camera.
     * @param length Defines the length of the ray to create
     * @param transform Defines the transform to apply to the ray, by default the world matrix is used to create a world space ray
     * @param origin Defines the start point of the ray which defaults to the camera position
     * @returns the forward ray
     */
    getForwardRay(length?: number, transform?: Matrix, origin?: Vector3): Ray;
    /**
     * Gets a ray in the forward direction from the camera.
     * @param refRay the ray to (re)use when setting the values
     * @param length Defines the length of the ray to create
     * @param transform Defines the transform to apply to the ray, by default the world matrix is used to create a world space ray
     * @param origin Defines the start point of the ray which defaults to the camera position
     * @returns the forward ray
     */
    getForwardRayToRef(refRay: Ray, length?: number, transform?: Matrix, origin?: Vector3): Ray;
    /**
     * Releases resources associated with this node.
     * @param doNotRecurse Set to true to not recurse into each children (recurse into each children by default)
     * @param disposeMaterialAndTextures Set to true to also dispose referenced materials and textures (false by default)
     */
    dispose(doNotRecurse?: boolean, disposeMaterialAndTextures?: boolean): void;
    /** @internal */
    _isLeftCamera: boolean;
    /**
     * Gets the left camera of a rig setup in case of Rigged Camera
     */
    get isLeftCamera(): boolean;
    /** @internal */
    _isRightCamera: boolean;
    /**
     * Gets the right camera of a rig setup in case of Rigged Camera
     */
    get isRightCamera(): boolean;
    /**
     * Gets the left camera of a rig setup in case of Rigged Camera
     */
    get leftCamera(): Nullable<FreeCamera>;
    /**
     * Gets the right camera of a rig setup in case of Rigged Camera
     */
    get rightCamera(): Nullable<FreeCamera>;
    /**
     * Gets the left camera target of a rig setup in case of Rigged Camera
     * @returns the target position
     */
    getLeftTarget(): Nullable<Vector3>;
    /**
     * Gets the right camera target of a rig setup in case of Rigged Camera
     * @returns the target position
     */
    getRightTarget(): Nullable<Vector3>;
    /**
     * @internal
     */
    setCameraRigMode(mode: number, rigParams: any): void;
    protected _setRigMode(rigParams: any): void;
    /** @internal */
    _getVRProjectionMatrix(): Matrix;
    /**
     * @internal
     */
    setCameraRigParameter(name: string, value: any): void;
    /**
     * needs to be overridden by children so sub has required properties to be copied
     * @internal
     */
    createRigCamera(name: string, cameraIndex: number): Nullable<Camera>;
    /**
     * May need to be overridden by children
     * @internal
     */
    _updateRigCameras(): void;
    /** @internal */
    _setupInputs(): void;
    /**
     * Serialiaze the camera setup to a json representation
     * @returns the JSON representation
     */
    serialize(): any;
    /**
     * Clones the current camera.
     * @param name The cloned camera name
     * @param newParent The cloned camera's new parent (none by default)
     * @returns the cloned camera
     */
    clone(name: string, newParent?: Nullable<Node>): Camera;
    /**
     * Gets the direction of the camera relative to a given local axis.
     * @param localAxis Defines the reference axis to provide a relative direction.
     * @returns the direction
     */
    getDirection(localAxis: DeepImmutable<Vector3>): Vector3;
    /**
     * Returns the current camera absolute rotation
     */
    get absoluteRotation(): Quaternion;
    /**
     * Gets the direction of the camera relative to a given local axis into a passed vector.
     * @param localAxis Defines the reference axis to provide a relative direction.
     * @param result Defines the vector to store the result in
     */
    getDirectionToRef(localAxis: DeepImmutable<Vector3>, result: Vector3): void;
    /**
     * Gets a camera constructor for a given camera type
     * @param type The type of the camera to construct (should be equal to one of the camera class name)
     * @param name The name of the camera the result will be able to instantiate
     * @param scene The scene the result will construct the camera in
     * @param interaxial_distance In case of stereoscopic setup, the distance between both eyes
     * @param isStereoscopicSideBySide In case of stereoscopic setup, should the sereo be side b side
     * @returns a factory method to construct the camera
     */
    static GetConstructorFromName(type: string, name: string, scene: Scene, interaxial_distance?: number, isStereoscopicSideBySide?: boolean): () => Camera;
    /**
     * Compute the world  matrix of the camera.
     * @returns the camera world matrix
     */
    computeWorldMatrix(): Matrix;
    /**
     * Parse a JSON and creates the camera from the parsed information
     * @param parsedCamera The JSON to parse
     * @param scene The scene to instantiate the camera in
     * @returns the newly constructed camera
     */
    static Parse(parsedCamera: any, scene: Scene): Camera;
    /** @internal */
    _calculateHandednessMultiplier(): number;
}

/**
 * A TransformNode is an object that is not rendered but can be used as a center of transformation. This can decrease memory usage and increase rendering speed compared to using an empty mesh as a parent and is less complicated than using a pivot matrix.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/parent_pivot/transform_node
 */
declare class TransformNode extends Node {
    /**
     * Object will not rotate to face the camera
     */
    static BILLBOARDMODE_NONE: number;
    /**
     * Object will rotate to face the camera but only on the x axis
     */
    static BILLBOARDMODE_X: number;
    /**
     * Object will rotate to face the camera but only on the y axis
     */
    static BILLBOARDMODE_Y: number;
    /**
     * Object will rotate to face the camera but only on the z axis
     */
    static BILLBOARDMODE_Z: number;
    /**
     * Object will rotate to face the camera
     */
    static BILLBOARDMODE_ALL: number;
    /**
     * Object will rotate to face the camera's position instead of orientation
     */
    static BILLBOARDMODE_USE_POSITION: number;
    /**
     * Child transform with Billboard flags should or should not apply parent rotation (default if off)
     */
    static BillboardUseParentOrientation: boolean;
    private static _TmpRotation;
    private static _TmpScaling;
    private static _TmpTranslation;
    private static _TmpRHRestore;
    private _forward;
    private _up;
    private _right;
    private _position;
    private _rotation;
    private _rotationQuaternion;
    protected _scaling: Vector3;
    private _transformToBoneReferal;
    private _currentParentWhenAttachingToBone;
    private _isAbsoluteSynced;
    private _billboardMode;
    /**
     * Gets or sets the billboard mode. Default is 0.
     *
     * | Value | Type | Description |
     * | --- | --- | --- |
     * | 0 | BILLBOARDMODE_NONE |  |
     * | 1 | BILLBOARDMODE_X |  |
     * | 2 | BILLBOARDMODE_Y |  |
     * | 4 | BILLBOARDMODE_Z |  |
     * | 7 | BILLBOARDMODE_ALL |  |
     *
     */
    get billboardMode(): number;
    set billboardMode(value: number);
    /**
     * Multiplication factor on scale x/y/z when computing the world matrix. Eg. for a 1x1x1 cube setting this to 2 will make it a 2x2x2 cube
     */
    scalingDeterminant: number;
    private _infiniteDistance;
    /**
     * Gets or sets the distance of the object to max, often used by skybox
     */
    get infiniteDistance(): boolean;
    set infiniteDistance(value: boolean);
    /**
     * Gets or sets a boolean indicating that non uniform scaling (when at least one component is different from others) should be ignored.
     * By default the system will update normals to compensate
     */
    ignoreNonUniformScaling: boolean;
    /**
     * Gets or sets a boolean indicating that even if rotationQuaternion is defined, you can keep updating rotation property and Babylon.js will just mix both
     */
    reIntegrateRotationIntoRotationQuaternion: boolean;
    /** @internal */
    _poseMatrix: Nullable<Matrix>;
    /** @internal */
    _localMatrix: Matrix;
    private _usePivotMatrix;
    private _absolutePosition;
    private _absoluteScaling;
    private _absoluteRotationQuaternion;
    private _pivotMatrix;
    private _pivotMatrixInverse;
    /** @internal */
    _postMultiplyPivotMatrix: boolean;
    protected _isWorldMatrixFrozen: boolean;
    /** @internal */
    _indexInSceneTransformNodesArray: number;
    /**
     * An event triggered after the world matrix is updated
     */
    onAfterWorldMatrixUpdateObservable: Observable<TransformNode>;
    constructor(name: string, scene?: Nullable<Scene>, isPure?: boolean);
    /**
     * Gets a string identifying the name of the class
     * @returns "TransformNode" string
     */
    getClassName(): string;
    /**
     * Gets or set the node position (default is (0.0, 0.0, 0.0))
     */
    get position(): Vector3;
    set position(newPosition: Vector3);
    /**
     * return true if a pivot has been set
     * @returns true if a pivot matrix is used
     */
    isUsingPivotMatrix(): boolean;
    /**
     * @returns true if pivot matrix must be cancelled in the world matrix. When this parameter is set to true (default), the inverse of the pivot matrix is also applied at the end to cancel the transformation effect.
     */
    isUsingPostMultiplyPivotMatrix(): boolean;
    /**
     * Gets or sets the rotation property : a Vector3 defining the rotation value in radians around each local axis X, Y, Z  (default is (0.0, 0.0, 0.0)).
     * If rotation quaternion is set, this Vector3 will be ignored and copy from the quaternion
     */
    get rotation(): Vector3;
    set rotation(newRotation: Vector3);
    /**
     * Gets or sets the scaling property : a Vector3 defining the node scaling along each local axis X, Y, Z (default is (1.0, 1.0, 1.0)).
     */
    get scaling(): Vector3;
    set scaling(newScaling: Vector3);
    /**
     * Gets or sets the rotation Quaternion property : this a Quaternion object defining the node rotation by using a unit quaternion (undefined by default, but can be null).
     * If set, only the rotationQuaternion is then used to compute the node rotation (ie. node.rotation will be ignored)
     */
    get rotationQuaternion(): Nullable<Quaternion>;
    set rotationQuaternion(quaternion: Nullable<Quaternion>);
    /**
     * Allow user to specify custom mechanism for mark as dirty
     */
    customMarkAsDirty: () => void;
    private _markAsDirtyInternal;
    /**
     * The forward direction of that transform in world space.
     */
    get forward(): Vector3;
    /**
     * The up direction of that transform in world space.
     */
    get up(): Vector3;
    /**
     * The right direction of that transform in world space.
     */
    get right(): Vector3;
    /**
     * Copies the parameter passed Matrix into the mesh Pose matrix.
     * @param matrix the matrix to copy the pose from
     * @returns this TransformNode.
     */
    updatePoseMatrix(matrix: Matrix): TransformNode;
    /**
     * Returns the mesh Pose matrix.
     * @returns the pose matrix
     */
    getPoseMatrix(): Matrix;
    /** @internal */
    _isSynchronized(): boolean;
    /** @internal */
    _initCache(): void;
    /**
     * Returns the current mesh absolute position.
     * Returns a Vector3.
     */
    get absolutePosition(): Vector3;
    /**
     * Returns the current mesh absolute scaling.
     * Returns a Vector3.
     */
    get absoluteScaling(): Vector3;
    /**
     * Returns the current mesh absolute rotation.
     * Returns a Quaternion.
     */
    get absoluteRotationQuaternion(): Quaternion;
    /**
     * Sets a new matrix to apply before all other transformation
     * @param matrix defines the transform matrix
     * @returns the current TransformNode
     */
    setPreTransformMatrix(matrix: Matrix): TransformNode;
    /**
     * Sets a new pivot matrix to the current node
     * @param matrix defines the new pivot matrix to use
     * @param postMultiplyPivotMatrix defines if the pivot matrix must be cancelled in the world matrix. When this parameter is set to true (default), the inverse of the pivot matrix is also applied at the end to cancel the transformation effect
     * @returns the current TransformNode
     */
    setPivotMatrix(matrix: DeepImmutable<Matrix>, postMultiplyPivotMatrix?: boolean): TransformNode;
    /**
     * Returns the mesh pivot matrix.
     * Default : Identity.
     * @returns the matrix
     */
    getPivotMatrix(): Matrix;
    /**
     * Instantiate (when possible) or clone that node with its hierarchy
     * @param newParent defines the new parent to use for the instance (or clone)
     * @param options defines options to configure how copy is done
     * @param options.doNotInstantiate defines if the model must be instantiated or just cloned
     * @param onNewNodeCreated defines an option callback to call when a clone or an instance is created
     * @returns an instance (or a clone) of the current node with its hierarchy
     */
    instantiateHierarchy(newParent?: Nullable<TransformNode>, options?: {
        doNotInstantiate: boolean | ((node: TransformNode) => boolean);
    }, onNewNodeCreated?: (source: TransformNode, clone: TransformNode) => void): Nullable<TransformNode>;
    /**
     * Prevents the World matrix to be computed any longer.
     * Please note that the "moral" contract is that the world matrix is not going to be updated anymore. It is up to the developer to force updates.
     * You trade flexibility for performance. If you want to update it, you have to unfreeze it first.
     * @param newWorldMatrix defines an optional matrix to use as world matrix
     * @param decompose defines whether to decompose the given newWorldMatrix or directly assign
     * @returns the TransformNode.
     */
    freezeWorldMatrix(newWorldMatrix?: Nullable<Matrix>, decompose?: boolean): TransformNode;
    /**
     * Allows back the World matrix computation.
     * @returns the TransformNode.
     */
    unfreezeWorldMatrix(): this;
    /**
     * True if the World matrix has been frozen.
     */
    get isWorldMatrixFrozen(): boolean;
    /**
     * Returns the mesh absolute position in the World.
     * @returns a Vector3.
     */
    getAbsolutePosition(): Vector3;
    /**
     * Sets the mesh absolute position in the World from a Vector3 or an Array(3).
     * @param absolutePosition the absolute position to set
     * @returns the TransformNode.
     */
    setAbsolutePosition(absolutePosition: Vector3): TransformNode;
    /**
     * Sets the mesh position in its local space.
     * @param vector3 the position to set in localspace
     * @returns the TransformNode.
     */
    setPositionWithLocalVector(vector3: Vector3): TransformNode;
    /**
     * Returns the mesh position in the local space from the current World matrix values.
     * @returns a new Vector3.
     */
    getPositionExpressedInLocalSpace(): Vector3;
    /**
     * Translates the mesh along the passed Vector3 in its local space.
     * @param vector3 the distance to translate in localspace
     * @returns the TransformNode.
     */
    locallyTranslate(vector3: Vector3): TransformNode;
    private static _LookAtVectorCache;
    /**
     * Orients a mesh towards a target point. Mesh must be drawn facing user.
     * @param targetPoint the position (must be in same space as current mesh) to look at
     * @param yawCor optional yaw (y-axis) correction in radians
     * @param pitchCor optional pitch (x-axis) correction in radians
     * @param rollCor optional roll (z-axis) correction in radians
     * @param space the chosen space of the target
     * @returns the TransformNode.
     */
    lookAt(targetPoint: Vector3, yawCor?: number, pitchCor?: number, rollCor?: number, space?: Space): TransformNode;
    /**
     * Returns a new Vector3 that is the localAxis, expressed in the mesh local space, rotated like the mesh.
     * This Vector3 is expressed in the World space.
     * @param localAxis axis to rotate
     * @returns a new Vector3 that is the localAxis, expressed in the mesh local space, rotated like the mesh.
     */
    getDirection(localAxis: Vector3): Vector3;
    /**
     * Sets the Vector3 "result" as the rotated Vector3 "localAxis" in the same rotation than the mesh.
     * localAxis is expressed in the mesh local space.
     * result is computed in the World space from the mesh World matrix.
     * @param localAxis axis to rotate
     * @param result the resulting transformnode
     * @returns this TransformNode.
     */
    getDirectionToRef(localAxis: Vector3, result: Vector3): TransformNode;
    /**
     * Sets this transform node rotation to the given local axis.
     * @param localAxis the axis in local space
     * @param yawCor optional yaw (y-axis) correction in radians
     * @param pitchCor optional pitch (x-axis) correction in radians
     * @param rollCor optional roll (z-axis) correction in radians
     * @returns this TransformNode
     */
    setDirection(localAxis: Vector3, yawCor?: number, pitchCor?: number, rollCor?: number): TransformNode;
    /**
     * Sets a new pivot point to the current node
     * @param point defines the new pivot point to use
     * @param space defines if the point is in world or local space (local by default)
     * @returns the current TransformNode
     */
    setPivotPoint(point: Vector3, space?: Space): TransformNode;
    /**
     * Returns a new Vector3 set with the mesh pivot point coordinates in the local space.
     * @returns the pivot point
     */
    getPivotPoint(): Vector3;
    /**
     * Sets the passed Vector3 "result" with the coordinates of the mesh pivot point in the local space.
     * @param result the vector3 to store the result
     * @returns this TransformNode.
     */
    getPivotPointToRef(result: Vector3): TransformNode;
    /**
     * Returns a new Vector3 set with the mesh pivot point World coordinates.
     * @returns a new Vector3 set with the mesh pivot point World coordinates.
     */
    getAbsolutePivotPoint(): Vector3;
    /**
     * Sets the Vector3 "result" coordinates with the mesh pivot point World coordinates.
     * @param result vector3 to store the result
     * @returns this TransformNode.
     */
    getAbsolutePivotPointToRef(result: Vector3): TransformNode;
    /**
     * Flag the transform node as dirty (Forcing it to update everything)
     * @param property if set to "rotation" the objects rotationQuaternion will be set to null
     * @returns this  node
     */
    markAsDirty(property?: string): Node;
    /**
     * Defines the passed node as the parent of the current node.
     * The node will remain exactly where it is and its position / rotation will be updated accordingly.
     * If you don't want to preserve the current rotation / position, assign the parent through parent accessor.
     * Note that if the mesh has a pivot matrix / point defined it will be applied after the parent was updated.
     * In that case the node will not remain in the same space as it is, as the pivot will be applied.
     * To avoid this, you can set updatePivot to true and the pivot will be updated to identity
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/parent_pivot/parent
     * @param node the node ot set as the parent
     * @param preserveScalingSign if true, keep scaling sign of child. Otherwise, scaling sign might change.
     * @param updatePivot if true, update the pivot matrix to keep the node in the same space as before
     * @returns this TransformNode.
     */
    setParent(node: Nullable<Node>, preserveScalingSign?: boolean, updatePivot?: boolean): TransformNode;
    /**
     * Adds the passed mesh as a child to the current mesh.
     * The node will remain exactly where it is and its position / rotation will be updated accordingly.
     * This method is equivalent to calling setParent().
     * @param mesh defines the child mesh
     * @param preserveScalingSign if true, keep scaling sign of child. Otherwise, scaling sign might change.
     * @returns the current mesh
     */
    addChild(mesh: TransformNode, preserveScalingSign?: boolean): this;
    /**
     * Removes the passed mesh from the current mesh children list
     * @param mesh defines the child mesh
     * @param preserveScalingSign if true, keep scaling sign of child. Otherwise, scaling sign might change.
     * @returns the current mesh
     */
    removeChild(mesh: TransformNode, preserveScalingSign?: boolean): this;
    private _nonUniformScaling;
    /**
     * True if the scaling property of this object is non uniform eg. (1,2,1)
     */
    get nonUniformScaling(): boolean;
    /**
     * @internal
     */
    _updateNonUniformScalingState(value: boolean): boolean;
    /**
     * Attach the current TransformNode to another TransformNode associated with a bone
     * @param bone Bone affecting the TransformNode
     * @param affectedTransformNode TransformNode associated with the bone
     * @returns this object
     */
    attachToBone(bone: Bone, affectedTransformNode: TransformNode): TransformNode;
    /**
     * Detach the transform node if its associated with a bone
     * @param resetToPreviousParent Indicates if the parent that was in effect when attachToBone was called should be set back or if we should set parent to null instead (defaults to the latter)
     * @returns this object
     */
    detachFromBone(resetToPreviousParent?: boolean): TransformNode;
    private static _RotationAxisCache;
    /**
     * Rotates the mesh around the axis vector for the passed angle (amount) expressed in radians, in the given space.
     * space (default LOCAL) can be either Space.LOCAL, either Space.WORLD.
     * Note that the property `rotationQuaternion` is then automatically updated and the property `rotation` is set to (0,0,0) and no longer used.
     * The passed axis is also normalized.
     * @param axis the axis to rotate around
     * @param amount the amount to rotate in radians
     * @param space Space to rotate in (Default: local)
     * @returns the TransformNode.
     */
    rotate(axis: Vector3, amount: number, space?: Space): TransformNode;
    /**
     * Rotates the mesh around the axis vector for the passed angle (amount) expressed in radians, in world space.
     * Note that the property `rotationQuaternion` is then automatically updated and the property `rotation` is set to (0,0,0) and no longer used.
     * The passed axis is also normalized. .
     * Method is based on http://www.euclideanspace.com/maths/geometry/affine/aroundPoint/index.htm
     * @param point the point to rotate around
     * @param axis the axis to rotate around
     * @param amount the amount to rotate in radians
     * @returns the TransformNode
     */
    rotateAround(point: Vector3, axis: Vector3, amount: number): TransformNode;
    /**
     * Translates the mesh along the axis vector for the passed distance in the given space.
     * space (default LOCAL) can be either Space.LOCAL, either Space.WORLD.
     * @param axis the axis to translate in
     * @param distance the distance to translate
     * @param space Space to rotate in (Default: local)
     * @returns the TransformNode.
     */
    translate(axis: Vector3, distance: number, space?: Space): TransformNode;
    /**
     * Adds a rotation step to the mesh current rotation.
     * x, y, z are Euler angles expressed in radians.
     * This methods updates the current mesh rotation, either mesh.rotation, either mesh.rotationQuaternion if it's set.
     * This means this rotation is made in the mesh local space only.
     * It's useful to set a custom rotation order different from the BJS standard one YXZ.
     * Example : this rotates the mesh first around its local X axis, then around its local Z axis, finally around its local Y axis.
     * ```javascript
     * mesh.addRotation(x1, 0, 0).addRotation(0, 0, z2).addRotation(0, 0, y3);
     * ```
     * Note that `addRotation()` accumulates the passed rotation values to the current ones and computes the .rotation or .rotationQuaternion updated values.
     * Under the hood, only quaternions are used. So it's a little faster is you use .rotationQuaternion because it doesn't need to translate them back to Euler angles.
     * @param x Rotation to add
     * @param y Rotation to add
     * @param z Rotation to add
     * @returns the TransformNode.
     */
    addRotation(x: number, y: number, z: number): TransformNode;
    /**
     * @internal
     */
    protected _getEffectiveParent(): Nullable<Node>;
    /**
     * Returns whether the transform node world matrix computation needs the camera information to be computed.
     * This is the case when the node is a billboard or has an infinite distance for instance.
     * @returns true if the world matrix computation needs the camera information to be computed
     */
    isWorldMatrixCameraDependent(): boolean;
    /**
     * Computes the world matrix of the node
     * @param force defines if the cache version should be invalidated forcing the world matrix to be created from scratch
     * @param camera defines the camera used if different from the scene active camera (This is used with modes like Billboard or infinite distance)
     * @returns the world matrix
     */
    computeWorldMatrix(force?: boolean, camera?: Nullable<Camera>): Matrix;
    /**
     * Resets this nodeTransform's local matrix to Matrix.Identity().
     * @param independentOfChildren indicates if all child nodeTransform's world-space transform should be preserved.
     */
    resetLocalMatrix(independentOfChildren?: boolean): void;
    protected _afterComputeWorldMatrix(): void;
    /**
     * If you'd like to be called back after the mesh position, rotation or scaling has been updated.
     * @param func callback function to add
     *
     * @returns the TransformNode.
     */
    registerAfterWorldMatrixUpdate(func: (mesh: TransformNode) => void): TransformNode;
    /**
     * Removes a registered callback function.
     * @param func callback function to remove
     * @returns the TransformNode.
     */
    unregisterAfterWorldMatrixUpdate(func: (mesh: TransformNode) => void): TransformNode;
    /**
     * Gets the position of the current mesh in camera space
     * @param camera defines the camera to use
     * @returns a position
     */
    getPositionInCameraSpace(camera?: Nullable<Camera>): Vector3;
    /**
     * Returns the distance from the mesh to the active camera
     * @param camera defines the camera to use
     * @returns the distance
     */
    getDistanceToCamera(camera?: Nullable<Camera>): number;
    /**
     * Clone the current transform node
     * @param name Name of the new clone
     * @param newParent New parent for the clone
     * @param doNotCloneChildren Do not clone children hierarchy
     * @returns the new transform node
     */
    clone(name: string, newParent: Nullable<Node>, doNotCloneChildren?: boolean): Nullable<TransformNode>;
    /**
     * Serializes the objects information.
     * @param currentSerializationObject defines the object to serialize in
     * @returns the serialized object
     */
    serialize(currentSerializationObject?: any): any;
    /**
     * Returns a new TransformNode object parsed from the source provided.
     * @param parsedTransformNode is the source.
     * @param scene the scene the object belongs to
     * @param rootUrl is a string, it's the root URL to prefix the `delayLoadingFile` property with
     * @returns a new TransformNode object parsed from the source provided.
     */
    static Parse(parsedTransformNode: any, scene: Scene, rootUrl: string): TransformNode;
    /**
     * Get all child-transformNodes of this node
     * @param directDescendantsOnly defines if true only direct descendants of 'this' will be considered, if false direct and also indirect (children of children, an so on in a recursive manner) descendants of 'this' will be considered
     * @param predicate defines an optional predicate that will be called on every evaluated child, the predicate must return true for a given child to be part of the result, otherwise it will be ignored
     * @returns an array of TransformNode
     */
    getChildTransformNodes(directDescendantsOnly?: boolean, predicate?: (node: Node) => boolean): TransformNode[];
    /**
     * Releases resources associated with this transform node.
     * @param doNotRecurse Set to true to not recurse into each children (recurse into each children by default)
     * @param disposeMaterialAndTextures Set to true to also dispose referenced materials and textures (false by default)
     */
    dispose(doNotRecurse?: boolean, disposeMaterialAndTextures?: boolean): void;
    /**
     * Uniformly scales the mesh to fit inside of a unit cube (1 X 1 X 1 units)
     * @param includeDescendants Use the hierarchy's bounding box instead of the mesh's bounding box. Default is false
     * @param ignoreRotation ignore rotation when computing the scale (ie. object will be axis aligned). Default is false
     * @param predicate predicate that is passed in to getHierarchyBoundingVectors when selecting which object should be included when scaling
     * @returns the current mesh
     */
    normalizeToUnitCube(includeDescendants?: boolean, ignoreRotation?: boolean, predicate?: Nullable<(node: AbstractMesh) => boolean>): TransformNode;
    private _syncAbsoluteScalingAndRotation;
}

/**
 * Represents a vector of any dimension
 */
interface Vector<N extends number[], I> extends Tensor<N, I> {
    /**
     * @see Tensor.dimension
     */
    readonly dimension: Readonly<Dimension<N>>;
    /**
     * @see Tensor.rank
     */
    readonly rank: 1;
    /**
     * Gets the length of the vector
     * @returns the vector length (float)
     */
    length(): number;
    /**
     * Gets the vector squared length
     * @returns the vector squared length (float)
     */
    lengthSquared(): number;
    /**
     * Normalize the vector
     * @returns the current updated Vector
     */
    normalize(): this;
    /**
     * Normalize the current Vector with the given input length.
     * Please note that this is an in place operation.
     * @param len the length of the vector
     * @returns the current updated Vector
     */
    normalizeFromLength(len: number): this;
    /**
     * Normalize the current Vector to a new vector
     * @returns the new Vector
     */
    normalizeToNew(): Vector<N, I>;
    /**
     * Normalize the current Vector to the reference
     * @param reference define the Vector to update
     * @returns the updated Vector
     */
    normalizeToRef<T extends I>(reference: T): T;
}
/**
 * Class representing a vector containing 2 coordinates
 * Example Playground - Overview -  https://playground.babylonjs.com/#QYBWV4#9
 */
declare class Vector2 implements Vector<Tuple<number, 2>, IVector2Like>, IVector2Like {
    /** [0] defines the first coordinate */
    x: number;
    /** [0] defines the second coordinate */
    y: number;
    /**
     * If the first vector is flagged with integers (as everything is 0,0), V8 stores all of the properties as integers internally because it doesn't know any better yet.
     * If subsequent vectors are created with non-integer values, V8 determines that it would be best to represent these properties as doubles instead of integers,
     * and henceforth it will use floating-point representation for all Vector2 instances that it creates.
     * But the original Vector2 instances are unchanged and has a "deprecated map".
     * If we keep using the Vector2 instances from step 1, it will now be a poison pill which will mess up optimizations in any code it touches.
     */
    static _V8PerformanceHack: DeepImmutable<Vector2>;
    private static _ZeroReadOnly;
    /**
     * @see Tensor.dimension
     */
    readonly dimension: Readonly<[2]>;
    /**
     * @see Tensor.rank
     */
    readonly rank: 1;
    /**
     * Creates a new Vector2 from the given x and y coordinates
     * @param x defines the first coordinate
     * @param y defines the second coordinate
     */
    constructor(
    /** [0] defines the first coordinate */
    x?: number, 
    /** [0] defines the second coordinate */
    y?: number);
    /**
     * Gets a string with the Vector2 coordinates
     * @returns a string with the Vector2 coordinates
     */
    toString(): string;
    /**
     * Gets class name
     * @returns the string "Vector2"
     */
    getClassName(): string;
    /**
     * Gets current vector hash code
     * @returns the Vector2 hash code as a number
     */
    getHashCode(): number;
    /**
     * Sets the Vector2 coordinates in the given array or Float32Array from the given index.
     * Example Playground https://playground.babylonjs.com/#QYBWV4#15
     * @param array defines the source array
     * @param index defines the offset in source array
     * @returns the current Vector2
     */
    toArray(array: FloatArray, index?: number): this;
    /**
     * Update the current vector from an array
     * Example Playground https://playground.babylonjs.com/#QYBWV4#39
     * @param array defines the destination array
     * @param offset defines the offset in the destination array
     * @returns the current Vector2
     */
    fromArray(array: FloatArray, offset?: number): this;
    /**
     * Copy the current vector to an array
     * Example Playground https://playground.babylonjs.com/#QYBWV4#40
     * @returns a new array with 2 elements: the Vector2 coordinates.
     */
    asArray(): [number, number];
    /**
     * Sets the Vector2 coordinates with the given Vector2 coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#24
     * @param source defines the source Vector2
     * @returns the current updated Vector2
     */
    copyFrom(source: DeepImmutable<IVector2Like>): this;
    /**
     * Sets the Vector2 coordinates with the given floats
     * Example Playground https://playground.babylonjs.com/#QYBWV4#25
     * @param x defines the first coordinate
     * @param y defines the second coordinate
     * @returns the current updated Vector2
     */
    copyFromFloats(x: number, y: number): this;
    /**
     * Sets the Vector2 coordinates with the given floats
     * Example Playground https://playground.babylonjs.com/#QYBWV4#62
     * @param x defines the first coordinate
     * @param y defines the second coordinate
     * @returns the current updated Vector2
     */
    set(x: number, y: number): this;
    /**
     * Copies the given float to the current Vector2 coordinates
     * @param v defines the x and y coordinates of the operand
     * @returns the current updated Vector2
     */
    setAll(v: number): this;
    /**
     * Add another vector with the current one
     * Example Playground https://playground.babylonjs.com/#QYBWV4#11
     * @param otherVector defines the other vector
     * @returns a new Vector2 set with the addition of the current Vector2 and the given one coordinates
     */
    add(otherVector: DeepImmutable<IVector2Like>): Vector2;
    /**
     * Sets the "result" coordinates with the addition of the current Vector2 and the given one coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#12
     * @param otherVector defines the other vector
     * @param result defines the target vector
     * @returns result input
     */
    addToRef<T extends IVector2Like>(otherVector: DeepImmutable<IVector2Like>, result: T): T;
    /**
     * Set the Vector2 coordinates by adding the given Vector2 coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#13
     * @param otherVector defines the other vector
     * @returns the current updated Vector2
     */
    addInPlace(otherVector: DeepImmutable<IVector2Like>): this;
    /**
     * Adds the given coordinates to the current Vector2
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @returns the current updated Vector2
     */
    addInPlaceFromFloats(x: number, y: number): this;
    /**
     * Gets a new Vector2 by adding the current Vector2 coordinates to the given Vector3 x, y coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#14
     * @param otherVector defines the other vector
     * @returns a new Vector2
     */
    addVector3(otherVector: IVector3Like): Vector2;
    /**
     * Gets a new Vector2 set with the subtracted coordinates of the given one from the current Vector2
     * Example Playground https://playground.babylonjs.com/#QYBWV4#61
     * @param otherVector defines the other vector
     * @returns a new Vector2
     */
    subtract(otherVector: DeepImmutable<IVector2Like>): Vector2;
    /**
     * Sets the "result" coordinates with the subtraction of the given one from the current Vector2 coordinates.
     * Example Playground https://playground.babylonjs.com/#QYBWV4#63
     * @param otherVector defines the other vector
     * @param result defines the target vector
     * @returns result input
     */
    subtractToRef<T extends IVector2Like>(otherVector: DeepImmutable<IVector2Like>, result: T): T;
    /**
     * Sets the current Vector2 coordinates by subtracting from it the given one coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#88
     * @param otherVector defines the other vector
     * @returns the current updated Vector2
     */
    subtractInPlace(otherVector: DeepImmutable<IVector2Like>): this;
    /**
     * Multiplies in place the current Vector2 coordinates by the given ones
     * Example Playground https://playground.babylonjs.com/#QYBWV4#43
     * @param otherVector defines the other vector
     * @returns the current updated Vector2
     */
    multiplyInPlace(otherVector: DeepImmutable<IVector2Like>): this;
    /**
     * Returns a new Vector2 set with the multiplication of the current Vector2 and the given one coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#42
     * @param otherVector defines the other vector
     * @returns a new Vector2
     */
    multiply(otherVector: DeepImmutable<IVector2Like>): Vector2;
    /**
     * Sets "result" coordinates with the multiplication of the current Vector2 and the given one coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#44
     * @param otherVector defines the other vector
     * @param result defines the target vector
     * @returns result input
     */
    multiplyToRef<T extends IVector2Like>(otherVector: DeepImmutable<IVector2Like>, result: T): T;
    /**
     * Gets a new Vector2 set with the Vector2 coordinates multiplied by the given floats
     * Example Playground https://playground.babylonjs.com/#QYBWV4#89
     * @param x defines the first coordinate
     * @param y defines the second coordinate
     * @returns a new Vector2
     */
    multiplyByFloats(x: number, y: number): Vector2;
    /**
     * Returns a new Vector2 set with the Vector2 coordinates divided by the given one coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#27
     * @param otherVector defines the other vector
     * @returns a new Vector2
     */
    divide(otherVector: DeepImmutable<IVector2Like>): Vector2;
    /**
     * Sets the "result" coordinates with the Vector2 divided by the given one coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#30
     * @param otherVector defines the other vector
     * @param result defines the target vector
     * @returns result input
     */
    divideToRef<T extends IVector2Like>(otherVector: DeepImmutable<IVector2Like>, result: T): T;
    /**
     * Divides the current Vector2 coordinates by the given ones
     * Example Playground https://playground.babylonjs.com/#QYBWV4#28
     * @param otherVector defines the other vector
     * @returns the current updated Vector2
     */
    divideInPlace(otherVector: DeepImmutable<IVector2Like>): this;
    /**
     * Updates the current Vector2 with the minimal coordinate values between its and the given vector ones
     * @param other defines the second operand
     * @returns the current updated Vector2
     */
    minimizeInPlace(other: DeepImmutable<IVector2Like>): this;
    /**
     * Updates the current Vector2 with the maximal coordinate values between its and the given vector ones.
     * @param other defines the second operand
     * @returns the current updated Vector2
     */
    maximizeInPlace(other: DeepImmutable<IVector2Like>): this;
    /**
     * Updates the current Vector2 with the minimal coordinate values between its and the given coordinates
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @returns the current updated Vector2
     */
    minimizeInPlaceFromFloats(x: number, y: number): this;
    /**
     * Updates the current Vector2 with the maximal coordinate values between its and the given coordinates.
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @returns the current updated Vector2
     */
    maximizeInPlaceFromFloats(x: number, y: number): this;
    /**
     * Returns a new Vector2 set with the subtraction of the given floats from the current Vector2 coordinates
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @returns the resulting Vector2
     */
    subtractFromFloats(x: number, y: number): Vector2;
    /**
     * Subtracts the given floats from the current Vector2 coordinates and set the given vector "result" with this result
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param result defines the Vector2 object where to store the result
     * @returns the result
     */
    subtractFromFloatsToRef<T extends IVector2Like>(x: number, y: number, result: T): T;
    /**
     * Gets a new Vector2 with current Vector2 negated coordinates
     * @returns a new Vector2
     */
    negate(): Vector2;
    /**
     * Negate this vector in place
     * Example Playground https://playground.babylonjs.com/#QYBWV4#23
     * @returns this
     */
    negateInPlace(): this;
    /**
     * Negate the current Vector2 and stores the result in the given vector "result" coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#41
     * @param result defines the Vector2 object where to store the result
     * @returns the result
     */
    negateToRef<T extends IVector2Like>(result: T): T;
    /**
     * Multiply the Vector2 coordinates by
     * Example Playground https://playground.babylonjs.com/#QYBWV4#59
     * @param scale defines the scaling factor
     * @returns the current updated Vector2
     */
    scaleInPlace(scale: number): this;
    /**
     * Returns a new Vector2 scaled by "scale" from the current Vector2
     * Example Playground https://playground.babylonjs.com/#QYBWV4#52
     * @param scale defines the scaling factor
     * @returns a new Vector2
     */
    scale(scale: number): Vector2;
    /**
     * Scale the current Vector2 values by a factor to a given Vector2
     * Example Playground https://playground.babylonjs.com/#QYBWV4#57
     * @param scale defines the scale factor
     * @param result defines the Vector2 object where to store the result
     * @returns result input
     */
    scaleToRef<T extends IVector2Like>(scale: number, result: T): T;
    /**
     * Scale the current Vector2 values by a factor and add the result to a given Vector2
     * Example Playground https://playground.babylonjs.com/#QYBWV4#58
     * @param scale defines the scale factor
     * @param result defines the Vector2 object where to store the result
     * @returns result input
     */
    scaleAndAddToRef<T extends IVector2Like>(scale: number, result: T): T;
    /**
     * Gets a boolean if two vectors are equals
     * Example Playground https://playground.babylonjs.com/#QYBWV4#31
     * @param otherVector defines the other vector
     * @returns true if the given vector coordinates strictly equal the current Vector2 ones
     */
    equals(otherVector: DeepImmutable<IVector2Like>): boolean;
    /**
     * Gets a boolean if two vectors are equals (using an epsilon value)
     * Example Playground https://playground.babylonjs.com/#QYBWV4#32
     * @param otherVector defines the other vector
     * @param epsilon defines the minimal distance to consider equality
     * @returns true if the given vector coordinates are close to the current ones by a distance of epsilon.
     */
    equalsWithEpsilon(otherVector: DeepImmutable<IVector2Like>, epsilon?: number): boolean;
    /**
     * Returns true if the current Vector2 coordinates equals the given floats
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @returns true if both vectors are equal
     */
    equalsToFloats(x: number, y: number): boolean;
    /**
     * Gets a new Vector2 from current Vector2 floored values
     * Example Playground https://playground.babylonjs.com/#QYBWV4#35
     * eg (1.2, 2.31) returns (1, 2)
     * @returns a new Vector2
     */
    floor(): Vector2;
    /**
     * Gets the current Vector2's floored values and stores them in result
     * @param result the Vector2 to store the result in
     * @returns the result Vector2
     */
    floorToRef<T extends IVector2Like>(result: T): T;
    /**
     * Gets a new Vector2 from current Vector2 fractional values
     * Example Playground https://playground.babylonjs.com/#QYBWV4#34
     * eg (1.2, 2.31) returns (0.2, 0.31)
     * @returns a new Vector2
     */
    fract(): Vector2;
    /**
     * Gets the current Vector2's fractional values and stores them in result
     * @param result the Vector2 to store the result in
     * @returns the result Vector2
     */
    fractToRef<T extends IVector2Like>(result: T): T;
    /**
     * Gets a new Vector2 rotated by the given angle
     * @param angle defines the rotation angle
     * @returns a new Vector2
     */
    rotate(angle: number): Vector2;
    /**
     * Rotate the current vector into a given result vector
     * Example Playground https://playground.babylonjs.com/#QYBWV4#49
     * @param angle defines the rotation angle
     * @param result defines the result vector where to store the rotated vector
     * @returns result input
     */
    rotateToRef<T extends IVector2Like>(angle: number, result: T): T;
    /**
     * Gets the length of the vector
     * @returns the vector length (float)
     */
    length(): number;
    /**
     * Gets the vector squared length
     * @returns the vector squared length (float)
     */
    lengthSquared(): number;
    /**
     * Normalize the vector
     * Example Playground https://playground.babylonjs.com/#QYBWV4#48
     * @returns the current updated Vector2
     */
    normalize(): this;
    /**
     * Normalize the current Vector2 with the given input length.
     * Please note that this is an in place operation.
     * @param len the length of the vector
     * @returns the current updated Vector2
     */
    normalizeFromLength(len: number): this;
    /**
     * Normalize the current Vector2 to a new vector
     * @returns the new Vector2
     */
    normalizeToNew(): Vector2;
    /**
     * Normalize the current Vector2 to the reference
     * @param result define the Vector to update
     * @returns the updated Vector2
     */
    normalizeToRef<T extends IVector2Like>(result: T): T;
    /**
     * Gets a new Vector2 copied from the Vector2
     * Example Playground https://playground.babylonjs.com/#QYBWV4#20
     * @returns a new Vector2
     */
    clone(): Vector2;
    /**
     * Gets the dot product of the current vector and the vector "otherVector"
     * @param otherVector defines second vector
     * @returns the dot product (float)
     */
    dot(otherVector: DeepImmutable<IVector2Like>): number;
    /**
     * Gets a new Vector2(0, 0)
     * @returns a new Vector2
     */
    static Zero(): Vector2;
    /**
     * Gets a new Vector2(1, 1)
     * @returns a new Vector2
     */
    static One(): Vector2;
    /**
     * Returns a new Vector2 with random values between min and max
     * @param min the minimum random value
     * @param max the maximum random value
     * @returns a Vector2 with random values between min and max
     */
    static Random(min?: number, max?: number): Vector2;
    /**
     * Sets a Vector2 with random values between min and max
     * @param min the minimum random value
     * @param max the maximum random value
     * @param ref the ref to store the values in
     * @returns the ref with random values between min and max
     */
    static RandomToRef<T extends Vector2>(min: number | undefined, max: number | undefined, ref: T): T;
    /**
     * Gets a zero Vector2 that must not be updated
     */
    static get ZeroReadOnly(): DeepImmutable<Vector2>;
    /**
     * Gets a new Vector2 set from the given index element of the given array
     * Example Playground https://playground.babylonjs.com/#QYBWV4#79
     * @param array defines the data source
     * @param offset defines the offset in the data source
     * @returns a new Vector2
     */
    static FromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): Vector2;
    /**
     * Sets "result" from the given index element of the given array
     * Example Playground https://playground.babylonjs.com/#QYBWV4#80
     * @param array defines the data source
     * @param offset defines the offset in the data source
     * @param result defines the target vector
     * @returns result input
     */
    static FromArrayToRef<T extends Vector2>(array: DeepImmutable<ArrayLike<number>>, offset: number, result: T): T;
    /**
     * Sets the given vector "result" with the given floats.
     * @param x defines the x coordinate of the source
     * @param y defines the y coordinate of the source
     * @param result defines the Vector2 where to store the result
     * @returns the result vector
     */
    static FromFloatsToRef<T extends Vector2>(x: number, y: number, result: T): T;
    /**
     * Gets a new Vector2 located for "amount" (float) on the CatmullRom spline defined by the given four Vector2
     * Example Playground https://playground.babylonjs.com/#QYBWV4#65
     * @param value1 defines 1st point of control
     * @param value2 defines 2nd point of control
     * @param value3 defines 3rd point of control
     * @param value4 defines 4th point of control
     * @param amount defines the interpolation factor
     * @returns a new Vector2
     */
    static CatmullRom(value1: DeepImmutable<IVector2Like>, value2: DeepImmutable<IVector2Like>, value3: DeepImmutable<IVector2Like>, value4: DeepImmutable<IVector2Like>, amount: number): Vector2;
    /**
     * Sets reference with same the coordinates than "value" ones if the vector "value" is in the square defined by "min" and "max".
     * If a coordinate of "value" is lower than "min" coordinates, the returned Vector2 is given this "min" coordinate.
     * If a coordinate of "value" is greater than "max" coordinates, the returned Vector2 is given this "max" coordinate
     * @param value defines the value to clamp
     * @param min defines the lower limit
     * @param max defines the upper limit
     * @param ref the reference
     * @returns the reference
     */
    static ClampToRef<T extends Vector2>(value: DeepImmutable<IVector2Like>, min: DeepImmutable<IVector2Like>, max: DeepImmutable<IVector2Like>, ref: T): T;
    /**
     * Returns a new Vector2 set with same the coordinates than "value" ones if the vector "value" is in the square defined by "min" and "max".
     * If a coordinate of "value" is lower than "min" coordinates, the returned Vector2 is given this "min" coordinate.
     * If a coordinate of "value" is greater than "max" coordinates, the returned Vector2 is given this "max" coordinate
     * Example Playground https://playground.babylonjs.com/#QYBWV4#76
     * @param value defines the value to clamp
     * @param min defines the lower limit
     * @param max defines the upper limit
     * @returns a new Vector2
     */
    static Clamp(value: DeepImmutable<IVector2Like>, min: DeepImmutable<IVector2Like>, max: DeepImmutable<IVector2Like>): Vector2;
    /**
     * Returns a new Vector2 located for "amount" (float) on the Hermite spline defined by the vectors "value1", "value2", "tangent1", "tangent2"
     * Example Playground https://playground.babylonjs.com/#QYBWV4#81
     * @param value1 defines the 1st control point
     * @param tangent1 defines the outgoing tangent
     * @param value2 defines the 2nd control point
     * @param tangent2 defines the incoming tangent
     * @param amount defines the interpolation factor
     * @returns a new Vector2
     */
    static Hermite(value1: DeepImmutable<IVector2Like>, tangent1: DeepImmutable<IVector2Like>, value2: DeepImmutable<IVector2Like>, tangent2: DeepImmutable<IVector2Like>, amount: number): Vector2;
    /**
     * Returns a new Vector2 which is the 1st derivative of the Hermite spline defined by the vectors "value1", "value2", "tangent1", "tangent2".
     * Example Playground https://playground.babylonjs.com/#QYBWV4#82
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @returns 1st derivative
     */
    static Hermite1stDerivative(value1: DeepImmutable<IVector2Like>, tangent1: DeepImmutable<IVector2Like>, value2: DeepImmutable<IVector2Like>, tangent2: DeepImmutable<IVector2Like>, time: number): Vector2;
    /**
     * Returns a new Vector2 which is the 1st derivative of the Hermite spline defined by the vectors "value1", "value2", "tangent1", "tangent2".
     * Example Playground https://playground.babylonjs.com/#QYBWV4#83
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @param result define where the derivative will be stored
     * @returns result input
     */
    static Hermite1stDerivativeToRef<T extends Vector2>(value1: DeepImmutable<IVector2Like>, tangent1: DeepImmutable<IVector2Like>, value2: DeepImmutable<IVector2Like>, tangent2: DeepImmutable<IVector2Like>, time: number, result: T): T;
    /**
     * Returns a new Vector2 located for "amount" (float) on the linear interpolation between the vector "start" adn the vector "end".
     * Example Playground https://playground.babylonjs.com/#QYBWV4#84
     * @param start defines the start vector
     * @param end defines the end vector
     * @param amount defines the interpolation factor
     * @returns a new Vector2
     */
    static Lerp(start: DeepImmutable<IVector2Like>, end: DeepImmutable<IVector2Like>, amount: number): Vector2;
    /**
     * Sets the given vector "result" with the result of the linear interpolation from the vector "start" for "amount" to the vector "end"
     * @param start defines the start value
     * @param end defines the end value
     * @param amount max defines amount between both (between 0 and 1)
     * @param result defines the Vector2 where to store the result
     * @returns result input
     */
    static LerpToRef(start: DeepImmutable<IVector2Like>, end: DeepImmutable<IVector2Like>, amount: number, result: Vector2): Vector2;
    /**
     * Gets the dot product of the vector "left" and the vector "right"
     * Example Playground https://playground.babylonjs.com/#QYBWV4#90
     * @param left defines first vector
     * @param right defines second vector
     * @returns the dot product (float)
     */
    static Dot(left: DeepImmutable<IVector2Like>, right: DeepImmutable<IVector2Like>): number;
    /**
     * Returns a new Vector2 equal to the normalized given vector
     * Example Playground https://playground.babylonjs.com/#QYBWV4#46
     * @param vector defines the vector to normalize
     * @returns a new Vector2
     */
    static Normalize(vector: DeepImmutable<Vector2>): Vector2;
    /**
     * Normalize a given vector into a second one
     * Example Playground https://playground.babylonjs.com/#QYBWV4#50
     * @param vector defines the vector to normalize
     * @param result defines the vector where to store the result
     * @returns result input
     */
    static NormalizeToRef<T extends Vector2>(vector: DeepImmutable<Vector2>, result: T): T;
    /**
     * Gets a new Vector2 set with the minimal coordinate values from the "left" and "right" vectors
     * Example Playground https://playground.babylonjs.com/#QYBWV4#86
     * @param left defines 1st vector
     * @param right defines 2nd vector
     * @returns a new Vector2
     */
    static Minimize(left: DeepImmutable<IVector2Like>, right: DeepImmutable<IVector2Like>): Vector2;
    /**
     * Gets a new Vector2 set with the maximal coordinate values from the "left" and "right" vectors
     * Example Playground https://playground.babylonjs.com/#QYBWV4#86
     * @param left defines 1st vector
     * @param right defines 2nd vector
     * @returns a new Vector2
     */
    static Maximize(left: DeepImmutable<IVector2Like>, right: DeepImmutable<IVector2Like>): Vector2;
    /**
     * Gets a new Vector2 set with the transformed coordinates of the given vector by the given transformation matrix
     * Example Playground https://playground.babylonjs.com/#QYBWV4#17
     * @param vector defines the vector to transform
     * @param transformation defines the matrix to apply
     * @returns a new Vector2
     */
    static Transform(vector: DeepImmutable<IVector2Like>, transformation: DeepImmutable<Matrix>): Vector2;
    /**
     * Transforms the given vector coordinates by the given transformation matrix and stores the result in the vector "result" coordinates
     * Example Playground https://playground.babylonjs.com/#QYBWV4#19
     * @param vector defines the vector to transform
     * @param transformation defines the matrix to apply
     * @param result defines the target vector
     * @returns result input
     */
    static TransformToRef<T extends Vector2>(vector: DeepImmutable<IVector2Like>, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Determines if a given vector is included in a triangle
     * Example Playground https://playground.babylonjs.com/#QYBWV4#87
     * @param p defines the vector to test
     * @param p0 defines 1st triangle point
     * @param p1 defines 2nd triangle point
     * @param p2 defines 3rd triangle point
     * @returns true if the point "p" is in the triangle defined by the vectors "p0", "p1", "p2"
     */
    static PointInTriangle(p: DeepImmutable<IVector2Like>, p0: DeepImmutable<IVector2Like>, p1: DeepImmutable<IVector2Like>, p2: DeepImmutable<IVector2Like>): boolean;
    /**
     * Gets the distance between the vectors "value1" and "value2"
     * Example Playground https://playground.babylonjs.com/#QYBWV4#71
     * @param value1 defines first vector
     * @param value2 defines second vector
     * @returns the distance between vectors
     */
    static Distance(value1: DeepImmutable<IVector2Like>, value2: DeepImmutable<IVector2Like>): number;
    /**
     * Returns the squared distance between the vectors "value1" and "value2"
     * Example Playground https://playground.babylonjs.com/#QYBWV4#72
     * @param value1 defines first vector
     * @param value2 defines second vector
     * @returns the squared distance between vectors
     */
    static DistanceSquared(value1: DeepImmutable<IVector2Like>, value2: DeepImmutable<IVector2Like>): number;
    /**
     * Gets a new Vector2 located at the center of the vectors "value1" and "value2"
     * Example Playground https://playground.babylonjs.com/#QYBWV4#86
     * Example Playground https://playground.babylonjs.com/#QYBWV4#66
     * @param value1 defines first vector
     * @param value2 defines second vector
     * @returns a new Vector2
     */
    static Center(value1: DeepImmutable<IVector2Like>, value2: DeepImmutable<IVector2Like>): Vector2;
    /**
     * Gets the center of the vectors "value1" and "value2" and stores the result in the vector "ref"
     * Example Playground https://playground.babylonjs.com/#QYBWV4#66
     * @param value1 defines first vector
     * @param value2 defines second vector
     * @param ref defines third vector
     * @returns ref
     */
    static CenterToRef<T extends Vector2>(value1: DeepImmutable<IVector2Like>, value2: DeepImmutable<IVector2Like>, ref: T): T;
    /**
     * Gets the shortest distance (float) between the point "p" and the segment defined by the two points "segA" and "segB".
     * Example Playground https://playground.babylonjs.com/#QYBWV4#77
     * @param p defines the middle point
     * @param segA defines one point of the segment
     * @param segB defines the other point of the segment
     * @returns the shortest distance
     */
    static DistanceOfPointFromSegment(p: DeepImmutable<Vector2>, segA: DeepImmutable<Vector2>, segB: DeepImmutable<Vector2>): number;
}
/**
 * Class used to store (x,y,z) vector representation
 * A Vector3 is the main object used in 3D geometry
 * It can represent either the coordinates of a point the space, either a direction
 * Reminder: js uses a left handed forward facing system
 * Example Playground - Overview - https://playground.babylonjs.com/#R1F8YU
 */
declare class Vector3 implements Vector<Tuple<number, 3>, IVector3LikeInternal>, IVector3Like {
    /**
     * If the first vector is flagged with integers (as everything is 0,0,0), V8 stores all of the properties as integers internally because it doesn't know any better yet.
     * If subsequent vectors are created with non-integer values, V8 determines that it would be best to represent these properties as doubles instead of integers,
     * and henceforth it will use floating-point representation for all Vector3 instances that it creates.
     * But the original Vector3 instances are unchanged and has a "deprecated map".
     * If we keep using the Vector3 instances from step 1, it will now be a poison pill which will mess up optimizations in any code it touches.
     */
    static _V8PerformanceHack: DeepImmutable<Vector3>;
    private static _UpReadOnly;
    private static _DownReadOnly;
    private static _LeftHandedForwardReadOnly;
    private static _RightHandedForwardReadOnly;
    private static _LeftHandedBackwardReadOnly;
    private static _RightHandedBackwardReadOnly;
    private static _RightReadOnly;
    private static _LeftReadOnly;
    private static _ZeroReadOnly;
    private static _OneReadOnly;
    /**
     * @see Tensor.dimension
     */
    readonly dimension: Readonly<[3]>;
    /**
     * @see Tensor.rank
     */
    readonly rank: 1;
    /** @internal */
    _x: number;
    /** @internal */
    _y: number;
    /** @internal */
    _z: number;
    /** @internal */
    _isDirty: boolean;
    /** Gets or sets the x coordinate */
    get x(): number;
    set x(value: number);
    /** Gets or sets the y coordinate */
    get y(): number;
    set y(value: number);
    /** Gets or sets the z coordinate */
    get z(): number;
    set z(value: number);
    /**
     * Creates a new Vector3 object from the given x, y, z (floats) coordinates.
     * @param x defines the first coordinates (on X axis)
     * @param y defines the second coordinates (on Y axis)
     * @param z defines the third coordinates (on Z axis)
     */
    constructor(x?: number, y?: number, z?: number);
    /**
     * Creates a string representation of the Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#67
     * @returns a string with the Vector3 coordinates.
     */
    toString(): string;
    /**
     * Gets the class name
     * @returns the string "Vector3"
     */
    getClassName(): string;
    /**
     * Creates the Vector3 hash code
     * @returns a number which tends to be unique between Vector3 instances
     */
    getHashCode(): number;
    /**
     * Creates an array containing three elements : the coordinates of the Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#10
     * @returns a new array of numbers
     */
    asArray(): Tuple<number, 3>;
    /**
     * Populates the given array or Float32Array from the given index with the successive coordinates of the Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#65
     * @param array defines the destination array
     * @param index defines the offset in the destination array
     * @returns the current Vector3
     */
    toArray(array: FloatArray, index?: number): this;
    /**
     * Update the current vector from an array
     * Example Playground https://playground.babylonjs.com/#R1F8YU#24
     * @param array defines the destination array
     * @param offset defines the offset in the destination array
     * @returns the current Vector3
     */
    fromArray(array: DeepImmutable<FloatArray>, offset?: number): this;
    /**
     * Converts the current Vector3 into a quaternion (considering that the Vector3 contains Euler angles representation of a rotation)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#66
     * @returns a new Quaternion object, computed from the Vector3 coordinates
     */
    toQuaternion(): Quaternion;
    /**
     * Adds the given vector to the current Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#4
     * @param otherVector defines the second operand
     * @returns the current updated Vector3
     */
    addInPlace(otherVector: DeepImmutable<Vector3>): this;
    /**
     * Adds the given coordinates to the current Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#5
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @returns the current updated Vector3
     */
    addInPlaceFromFloats(x: number, y: number, z: number): this;
    /**
     * Gets a new Vector3, result of the addition the current Vector3 and the given vector
     * Example Playground https://playground.babylonjs.com/#R1F8YU#3
     * @param otherVector defines the second operand
     * @returns the resulting Vector3
     */
    add(otherVector: DeepImmutable<IVector3LikeInternal>): Vector3;
    /**
     * Adds the current Vector3 to the given one and stores the result in the vector "result"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#6
     * @param otherVector defines the second operand
     * @param result defines the Vector3 object where to store the result
     * @returns the result
     */
    addToRef<T extends IVector3LikeInternal>(otherVector: DeepImmutable<IVector3LikeInternal>, result: T): T;
    /**
     * Subtract the given vector from the current Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#61
     * @param otherVector defines the second operand
     * @returns the current updated Vector3
     */
    subtractInPlace(otherVector: DeepImmutable<IVector3LikeInternal>): this;
    /**
     * Returns a new Vector3, result of the subtraction of the given vector from the current Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#60
     * @param otherVector defines the second operand
     * @returns the resulting Vector3
     */
    subtract(otherVector: DeepImmutable<IVector3LikeInternal>): Vector3;
    /**
     * Subtracts the given vector from the current Vector3 and stores the result in the vector "result".
     * Example Playground https://playground.babylonjs.com/#R1F8YU#63
     * @param otherVector defines the second operand
     * @param result defines the Vector3 object where to store the result
     * @returns the result
     */
    subtractToRef<T extends IVector3LikeInternal>(otherVector: DeepImmutable<IVector3LikeInternal>, result: T): T;
    /**
     * Returns a new Vector3 set with the subtraction of the given floats from the current Vector3 coordinates
     * Example Playground https://playground.babylonjs.com/#R1F8YU#62
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @returns the resulting Vector3
     */
    subtractFromFloats(x: number, y: number, z: number): Vector3;
    /**
     * Subtracts the given floats from the current Vector3 coordinates and set the given vector "result" with this result
     * Example Playground https://playground.babylonjs.com/#R1F8YU#64
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @param result defines the Vector3 object where to store the result
     * @returns the result
     */
    subtractFromFloatsToRef<T extends IVector3LikeInternal>(x: number, y: number, z: number, result: T): T;
    /**
     * Gets a new Vector3 set with the current Vector3 negated coordinates
     * Example Playground https://playground.babylonjs.com/#R1F8YU#35
     * @returns a new Vector3
     */
    negate(): Vector3;
    /**
     * Negate this vector in place
     * Example Playground https://playground.babylonjs.com/#R1F8YU#36
     * @returns this
     */
    negateInPlace(): this;
    /**
     * Negate the current Vector3 and stores the result in the given vector "result" coordinates
     * Example Playground https://playground.babylonjs.com/#R1F8YU#37
     * @param result defines the Vector3 object where to store the result
     * @returns the result
     */
    negateToRef<T extends IVector3LikeInternal>(result: T): T;
    /**
     * Multiplies the Vector3 coordinates by the float "scale"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#56
     * @param scale defines the multiplier factor
     * @returns the current updated Vector3
     */
    scaleInPlace(scale: number): this;
    /**
     * Returns a new Vector3 set with the current Vector3 coordinates multiplied by the float "scale"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#53
     * @param scale defines the multiplier factor
     * @returns a new Vector3
     */
    scale(scale: number): Vector3;
    /**
     * Multiplies the current Vector3 coordinates by the float "scale" and stores the result in the given vector "result" coordinates
     * Example Playground https://playground.babylonjs.com/#R1F8YU#57
     * @param scale defines the multiplier factor
     * @param result defines the Vector3 object where to store the result
     * @returns the result
     */
    scaleToRef<T extends IVector3LikeInternal>(scale: number, result: T): T;
    /**
     * Creates a vector normal (perpendicular) to the current Vector3 and stores the result in the given vector
     * Out of the infinite possibilities the normal chosen is the one formed by rotating the current vector
     * 90 degrees about an axis which lies perpendicular to the current vector
     * and its projection on the xz plane. In the case of a current vector in the xz plane
     * the normal is calculated to be along the y axis.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#230
     * Example Playground https://playground.babylonjs.com/#R1F8YU#231
     * @param result defines the Vector3 object where to store the resultant normal
     * @returns the result
     */
    getNormalToRef(result: Vector3): Vector3;
    /**
     * Rotates the vector using the given unit quaternion and stores the new vector in result
     * Example Playground https://playground.babylonjs.com/#R1F8YU#9
     * @param q the unit quaternion representing the rotation
     * @param result the output vector
     * @returns the result
     */
    applyRotationQuaternionToRef<T extends Vector3>(q: Quaternion, result: T): T;
    /**
     * Rotates the vector in place using the given unit quaternion
     * Example Playground https://playground.babylonjs.com/#R1F8YU#8
     * @param q the unit quaternion representing the rotation
     * @returns the current updated Vector3
     */
    applyRotationQuaternionInPlace(q: Quaternion): this;
    /**
     * Rotates the vector using the given unit quaternion and returns the new vector
     * Example Playground https://playground.babylonjs.com/#R1F8YU#7
     * @param q the unit quaternion representing the rotation
     * @returns a new Vector3
     */
    applyRotationQuaternion(q: Quaternion): Vector3;
    /**
     * Scale the current Vector3 values by a factor and add the result to a given Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#55
     * @param scale defines the scale factor
     * @param result defines the Vector3 object where to store the result
     * @returns result input
     */
    scaleAndAddToRef<T extends IVector3LikeInternal>(scale: number, result: T): T;
    /**
     * Projects the current point Vector3 to a plane along a ray starting from a specified origin and passing through the current point Vector3.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#48
     * @param plane defines the plane to project to
     * @param origin defines the origin of the projection ray
     * @returns the projected vector3
     */
    projectOnPlane(plane: Plane, origin: Vector3): Vector3;
    /**
     * Projects the current point Vector3 to a plane along a ray starting from a specified origin and passing through the current point Vector3.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#49
     * @param plane defines the plane to project to
     * @param origin defines the origin of the projection ray
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    projectOnPlaneToRef<T extends Vector3>(plane: Plane, origin: Vector3, result: T): T;
    /**
     * Returns true if the current Vector3 and the given vector coordinates are strictly equal
     * Example Playground https://playground.babylonjs.com/#R1F8YU#19
     * @param otherVector defines the second operand
     * @returns true if both vectors are equals
     */
    equals(otherVector: DeepImmutable<Vector3>): boolean;
    /**
     * Returns true if the current Vector3 and the given vector coordinates are distant less than epsilon
     * Example Playground https://playground.babylonjs.com/#R1F8YU#21
     * @param otherVector defines the second operand
     * @param epsilon defines the minimal distance to define values as equals
     * @returns true if both vectors are distant less than epsilon
     */
    equalsWithEpsilon(otherVector: DeepImmutable<Vector3>, epsilon?: number): boolean;
    /**
     * Returns true if the current Vector3 coordinates equals the given floats
     * Example Playground https://playground.babylonjs.com/#R1F8YU#20
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @returns true if both vectors are equal
     */
    equalsToFloats(x: number, y: number, z: number): boolean;
    /**
     * Multiplies the current Vector3 coordinates by the given ones
     * Example Playground https://playground.babylonjs.com/#R1F8YU#32
     * @param otherVector defines the second operand
     * @returns the current updated Vector3
     */
    multiplyInPlace(otherVector: DeepImmutable<IVector3LikeInternal>): this;
    /**
     * Returns a new Vector3, result of the multiplication of the current Vector3 by the given vector
     * Example Playground https://playground.babylonjs.com/#R1F8YU#31
     * @param otherVector defines the second operand
     * @returns the new Vector3
     */
    multiply(otherVector: DeepImmutable<IVector3LikeInternal>): Vector3;
    /**
     * Multiplies the current Vector3 by the given one and stores the result in the given vector "result"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#33
     * @param otherVector defines the second operand
     * @param result defines the Vector3 object where to store the result
     * @returns the result
     */
    multiplyToRef<T extends IVector3LikeInternal>(otherVector: DeepImmutable<IVector3LikeInternal>, result: T): T;
    /**
     * Returns a new Vector3 set with the result of the multiplication of the current Vector3 coordinates by the given floats
     * Example Playground https://playground.babylonjs.com/#R1F8YU#34
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @returns the new Vector3
     */
    multiplyByFloats(x: number, y: number, z: number): Vector3;
    /**
     * Returns a new Vector3 set with the result of the division of the current Vector3 coordinates by the given ones
     * Example Playground https://playground.babylonjs.com/#R1F8YU#16
     * @param otherVector defines the second operand
     * @returns the new Vector3
     */
    divide(otherVector: DeepImmutable<IVector3LikeInternal>): Vector3;
    /**
     * Divides the current Vector3 coordinates by the given ones and stores the result in the given vector "result"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#18
     * @param otherVector defines the second operand
     * @param result defines the Vector3 object where to store the result
     * @returns the result
     */
    divideToRef<T extends IVector3LikeInternal>(otherVector: DeepImmutable<IVector3LikeInternal>, result: T): T;
    /**
     * Divides the current Vector3 coordinates by the given ones.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#17
     * @param otherVector defines the second operand
     * @returns the current updated Vector3
     */
    divideInPlace(otherVector: DeepImmutable<IVector3LikeInternal>): this;
    /**
     * Updates the current Vector3 with the minimal coordinate values between its and the given vector ones
     * Example Playground https://playground.babylonjs.com/#R1F8YU#29
     * @param other defines the second operand
     * @returns the current updated Vector3
     */
    minimizeInPlace(other: DeepImmutable<IVector3LikeInternal>): this;
    /**
     * Updates the current Vector3 with the maximal coordinate values between its and the given vector ones.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#27
     * @param other defines the second operand
     * @returns the current updated Vector3
     */
    maximizeInPlace(other: DeepImmutable<IVector3LikeInternal>): this;
    /**
     * Updates the current Vector3 with the minimal coordinate values between its and the given coordinates
     * Example Playground https://playground.babylonjs.com/#R1F8YU#30
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @returns the current updated Vector3
     */
    minimizeInPlaceFromFloats(x: number, y: number, z: number): this;
    /**
     * Updates the current Vector3 with the maximal coordinate values between its and the given coordinates.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#28
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @returns the current updated Vector3
     */
    maximizeInPlaceFromFloats(x: number, y: number, z: number): this;
    /**
     * Due to float precision, scale of a mesh could be uniform but float values are off by a small fraction
     * Check if is non uniform within a certain amount of decimal places to account for this
     * @param epsilon the amount the values can differ
     * @returns if the vector is non uniform to a certain number of decimal places
     */
    isNonUniformWithinEpsilon(epsilon: number): boolean;
    /**
     * Gets a boolean indicating that the vector is non uniform meaning x, y or z are not all the same
     */
    get isNonUniform(): boolean;
    /**
     * Gets the current Vector3's floored values and stores them in result
     * @param result the vector to store the result in
     * @returns the result vector
     */
    floorToRef<T extends IVector3LikeInternal>(result: T): T;
    /**
     * Gets a new Vector3 from current Vector3 floored values
     * Example Playground https://playground.babylonjs.com/#R1F8YU#22
     * @returns a new Vector3
     */
    floor(): Vector3;
    /**
     * Gets the current Vector3's fractional values and stores them in result
     * @param result the vector to store the result in
     * @returns the result vector
     */
    fractToRef<T extends IVector3LikeInternal>(result: T): T;
    /**
     * Gets a new Vector3 from current Vector3 fractional values
     * Example Playground https://playground.babylonjs.com/#R1F8YU#23
     * @returns a new Vector3
     */
    fract(): Vector3;
    /**
     * Gets the length of the Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#25
     * @returns the length of the Vector3
     */
    length(): number;
    /**
     * Gets the squared length of the Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#26
     * @returns squared length of the Vector3
     */
    lengthSquared(): number;
    /**
     * Gets a boolean indicating if the vector contains a zero in one of its components
     * Example Playground https://playground.babylonjs.com/#R1F8YU#1
     */
    get hasAZeroComponent(): boolean;
    /**
     * Normalize the current Vector3.
     * Please note that this is an in place operation.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#122
     * @returns the current updated Vector3
     */
    normalize(): this;
    /**
     * Reorders the x y z properties of the vector in place
     * Example Playground https://playground.babylonjs.com/#R1F8YU#44
     * @param order new ordering of the properties (eg. for vector 1,2,3 with "ZYX" will produce 3,2,1)
     * @returns the current updated vector
     */
    reorderInPlace(order: string): this;
    /**
     * Rotates the vector around 0,0,0 by a quaternion
     * Example Playground https://playground.babylonjs.com/#R1F8YU#47
     * @param quaternion the rotation quaternion
     * @param result vector to store the result
     * @returns the resulting vector
     */
    rotateByQuaternionToRef<T extends Vector3>(quaternion: Quaternion, result: T): T;
    /**
     * Rotates a vector around a given point
     * Example Playground https://playground.babylonjs.com/#R1F8YU#46
     * @param quaternion the rotation quaternion
     * @param point the point to rotate around
     * @param result vector to store the result
     * @returns the resulting vector
     */
    rotateByQuaternionAroundPointToRef<T extends Vector3>(quaternion: Quaternion, point: Vector3, result: T): T;
    /**
     * Returns a new Vector3 as the cross product of the current vector and the "other" one
     * The cross product is then orthogonal to both current and "other"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#14
     * @param other defines the right operand
     * @returns the cross product
     */
    cross(other: Vector3): Vector3;
    /**
     * Normalize the current Vector3 with the given input length.
     * Please note that this is an in place operation.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#123
     * @param len the length of the vector
     * @returns the current updated Vector3
     */
    normalizeFromLength(len: number): this;
    /**
     * Normalize the current Vector3 to a new vector
     * Example Playground https://playground.babylonjs.com/#R1F8YU#124
     * @returns the new Vector3
     */
    normalizeToNew(): Vector3;
    /**
     * Normalize the current Vector3 to the reference
     * Example Playground https://playground.babylonjs.com/#R1F8YU#125
     * @param result define the Vector3 to update
     * @returns the updated Vector3
     */
    normalizeToRef<T extends IVector3LikeInternal>(result: T): T;
    /**
     * Creates a new Vector3 copied from the current Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#11
     * @returns the new Vector3
     */
    clone(): Vector3;
    /**
     * Copies the given vector coordinates to the current Vector3 ones
     * Example Playground https://playground.babylonjs.com/#R1F8YU#12
     * @param source defines the source Vector3
     * @returns the current updated Vector3
     */
    copyFrom(source: DeepImmutable<Vector3>): this;
    /**
     * Copies the given floats to the current Vector3 coordinates
     * Example Playground https://playground.babylonjs.com/#R1F8YU#13
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @returns the current updated Vector3
     */
    copyFromFloats(x: number, y: number, z: number): this;
    /**
     * Copies the given floats to the current Vector3 coordinates
     * Example Playground https://playground.babylonjs.com/#R1F8YU#58
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @returns the current updated Vector3
     */
    set(x: number, y: number, z: number): this;
    /**
     * Copies the given float to the current Vector3 coordinates
     * Example Playground https://playground.babylonjs.com/#R1F8YU#59
     * @param v defines the x, y and z coordinates of the operand
     * @returns the current updated Vector3
     */
    setAll(v: number): this;
    /**
     * Get the clip factor between two vectors
     * Example Playground https://playground.babylonjs.com/#R1F8YU#126
     * @param vector0 defines the first operand
     * @param vector1 defines the second operand
     * @param axis defines the axis to use
     * @param size defines the size along the axis
     * @returns the clip factor
     */
    static GetClipFactor(vector0: DeepImmutable<Vector3>, vector1: DeepImmutable<Vector3>, axis: DeepImmutable<Vector3>, size: number): number;
    /**
     * Get angle between two vectors
     * Example Playground https://playground.babylonjs.com/#R1F8YU#86
     * @param vector0 the starting point
     * @param vector1 the ending point
     * @param normal direction of the normal
     * @returns the angle between vector0 and vector1
     */
    static GetAngleBetweenVectors(vector0: DeepImmutable<Vector3>, vector1: DeepImmutable<Vector3>, normal: DeepImmutable<Vector3>): number;
    /**
     * Get angle between two vectors projected on a plane
     * Example Playground https://playground.babylonjs.com/#R1F8YU#87
     * Expectation compute time: 0.01 ms (median) and 0.02 ms (percentile 95%)
     * @param vector0 angle between vector0 and vector1
     * @param vector1 angle between vector0 and vector1
     * @param normal Normal of the projection plane
     * @returns the angle in radians (float) between vector0 and vector1 projected on the plane with the specified normal
     */
    static GetAngleBetweenVectorsOnPlane(vector0: DeepImmutable<Vector3>, vector1: DeepImmutable<Vector3>, normal: DeepImmutable<Vector3>): number;
    /**
     * Gets the rotation that aligns the roll axis (Y) to the line joining the start point to the target point and stores it in the ref Vector3
     * Example PG https://playground.babylonjs.com/#R1F8YU#189
     * @param start the starting point
     * @param target the target point
     * @param ref the vector3 to store the result
     * @returns ref in the form (pitch, yaw, 0)
     */
    static PitchYawRollToMoveBetweenPointsToRef<T extends Vector3>(start: Vector3, target: Vector3, ref: T): T;
    /**
     * Gets the rotation that aligns the roll axis (Y) to the line joining the start point to the target point
     * Example PG https://playground.babylonjs.com/#R1F8YU#188
     * @param start the starting point
     * @param target the target point
     * @returns the rotation in the form (pitch, yaw, 0)
     */
    static PitchYawRollToMoveBetweenPoints(start: Vector3, target: Vector3): Vector3;
    /**
     * Slerp between two vectors. See also `SmoothToRef`
     * Slerp is a spherical linear interpolation
     * giving a slow in and out effect
     * Example Playground 1 https://playground.babylonjs.com/#R1F8YU#108
     * Example Playground 2 https://playground.babylonjs.com/#R1F8YU#109
     * @param vector0 Start vector
     * @param vector1 End vector
     * @param slerp amount (will be clamped between 0 and 1)
     * @param result The slerped vector
     * @returns The slerped vector
     */
    static SlerpToRef<T extends Vector3 = Vector3>(vector0: Vector3, vector1: Vector3, slerp: number, result: T): T;
    /**
     * Smooth interpolation between two vectors using Slerp
     * Example Playground https://playground.babylonjs.com/#R1F8YU#110
     * @param source source vector
     * @param goal goal vector
     * @param deltaTime current interpolation frame
     * @param lerpTime total interpolation time
     * @param result the smoothed vector
     * @returns the smoothed vector
     */
    static SmoothToRef<T extends Vector3 = Vector3>(source: Vector3, goal: Vector3, deltaTime: number, lerpTime: number, result: T): T;
    /**
     * Returns a new Vector3 set from the index "offset" of the given array
     * Example Playground https://playground.babylonjs.com/#R1F8YU#83
     * @param array defines the source array
     * @param offset defines the offset in the source array
     * @returns the new Vector3
     */
    static FromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): Vector3;
    /**
     * Returns a new Vector3 set from the index "offset" of the given Float32Array
     * @param array defines the source array
     * @param offset defines the offset in the source array
     * @returns the new Vector3
     * @deprecated Please use FromArray instead.
     */
    static FromFloatArray(array: DeepImmutable<Float32Array>, offset?: number): Vector3;
    /**
     * Sets the given vector "result" with the element values from the index "offset" of the given array
     * Example Playground https://playground.babylonjs.com/#R1F8YU#84
     * @param array defines the source array
     * @param offset defines the offset in the source array
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static FromArrayToRef<T extends Vector3>(array: DeepImmutable<ArrayLike<number>>, offset: number, result: T): T;
    /**
     * Sets the given vector "result" with the element values from the index "offset" of the given Float32Array
     * @param array defines the source array
     * @param offset defines the offset in the source array
     * @param result defines the Vector3 where to store the result
     * @deprecated Please use FromArrayToRef instead.
     * @returns result input
     */
    static FromFloatArrayToRef<T extends Vector3>(array: DeepImmutable<Float32Array>, offset: number, result: T): T;
    /**
     * Sets the given vector "result" with the given floats.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#85
     * @param x defines the x coordinate of the source
     * @param y defines the y coordinate of the source
     * @param z defines the z coordinate of the source
     * @param result defines the Vector3 where to store the result
     * @returns the result vector
     */
    static FromFloatsToRef<T extends Vector3 = Vector3>(x: number, y: number, z: number, result: T): T;
    /**
     * Returns a new Vector3 set to (0.0, 0.0, 0.0)
     * @returns a new empty Vector3
     */
    static Zero(): Vector3;
    /**
     * Returns a new Vector3 set to (1.0, 1.0, 1.0)
     * @returns a new Vector3
     */
    static One(): Vector3;
    /**
     * Returns a new Vector3 set to (0.0, 1.0, 0.0)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#71
     * @returns a new up Vector3
     */
    static Up(): Vector3;
    /**
     * Gets an up Vector3 that must not be updated
     */
    static get UpReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a down Vector3 that must not be updated
     */
    static get DownReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a right Vector3 that must not be updated
     */
    static get RightReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a left Vector3 that must not be updated
     */
    static get LeftReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a forward Vector3 that must not be updated
     */
    static get LeftHandedForwardReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a forward Vector3 that must not be updated
     */
    static get RightHandedForwardReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a backward Vector3 that must not be updated
     */
    static get LeftHandedBackwardReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a backward Vector3 that must not be updated
     */
    static get RightHandedBackwardReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a zero Vector3 that must not be updated
     */
    static get ZeroReadOnly(): DeepImmutable<Vector3>;
    /**
     * Gets a one Vector3 that must not be updated
     */
    static get OneReadOnly(): DeepImmutable<Vector3>;
    /**
     * Returns a new Vector3 set to (0.0, -1.0, 0.0)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#71
     * @returns a new down Vector3
     */
    static Down(): Vector3;
    /**
     * Returns a new Vector3 set to (0.0, 0.0, 1.0)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#71
     * @param rightHandedSystem is the scene right-handed (negative z)
     * @returns a new forward Vector3
     */
    static Forward(rightHandedSystem?: boolean): Vector3;
    /**
     * Returns a new Vector3 set to (0.0, 0.0, -1.0)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#71
     * @param rightHandedSystem is the scene right-handed (negative-z)
     * @returns a new Backward Vector3
     */
    static Backward(rightHandedSystem?: boolean): Vector3;
    /**
     * Returns a new Vector3 set to (1.0, 0.0, 0.0)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#71
     * @returns a new right Vector3
     */
    static Right(): Vector3;
    /**
     * Returns a new Vector3 set to (-1.0, 0.0, 0.0)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#71
     * @returns a new left Vector3
     */
    static Left(): Vector3;
    /**
     * Returns a new Vector3 with random values between min and max
     * @param min the minimum random value
     * @param max the maximum random value
     * @returns a Vector3 with random values between min and max
     */
    static Random(min?: number, max?: number): Vector3;
    /**
     * Sets a Vector3 with random values between min and max
     * @param min the minimum random value
     * @param max the maximum random value
     * @param ref the ref to store the values in
     * @returns the ref with random values between min and max
     */
    static RandomToRef<T extends Vector3>(min: number | undefined, max: number | undefined, ref: T): T;
    /**
     * Returns a new Vector3 set with the result of the transformation by the given matrix of the given vector.
     * This method computes transformed coordinates only, not transformed direction vectors (ie. it takes translation in account)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#111
     * @param vector defines the Vector3 to transform
     * @param transformation defines the transformation matrix
     * @returns the transformed Vector3
     */
    static TransformCoordinates(vector: DeepImmutable<Vector3>, transformation: DeepImmutable<Matrix>): Vector3;
    /**
     * Sets the given vector "result" coordinates with the result of the transformation by the given matrix of the given vector
     * This method computes transformed coordinates only, not transformed direction vectors (ie. it takes translation in account)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#113
     * @param vector defines the Vector3 to transform
     * @param transformation defines the transformation matrix
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static TransformCoordinatesToRef<T extends Vector3>(vector: DeepImmutable<Vector3>, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Sets the given vector "result" coordinates with the result of the transformation by the given matrix of the given floats (x, y, z)
     * This method computes transformed coordinates only, not transformed direction vectors
     * Example Playground https://playground.babylonjs.com/#R1F8YU#115
     * @param x define the x coordinate of the source vector
     * @param y define the y coordinate of the source vector
     * @param z define the z coordinate of the source vector
     * @param transformation defines the transformation matrix
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static TransformCoordinatesFromFloatsToRef<T extends Vector3>(x: number, y: number, z: number, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Returns a new Vector3 set with the result of the normal transformation by the given matrix of the given vector
     * This methods computes transformed normalized direction vectors only (ie. it does not apply translation)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#112
     * @param vector defines the Vector3 to transform
     * @param transformation defines the transformation matrix
     * @returns the new Vector3
     */
    static TransformNormal(vector: DeepImmutable<Vector3>, transformation: DeepImmutable<Matrix>): Vector3;
    /**
     * Sets the given vector "result" with the result of the normal transformation by the given matrix of the given vector
     * This methods computes transformed normalized direction vectors only (ie. it does not apply translation)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#114
     * @param vector defines the Vector3 to transform
     * @param transformation defines the transformation matrix
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static TransformNormalToRef<T extends Vector3>(vector: DeepImmutable<Vector3>, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Sets the given vector "result" with the result of the normal transformation by the given matrix of the given floats (x, y, z)
     * This methods computes transformed normalized direction vectors only (ie. it does not apply translation)
     * Example Playground https://playground.babylonjs.com/#R1F8YU#116
     * @param x define the x coordinate of the source vector
     * @param y define the y coordinate of the source vector
     * @param z define the z coordinate of the source vector
     * @param transformation defines the transformation matrix
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static TransformNormalFromFloatsToRef<T extends Vector3>(x: number, y: number, z: number, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Returns a new Vector3 located for "amount" on the CatmullRom interpolation spline defined by the vectors "value1", "value2", "value3", "value4"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#69
     * @param value1 defines the first control point
     * @param value2 defines the second control point
     * @param value3 defines the third control point
     * @param value4 defines the fourth control point
     * @param amount defines the amount on the spline to use
     * @returns the new Vector3
     */
    static CatmullRom(value1: DeepImmutable<Vector3>, value2: DeepImmutable<Vector3>, value3: DeepImmutable<Vector3>, value4: DeepImmutable<Vector3>, amount: number): Vector3;
    /**
     * Returns a new Vector3 set with the coordinates of "value", if the vector "value" is in the cube defined by the vectors "min" and "max"
     * If a coordinate value of "value" is lower than one of the "min" coordinate, then this "value" coordinate is set with the "min" one
     * If a coordinate value of "value" is greater than one of the "max" coordinate, then this "value" coordinate is set with the "max" one
     * Example Playground https://playground.babylonjs.com/#R1F8YU#76
     * @param value defines the current value
     * @param min defines the lower range value
     * @param max defines the upper range value
     * @returns the new Vector3
     */
    static Clamp(value: DeepImmutable<Vector3>, min: DeepImmutable<Vector3>, max: DeepImmutable<Vector3>): Vector3;
    /**
     * Sets the given vector "result" with the coordinates of "value", if the vector "value" is in the cube defined by the vectors "min" and "max"
     * If a coordinate value of "value" is lower than one of the "min" coordinate, then this "value" coordinate is set with the "min" one
     * If a coordinate value of "value" is greater than one of the "max" coordinate, then this "value" coordinate is set with the "max" one
     * Example Playground https://playground.babylonjs.com/#R1F8YU#77
     * @param value defines the current value
     * @param min defines the lower range value
     * @param max defines the upper range value
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static ClampToRef<T extends Vector3>(value: DeepImmutable<Vector3>, min: DeepImmutable<Vector3>, max: DeepImmutable<Vector3>, result: T): T;
    /**
     * Checks if a given vector is inside a specific range
     * Example Playground https://playground.babylonjs.com/#R1F8YU#75
     * @param v defines the vector to test
     * @param min defines the minimum range
     * @param max defines the maximum range
     */
    static CheckExtends(v: Vector3, min: Vector3, max: Vector3): void;
    /**
     * Returns a new Vector3 located for "amount" (float) on the Hermite interpolation spline defined by the vectors "value1", "tangent1", "value2", "tangent2"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#89
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent vector
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent vector
     * @param amount defines the amount on the interpolation spline (between 0 and 1)
     * @returns the new Vector3
     */
    static Hermite(value1: DeepImmutable<Vector3>, tangent1: DeepImmutable<Vector3>, value2: DeepImmutable<Vector3>, tangent2: DeepImmutable<Vector3>, amount: number): Vector3;
    /**
     * Returns a new Vector3 which is the 1st derivative of the Hermite spline defined by the vectors "value1", "value2", "tangent1", "tangent2".
     * Example Playground https://playground.babylonjs.com/#R1F8YU#90
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @returns 1st derivative
     */
    static Hermite1stDerivative(value1: DeepImmutable<Vector3>, tangent1: DeepImmutable<Vector3>, value2: DeepImmutable<Vector3>, tangent2: DeepImmutable<Vector3>, time: number): Vector3;
    /**
     * Update a Vector3 with the 1st derivative of the Hermite spline defined by the vectors "value1", "value2", "tangent1", "tangent2".
     * Example Playground https://playground.babylonjs.com/#R1F8YU#91
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @param result define where to store the derivative
     * @returns result input
     */
    static Hermite1stDerivativeToRef<T extends Vector3>(value1: DeepImmutable<Vector3>, tangent1: DeepImmutable<Vector3>, value2: DeepImmutable<Vector3>, tangent2: DeepImmutable<Vector3>, time: number, result: T): T;
    /**
     * Returns a new Vector3 located for "amount" (float) on the linear interpolation between the vectors "start" and "end"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#95
     * @param start defines the start value
     * @param end defines the end value
     * @param amount max defines amount between both (between 0 and 1)
     * @returns the new Vector3
     */
    static Lerp(start: DeepImmutable<Vector3>, end: DeepImmutable<Vector3>, amount: number): Vector3;
    /**
     * Sets the given vector "result" with the result of the linear interpolation from the vector "start" for "amount" to the vector "end"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#93
     * @param start defines the start value
     * @param end defines the end value
     * @param amount max defines amount between both (between 0 and 1)
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static LerpToRef<T extends Vector3>(start: DeepImmutable<Vector3>, end: DeepImmutable<Vector3>, amount: number, result: T): T;
    /**
     * Returns the dot product (float) between the vectors "left" and "right"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#82
     * @param left defines the left operand
     * @param right defines the right operand
     * @returns the dot product
     */
    static Dot(left: DeepImmutable<Vector3>, right: DeepImmutable<Vector3>): number;
    /**
     * Returns the dot product (float) between the current vectors and "otherVector"
     * @param otherVector defines the right operand
     * @returns the dot product
     */
    dot(otherVector: DeepImmutable<Vector3>): number;
    /**
     * Returns a new Vector3 as the cross product of the vectors "left" and "right"
     * The cross product is then orthogonal to both "left" and "right"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#15
     * @param left defines the left operand
     * @param right defines the right operand
     * @returns the cross product
     */
    static Cross(left: DeepImmutable<Vector3>, right: DeepImmutable<Vector3>): Vector3;
    /**
     * Sets the given vector "result" with the cross product of "left" and "right"
     * The cross product is then orthogonal to both "left" and "right"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#78
     * @param left defines the left operand
     * @param right defines the right operand
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static CrossToRef<T extends Vector3>(left: DeepImmutable<Vector3>, right: DeepImmutable<Vector3>, result: T): T;
    /**
     * Returns a new Vector3 as the normalization of the given vector
     * Example Playground https://playground.babylonjs.com/#R1F8YU#98
     * @param vector defines the Vector3 to normalize
     * @returns the new Vector3
     */
    static Normalize(vector: DeepImmutable<Vector3>): Vector3;
    /**
     * Sets the given vector "result" with the normalization of the given first vector
     * Example Playground https://playground.babylonjs.com/#R1F8YU#98
     * @param vector defines the Vector3 to normalize
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static NormalizeToRef<T extends Vector3>(vector: DeepImmutable<Vector3>, result: T): T;
    /**
     * Project a Vector3 onto screen space
     * Example Playground https://playground.babylonjs.com/#R1F8YU#101
     * @param vector defines the Vector3 to project
     * @param world defines the world matrix to use
     * @param transform defines the transform (view x projection) matrix to use
     * @param viewport defines the screen viewport to use
     * @returns the new Vector3
     */
    static Project(vector: DeepImmutable<Vector3>, world: DeepImmutable<Matrix>, transform: DeepImmutable<Matrix>, viewport: DeepImmutable<Viewport>): Vector3;
    /**
     * Project a Vector3 onto screen space to reference
     * Example Playground https://playground.babylonjs.com/#R1F8YU#102
     * @param vector defines the Vector3 to project
     * @param world defines the world matrix to use
     * @param transform defines the transform (view x projection) matrix to use
     * @param viewport defines the screen viewport to use
     * @param result the vector in which the screen space will be stored
     * @returns result input
     */
    static ProjectToRef<T extends Vector3>(vector: DeepImmutable<Vector3>, world: DeepImmutable<Matrix>, transform: DeepImmutable<Matrix>, viewport: DeepImmutable<Viewport>, result: T): T;
    /**
     * Reflects a vector off the plane defined by a normalized normal
     * @param inDirection defines the vector direction
     * @param normal defines the normal - Must be normalized
     * @returns the resulting vector
     */
    static Reflect(inDirection: DeepImmutable<Vector3>, normal: DeepImmutable<Vector3>): Vector3;
    /**
     * Reflects a vector off the plane defined by a normalized normal to reference
     * @param inDirection defines the vector direction
     * @param normal defines the normal - Must be normalized
     * @param ref defines the Vector3 where to store the result
     * @returns the resulting vector
     */
    static ReflectToRef<T extends Vector3>(inDirection: DeepImmutable<Vector3>, normal: DeepImmutable<Vector3>, ref: T): T;
    /**
     * Unproject from screen space to object space
     * Example Playground https://playground.babylonjs.com/#R1F8YU#121
     * @param source defines the screen space Vector3 to use
     * @param viewportWidth defines the current width of the viewport
     * @param viewportHeight defines the current height of the viewport
     * @param world defines the world matrix to use (can be set to Identity to go to world space)
     * @param transform defines the transform (view x projection) matrix to use
     * @returns the new Vector3
     */
    static UnprojectFromTransform(source: DeepImmutable<Vector3>, viewportWidth: number, viewportHeight: number, world: DeepImmutable<Matrix>, transform: DeepImmutable<Matrix>): Vector3;
    /**
     * Unproject from screen space to object space
     * Example Playground https://playground.babylonjs.com/#R1F8YU#117
     * @param source defines the screen space Vector3 to use
     * @param viewportWidth defines the current width of the viewport
     * @param viewportHeight defines the current height of the viewport
     * @param world defines the world matrix to use (can be set to Identity to go to world space)
     * @param view defines the view matrix to use
     * @param projection defines the projection matrix to use
     * @returns the new Vector3
     */
    static Unproject(source: DeepImmutable<Vector3>, viewportWidth: number, viewportHeight: number, world: DeepImmutable<Matrix>, view: DeepImmutable<Matrix>, projection: DeepImmutable<Matrix>): Vector3;
    /**
     * Unproject from screen space to object space
     * Example Playground https://playground.babylonjs.com/#R1F8YU#119
     * @param source defines the screen space Vector3 to use
     * @param viewportWidth defines the current width of the viewport
     * @param viewportHeight defines the current height of the viewport
     * @param world defines the world matrix to use (can be set to Identity to go to world space)
     * @param view defines the view matrix to use
     * @param projection defines the projection matrix to use
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static UnprojectToRef<T extends Vector3>(source: DeepImmutable<Vector3>, viewportWidth: number, viewportHeight: number, world: DeepImmutable<Matrix>, view: DeepImmutable<Matrix>, projection: DeepImmutable<Matrix>, result: T): T;
    /**
     * Unproject from screen space to object space
     * Example Playground https://playground.babylonjs.com/#R1F8YU#120
     * @param sourceX defines the screen space x coordinate to use
     * @param sourceY defines the screen space y coordinate to use
     * @param sourceZ defines the screen space z coordinate to use
     * @param viewportWidth defines the current width of the viewport
     * @param viewportHeight defines the current height of the viewport
     * @param world defines the world matrix to use (can be set to Identity to go to world space)
     * @param view defines the view matrix to use
     * @param projection defines the projection matrix to use
     * @param result defines the Vector3 where to store the result
     * @returns result input
     */
    static UnprojectFloatsToRef<T extends Vector3>(sourceX: float, sourceY: float, sourceZ: float, viewportWidth: number, viewportHeight: number, world: DeepImmutable<Matrix>, view: DeepImmutable<Matrix>, projection: DeepImmutable<Matrix>, result: T): T;
    /**
     * Gets the minimal coordinate values between two Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#97
     * @param left defines the first operand
     * @param right defines the second operand
     * @returns the new Vector3
     */
    static Minimize(left: DeepImmutable<Vector3>, right: DeepImmutable<Vector3>): Vector3;
    /**
     * Gets the maximal coordinate values between two Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#96
     * @param left defines the first operand
     * @param right defines the second operand
     * @returns the new Vector3
     */
    static Maximize(left: DeepImmutable<Vector3>, right: DeepImmutable<Vector3>): Vector3;
    /**
     * Returns the distance between the vectors "value1" and "value2"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#81
     * @param value1 defines the first operand
     * @param value2 defines the second operand
     * @returns the distance
     */
    static Distance(value1: DeepImmutable<Vector3>, value2: DeepImmutable<Vector3>): number;
    /**
     * Returns the squared distance between the vectors "value1" and "value2"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#80
     * @param value1 defines the first operand
     * @param value2 defines the second operand
     * @returns the squared distance
     */
    static DistanceSquared(value1: DeepImmutable<Vector3>, value2: DeepImmutable<Vector3>): number;
    /**
     * Projects "vector" on the triangle determined by its extremities "p0", "p1" and "p2", stores the result in "ref"
     * and returns the distance to the projected point.
     * Example Playground https://playground.babylonjs.com/#R1F8YU#104
     * From http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.4264&rep=rep1&type=pdf
     *
     * @param vector the vector to get distance from
     * @param p0 extremity of the triangle
     * @param p1 extremity of the triangle
     * @param p2 extremity of the triangle
     * @param ref variable to store the result to
     * @returns The distance between "ref" and "vector"
     */
    static ProjectOnTriangleToRef(vector: DeepImmutable<Vector3>, p0: DeepImmutable<Vector3>, p1: DeepImmutable<Vector3>, p2: DeepImmutable<Vector3>, ref: Vector3): number;
    /**
     * Returns a new Vector3 located at the center between "value1" and "value2"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#72
     * @param value1 defines the first operand
     * @param value2 defines the second operand
     * @returns the new Vector3
     */
    static Center(value1: DeepImmutable<Vector3>, value2: DeepImmutable<Vector3>): Vector3;
    /**
     * Gets the center of the vectors "value1" and "value2" and stores the result in the vector "ref"
     * Example Playground https://playground.babylonjs.com/#R1F8YU#73
     * @param value1 defines first vector
     * @param value2 defines second vector
     * @param ref defines third vector
     * @returns ref
     */
    static CenterToRef<T extends Vector3>(value1: DeepImmutable<Vector3>, value2: DeepImmutable<Vector3>, ref: T): T;
    /**
     * Given three orthogonal normalized left-handed oriented Vector3 axis in space (target system),
     * RotationFromAxis() returns the rotation Euler angles (ex : rotation.x, rotation.y, rotation.z) to apply
     * to something in order to rotate it from its local system to the given target system
     * Note: axis1, axis2 and axis3 are normalized during this operation
     * Example Playground https://playground.babylonjs.com/#R1F8YU#106
     * @param axis1 defines the first axis
     * @param axis2 defines the second axis
     * @param axis3 defines the third axis
     * @returns a new Vector3
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/center_origin/target_align
     */
    static RotationFromAxis(axis1: DeepImmutable<Vector3>, axis2: DeepImmutable<Vector3>, axis3: DeepImmutable<Vector3>): Vector3;
    /**
     * The same than RotationFromAxis but updates the given ref Vector3 parameter instead of returning a new Vector3
     * Example Playground https://playground.babylonjs.com/#R1F8YU#107
     * @param axis1 defines the first axis
     * @param axis2 defines the second axis
     * @param axis3 defines the third axis
     * @param ref defines the Vector3 where to store the result
     * @returns result input
     */
    static RotationFromAxisToRef<T extends Vector3>(axis1: DeepImmutable<Vector3>, axis2: DeepImmutable<Vector3>, axis3: DeepImmutable<Vector3>, ref: T): T;
}
/**
 * Vector4 class created for EulerAngle class conversion to Quaternion
 */
declare class Vector4 implements Vector<Tuple<number, 4>, IVector4Like>, IVector4Like {
    /**
     * If the first vector is flagged with integers (as everything is 0,0,0,0), V8 stores all of the properties as integers internally because it doesn't know any better yet.
     * If subsequent vectors are created with non-integer values, V8 determines that it would be best to represent these properties as doubles instead of integers,
     * and henceforth it will use floating-point representation for all Vector4 instances that it creates.
     * But the original Vector4 instances are unchanged and has a "deprecated map".
     * If we keep using the Vector4 instances from step 1, it will now be a poison pill which will mess up optimizations in any code it touches.
     */
    static _V8PerformanceHack: DeepImmutable<Vector4>;
    private static _ZeroReadOnly;
    /**
     * @see Tensor.dimension
     */
    readonly dimension: Readonly<[4]>;
    /**
     * @see Tensor.rank
     */
    readonly rank: 1;
    /** @internal */
    _x: number;
    /** @internal */
    _y: number;
    /** @internal */
    _z: number;
    /** @internal */
    _w: number;
    /** @internal */
    _isDirty: boolean;
    /** Gets or sets the x coordinate */
    get x(): number;
    set x(value: number);
    /** Gets or sets the y coordinate */
    get y(): number;
    set y(value: number);
    /** Gets or sets the z coordinate */
    get z(): number;
    set z(value: number);
    /** Gets or sets the w coordinate */
    get w(): number;
    set w(value: number);
    /**
     * Creates a Vector4 object from the given floats.
     * @param x x value of the vector
     * @param y y value of the vector
     * @param z z value of the vector
     * @param w w value of the vector
     */
    constructor(x?: number, y?: number, z?: number, w?: number);
    /**
     * Returns the string with the Vector4 coordinates.
     * @returns a string containing all the vector values
     */
    toString(): string;
    /**
     * Returns the string "Vector4".
     * @returns "Vector4"
     */
    getClassName(): string;
    /**
     * Returns the Vector4 hash code.
     * @returns a unique hash code
     */
    getHashCode(): number;
    /**
     * Returns a new array populated with 4 elements : the Vector4 coordinates.
     * @returns the resulting array
     */
    asArray(): Tuple<number, 4>;
    /**
     * Populates the given array from the given index with the Vector4 coordinates.
     * @param array array to populate
     * @param index index of the array to start at (default: 0)
     * @returns the Vector4.
     */
    toArray(array: FloatArray, index?: number): this;
    /**
     * Update the current vector from an array
     * @param array defines the destination array
     * @param offset defines the offset in the destination array
     * @returns the current Vector3
     */
    fromArray(array: FloatArray, offset?: number): this;
    /**
     * Adds the given vector to the current Vector4.
     * @param otherVector the vector to add
     * @returns the updated Vector4.
     */
    addInPlace(otherVector: DeepImmutable<Vector4>): this;
    /**
     * Adds the given coordinates to the current Vector4
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @param w defines the w coordinate of the operand
     * @returns the current updated Vector4
     */
    addInPlaceFromFloats(x: number, y: number, z: number, w: number): this;
    /**
     * Returns a new Vector4 as the result of the addition of the current Vector4 and the given one.
     * @param otherVector the vector to add
     * @returns the resulting vector
     */
    add(otherVector: DeepImmutable<IVector4Like>): Vector4;
    /**
     * Updates the given vector "result" with the result of the addition of the current Vector4 and the given one.
     * @param otherVector the vector to add
     * @param result the vector to store the result
     * @returns result input
     */
    addToRef<T extends IVector4Like>(otherVector: DeepImmutable<IVector4Like>, result: T): T;
    /**
     * Subtract in place the given vector from the current Vector4.
     * @param otherVector the vector to subtract
     * @returns the updated Vector4.
     */
    subtractInPlace(otherVector: DeepImmutable<IVector4Like>): this;
    /**
     * Returns a new Vector4 with the result of the subtraction of the given vector from the current Vector4.
     * @param otherVector the vector to add
     * @returns the new vector with the result
     */
    subtract(otherVector: DeepImmutable<IVector4Like>): Vector4;
    /**
     * Sets the given vector "result" with the result of the subtraction of the given vector from the current Vector4.
     * @param otherVector the vector to subtract
     * @param result the vector to store the result
     * @returns result input
     */
    subtractToRef<T extends IVector4Like>(otherVector: DeepImmutable<IVector4Like>, result: T): T;
    /**
     * Returns a new Vector4 set with the result of the subtraction of the given floats from the current Vector4 coordinates.
     * @param x value to subtract
     * @param y value to subtract
     * @param z value to subtract
     * @param w value to subtract
     * @returns new vector containing the result
     */
    subtractFromFloats(x: number, y: number, z: number, w: number): Vector4;
    /**
     * Sets the given vector "result" set with the result of the subtraction of the given floats from the current Vector4 coordinates.
     * @param x value to subtract
     * @param y value to subtract
     * @param z value to subtract
     * @param w value to subtract
     * @param result the vector to store the result in
     * @returns result input
     */
    subtractFromFloatsToRef<T extends IVector4Like>(x: number, y: number, z: number, w: number, result: T): T;
    /**
     * Returns a new Vector4 set with the current Vector4 negated coordinates.
     * @returns a new vector with the negated values
     */
    negate(): Vector4;
    /**
     * Negate this vector in place
     * @returns this
     */
    negateInPlace(): this;
    /**
     * Negate the current Vector4 and stores the result in the given vector "result" coordinates
     * @param result defines the Vector3 object where to store the result
     * @returns the result
     */
    negateToRef<T extends IVector4Like>(result: T): T;
    /**
     * Multiplies the current Vector4 coordinates by scale (float).
     * @param scale the number to scale with
     * @returns the updated Vector4.
     */
    scaleInPlace(scale: number): this;
    /**
     * Returns a new Vector4 set with the current Vector4 coordinates multiplied by scale (float).
     * @param scale the number to scale with
     * @returns a new vector with the result
     */
    scale(scale: number): Vector4;
    /**
     * Sets the given vector "result" with the current Vector4 coordinates multiplied by scale (float).
     * @param scale the number to scale with
     * @param result a vector to store the result in
     * @returns result input
     */
    scaleToRef<T extends IVector4Like>(scale: number, result: T): T;
    /**
     * Scale the current Vector4 values by a factor and add the result to a given Vector4
     * @param scale defines the scale factor
     * @param result defines the Vector4 object where to store the result
     * @returns result input
     */
    scaleAndAddToRef<T extends IVector4Like>(scale: number, result: T): T;
    /**
     * Boolean : True if the current Vector4 coordinates are stricly equal to the given ones.
     * @param otherVector the vector to compare against
     * @returns true if they are equal
     */
    equals(otherVector: DeepImmutable<IVector4Like>): boolean;
    /**
     * Boolean : True if the current Vector4 coordinates are each beneath the distance "epsilon" from the given vector ones.
     * @param otherVector vector to compare against
     * @param epsilon (Default: very small number)
     * @returns true if they are equal
     */
    equalsWithEpsilon(otherVector: DeepImmutable<IVector4Like>, epsilon?: number): boolean;
    /**
     * Boolean : True if the given floats are strictly equal to the current Vector4 coordinates.
     * @param x x value to compare against
     * @param y y value to compare against
     * @param z z value to compare against
     * @param w w value to compare against
     * @returns true if equal
     */
    equalsToFloats(x: number, y: number, z: number, w: number): boolean;
    /**
     * Multiplies in place the current Vector4 by the given one.
     * @param otherVector vector to multiple with
     * @returns the updated Vector4.
     */
    multiplyInPlace(otherVector: DeepImmutable<IVector4Like>): this;
    /**
     * Returns a new Vector4 set with the multiplication result of the current Vector4 and the given one.
     * @param otherVector vector to multiple with
     * @returns resulting new vector
     */
    multiply(otherVector: DeepImmutable<IVector4Like>): Vector4;
    /**
     * Updates the given vector "result" with the multiplication result of the current Vector4 and the given one.
     * @param otherVector vector to multiple with
     * @param result vector to store the result
     * @returns result input
     */
    multiplyToRef<T extends IVector4Like>(otherVector: DeepImmutable<IVector4Like>, result: T): T;
    /**
     * Returns a new Vector4 set with the multiplication result of the given floats and the current Vector4 coordinates.
     * @param x x value multiply with
     * @param y y value multiply with
     * @param z z value multiply with
     * @param w w value multiply with
     * @returns resulting new vector
     */
    multiplyByFloats(x: number, y: number, z: number, w: number): Vector4;
    /**
     * Returns a new Vector4 set with the division result of the current Vector4 by the given one.
     * @param otherVector vector to devide with
     * @returns resulting new vector
     */
    divide(otherVector: DeepImmutable<IVector4Like>): Vector4;
    /**
     * Updates the given vector "result" with the division result of the current Vector4 by the given one.
     * @param otherVector vector to devide with
     * @param result vector to store the result
     * @returns result input
     */
    divideToRef<T extends IVector4Like>(otherVector: DeepImmutable<IVector4Like>, result: T): T;
    /**
     * Divides the current Vector3 coordinates by the given ones.
     * @param otherVector vector to devide with
     * @returns the updated Vector3.
     */
    divideInPlace(otherVector: DeepImmutable<IVector4Like>): this;
    /**
     * Updates the Vector4 coordinates with the minimum values between its own and the given vector ones
     * @param other defines the second operand
     * @returns the current updated Vector4
     */
    minimizeInPlace(other: DeepImmutable<IVector4Like>): this;
    /**
     * Updates the Vector4 coordinates with the maximum values between its own and the given vector ones
     * @param other defines the second operand
     * @returns the current updated Vector4
     */
    maximizeInPlace(other: DeepImmutable<IVector4Like>): this;
    /**
     * Updates the current Vector4 with the minimal coordinate values between its and the given coordinates
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @param w defines the w coordinate of the operand
     * @returns the current updated Vector4
     */
    minimizeInPlaceFromFloats(x: number, y: number, z: number, w: number): this;
    /**
     * Updates the current Vector4 with the maximal coordinate values between its and the given coordinates.
     * @param x defines the x coordinate of the operand
     * @param y defines the y coordinate of the operand
     * @param z defines the z coordinate of the operand
     * @param w defines the w coordinate of the operand
     * @returns the current updated Vector4
     */
    maximizeInPlaceFromFloats(x: number, y: number, z: number, w: number): this;
    /**
     * Gets the current Vector4's floored values and stores them in result
     * @param result the vector to store the result in
     * @returns the result vector
     */
    floorToRef<T extends IVector4Like>(result: T): T;
    /**
     * Gets a new Vector4 from current Vector4 floored values
     * @returns a new Vector4
     */
    floor(): Vector4;
    /**
     * Gets the current Vector4's fractional values and stores them in result
     * @param result the vector to store the result in
     * @returns the result vector
     */
    fractToRef<T extends IVector4Like>(result: T): T;
    /**
     * Gets a new Vector4 from current Vector4 fractional values
     * @returns a new Vector4
     */
    fract(): Vector4;
    /**
     * Returns the Vector4 length (float).
     * @returns the length
     */
    length(): number;
    /**
     * Returns the Vector4 squared length (float).
     * @returns the length squared
     */
    lengthSquared(): number;
    /**
     * Normalizes in place the Vector4.
     * @returns the updated Vector4.
     */
    normalize(): this;
    /**
     * Normalize the current Vector4 with the given input length.
     * Please note that this is an in place operation.
     * @param len the length of the vector
     * @returns the current updated Vector4
     */
    normalizeFromLength(len: number): this;
    /**
     * Normalize the current Vector4 to a new vector
     * @returns the new Vector4
     */
    normalizeToNew(): Vector4;
    /**
     * Normalize the current Vector4 to the reference
     * @param reference define the Vector4 to update
     * @returns the updated Vector4
     */
    normalizeToRef<T extends IVector4Like>(reference: T): T;
    /**
     * Returns a new Vector3 from the Vector4 (x, y, z) coordinates.
     * @returns this converted to a new vector3
     */
    toVector3(): Vector3;
    /**
     * Returns a new Vector4 copied from the current one.
     * @returns the new cloned vector
     */
    clone(): Vector4;
    /**
     * Updates the current Vector4 with the given one coordinates.
     * @param source the source vector to copy from
     * @returns the updated Vector4.
     */
    copyFrom(source: DeepImmutable<IVector4Like>): this;
    /**
     * Updates the current Vector4 coordinates with the given floats.
     * @param x float to copy from
     * @param y float to copy from
     * @param z float to copy from
     * @param w float to copy from
     * @returns the updated Vector4.
     */
    copyFromFloats(x: number, y: number, z: number, w: number): this;
    /**
     * Updates the current Vector4 coordinates with the given floats.
     * @param x float to set from
     * @param y float to set from
     * @param z float to set from
     * @param w float to set from
     * @returns the updated Vector4.
     */
    set(x: number, y: number, z: number, w: number): this;
    /**
     * Copies the given float to the current Vector4 coordinates
     * @param v defines the x, y, z and w coordinates of the operand
     * @returns the current updated Vector4
     */
    setAll(v: number): this;
    /**
     * Returns the dot product (float) between the current vectors and "otherVector"
     * @param otherVector defines the right operand
     * @returns the dot product
     */
    dot(otherVector: DeepImmutable<IVector4Like>): number;
    /**
     * Returns a new Vector4 set from the starting index of the given array.
     * @param array the array to pull values from
     * @param offset the offset into the array to start at
     * @returns the new vector
     */
    static FromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): Vector4;
    /**
     * Updates the given vector "result" from the starting index of the given array.
     * @param array the array to pull values from
     * @param offset the offset into the array to start at
     * @param result the vector to store the result in
     * @returns result input
     */
    static FromArrayToRef<T extends IVector4Like>(array: DeepImmutable<ArrayLike<number>>, offset: number, result: T): T;
    /**
     * Updates the given vector "result" from the starting index of the given Float32Array.
     * @param array the array to pull values from
     * @param offset the offset into the array to start at
     * @param result the vector to store the result in
     * @returns result input
     */
    static FromFloatArrayToRef<T extends IVector4Like>(array: DeepImmutable<Float32Array>, offset: number, result: T): T;
    /**
     * Updates the given vector "result" coordinates from the given floats.
     * @param x float to set from
     * @param y float to set from
     * @param z float to set from
     * @param w float to set from
     * @param result the vector to the floats in
     * @returns result input
     */
    static FromFloatsToRef<T extends IVector4Like>(x: number, y: number, z: number, w: number, result: T): T;
    /**
     * Returns a new Vector4 set to (0.0, 0.0, 0.0, 0.0)
     * @returns the new vector
     */
    static Zero(): Vector4;
    /**
     * Returns a new Vector4 set to (1.0, 1.0, 1.0, 1.0)
     * @returns the new vector
     */
    static One(): Vector4;
    /**
     * Returns a new Vector4 with random values between min and max
     * @param min the minimum random value
     * @param max the maximum random value
     * @returns a Vector4 with random values between min and max
     */
    static Random(min?: number, max?: number): Vector4;
    /**
     * Sets a Vector4 with random values between min and max
     * @param min the minimum random value
     * @param max the maximum random value
     * @param ref the ref to store the values in
     * @returns the ref with random values between min and max
     */
    static RandomToRef<T extends IVector4Like>(min: number | undefined, max: number | undefined, ref: T): T;
    /**
     * Returns a new Vector4 set with the coordinates of "value", if the vector "value" is in the cube defined by the vectors "min" and "max"
     * If a coordinate value of "value" is lower than one of the "min" coordinate, then this "value" coordinate is set with the "min" one
     * If a coordinate value of "value" is greater than one of the "max" coordinate, then this "value" coordinate is set with the "max" one
     * @param value defines the current value
     * @param min defines the lower range value
     * @param max defines the upper range value
     * @returns the new Vector4
     */
    static Clamp(value: DeepImmutable<IVector4Like>, min: DeepImmutable<IVector4Like>, max: DeepImmutable<IVector4Like>): Vector4;
    /**
     * Sets the given vector "result" with the coordinates of "value", if the vector "value" is in the cube defined by the vectors "min" and "max"
     * If a coordinate value of "value" is lower than one of the "min" coordinate, then this "value" coordinate is set with the "min" one
     * If a coordinate value of "value" is greater than one of the "max" coordinate, then this "value" coordinate is set with the "max" one
     * @param value defines the current value
     * @param min defines the lower range value
     * @param max defines the upper range value
     * @param result defines the Vector4 where to store the result
     * @returns result input
     */
    static ClampToRef<T extends IVector4Like>(value: DeepImmutable<IVector4Like>, min: DeepImmutable<IVector4Like>, max: DeepImmutable<IVector4Like>, result: T): T;
    /**
     * Checks if a given vector is inside a specific range
     * Example Playground https://playground.babylonjs.com/#R1F8YU#75
     * @param v defines the vector to test
     * @param min defines the minimum range
     * @param max defines the maximum range
     */
    static CheckExtends(v: IVector4Like, min: Vector4, max: Vector4): void;
    /**
     * Gets a zero Vector4 that must not be updated
     */
    static get ZeroReadOnly(): DeepImmutable<Vector4>;
    /**
     * Returns a new normalized Vector4 from the given one.
     * @param vector the vector to normalize
     * @returns the vector
     */
    static Normalize(vector: DeepImmutable<Vector4>): Vector4;
    /**
     * Updates the given vector "result" from the normalization of the given one.
     * @param vector the vector to normalize
     * @param result the vector to store the result in
     * @returns result input
     */
    static NormalizeToRef<T extends IVector4Like>(vector: DeepImmutable<Vector4>, result: T): T;
    /**
     * Returns a vector with the minimum values from the left and right vectors
     * @param left left vector to minimize
     * @param right right vector to minimize
     * @returns a new vector with the minimum of the left and right vector values
     */
    static Minimize<T extends Vector4>(left: DeepImmutable<T>, right: DeepImmutable<Vector4>): Vector4;
    /**
     * Returns a vector with the maximum values from the left and right vectors
     * @param left left vector to maximize
     * @param right right vector to maximize
     * @returns a new vector with the maximum of the left and right vector values
     */
    static Maximize(left: DeepImmutable<IVector4Like>, right: DeepImmutable<IVector4Like>): Vector4;
    /**
     * Returns the distance (float) between the vectors "value1" and "value2".
     * @param value1 value to calulate the distance between
     * @param value2 value to calulate the distance between
     * @returns the distance between the two vectors
     */
    static Distance(value1: DeepImmutable<IVector4Like>, value2: DeepImmutable<IVector4Like>): number;
    /**
     * Returns the squared distance (float) between the vectors "value1" and "value2".
     * @param value1 value to calulate the distance between
     * @param value2 value to calulate the distance between
     * @returns the distance between the two vectors squared
     */
    static DistanceSquared(value1: DeepImmutable<IVector4Like>, value2: DeepImmutable<IVector4Like>): number;
    /**
     * Returns a new Vector4 located at the center between the vectors "value1" and "value2".
     * @param value1 value to calulate the center between
     * @param value2 value to calulate the center between
     * @returns the center between the two vectors
     */
    static Center(value1: DeepImmutable<IVector4Like>, value2: DeepImmutable<IVector4Like>): Vector4;
    /**
     * Gets the center of the vectors "value1" and "value2" and stores the result in the vector "ref"
     * @param value1 defines first vector
     * @param value2 defines second vector
     * @param ref defines third vector
     * @returns ref
     */
    static CenterToRef<T extends IVector4Like>(value1: DeepImmutable<IVector4Like>, value2: DeepImmutable<IVector4Like>, ref: T): T;
    /**
     * Returns a new Vector4 set with the result of the transformation by the given matrix of the given vector.
     * This method computes tranformed coordinates only, not transformed direction vectors (ie. it takes translation in account)
     * The difference with Vector3.TransformCoordinates is that the w component is not used to divide the other coordinates but is returned in the w coordinate instead
     * @param vector defines the Vector3 to transform
     * @param transformation defines the transformation matrix
     * @returns the transformed Vector4
     */
    static TransformCoordinates(vector: DeepImmutable<Vector3>, transformation: DeepImmutable<Matrix>): Vector4;
    /**
     * Sets the given vector "result" coordinates with the result of the transformation by the given matrix of the given vector
     * This method computes tranformed coordinates only, not transformed direction vectors (ie. it takes translation in account)
     * The difference with Vector3.TransformCoordinatesToRef is that the w component is not used to divide the other coordinates but is returned in the w coordinate instead
     * @param vector defines the Vector3 to transform
     * @param transformation defines the transformation matrix
     * @param result defines the Vector4 where to store the result
     * @returns result input
     */
    static TransformCoordinatesToRef<T extends IVector4Like>(vector: DeepImmutable<Vector3>, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Sets the given vector "result" coordinates with the result of the transformation by the given matrix of the given floats (x, y, z)
     * This method computes tranformed coordinates only, not transformed direction vectors
     * The difference with Vector3.TransformCoordinatesFromFloatsToRef is that the w component is not used to divide the other coordinates but is returned in the w coordinate instead
     * @param x define the x coordinate of the source vector
     * @param y define the y coordinate of the source vector
     * @param z define the z coordinate of the source vector
     * @param transformation defines the transformation matrix
     * @param result defines the Vector4 where to store the result
     * @returns result input
     */
    static TransformCoordinatesFromFloatsToRef<T extends IVector4Like>(x: number, y: number, z: number, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Returns a new Vector4 set with the result of the normal transformation by the given matrix of the given vector.
     * This methods computes transformed normalized direction vectors only.
     * @param vector the vector to transform
     * @param transformation the transformation matrix to apply
     * @returns the new vector
     */
    static TransformNormal(vector: DeepImmutable<IVector4Like>, transformation: DeepImmutable<Matrix>): Vector4;
    /**
     * Sets the given vector "result" with the result of the normal transformation by the given matrix of the given vector.
     * This methods computes transformed normalized direction vectors only.
     * @param vector the vector to transform
     * @param transformation the transformation matrix to apply
     * @param result the vector to store the result in
     * @returns result input
     */
    static TransformNormalToRef<T extends IVector4Like>(vector: DeepImmutable<IVector4Like>, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Sets the given vector "result" with the result of the normal transformation by the given matrix of the given floats (x, y, z, w).
     * This methods computes transformed normalized direction vectors only.
     * @param x value to transform
     * @param y value to transform
     * @param z value to transform
     * @param w value to transform
     * @param transformation the transformation matrix to apply
     * @param result the vector to store the results in
     * @returns result input
     */
    static TransformNormalFromFloatsToRef<T extends IVector4Like>(x: number, y: number, z: number, w: number, transformation: DeepImmutable<Matrix>, result: T): T;
    /**
     * Creates a new Vector4 from a Vector3
     * @param source defines the source data
     * @param w defines the 4th component (default is 0)
     * @returns a new Vector4
     */
    static FromVector3(source: Vector3, w?: number): Vector4;
    /**
     * Returns the dot product (float) between the vectors "left" and "right"
     * @param left defines the left operand
     * @param right defines the right operand
     * @returns the dot product
     */
    static Dot(left: DeepImmutable<IVector4Like>, right: DeepImmutable<IVector4Like>): number;
}
/**
 * Class used to store quaternion data
 * Example Playground - Overview - https://playground.babylonjs.com/#L49EJ7#100
 * @see https://en.wikipedia.org/wiki/Quaternion
 * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms
 */
declare class Quaternion implements Tensor<Tuple<number, 4>, Quaternion>, IQuaternionLike {
    /**
     * If the first quaternion is flagged with integers (as everything is 0,0,0,0), V8 stores all of the properties as integers internally because it doesn't know any better yet.
     * If subsequent quaternion are created with non-integer values, V8 determines that it would be best to represent these properties as doubles instead of integers,
     * and henceforth it will use floating-point representation for all quaternion instances that it creates.
     * But the original quaternion instances are unchanged and has a "deprecated map".
     * If we keep using the quaternion instances from step 1, it will now be a poison pill which will mess up optimizations in any code it touches.
     */
    static _V8PerformanceHack: DeepImmutable<Quaternion>;
    /** @internal */
    _x: number;
    /** @internal */
    _y: number;
    /** @internal */
    _z: number;
    /** @internal */
    _w: number;
    /** @internal */
    _isDirty: boolean;
    /** Gets or sets the x coordinate */
    get x(): number;
    set x(value: number);
    /** Gets or sets the y coordinate */
    get y(): number;
    set y(value: number);
    /** Gets or sets the z coordinate */
    get z(): number;
    set z(value: number);
    /** Gets or sets the w coordinate */
    get w(): number;
    set w(value: number);
    /**
     * @see Tensor.dimension
     */
    readonly dimension: Readonly<[4]>;
    /**
     * @see Tensor.rank
     */
    readonly rank: 1;
    /**
     * Creates a new Quaternion from the given floats
     * @param x defines the first component (0 by default)
     * @param y defines the second component (0 by default)
     * @param z defines the third component (0 by default)
     * @param w defines the fourth component (1.0 by default)
     */
    constructor(x?: number, y?: number, z?: number, w?: number);
    /**
     * Gets a string representation for the current quaternion
     * @returns a string with the Quaternion coordinates
     */
    toString(): string;
    /**
     * Gets the class name of the quaternion
     * @returns the string "Quaternion"
     */
    getClassName(): string;
    /**
     * Gets a hash code for this quaternion
     * @returns the quaternion hash code
     */
    getHashCode(): number;
    /**
     * Copy the quaternion to an array
     * Example Playground https://playground.babylonjs.com/#L49EJ7#13
     * @returns a new array populated with 4 elements from the quaternion coordinates
     */
    asArray(): Tuple<number, 4>;
    /**
     * Stores from the starting index in the given array the Quaternion successive values
     * Example Playground https://playground.babylonjs.com/#L49EJ7#59
     * @param array defines the array where to store the x,y,z,w components
     * @param index defines an optional index in the target array to define where to start storing values
     * @returns the current Quaternion object
     */
    toArray(array: FloatArray, index?: number): this;
    fromArray(array: FloatArray, index?: number): this;
    /**
     * Check if two quaternions are equals
     * Example Playground https://playground.babylonjs.com/#L49EJ7#38
     * @param otherQuaternion defines the second operand
     * @returns true if the current quaternion and the given one coordinates are strictly equals
     */
    equals(otherQuaternion: DeepImmutable<Quaternion>): boolean;
    /**
     * Gets a boolean if two quaternions are equals (using an epsilon value)
     * Example Playground https://playground.babylonjs.com/#L49EJ7#37
     * @param otherQuaternion defines the other quaternion
     * @param epsilon defines the minimal distance to consider equality
     * @returns true if the given quaternion coordinates are close to the current ones by a distance of epsilon.
     */
    equalsWithEpsilon(otherQuaternion: DeepImmutable<Quaternion>, epsilon?: number): boolean;
    /**
     * Gets a boolean if two quaternions are equals (using an epsilon value), taking care of double cover : https://www.reedbeta.com/blog/why-quaternions-double-cover/
     * @param otherQuaternion defines the other quaternion
     * @param epsilon defines the minimal distance to consider equality
     * @returns true if the given quaternion coordinates are close to the current ones by a distance of epsilon.
     */
    isApprox(otherQuaternion: DeepImmutable<Quaternion>, epsilon?: number): boolean;
    /**
     * Clone the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#12
     * @returns a new quaternion copied from the current one
     */
    clone(): Quaternion;
    /**
     * Copy a quaternion to the current one
     * Example Playground https://playground.babylonjs.com/#L49EJ7#86
     * @param other defines the other quaternion
     * @returns the updated current quaternion
     */
    copyFrom(other: DeepImmutable<Quaternion>): this;
    /**
     * Updates the current quaternion with the given float coordinates
     * Example Playground https://playground.babylonjs.com/#L49EJ7#87
     * @param x defines the x coordinate
     * @param y defines the y coordinate
     * @param z defines the z coordinate
     * @param w defines the w coordinate
     * @returns the updated current quaternion
     */
    copyFromFloats(x: number, y: number, z: number, w: number): this;
    /**
     * Updates the current quaternion from the given float coordinates
     * Example Playground https://playground.babylonjs.com/#L49EJ7#56
     * @param x defines the x coordinate
     * @param y defines the y coordinate
     * @param z defines the z coordinate
     * @param w defines the w coordinate
     * @returns the updated current quaternion
     */
    set(x: number, y: number, z: number, w: number): this;
    setAll(value: number): this;
    /**
     * Adds two quaternions
     * Example Playground https://playground.babylonjs.com/#L49EJ7#10
     * @param other defines the second operand
     * @returns a new quaternion as the addition result of the given one and the current quaternion
     */
    add(other: DeepImmutable<Quaternion>): Quaternion;
    /**
     * Add a quaternion to the current one
     * Example Playground https://playground.babylonjs.com/#L49EJ7#11
     * @param other defines the quaternion to add
     * @returns the current quaternion
     */
    addInPlace(other: DeepImmutable<Quaternion>): this;
    addToRef<T extends Quaternion>(other: DeepImmutable<this>, result: T): T;
    addInPlaceFromFloats(x: number, y: number, z: number, w: number): this;
    subtractToRef<T extends Quaternion>(other: DeepImmutable<this>, result: T): T;
    subtractFromFloats(x: number, y: number, z: number, w: number): Quaternion;
    subtractFromFloatsToRef<T extends Quaternion>(x: number, y: number, z: number, w: number, result: T): T;
    /**
     * Subtract two quaternions
     * Example Playground https://playground.babylonjs.com/#L49EJ7#57
     * @param other defines the second operand
     * @returns a new quaternion as the subtraction result of the given one from the current one
     */
    subtract(other: DeepImmutable<this>): Quaternion;
    /**
     * Subtract a quaternion to the current one
     * Example Playground https://playground.babylonjs.com/#L49EJ7#58
     * @param other defines the quaternion to subtract
     * @returns the current quaternion
     */
    subtractInPlace(other: DeepImmutable<Quaternion>): this;
    /**
     * Multiplies the current quaternion by a scale factor
     * Example Playground https://playground.babylonjs.com/#L49EJ7#88
     * @param value defines the scale factor
     * @returns a new quaternion set by multiplying the current quaternion coordinates by the float "scale"
     */
    scale(value: number): Quaternion;
    /**
     * Scale the current quaternion values by a factor and stores the result to a given quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#89
     * @param scale defines the scale factor
     * @param result defines the Quaternion object where to store the result
     * @returns result input
     */
    scaleToRef<T extends Quaternion>(scale: number, result: T): T;
    /**
     * Multiplies in place the current quaternion by a scale factor
     * Example Playground https://playground.babylonjs.com/#L49EJ7#90
     * @param value defines the scale factor
     * @returns the current modified quaternion
     */
    scaleInPlace(value: number): this;
    /**
     * Scale the current quaternion values by a factor and add the result to a given quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#91
     * @param scale defines the scale factor
     * @param result defines the Quaternion object where to store the result
     * @returns result input
     */
    scaleAndAddToRef<T extends Quaternion>(scale: number, result: T): T;
    /**
     * Multiplies two quaternions
     * Example Playground https://playground.babylonjs.com/#L49EJ7#43
     * @param q1 defines the second operand
     * @returns a new quaternion set as the multiplication result of the current one with the given one "q1"
     */
    multiply(q1: DeepImmutable<Quaternion>): Quaternion;
    /**
     * Sets the given "result" as the multiplication result of the current one with the given one "q1"
     * Example Playground https://playground.babylonjs.com/#L49EJ7#45
     * @param q1 defines the second operand
     * @param result defines the target quaternion
     * @returns the current quaternion
     */
    multiplyToRef<T extends Quaternion>(q1: DeepImmutable<Quaternion>, result: T): T;
    /**
     * Updates the current quaternion with the multiplication of itself with the given one "q1"
     * Example Playground https://playground.babylonjs.com/#L49EJ7#46
     * @param other defines the second operand
     * @returns the currentupdated quaternion
     */
    multiplyInPlace(other: DeepImmutable<Quaternion>): this;
    multiplyByFloats(x: number, y: number, z: number, w: number): this;
    /**
     * @internal
     * Do not use
     */
    divide(_other: DeepImmutable<this>): this;
    /**
     * @internal
     * Do not use
     */
    divideToRef<T extends Quaternion>(_other: DeepImmutable<this>, _result: T): T;
    /**
     * @internal
     * Do not use
     */
    divideInPlace(_other: DeepImmutable<this>): this;
    /**
     * @internal
     * Do not use
     */
    minimizeInPlace(): this;
    /**
     * @internal
     * Do not use
     */
    minimizeInPlaceFromFloats(): this;
    /**
     * @internal
     * Do not use
     */
    maximizeInPlace(): this;
    /**
     * @internal
     * Do not use
     */
    maximizeInPlaceFromFloats(): this;
    negate(): Quaternion;
    negateInPlace(): this;
    negateToRef<T extends Quaternion>(result: T): T;
    equalsToFloats(x: number, y: number, z: number, w: number): boolean;
    /**
     * @internal
     * Do not use
     */
    floorToRef<T extends Quaternion>(_result: T): T;
    /**
     * @internal
     * Do not use
     */
    floor(): Quaternion;
    /**
     * @internal
     * Do not use
     */
    fractToRef<T extends Quaternion>(_result: T): T;
    /**
     * @internal
     * Do not use
     */
    fract(): Quaternion;
    /**
     * Conjugates the current quaternion and stores the result in the given quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#81
     * @param ref defines the target quaternion
     * @returns result input
     */
    conjugateToRef<T extends Quaternion>(ref: T): T;
    /**
     * Conjugates in place the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#82
     * @returns the current updated quaternion
     */
    conjugateInPlace(): this;
    /**
     * Conjugates (1-q) the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#83
     * @returns a new quaternion
     */
    conjugate(): Quaternion;
    /**
     * Returns the inverse of the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#84
     * @returns a new quaternion
     */
    invert(): Quaternion;
    /**
     * Invert in place the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#85
     * @returns this quaternion
     */
    invertInPlace(): this;
    /**
     * Gets squared length of current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#29
     * @returns the quaternion length (float)
     */
    lengthSquared(): number;
    /**
     * Gets length of current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#28
     * @returns the quaternion length (float)
     */
    length(): number;
    /**
     * Normalize in place the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#54
     * @returns the current updated quaternion
     */
    normalize(): this;
    /**
     * Normalize the current quaternion with the given input length.
     * Please note that this is an in place operation.
     * @param len the length of the quaternion
     * @returns the current updated Quaternion
     */
    normalizeFromLength(len: number): this;
    /**
     * Normalize a copy of the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#55
     * @returns the normalized quaternion
     */
    normalizeToNew(): Quaternion;
    /**
     * Normalize the current Quaternion to the reference
     * @param reference define the Quaternion to update
     * @returns the updated Quaternion
     */
    normalizeToRef<T extends Quaternion>(reference: T): T;
    /**
     * Returns a new Vector3 set with the Euler angles translated from the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#32
     * @returns a new Vector3 containing the Euler angles
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/center_origin/rotation_conventions
     */
    toEulerAngles(): Vector3;
    /**
     * Sets the given vector3 "result" with the Euler angles translated from the current quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#31
     * @param result defines the vector which will be filled with the Euler angles
     * @returns result input
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/center_origin/rotation_conventions
     */
    toEulerAnglesToRef<T extends Vector3>(result: T): T;
    /**
     * Sets the given vector3 "result" with the Alpha, Beta, Gamma Euler angles translated from the current quaternion
     * @param result defines the vector which will be filled with the Euler angles
     * @returns result input
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/center_origin/rotation_conventions
     */
    toAlphaBetaGammaToRef<T extends Vector3>(result: T): T;
    /**
     * Updates the given rotation matrix with the current quaternion values
     * Example Playground https://playground.babylonjs.com/#L49EJ7#67
     * @param result defines the target matrix
     * @returns the updated matrix with the rotation
     */
    toRotationMatrix<T extends Matrix>(result: T): T;
    /**
     * Updates the current quaternion from the given rotation matrix values
     * Example Playground https://playground.babylonjs.com/#L49EJ7#41
     * @param matrix defines the source matrix
     * @returns the current updated quaternion
     */
    fromRotationMatrix(matrix: DeepImmutable<Matrix>): this;
    /**
     * Returns the dot product (float) between the current quaternions and "other"
     * @param other defines the right operand
     * @returns the dot product
     */
    dot(other: DeepImmutable<this>): number;
    /**
     * Converts the current quaternion to an axis angle representation
     * @returns the axis and angle in radians
     */
    toAxisAngle(): {
        axis: Vector3;
        angle: number;
    };
    /**
     * Converts the current quaternion to an axis angle representation
     * @param axis defines the target axis vector
     * @returns the angle in radians
     */
    toAxisAngleToRef<T extends Vector3>(axis: T): number;
    /**
     * Creates a new quaternion from a rotation matrix
     * Example Playground https://playground.babylonjs.com/#L49EJ7#101
     * @param matrix defines the source matrix
     * @returns a new quaternion created from the given rotation matrix values
     */
    static FromRotationMatrix(matrix: DeepImmutable<Matrix>): Quaternion;
    /**
     * Updates the given quaternion with the given rotation matrix values
     * Example Playground https://playground.babylonjs.com/#L49EJ7#102
     * @param matrix defines the source matrix
     * @param result defines the target quaternion
     * @returns result input
     */
    static FromRotationMatrixToRef<T extends Quaternion>(matrix: DeepImmutable<Matrix>, result: T): T;
    /**
     * Returns the dot product (float) between the quaternions "left" and "right"
     * Example Playground https://playground.babylonjs.com/#L49EJ7#61
     * @param left defines the left operand
     * @param right defines the right operand
     * @returns the dot product
     */
    static Dot(left: DeepImmutable<Quaternion>, right: DeepImmutable<Quaternion>): number;
    /**
     * Checks if the orientations of two rotation quaternions are close to each other
     * Example Playground https://playground.babylonjs.com/#L49EJ7#60
     * @param quat0 defines the first quaternion to check
     * @param quat1 defines the second quaternion to check
     * @param epsilon defines closeness, 0 same orientation, 1 PI apart, default 0.1
     * @returns true if the two quaternions are close to each other within epsilon
     */
    static AreClose(quat0: DeepImmutable<Quaternion>, quat1: DeepImmutable<Quaternion>, epsilon?: number): boolean;
    /**
     * Smooth interpolation between two quaternions using Slerp
     * Example Playground https://playground.babylonjs.com/#L49EJ7#93
     * @param source source quaternion
     * @param goal goal quaternion
     * @param deltaTime current interpolation frame
     * @param lerpTime total interpolation time
     * @param result the smoothed quaternion
     * @returns the smoothed quaternion
     */
    static SmoothToRef<T extends Quaternion>(source: Quaternion, goal: Quaternion, deltaTime: number, lerpTime: number, result: T): T;
    /**
     * Creates an empty quaternion
     * @returns a new quaternion set to (0.0, 0.0, 0.0)
     */
    static Zero(): Quaternion;
    /**
     * Inverse a given quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#103
     * @param q defines the source quaternion
     * @returns a new quaternion as the inverted current quaternion
     */
    static Inverse(q: DeepImmutable<Quaternion>): Quaternion;
    /**
     * Inverse a given quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#104
     * @param q defines the source quaternion
     * @param result the quaternion the result will be stored in
     * @returns the result quaternion
     */
    static InverseToRef<T extends Quaternion>(q: Quaternion, result: T): T;
    /**
     * Creates an identity quaternion
     * @returns the identity quaternion
     */
    static Identity(): Quaternion;
    /**
     * Gets a boolean indicating if the given quaternion is identity
     * @param quaternion defines the quaternion to check
     * @returns true if the quaternion is identity
     */
    static IsIdentity(quaternion: DeepImmutable<Quaternion>): boolean;
    /**
     * Creates a quaternion from a rotation around an axis
     * Example Playground https://playground.babylonjs.com/#L49EJ7#72
     * @param axis defines the axis to use
     * @param angle defines the angle to use
     * @returns a new quaternion created from the given axis (Vector3) and angle in radians (float)
     */
    static RotationAxis(axis: DeepImmutable<Vector3>, angle: number): Quaternion;
    /**
     * Creates a rotation around an axis and stores it into the given quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#73
     * @param axis defines the axis to use
     * @param angle defines the angle to use
     * @param result defines the target quaternion
     * @returns the target quaternion
     */
    static RotationAxisToRef<T extends Quaternion>(axis: DeepImmutable<Vector3>, angle: number, result: T): T;
    /**
     * Creates a new quaternion from data stored into an array
     * Example Playground https://playground.babylonjs.com/#L49EJ7#63
     * @param array defines the data source
     * @param offset defines the offset in the source array where the data starts
     * @returns a new quaternion
     */
    static FromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): Quaternion;
    /**
     * Updates the given quaternion "result" from the starting index of the given array.
     * Example Playground https://playground.babylonjs.com/#L49EJ7#64
     * @param array the array to pull values from
     * @param offset the offset into the array to start at
     * @param result the quaternion to store the result in
     * @returns result input
     */
    static FromArrayToRef<T extends Quaternion>(array: DeepImmutable<ArrayLike<number>>, offset: number, result: T): T;
    /**
     * Sets the given quaternion "result" with the given floats.
     * @param x defines the x coordinate of the source
     * @param y defines the y coordinate of the source
     * @param z defines the z coordinate of the source
     * @param w defines the w coordinate of the source
     * @param result defines the quaternion where to store the result
     * @returns the result quaternion
     */
    static FromFloatsToRef<T extends Quaternion = Quaternion>(x: number, y: number, z: number, w: number, result: T): T;
    /**
     * Create a quaternion from Euler rotation angles
     * Example Playground https://playground.babylonjs.com/#L49EJ7#33
     * @param x Pitch
     * @param y Yaw
     * @param z Roll
     * @returns the new Quaternion
     */
    static FromEulerAngles(x: number, y: number, z: number): Quaternion;
    /**
     * Updates a quaternion from Euler rotation angles
     * Example Playground https://playground.babylonjs.com/#L49EJ7#34
     * @param x Pitch
     * @param y Yaw
     * @param z Roll
     * @param result the quaternion to store the result
     * @returns the updated quaternion
     */
    static FromEulerAnglesToRef<T extends Quaternion>(x: number, y: number, z: number, result: T): T;
    /**
     * Create a quaternion from Euler rotation vector
     * Example Playground https://playground.babylonjs.com/#L49EJ7#35
     * @param vec the Euler vector (x Pitch, y Yaw, z Roll)
     * @returns the new Quaternion
     */
    static FromEulerVector(vec: DeepImmutable<Vector3>): Quaternion;
    /**
     * Updates a quaternion from Euler rotation vector
     * Example Playground https://playground.babylonjs.com/#L49EJ7#36
     * @param vec the Euler vector (x Pitch, y Yaw, z Roll)
     * @param result the quaternion to store the result
     * @returns the updated quaternion
     */
    static FromEulerVectorToRef<T extends Quaternion>(vec: DeepImmutable<Vector3>, result: T): T;
    /**
     * Updates a quaternion so that it rotates vector vecFrom to vector vecTo
     * Example Playground - https://playground.babylonjs.com/#L49EJ7#70
     * @param vecFrom defines the direction vector from which to rotate
     * @param vecTo defines the direction vector to which to rotate
     * @param result the quaternion to store the result
     * @param epsilon defines the minimal dot value to define vecs as opposite. Default: `BABYLON.Epsilon`
     * @returns the updated quaternion
     */
    static FromUnitVectorsToRef<T extends Quaternion>(vecFrom: DeepImmutable<Vector3>, vecTo: DeepImmutable<Vector3>, result: T, epsilon?: number): T;
    /**
     * Creates a new quaternion from the given Euler float angles (y, x, z)
     * Example Playground https://playground.babylonjs.com/#L49EJ7#77
     * @param yaw defines the rotation around Y axis
     * @param pitch defines the rotation around X axis
     * @param roll defines the rotation around Z axis
     * @returns the new quaternion
     */
    static RotationYawPitchRoll(yaw: number, pitch: number, roll: number): Quaternion;
    /**
     * Creates a new rotation from the given Euler float angles (y, x, z) and stores it in the target quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#561
     * @param yaw defines the rotation around Y axis
     * @param pitch defines the rotation around X axis
     * @param roll defines the rotation around Z axis
     * @param result defines the target quaternion
     * @returns result input
     */
    static RotationYawPitchRollToRef<T extends Quaternion>(yaw: number, pitch: number, roll: number, result: T): T;
    /**
     * Creates a new quaternion from the given Euler float angles expressed in z-x-z orientation
     * Example Playground https://playground.babylonjs.com/#L49EJ7#68
     * @param alpha defines the rotation around first axis
     * @param beta defines the rotation around second axis
     * @param gamma defines the rotation around third axis
     * @returns the new quaternion
     */
    static RotationAlphaBetaGamma(alpha: number, beta: number, gamma: number): Quaternion;
    /**
     * Creates a new quaternion from the given Euler float angles expressed in z-x-z orientation and stores it in the target quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#69
     * @param alpha defines the rotation around first axis
     * @param beta defines the rotation around second axis
     * @param gamma defines the rotation around third axis
     * @param result defines the target quaternion
     * @returns result input
     */
    static RotationAlphaBetaGammaToRef<T extends Quaternion>(alpha: number, beta: number, gamma: number, result: T): T;
    /**
     * Creates a new quaternion containing the rotation value to reach the target (axis1, axis2, axis3) orientation as a rotated XYZ system (axis1, axis2 and axis3 are normalized during this operation)
     * Example Playground https://playground.babylonjs.com/#L49EJ7#75
     * @param axis1 defines the first axis
     * @param axis2 defines the second axis
     * @param axis3 defines the third axis
     * @returns the new quaternion
     */
    static RotationQuaternionFromAxis(axis1: DeepImmutable<Vector3>, axis2: DeepImmutable<Vector3>, axis3: DeepImmutable<Vector3>): Quaternion;
    /**
     * Creates a rotation value to reach the target (axis1, axis2, axis3) orientation as a rotated XYZ system (axis1, axis2 and axis3 are normalized during this operation) and stores it in the target quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#76
     * @param axis1 defines the first axis
     * @param axis2 defines the second axis
     * @param axis3 defines the third axis
     * @param ref defines the target quaternion
     * @returns result input
     */
    static RotationQuaternionFromAxisToRef<T extends Quaternion>(axis1: DeepImmutable<Vector3>, axis2: DeepImmutable<Vector3>, axis3: DeepImmutable<Vector3>, ref: T): T;
    /**
     * Creates a new rotation value to orient an object to look towards the given forward direction, the up direction being oriented like "up".
     * This function works in left handed mode
     * Example Playground https://playground.babylonjs.com/#L49EJ7#96
     * @param forward defines the forward direction - Must be normalized and orthogonal to up.
     * @param up defines the up vector for the entity - Must be normalized and orthogonal to forward.
     * @returns A new quaternion oriented toward the specified forward and up.
     */
    static FromLookDirectionLH(forward: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>): Quaternion;
    /**
     * Creates a new rotation value to orient an object to look towards the given forward direction with the up direction being oriented like "up", and stores it in the target quaternion.
     * This function works in left handed mode
     * Example Playground https://playground.babylonjs.com/#L49EJ7#97
     * @param forward defines the forward direction - Must be normalized and orthogonal to up.
     * @param up defines the up vector for the entity - Must be normalized and orthogonal to forward.
     * @param ref defines the target quaternion.
     * @returns result input
     */
    static FromLookDirectionLHToRef<T extends Quaternion>(forward: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>, ref: T): T;
    /**
     * Creates a new rotation value to orient an object to look towards the given forward direction, the up direction being oriented like "up".
     * This function works in right handed mode
     * Example Playground https://playground.babylonjs.com/#L49EJ7#98
     * @param forward defines the forward direction - Must be normalized and orthogonal to up.
     * @param up defines the up vector for the entity - Must be normalized and orthogonal to forward.
     * @returns A new quaternion oriented toward the specified forward and up.
     */
    static FromLookDirectionRH(forward: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>): Quaternion;
    /**
     * Creates a new rotation value to orient an object to look towards the given forward direction with the up direction being oriented like "up", and stores it in the target quaternion.
     * This function works in right handed mode
     * Example Playground https://playground.babylonjs.com/#L49EJ7#105
     * @param forward defines the forward direction - Must be normalized and orthogonal to up.
     * @param up defines the up vector for the entity - Must be normalized and orthogonal to forward.
     * @param ref defines the target quaternion.
     * @returns result input
     */
    static FromLookDirectionRHToRef<T extends Quaternion>(forward: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>, ref: T): T;
    /**
     * Interpolates between two quaternions
     * Example Playground https://playground.babylonjs.com/#L49EJ7#79
     * @param left defines first quaternion
     * @param right defines second quaternion
     * @param amount defines the gradient to use
     * @returns the new interpolated quaternion
     */
    static Slerp(left: DeepImmutable<Quaternion>, right: DeepImmutable<Quaternion>, amount: number): Quaternion;
    /**
     * Interpolates between two quaternions and stores it into a target quaternion
     * Example Playground https://playground.babylonjs.com/#L49EJ7#92
     * @param left defines first quaternion
     * @param right defines second quaternion
     * @param amount defines the gradient to use
     * @param result defines the target quaternion
     * @returns result input
     */
    static SlerpToRef<T extends Quaternion>(left: DeepImmutable<Quaternion>, right: DeepImmutable<Quaternion>, amount: number, result: T): T;
    /**
     * Interpolate between two quaternions using Hermite interpolation
     * Example Playground https://playground.babylonjs.com/#L49EJ7#47
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/drawCurves#hermite-quaternion-spline
     * @param value1 defines first quaternion
     * @param tangent1 defines the incoming tangent
     * @param value2 defines second quaternion
     * @param tangent2 defines the outgoing tangent
     * @param amount defines the target quaternion
     * @returns the new interpolated quaternion
     */
    static Hermite(value1: DeepImmutable<Quaternion>, tangent1: DeepImmutable<Quaternion>, value2: DeepImmutable<Quaternion>, tangent2: DeepImmutable<Quaternion>, amount: number): Quaternion;
    /**
     * Returns a new Quaternion which is the 1st derivative of the Hermite spline defined by the quaternions "value1", "value2", "tangent1", "tangent2".
     * Example Playground https://playground.babylonjs.com/#L49EJ7#48
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @returns 1st derivative
     */
    static Hermite1stDerivative(value1: DeepImmutable<Quaternion>, tangent1: DeepImmutable<Quaternion>, value2: DeepImmutable<Quaternion>, tangent2: DeepImmutable<Quaternion>, time: number): Quaternion;
    /**
     * Update a Quaternion with the 1st derivative of the Hermite spline defined by the quaternions "value1", "value2", "tangent1", "tangent2".
     * Example Playground https://playground.babylonjs.com/#L49EJ7#49
     * @param value1 defines the first control point
     * @param tangent1 defines the first tangent
     * @param value2 defines the second control point
     * @param tangent2 defines the second tangent
     * @param time define where the derivative must be done
     * @param result define where to store the derivative
     * @returns result input
     */
    static Hermite1stDerivativeToRef<T extends Quaternion>(value1: DeepImmutable<Quaternion>, tangent1: DeepImmutable<Quaternion>, value2: DeepImmutable<Quaternion>, tangent2: DeepImmutable<Quaternion>, time: number, result: T): T;
    /**
     * Returns a new Quaternion as the normalization of the given Quaternion
     * @param quat defines the Quaternion to normalize
     * @returns the new Quaternion
     */
    static Normalize(quat: DeepImmutable<Quaternion>): Quaternion;
    /**
     * Sets the given Quaternion "result" with the normalization of the given first Quaternion
     * @param quat defines the Quaternion to normalize
     * @param result defines the Quaternion where to store the result
     * @returns result input
     */
    static NormalizeToRef<T extends Quaternion>(quat: DeepImmutable<Quaternion>, result: T): T;
    /**
     * Returns a new Quaternion set with the coordinates of "value", if the quaternion "value" is in the cube defined by the quaternions "min" and "max"
     * If a coordinate value of "value" is lower than one of the "min" coordinate, then this "value" coordinate is set with the "min" one
     * If a coordinate value of "value" is greater than one of the "max" coordinate, then this "value" coordinate is set with the "max" one
     * @param value defines the current value
     * @param min defines the lower range value
     * @param max defines the upper range value
     * @returns the new Quaternion
     */
    static Clamp(value: DeepImmutable<Quaternion>, min: DeepImmutable<Quaternion>, max: DeepImmutable<Quaternion>): Quaternion;
    /**
     * Sets the given quaternion "result" with the coordinates of "value", if the quaternion "value" is in the cube defined by the quaternions "min" and "max"
     * If a coordinate value of "value" is lower than one of the "min" coordinate, then this "value" coordinate is set with the "min" one
     * If a coordinate value of "value" is greater than one of the "max" coordinate, then this "value" coordinate is set with the "max" one
     * @param value defines the current value
     * @param min defines the lower range value
     * @param max defines the upper range value
     * @param result defines the Quaternion where to store the result
     * @returns result input
     */
    static ClampToRef<T extends Quaternion>(value: DeepImmutable<Quaternion>, min: DeepImmutable<Quaternion>, max: DeepImmutable<Quaternion>, result: T): T;
    /**
     * Returns a new Quaternion with random values between min and max
     * @param min the minimum random value
     * @param max the maximum random value
     * @returns a Quaternion with random values between min and max
     */
    static Random(min?: number, max?: number): Quaternion;
    /**
     * Sets a Quaternion with random values between min and max
     * @param min the minimum random value
     * @param max the maximum random value
     * @param ref the ref to store the values in
     * @returns the ref with random values between min and max
     */
    static RandomToRef<T extends Quaternion>(min: number | undefined, max: number | undefined, ref: T): T;
    /**
     * Do not use
     * @internal
     */
    static Minimize(): Quaternion;
    /**
     * Do not use
     * @internal
     */
    static Maximize(): Quaternion;
    /**
     * Returns the distance (float) between the quaternions "value1" and "value2".
     * @param value1 value to calulate the distance between
     * @param value2 value to calulate the distance between
     * @returns the distance between the two quaternions
     */
    static Distance(value1: DeepImmutable<Quaternion>, value2: DeepImmutable<Quaternion>): number;
    /**
     * Returns the squared distance (float) between the quaternions "value1" and "value2".
     * @param value1 value to calulate the distance between
     * @param value2 value to calulate the distance between
     * @returns the distance between the two quaternions squared
     */
    static DistanceSquared(value1: DeepImmutable<Quaternion>, value2: DeepImmutable<Quaternion>): number;
    /**
     * Returns a new Quaternion located at the center between the quaternions "value1" and "value2".
     * @param value1 value to calulate the center between
     * @param value2 value to calulate the center between
     * @returns the center between the two quaternions
     */
    static Center(value1: DeepImmutable<Quaternion>, value2: DeepImmutable<Quaternion>): Quaternion;
    /**
     * Gets the center of the quaternions "value1" and "value2" and stores the result in the quaternion "ref"
     * @param value1 defines first quaternion
     * @param value2 defines second quaternion
     * @param ref defines third quaternion
     * @returns ref
     */
    static CenterToRef<T extends Quaternion>(value1: DeepImmutable<Quaternion>, value2: DeepImmutable<Quaternion>, ref: T): T;
}
/**
 * Class used to store matrix data (4x4)
 * Note on matrix definitions in Babylon.js for setting values directly
 * rather than using one of the methods available.
 * Matrix size is given by rows x columns.
 * A Vector3 is a 1 X 3 matrix [x, y, z].
 *
 * In Babylon.js multiplying a 1 x 3 matrix by a 4 x 4 matrix
 * is done using BABYLON.Vector4.TransformCoordinates(Vector3, Matrix).
 * and extending the passed Vector3 to a Vector4, V = [x, y, z, 1].
 * Let M be a matrix with elements m(row, column), so that
 * m(2, 3) is the element in row 2 column 3 of M.
 *
 * Multiplication is of the form VM and has the resulting Vector4
 * VM = [xm(0, 0) + ym(1, 0) + zm(2, 0) + m(3, 0), xm(0, 1) + ym(1, 1) + zm(2, 1) + m(3, 1), xm(0, 2) + ym(1, 2) + zm(2, 2) + m(3, 2), xm(0, 3) + ym(1, 3) + zm(2, 3) + m(3, 3)].
 * On the web you will find many examples that use the opposite convention of MV,
 * in which case to make use of the examples you will need to transpose the matrix.
 *
 * Example Playground - Overview Linear Algebra - https://playground.babylonjs.com/#AV9X17
 * Example Playground - Overview Transformation - https://playground.babylonjs.com/#AV9X17#1
 * Example Playground - Overview Projection - https://playground.babylonjs.com/#AV9X17#2
 */
declare class Matrix implements Tensor<Tuple<Tuple<number, 4>, 4>, Matrix>, IMatrixLike {
    /**
     * @see Tensor.dimension
     */
    readonly dimension: Readonly<[4, 4]>;
    /**
     * @see Tensor.rank
     */
    readonly rank: 2;
    /**
     * Gets the precision of matrix computations
     */
    static get Use64Bits(): boolean;
    private static _IdentityReadOnly;
    private _isIdentity;
    private _isIdentityDirty;
    private _isIdentity3x2;
    private _isIdentity3x2Dirty;
    /**
     * Gets the update flag of the matrix which is an unique number for the matrix.
     * It will be incremented every time the matrix data change.
     * You can use it to speed the comparison between two versions of the same matrix.
     */
    updateFlag: number;
    private readonly _m;
    /**
     * Gets the internal data of the matrix
     */
    get m(): DeepImmutable<Tuple<number, 16>>;
    /**
     * Update the updateFlag to indicate that the matrix has been updated
     */
    markAsUpdated(): void;
    private _updateIdentityStatus;
    /**
     * Creates an empty matrix (filled with zeros)
     */
    constructor();
    /**
     * Check if the current matrix is identity
     * @returns true is the matrix is the identity matrix
     */
    isIdentity(): boolean;
    /**
     * Check if the current matrix is identity as a texture matrix (3x2 store in 4x4)
     * @returns true is the matrix is the identity matrix
     */
    isIdentityAs3x2(): boolean;
    /**
     * Gets the determinant of the matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#34
     * @returns the matrix determinant
     */
    determinant(): number;
    /**
     * Gets a string with the Matrix values
     * @returns a string with the Matrix values
     */
    toString(): string;
    /**
     * Returns the matrix as a Float32Array or Array<number>
     * @deprecated Use asArray
     */
    toArray(): FloatArray;
    /**
     * Stores the matrix in a Float32Array or Array<number>
     * Example Playground - https://playground.babylonjs.com/#AV9X17#49
     * @param array The destination array
     * @param index The destination index to start ay
     * @returns the matrix
     */
    toArray(array: FloatArray, index: number): this;
    /**
     * Returns the matrix as a Float32Array or Array<number>
     * Example Playground - https://playground.babylonjs.com/#AV9X17#114
     * @returns the matrix underlying array.
     */
    asArray(): Tuple<number, 16>;
    fromArray(array: FloatArray, index?: number): this;
    copyFromFloats(...floats: Tuple<number, 16>): this;
    set(...values: Tuple<number, 16>): this;
    setAll(value: number): this;
    /**
     * Inverts the current matrix in place
     * Example Playground - https://playground.babylonjs.com/#AV9X17#118
     * @returns the current inverted matrix
     */
    invert(): this;
    /**
     * Sets all the matrix elements to zero
     * @returns the current matrix
     */
    reset(): this;
    /**
     * Adds the current matrix with a second one
     * Example Playground - https://playground.babylonjs.com/#AV9X17#44
     * @param other defines the matrix to add
     * @returns a new matrix as the addition of the current matrix and the given one
     */
    add(other: DeepImmutable<Matrix>): Matrix;
    /**
     * Sets the given matrix "result" to the addition of the current matrix and the given one
     * Example Playground - https://playground.babylonjs.com/#AV9X17#45
     * @param other defines the matrix to add
     * @param result defines the target matrix
     * @returns result input
     */
    addToRef<T extends Matrix>(other: DeepImmutable<Matrix>, result: T): T;
    /**
     * Adds in place the given matrix to the current matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#46
     * @param other defines the second operand
     * @returns the current updated matrix
     */
    addToSelf(other: DeepImmutable<Matrix>): this;
    addInPlace(other: DeepImmutable<Matrix>): this;
    addInPlaceFromFloats(...floats: Tuple<number, 16>): this;
    subtract(other: DeepImmutable<Matrix>): this;
    subtractToRef<T extends Matrix>(other: DeepImmutable<Matrix>, result: T): T;
    subtractInPlace(other: DeepImmutable<Matrix>): this;
    subtractFromFloats(...floats: Tuple<number, 16>): Matrix;
    subtractFromFloatsToRef<T extends Matrix>(...args: [...Tuple<number, 16>, T]): T;
    /**
     * Sets the given matrix to the current inverted Matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#119
     * @param other defines the target matrix
     * @returns result input
     */
    invertToRef<T extends Matrix>(other: T): T;
    /**
     * add a value at the specified position in the current Matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#47
     * @param index the index of the value within the matrix. between 0 and 15.
     * @param value the value to be added
     * @returns the current updated matrix
     */
    addAtIndex(index: number, value: number): this;
    /**
     * mutiply the specified position in the current Matrix by a value
     * @param index the index of the value within the matrix. between 0 and 15.
     * @param value the value to be added
     * @returns the current updated matrix
     */
    multiplyAtIndex(index: number, value: number): this;
    /**
     * Inserts the translation vector (using 3 floats) in the current matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#120
     * @param x defines the 1st component of the translation
     * @param y defines the 2nd component of the translation
     * @param z defines the 3rd component of the translation
     * @returns the current updated matrix
     */
    setTranslationFromFloats(x: number, y: number, z: number): this;
    /**
     * Adds the translation vector (using 3 floats) in the current matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#20
     * Example Playground - https://playground.babylonjs.com/#AV9X17#48
     * @param x defines the 1st component of the translation
     * @param y defines the 2nd component of the translation
     * @param z defines the 3rd component of the translation
     * @returns the current updated matrix
     */
    addTranslationFromFloats(x: number, y: number, z: number): this;
    /**
     * Inserts the translation vector in the current matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#121
     * @param vector3 defines the translation to insert
     * @returns the current updated matrix
     */
    setTranslation(vector3: DeepImmutable<Vector3>): this;
    /**
     * Gets the translation value of the current matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#122
     * @returns a new Vector3 as the extracted translation from the matrix
     */
    getTranslation(): Vector3;
    /**
     * Fill a Vector3 with the extracted translation from the matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#123
     * @param result defines the Vector3 where to store the translation
     * @returns the current matrix
     */
    getTranslationToRef<T extends Vector3>(result: T): T;
    /**
     * Remove rotation and scaling part from the matrix
     * @returns the updated matrix
     */
    removeRotationAndScaling(): this;
    /**
     * Copy the current matrix from the given one
     * Example Playground - https://playground.babylonjs.com/#AV9X17#21
     * @param other defines the source matrix
     * @returns the current updated matrix
     */
    copyFrom(other: DeepImmutable<Matrix>): this;
    /**
     * Populates the given array from the starting index with the current matrix values
     * @param array defines the target array
     * @param offset defines the offset in the target array where to start storing values
     * @returns the current matrix
     */
    copyToArray(array: Float32Array | Array<number>, offset?: number): this;
    /**
     * Multiply two matrices
     * Example Playground - https://playground.babylonjs.com/#AV9X17#15
     * A.multiply(B) means apply B to A so result is B x A
     * @param other defines the second operand
     * @returns a new matrix set with the multiplication result of the current Matrix and the given one
     */
    multiply(other: DeepImmutable<Matrix>): Matrix;
    /**
     * This method performs component-by-component in-place multiplication, rather than true matrix multiplication.
     * Use multiply or multiplyToRef for matrix multiplication.
     * @param other defines the second operand
     * @returns the current updated matrix
     */
    multiplyInPlace(other: DeepImmutable<Matrix>): this;
    /**
     * This method performs a component-by-component multiplication of the current matrix with the array of transmitted numbers.
     * Use multiply or multiplyToRef for matrix multiplication.
     * @param floats defines the array of numbers to multiply the matrix by
     * @returns the current updated matrix
     */
    multiplyByFloats(...floats: Tuple<number, 16>): this;
    /**
     * Multiples the current matrix by the given floats and stores them in the given ref
     * @param args The floats and ref
     * @returns The updated ref
     */
    multiplyByFloatsToRef<T extends Matrix>(...args: [...Tuple<number, 16>, T]): T;
    /**
     * Sets the given matrix "result" with the multiplication result of the current Matrix and the given one
     * A.multiplyToRef(B, R) means apply B to A and store in R and R = B x A
     * Example Playground - https://playground.babylonjs.com/#AV9X17#16
     * @param other defines the second operand
     * @param result defines the matrix where to store the multiplication
     * @returns result input
     */
    multiplyToRef<T extends Matrix>(other: DeepImmutable<Matrix>, result: T): T;
    /**
     * Sets the Float32Array "result" from the given index "offset" with the multiplication of the current matrix and the given one
     * @param other defines the second operand
     * @param result defines the array where to store the multiplication
     * @param offset defines the offset in the target array where to start storing values
     * @returns the current matrix
     */
    multiplyToArray(other: DeepImmutable<Matrix>, result: Float32Array | Array<number>, offset: number): this;
    divide(other: DeepImmutable<Matrix>): Matrix;
    divideToRef<T extends Matrix>(other: DeepImmutable<Matrix>, result: T): T;
    divideInPlace(other: DeepImmutable<Matrix>): this;
    minimizeInPlace(other: DeepImmutable<Matrix>): this;
    minimizeInPlaceFromFloats(...floats: Tuple<number, 16>): this;
    maximizeInPlace(other: DeepImmutable<Matrix>): this;
    maximizeInPlaceFromFloats(...floats: Tuple<number, 16>): this;
    negate(): Matrix;
    negateInPlace(): this;
    negateToRef<T extends Matrix>(result: T): T;
    /**
     * Check equality between this matrix and a second one
     * @param value defines the second matrix to compare
     * @returns true is the current matrix and the given one values are strictly equal
     */
    equals(value: DeepImmutable<Matrix>): boolean;
    equalsWithEpsilon(other: DeepImmutable<Matrix>, epsilon?: number): boolean;
    equalsToFloats(...floats: Tuple<number, 16>): boolean;
    floor(): Matrix;
    floorToRef<T extends Matrix>(result: T): T;
    fract(): Matrix;
    fractToRef<T extends Matrix>(result: T): T;
    /**
     * Clone the current matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#18
     * @returns a new matrix from the current matrix
     */
    clone(): Matrix;
    /**
     * Returns the name of the current matrix class
     * @returns the string "Matrix"
     */
    getClassName(): string;
    /**
     * Gets the hash code of the current matrix
     * @returns the hash code
     */
    getHashCode(): number;
    /**
     * Decomposes the current Matrix into a translation, rotation and scaling components of the provided node
     * Example Playground - https://playground.babylonjs.com/#AV9X17#13
     * @param node the node to decompose the matrix to
     * @returns true if operation was successful
     */
    decomposeToTransformNode(node: TransformNode): boolean;
    /**
     * Decomposes the current Matrix into a translation, rotation and scaling components
     * Example Playground - https://playground.babylonjs.com/#AV9X17#12
     * @param scale defines the scale vector3 given as a reference to update
     * @param rotation defines the rotation quaternion given as a reference to update
     * @param translation defines the translation vector3 given as a reference to update
     * @param preserveScalingNode Use scaling sign coming from this node. Otherwise scaling sign might change.
     * @param useAbsoluteScaling Use scaling sign coming from this absoluteScaling when true or scaling otherwise.
     * @returns true if operation was successful
     */
    decompose(scale?: Vector3, rotation?: Quaternion, translation?: Vector3, preserveScalingNode?: TransformNode, useAbsoluteScaling?: boolean): boolean;
    /**
     * Gets specific row of the matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#36
     * @param index defines the number of the row to get
     * @returns the index-th row of the current matrix as a new Vector4
     */
    getRow(index: number): Nullable<Vector4>;
    /**
     * Gets specific row of the matrix to ref
     * Example Playground - https://playground.babylonjs.com/#AV9X17#36
     * @param index defines the number of the row to get
     * @param rowVector vector to store the index-th row of the current matrix
     * @returns result input
     */
    getRowToRef<T extends Vector4>(index: number, rowVector: T): T;
    /**
     * Sets the index-th row of the current matrix to the vector4 values
     * Example Playground - https://playground.babylonjs.com/#AV9X17#36
     * @param index defines the number of the row to set
     * @param row defines the target vector4
     * @returns the updated current matrix
     */
    setRow(index: number, row: Vector4): this;
    /**
     * Compute the transpose of the matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#40
     * @returns the new transposed matrix
     */
    transpose(): Matrix;
    /**
     * Compute the transpose of the matrix and store it in a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#41
     * @param result defines the target matrix
     * @returns result input
     */
    transposeToRef<T extends Matrix>(result: T): T;
    /**
     * Sets the index-th row of the current matrix with the given 4 x float values
     * Example Playground - https://playground.babylonjs.com/#AV9X17#36
     * @param index defines the row index
     * @param x defines the x component to set
     * @param y defines the y component to set
     * @param z defines the z component to set
     * @param w defines the w component to set
     * @returns the updated current matrix
     */
    setRowFromFloats(index: number, x: number, y: number, z: number, w: number): this;
    /**
     * Compute a new matrix set with the current matrix values multiplied by scale (float)
     * @param scale defines the scale factor
     * @returns a new matrix
     */
    scale(scale: number): Matrix;
    /**
     * Scale the current matrix values by a factor to a given result matrix
     * @param scale defines the scale factor
     * @param result defines the matrix to store the result
     * @returns result input
     */
    scaleToRef<T extends Matrix>(scale: number, result: T): T;
    /**
     * Scale the current matrix values by a factor and add the result to a given matrix
     * @param scale defines the scale factor
     * @param result defines the Matrix to store the result
     * @returns result input
     */
    scaleAndAddToRef<T extends Matrix>(scale: number, result: T): T;
    scaleInPlace(scale: number): this;
    /**
     * Writes to the given matrix a normal matrix, computed from this one (using values from identity matrix for fourth row and column).
     * Example Playground - https://playground.babylonjs.com/#AV9X17#17
     * @param ref matrix to store the result
     * @returns the reference matrix
     */
    toNormalMatrix<T extends Matrix>(ref: T): T;
    /**
     * Gets only rotation part of the current matrix
     * @returns a new matrix sets to the extracted rotation matrix from the current one
     */
    getRotationMatrix(): Matrix;
    /**
     * Extracts the rotation matrix from the current one and sets it as the given "result"
     * @param result defines the target matrix to store data to
     * @returns result input
     */
    getRotationMatrixToRef<T extends Matrix>(result: T): T;
    /**
     * Toggles model matrix from being right handed to left handed in place and vice versa
     * @returns the current updated matrix
     */
    toggleModelMatrixHandInPlace(): this;
    /**
     * Toggles projection matrix from being right handed to left handed in place and vice versa
     * @returns the current updated matrix
     */
    toggleProjectionMatrixHandInPlace(): this;
    /**
     * Creates a matrix from an array
     * Example Playground - https://playground.babylonjs.com/#AV9X17#42
     * @param array defines the source array
     * @param offset defines an offset in the source array
     * @returns a new Matrix set from the starting index of the given array
     */
    static FromArray(array: DeepImmutable<ArrayLike<number>>, offset?: number): Matrix;
    /**
     * Copy the content of an array into a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#43
     * @param array defines the source array
     * @param offset defines an offset in the source array
     * @param result defines the target matrix
     * @returns result input
     */
    static FromArrayToRef<T extends Matrix>(array: DeepImmutable<ArrayLike<number>>, offset: number, result: T): T;
    /**
     * Stores an array into a matrix after having multiplied each component by a given factor
     * Example Playground - https://playground.babylonjs.com/#AV9X17#50
     * @param array defines the source array
     * @param offset defines the offset in the source array
     * @param scale defines the scaling factor
     * @param result defines the target matrix
     * @returns result input
     */
    static FromFloat32ArrayToRefScaled<T extends Matrix>(array: DeepImmutable<Float32Array | Array<number>>, offset: number, scale: number, result: T): T;
    /**
     * Gets an identity matrix that must not be updated
     */
    static get IdentityReadOnly(): DeepImmutable<Matrix>;
    /**
     * Stores a list of values (16) inside a given matrix
     * @param initialM11 defines 1st value of 1st row
     * @param initialM12 defines 2nd value of 1st row
     * @param initialM13 defines 3rd value of 1st row
     * @param initialM14 defines 4th value of 1st row
     * @param initialM21 defines 1st value of 2nd row
     * @param initialM22 defines 2nd value of 2nd row
     * @param initialM23 defines 3rd value of 2nd row
     * @param initialM24 defines 4th value of 2nd row
     * @param initialM31 defines 1st value of 3rd row
     * @param initialM32 defines 2nd value of 3rd row
     * @param initialM33 defines 3rd value of 3rd row
     * @param initialM34 defines 4th value of 3rd row
     * @param initialM41 defines 1st value of 4th row
     * @param initialM42 defines 2nd value of 4th row
     * @param initialM43 defines 3rd value of 4th row
     * @param initialM44 defines 4th value of 4th row
     * @param result defines the target matrix
     */
    static FromValuesToRef(initialM11: number, initialM12: number, initialM13: number, initialM14: number, initialM21: number, initialM22: number, initialM23: number, initialM24: number, initialM31: number, initialM32: number, initialM33: number, initialM34: number, initialM41: number, initialM42: number, initialM43: number, initialM44: number, result: Matrix): void;
    /**
     * Creates new matrix from a list of values (16)
     * @param initialM11 defines 1st value of 1st row
     * @param initialM12 defines 2nd value of 1st row
     * @param initialM13 defines 3rd value of 1st row
     * @param initialM14 defines 4th value of 1st row
     * @param initialM21 defines 1st value of 2nd row
     * @param initialM22 defines 2nd value of 2nd row
     * @param initialM23 defines 3rd value of 2nd row
     * @param initialM24 defines 4th value of 2nd row
     * @param initialM31 defines 1st value of 3rd row
     * @param initialM32 defines 2nd value of 3rd row
     * @param initialM33 defines 3rd value of 3rd row
     * @param initialM34 defines 4th value of 3rd row
     * @param initialM41 defines 1st value of 4th row
     * @param initialM42 defines 2nd value of 4th row
     * @param initialM43 defines 3rd value of 4th row
     * @param initialM44 defines 4th value of 4th row
     * @returns the new matrix
     */
    static FromValues(initialM11: number, initialM12: number, initialM13: number, initialM14: number, initialM21: number, initialM22: number, initialM23: number, initialM24: number, initialM31: number, initialM32: number, initialM33: number, initialM34: number, initialM41: number, initialM42: number, initialM43: number, initialM44: number): Matrix;
    /**
     * Creates a new matrix composed by merging scale (vector3), rotation (quaternion) and translation (vector3)
     * Example Playground - https://playground.babylonjs.com/#AV9X17#24
     * @param scale defines the scale vector3
     * @param rotation defines the rotation quaternion
     * @param translation defines the translation vector3
     * @returns a new matrix
     */
    static Compose(scale: DeepImmutable<Vector3>, rotation: DeepImmutable<Quaternion>, translation: DeepImmutable<Vector3>): Matrix;
    /**
     * Sets a matrix to a value composed by merging scale (vector3), rotation (quaternion) and translation (vector3)
     * Example Playground - https://playground.babylonjs.com/#AV9X17#25
     * @param scale defines the scale vector3
     * @param rotation defines the rotation quaternion
     * @param translation defines the translation vector3
     * @param result defines the target matrix
     * @returns result input
     */
    static ComposeToRef<T extends Matrix>(scale: DeepImmutable<Vector3>, rotation: DeepImmutable<Quaternion>, translation: DeepImmutable<Vector3>, result: T): T;
    /**
     * Creates a new identity matrix
     * @returns a new identity matrix
     */
    static Identity(): Matrix;
    /**
     * Creates a new identity matrix and stores the result in a given matrix
     * @param result defines the target matrix
     * @returns result input
     */
    static IdentityToRef<T extends Matrix>(result: T): T;
    /**
     * Creates a new zero matrix
     * @returns a new zero matrix
     */
    static Zero(): Matrix;
    /**
     * Creates a new rotation matrix for "angle" radians around the X axis
     * Example Playground - https://playground.babylonjs.com/#AV9X17#97
     * @param angle defines the angle (in radians) to use
     * @returns the new matrix
     */
    static RotationX(angle: number): Matrix;
    /**
     * Creates a new matrix as the invert of a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#124
     * @param source defines the source matrix
     * @returns the new matrix
     */
    static Invert(source: DeepImmutable<Matrix>): Matrix;
    /**
     * Creates a new rotation matrix for "angle" radians around the X axis and stores it in a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#98
     * @param angle defines the angle (in radians) to use
     * @param result defines the target matrix
     * @returns result input
     */
    static RotationXToRef<T extends Matrix>(angle: number, result: T): T;
    /**
     * Creates a new rotation matrix for "angle" radians around the Y axis
     * Example Playground - https://playground.babylonjs.com/#AV9X17#99
     * @param angle defines the angle (in radians) to use
     * @returns the new matrix
     */
    static RotationY(angle: number): Matrix;
    /**
     * Creates a new rotation matrix for "angle" radians around the Y axis and stores it in a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#100
     * @param angle defines the angle (in radians) to use
     * @param result defines the target matrix
     * @returns result input
     */
    static RotationYToRef<T extends Matrix>(angle: number, result: T): T;
    /**
     * Creates a new rotation matrix for "angle" radians around the Z axis
     * Example Playground - https://playground.babylonjs.com/#AV9X17#101
     * @param angle defines the angle (in radians) to use
     * @returns the new matrix
     */
    static RotationZ(angle: number): Matrix;
    /**
     * Creates a new rotation matrix for "angle" radians around the Z axis and stores it in a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#102
     * @param angle defines the angle (in radians) to use
     * @param result defines the target matrix
     * @returns result input
     */
    static RotationZToRef<T extends Matrix>(angle: number, result: T): T;
    /**
     * Creates a new rotation matrix for "angle" radians around the given axis
     * Example Playground - https://playground.babylonjs.com/#AV9X17#96
     * @param axis defines the axis to use
     * @param angle defines the angle (in radians) to use
     * @returns the new matrix
     */
    static RotationAxis(axis: DeepImmutable<Vector3>, angle: number): Matrix;
    /**
     * Creates a new rotation matrix for "angle" radians around the given axis and stores it in a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#94
     * @param axis defines the axis to use
     * @param angle defines the angle (in radians) to use
     * @param result defines the target matrix
     * @returns result input
     */
    static RotationAxisToRef<T extends Matrix>(axis: DeepImmutable<Vector3>, angle: number, result: T): T;
    /**
     * Takes normalised vectors and returns a rotation matrix to align "from" with "to".
     * Taken from http://www.iquilezles.org/www/articles/noacos/noacos.htm
     * Example Playground - https://playground.babylonjs.com/#AV9X17#93
     * @param from defines the vector to align
     * @param to defines the vector to align to
     * @param result defines the target matrix
     * @param useYAxisForCoplanar defines a boolean indicating that we should favor Y axis for coplanar vectors (default is false)
     * @returns result input
     */
    static RotationAlignToRef<T extends Matrix>(from: DeepImmutable<Vector3>, to: DeepImmutable<Vector3>, result: T, useYAxisForCoplanar?: boolean): T;
    /**
     * Creates a rotation matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#103
     * Example Playground - https://playground.babylonjs.com/#AV9X17#105
     * @param yaw defines the yaw angle in radians (Y axis)
     * @param pitch defines the pitch angle in radians (X axis)
     * @param roll defines the roll angle in radians (Z axis)
     * @returns the new rotation matrix
     */
    static RotationYawPitchRoll(yaw: number, pitch: number, roll: number): Matrix;
    /**
     * Creates a rotation matrix and stores it in a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#104
     * @param yaw defines the yaw angle in radians (Y axis)
     * @param pitch defines the pitch angle in radians (X axis)
     * @param roll defines the roll angle in radians (Z axis)
     * @param result defines the target matrix
     * @returns result input
     */
    static RotationYawPitchRollToRef<T extends Matrix>(yaw: number, pitch: number, roll: number, result: T): T;
    /**
     * Creates a scaling matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#107
     * @param x defines the scale factor on X axis
     * @param y defines the scale factor on Y axis
     * @param z defines the scale factor on Z axis
     * @returns the new matrix
     */
    static Scaling(x: number, y: number, z: number): Matrix;
    /**
     * Creates a scaling matrix and stores it in a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#108
     * @param x defines the scale factor on X axis
     * @param y defines the scale factor on Y axis
     * @param z defines the scale factor on Z axis
     * @param result defines the target matrix
     * @returns result input
     */
    static ScalingToRef<T extends Matrix>(x: number, y: number, z: number, result: T): T;
    /**
     * Creates a translation matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#109
     * @param x defines the translation on X axis
     * @param y defines the translation on Y axis
     * @param z defines the translationon Z axis
     * @returns the new matrix
     */
    static Translation(x: number, y: number, z: number): Matrix;
    /**
     * Creates a translation matrix and stores it in a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#110
     * @param x defines the translation on X axis
     * @param y defines the translation on Y axis
     * @param z defines the translationon Z axis
     * @param result defines the target matrix
     * @returns result input
     */
    static TranslationToRef<T extends Matrix>(x: number, y: number, z: number, result: T): T;
    /**
     * Returns a new Matrix whose values are the interpolated values for "gradient" (float) between the ones of the matrices "startValue" and "endValue".
     * Example Playground - https://playground.babylonjs.com/#AV9X17#55
     * @param startValue defines the start value
     * @param endValue defines the end value
     * @param gradient defines the gradient factor
     * @returns the new matrix
     */
    static Lerp(startValue: DeepImmutable<Matrix>, endValue: DeepImmutable<Matrix>, gradient: number): Matrix;
    /**
     * Set the given matrix "result" as the interpolated values for "gradient" (float) between the ones of the matrices "startValue" and "endValue".
     * Example Playground - https://playground.babylonjs.com/#AV9X17#54
     * @param startValue defines the start value
     * @param endValue defines the end value
     * @param gradient defines the gradient factor
     * @param result defines the Matrix object where to store data
     * @returns result input
     */
    static LerpToRef<T extends Matrix>(startValue: DeepImmutable<Matrix>, endValue: DeepImmutable<Matrix>, gradient: number, result: T): T;
    /**
     * Builds a new matrix whose values are computed by:
     * * decomposing the "startValue" and "endValue" matrices into their respective scale, rotation and translation matrices
     * * interpolating for "gradient" (float) the values between each of these decomposed matrices between the start and the end
     * * recomposing a new matrix from these 3 interpolated scale, rotation and translation matrices
     * Example Playground - https://playground.babylonjs.com/#AV9X17#22
     * Example Playground - https://playground.babylonjs.com/#AV9X17#51
     * @param startValue defines the first matrix
     * @param endValue defines the second matrix
     * @param gradient defines the gradient between the two matrices
     * @returns the new matrix
     */
    static DecomposeLerp(startValue: DeepImmutable<Matrix>, endValue: DeepImmutable<Matrix>, gradient: number): Matrix;
    /**
     * Update a matrix to values which are computed by:
     * * decomposing the "startValue" and "endValue" matrices into their respective scale, rotation and translation matrices
     * * interpolating for "gradient" (float) the values between each of these decomposed matrices between the start and the end
     * * recomposing a new matrix from these 3 interpolated scale, rotation and translation matrices
     * Example Playground - https://playground.babylonjs.com/#AV9X17#23
     * Example Playground - https://playground.babylonjs.com/#AV9X17#53
     * @param startValue defines the first matrix
     * @param endValue defines the second matrix
     * @param gradient defines the gradient between the two matrices
     * @param result defines the target matrix
     * @returns result input
     */
    static DecomposeLerpToRef<T extends Matrix>(startValue: DeepImmutable<Matrix>, endValue: DeepImmutable<Matrix>, gradient: number, result: T): T;
    /**
     * Creates a new matrix that transforms vertices from world space to camera space. It takes three vectors as arguments that together describe the position and orientation of the camera.
     * This function generates a matrix suitable for a left handed coordinate system
     * Example Playground - https://playground.babylonjs.com/#AV9X17#58
     * Example Playground - https://playground.babylonjs.com/#AV9X17#59
     * @param eye defines the final position of the entity
     * @param target defines where the entity should look at
     * @param up defines the up vector for the entity
     * @returns the new matrix
     */
    static LookAtLH(eye: DeepImmutable<Vector3>, target: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>): Matrix;
    /**
     * Sets the given "result" Matrix to a matrix that transforms vertices from world space to camera space. It takes three vectors as arguments that together describe the position and orientation of the camera.
     * This function generates a matrix suitable for a left handed coordinate system
     * Example Playground - https://playground.babylonjs.com/#AV9X17#60
     * Example Playground - https://playground.babylonjs.com/#AV9X17#61
     * @param eye defines the final position of the entity
     * @param target defines where the entity should look at
     * @param up defines the up vector for the entity
     * @param result defines the target matrix
     * @returns result input
     */
    static LookAtLHToRef(eye: DeepImmutable<Vector3>, target: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>, result: Matrix): Matrix;
    /**
     * Creates a new matrix that transforms vertices from world space to camera space. It takes three vectors as arguments that together describe the position and orientation of the camera.
     * This function generates a matrix suitable for a right handed coordinate system
     * Example Playground - https://playground.babylonjs.com/#AV9X17#62
     * Example Playground - https://playground.babylonjs.com/#AV9X17#63
     * @param eye defines the final position of the entity
     * @param target defines where the entity should look at
     * @param up defines the up vector for the entity
     * @returns the new matrix
     */
    static LookAtRH(eye: DeepImmutable<Vector3>, target: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>): Matrix;
    /**
     * Sets the given "result" Matrix to a matrix that transforms vertices from world space to camera space. It takes three vectors as arguments that together describe the position and orientation of the camera.
     * This function generates a matrix suitable for a right handed coordinate system
     * Example Playground - https://playground.babylonjs.com/#AV9X17#64
     * Example Playground - https://playground.babylonjs.com/#AV9X17#65
     * @param eye defines the final position of the entity
     * @param target defines where the entity should look at
     * @param up defines the up vector for the entity
     * @param result defines the target matrix
     * @returns result input
     */
    static LookAtRHToRef<T extends Matrix>(eye: DeepImmutable<Vector3>, target: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>, result: T): T;
    /**
     * Creates a new matrix that transforms vertices from world space to camera space. It takes two vectors as arguments that together describe the orientation of the camera. The position is assumed to be at the origin (0,0,0)
     * This function generates a matrix suitable for a left handed coordinate system
     * Example Playground - https://playground.babylonjs.com/#AV9X17#66
     * @param forward defines the forward direction - Must be normalized and orthogonal to up.
     * @param up defines the up vector for the entity - Must be normalized and orthogonal to forward.
     * @returns the new matrix
     */
    static LookDirectionLH(forward: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>): Matrix;
    /**
     * Sets the given "result" Matrix to a matrix that transforms vertices from world space to camera space. It takes two vectors as arguments that together describe the orientation of the camera. The position is assumed to be at the origin (0,0,0)
     * This function generates a matrix suitable for a left handed coordinate system
     * Example Playground - https://playground.babylonjs.com/#AV9X17#67
     * @param forward defines the forward direction - Must be normalized and orthogonal to up.
     * @param up defines the up vector for the entity - Must be normalized and orthogonal to forward.
     * @param result defines the target matrix
     * @returns result input
     */
    static LookDirectionLHToRef<T extends Matrix>(forward: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>, result: T): T;
    /**
     * Creates a new matrix that transforms vertices from world space to camera space. It takes two vectors as arguments that together describe the orientation of the camera. The position is assumed to be at the origin (0,0,0)
     * This function generates a matrix suitable for a right handed coordinate system
     * Example Playground - https://playground.babylonjs.com/#AV9X17#68
     * @param forward defines the forward direction - Must be normalized and orthogonal to up.
     * @param up defines the up vector for the entity - Must be normalized and orthogonal to forward.
     * @returns the new matrix
     */
    static LookDirectionRH(forward: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>): Matrix;
    /**
     * Sets the given "result" Matrix to a matrix that transforms vertices from world space to camera space. It takes two vectors as arguments that together describe the orientation of the camera. The position is assumed to be at the origin (0,0,0)
     * This function generates a matrix suitable for a right handed coordinate system
     * Example Playground - https://playground.babylonjs.com/#AV9X17#69
     * @param forward defines the forward direction - Must be normalized and orthogonal to up.
     * @param up defines the up vector for the entity - Must be normalized and orthogonal to forward.
     * @param result defines the target matrix
     * @returns result input
     */
    static LookDirectionRHToRef<T extends Matrix>(forward: DeepImmutable<Vector3>, up: DeepImmutable<Vector3>, result: T): T;
    /**
     * Create a left-handed orthographic projection matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#70
     * @param width defines the viewport width
     * @param height defines the viewport height
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @returns a new matrix as a left-handed orthographic projection matrix
     */
    static OrthoLH(width: number, height: number, znear: number, zfar: number, halfZRange?: boolean): Matrix;
    /**
     * Store a left-handed orthographic projection to a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#71
     * @param width defines the viewport width
     * @param height defines the viewport height
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param result defines the target matrix
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @returns result input
     */
    static OrthoLHToRef<T extends Matrix>(width: number, height: number, znear: number, zfar: number, result: T, halfZRange?: boolean): T;
    /**
     * Create a left-handed orthographic projection matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#72
     * @param left defines the viewport left coordinate
     * @param right defines the viewport right coordinate
     * @param bottom defines the viewport bottom coordinate
     * @param top defines the viewport top coordinate
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @returns a new matrix as a left-handed orthographic projection matrix
     */
    static OrthoOffCenterLH(left: number, right: number, bottom: number, top: number, znear: number, zfar: number, halfZRange?: boolean): Matrix;
    /**
     * Stores a left-handed orthographic projection into a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#73
     * @param left defines the viewport left coordinate
     * @param right defines the viewport right coordinate
     * @param bottom defines the viewport bottom coordinate
     * @param top defines the viewport top coordinate
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param result defines the target matrix
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @returns result input
     */
    static OrthoOffCenterLHToRef<T extends Matrix>(left: number, right: number, bottom: number, top: number, znear: number, zfar: number, result: T, halfZRange?: boolean): T;
    /**
     * Stores a left-handed oblique projection into a given matrix
     * @param left defines the viewport left coordinate
     * @param right defines the viewport right coordinate
     * @param bottom defines the viewport bottom coordinate
     * @param top defines the viewport top coordinate
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param length Length of the shear
     * @param angle Angle (along X/Y Plane) to apply shear
     * @param distance Distance from shear point
     * @param result defines the target matrix
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @returns result input
     */
    static ObliqueOffCenterLHToRef<T extends Matrix>(left: number, right: number, bottom: number, top: number, znear: number, zfar: number, length: number, angle: number, distance: number, result: T, halfZRange?: boolean): T;
    /**
     * Creates a right-handed orthographic projection matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#76
     * @param left defines the viewport left coordinate
     * @param right defines the viewport right coordinate
     * @param bottom defines the viewport bottom coordinate
     * @param top defines the viewport top coordinate
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @returns a new matrix as a right-handed orthographic projection matrix
     */
    static OrthoOffCenterRH(left: number, right: number, bottom: number, top: number, znear: number, zfar: number, halfZRange?: boolean): Matrix;
    /**
     * Stores a right-handed orthographic projection into a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#77
     * @param left defines the viewport left coordinate
     * @param right defines the viewport right coordinate
     * @param bottom defines the viewport bottom coordinate
     * @param top defines the viewport top coordinate
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param result defines the target matrix
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @returns result input
     */
    static OrthoOffCenterRHToRef<T extends Matrix>(left: number, right: number, bottom: number, top: number, znear: number, zfar: number, result: T, halfZRange?: boolean): T;
    /**
     * Stores a right-handed oblique projection into a given matrix
     * @param left defines the viewport left coordinate
     * @param right defines the viewport right coordinate
     * @param bottom defines the viewport bottom coordinate
     * @param top defines the viewport top coordinate
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param length Length of the shear
     * @param angle Angle (along X/Y Plane) to apply shear
     * @param distance Distance from shear point
     * @param result defines the target matrix
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @returns result input
     */
    static ObliqueOffCenterRHToRef<T extends Matrix>(left: number, right: number, bottom: number, top: number, znear: number, zfar: number, length: number, angle: number, distance: number, result: T, halfZRange?: boolean): T;
    /**
     * Creates a left-handed perspective projection matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#85
     * @param width defines the viewport width
     * @param height defines the viewport height
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @param projectionPlaneTilt optional tilt angle of the projection plane around the X axis (horizontal)
     * @returns a new matrix as a left-handed perspective projection matrix
     */
    static PerspectiveLH(width: number, height: number, znear: number, zfar: number, halfZRange?: boolean, projectionPlaneTilt?: number): Matrix;
    /**
     * Creates a left-handed perspective projection matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#78
     * @param fov defines the horizontal field of view
     * @param aspect defines the aspect ratio
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane. If 0, assume we are in "infinite zfar" mode
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @param projectionPlaneTilt optional tilt angle of the projection plane around the X axis (horizontal)
     * @param reverseDepthBufferMode true to indicate that we are in a reverse depth buffer mode (meaning znear and zfar have been inverted when calling the function)
     * @returns a new matrix as a left-handed perspective projection matrix
     */
    static PerspectiveFovLH(fov: number, aspect: number, znear: number, zfar: number, halfZRange?: boolean, projectionPlaneTilt?: number, reverseDepthBufferMode?: boolean): Matrix;
    /**
     * Stores a left-handed perspective projection into a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#81
     * @param fov defines the horizontal field of view
     * @param aspect defines the aspect ratio
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane. If 0, assume we are in "infinite zfar" mode
     * @param result defines the target matrix
     * @param isVerticalFovFixed defines it the fov is vertically fixed (default) or horizontally
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @param projectionPlaneTilt optional tilt angle of the projection plane around the X axis (horizontal)
     * @param reverseDepthBufferMode true to indicate that we are in a reverse depth buffer mode (meaning znear and zfar have been inverted when calling the function)
     * @returns result input
     */
    static PerspectiveFovLHToRef<T extends Matrix>(fov: number, aspect: number, znear: number, zfar: number, result: T, isVerticalFovFixed?: boolean, halfZRange?: boolean, projectionPlaneTilt?: number, reverseDepthBufferMode?: boolean): T;
    /**
     * Stores a left-handed perspective projection into a given matrix with depth reversed
     * Example Playground - https://playground.babylonjs.com/#AV9X17#89
     * @param fov defines the horizontal field of view
     * @param aspect defines the aspect ratio
     * @param znear defines the near clip plane
     * @param zfar not used as infinity is used as far clip
     * @param result defines the target matrix
     * @param isVerticalFovFixed defines it the fov is vertically fixed (default) or horizontally
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @param projectionPlaneTilt optional tilt angle of the projection plane around the X axis (horizontal)
     * @returns result input
     */
    static PerspectiveFovReverseLHToRef<T extends Matrix>(fov: number, aspect: number, znear: number, zfar: number, result: T, isVerticalFovFixed?: boolean, halfZRange?: boolean, projectionPlaneTilt?: number): T;
    /**
     * Creates a right-handed perspective projection matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#83
     * @param fov defines the horizontal field of view
     * @param aspect defines the aspect ratio
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane. If 0, assume we are in "infinite zfar" mode
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @param projectionPlaneTilt optional tilt angle of the projection plane around the X axis (horizontal)
     * @param reverseDepthBufferMode true to indicate that we are in a reverse depth buffer mode (meaning znear and zfar have been inverted when calling the function)
     * @returns a new matrix as a right-handed perspective projection matrix
     */
    static PerspectiveFovRH(fov: number, aspect: number, znear: number, zfar: number, halfZRange?: boolean, projectionPlaneTilt?: number, reverseDepthBufferMode?: boolean): Matrix;
    /**
     * Stores a right-handed perspective projection into a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#84
     * @param fov defines the horizontal field of view
     * @param aspect defines the aspect ratio
     * @param znear defines the near clip plane
     * @param zfar defines the far clip plane. If 0, assume we are in "infinite zfar" mode
     * @param result defines the target matrix
     * @param isVerticalFovFixed defines it the fov is vertically fixed (default) or horizontally
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @param projectionPlaneTilt optional tilt angle of the projection plane around the X axis (horizontal)
     * @param reverseDepthBufferMode true to indicate that we are in a reverse depth buffer mode (meaning znear and zfar have been inverted when calling the function)
     * @returns result input
     */
    static PerspectiveFovRHToRef<T extends Matrix>(fov: number, aspect: number, znear: number, zfar: number, result: T, isVerticalFovFixed?: boolean, halfZRange?: boolean, projectionPlaneTilt?: number, reverseDepthBufferMode?: boolean): T;
    /**
     * Stores a right-handed perspective projection into a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#90
     * @param fov defines the horizontal field of view
     * @param aspect defines the aspect ratio
     * @param znear defines the near clip plane
     * @param zfar not used as infinity is used as far clip
     * @param result defines the target matrix
     * @param isVerticalFovFixed defines it the fov is vertically fixed (default) or horizontally
     * @param halfZRange true to generate NDC coordinates between 0 and 1 instead of -1 and 1 (default: false)
     * @param projectionPlaneTilt optional tilt angle of the projection plane around the X axis (horizontal)
     * @returns result input
     */
    static PerspectiveFovReverseRHToRef<T extends Matrix>(fov: number, aspect: number, znear: number, zfar: number, result: T, isVerticalFovFixed?: boolean, halfZRange?: boolean, projectionPlaneTilt?: number): T;
    /**
     * Computes a complete transformation matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#113
     * @param viewport defines the viewport to use
     * @param world defines the world matrix
     * @param view defines the view matrix
     * @param projection defines the projection matrix
     * @param zmin defines the near clip plane
     * @param zmax defines the far clip plane
     * @returns the transformation matrix
     */
    static GetFinalMatrix(viewport: DeepImmutable<Viewport>, world: DeepImmutable<Matrix>, view: DeepImmutable<Matrix>, projection: DeepImmutable<Matrix>, zmin: number, zmax: number): Matrix;
    /**
     * Extracts a 2x2 matrix from a given matrix and store the result in a Float32Array
     * @param matrix defines the matrix to use
     * @returns a new Float32Array array with 4 elements : the 2x2 matrix extracted from the given matrix
     */
    static GetAsMatrix2x2(matrix: DeepImmutable<Matrix>): Float32Array | Array<number>;
    /**
     * Extracts a 3x3 matrix from a given matrix and store the result in a Float32Array
     * @param matrix defines the matrix to use
     * @returns a new Float32Array array with 9 elements : the 3x3 matrix extracted from the given matrix
     */
    static GetAsMatrix3x3(matrix: DeepImmutable<Matrix>): Float32Array | Array<number>;
    /**
     * Compute the transpose of a given matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#111
     * @param matrix defines the matrix to transpose
     * @returns the new matrix
     */
    static Transpose(matrix: DeepImmutable<Matrix>): Matrix;
    /**
     * Compute the transpose of a matrix and store it in a target matrix
     * Example Playground - https://playground.babylonjs.com/#AV9X17#112
     * @param matrix defines the matrix to transpose
     * @param result defines the target matrix
     * @returns result input
     */
    static TransposeToRef<T extends Matrix>(matrix: DeepImmutable<Matrix>, result: T): T;
    /**
     * Computes a reflection matrix from a plane
     * Example Playground - https://playground.babylonjs.com/#AV9X17#87
     * @param plane defines the reflection plane
     * @returns a new matrix
     */
    static Reflection(plane: DeepImmutable<IPlaneLike>): Matrix;
    /**
     * Computes a reflection matrix from a plane
     * Example Playground - https://playground.babylonjs.com/#AV9X17#88
     * @param plane defines the reflection plane
     * @param result defines the target matrix
     * @returns result input
     */
    static ReflectionToRef<T extends Matrix>(plane: DeepImmutable<IPlaneLike>, result: T): T;
    /**
     * Sets the given matrix as a rotation matrix composed from the 3 left handed axes
     * @param xaxis defines the value of the 1st axis
     * @param yaxis defines the value of the 2nd axis
     * @param zaxis defines the value of the 3rd axis
     * @param result defines the target matrix
     * @returns result input
     */
    static FromXYZAxesToRef<T extends Matrix>(xaxis: DeepImmutable<Vector3>, yaxis: DeepImmutable<Vector3>, zaxis: DeepImmutable<Vector3>, result: T): T;
    /**
     * Creates a rotation matrix from a quaternion and stores it in a target matrix
     * @param quat defines the quaternion to use
     * @param result defines the target matrix
     * @returns result input
     */
    static FromQuaternionToRef<T extends Matrix>(quat: DeepImmutable<Quaternion>, result: T): T;
}

/**
 * Options to be used when creating an additive animation
 */
interface IMakeAnimationAdditiveOptions {
    /**
     * The frame that the animation should be relative to (if not provided, 0 will be used)
     */
    referenceFrame?: number;
    /**
     * The name of the animation range to convert to additive. If not provided, fromFrame / toFrame will be used
     * If fromFrame / toFrame are not provided either, the whole animation will be converted to additive
     */
    range?: string;
    /**
     * If true, the original animation will be cloned and converted to additive. If false, the original animation will be converted to additive (default is false)
     */
    cloneOriginalAnimation?: boolean;
    /**
     * The name of the cloned animation if cloneOriginalAnimation is true. If not provided, use the original animation name
     */
    clonedAnimationName?: string;
    /**
     * Together with toFrame, defines the range of the animation to convert to additive. Will only be used if range is not provided
     * If range and fromFrame / toFrame are not provided, the whole animation will be converted to additive
     */
    fromFrame?: number;
    /**
     * Together with fromFrame, defines the range of the animation to convert to additive.
     */
    toFrame?: number;
    /**
     * If true, the key frames will be clipped to the range specified by range or fromFrame / toFrame (default is false)
     */
    clipKeys?: boolean;
}
/**
 * @internal
 */
interface _IAnimationState {
    key: number;
    repeatCount: number;
    workValue?: any;
    loopMode?: number;
    offsetValue?: any;
    highLimitValue?: any;
}
/**
 * Class used to store any kind of animation
 */
declare class Animation {
    /**Name of the animation */
    name: string;
    /**Property to animate */
    targetProperty: string;
    /**The frames per second of the animation */
    framePerSecond: number;
    /**The data type of the animation */
    dataType: number;
    /**The loop mode of the animation */
    loopMode?: number | undefined;
    /**Specifies if blending should be enabled */
    enableBlending?: boolean | undefined;
    private static _UniqueIdGenerator;
    /**
     * Use matrix interpolation instead of using direct key value when animating matrices
     */
    static AllowMatricesInterpolation: boolean;
    /**
     * When matrix interpolation is enabled, this boolean forces the system to use Matrix.DecomposeLerp instead of Matrix.Lerp. Interpolation is more precise but slower
     */
    static AllowMatrixDecomposeForInterpolation: boolean;
    /**
     * Gets or sets the unique id of the animation (the uniqueness is solely among other animations)
     */
    uniqueId: number;
    /** Define the Url to load snippets */
    static SnippetUrl: string;
    /** Snippet ID if the animation was created from the snippet server */
    snippetId: string;
    /**
     * Stores the key frames of the animation
     */
    private _keys;
    /**
     * Stores the easing function of the animation
     */
    private _easingFunction;
    /**
     * @internal Internal use only
     */
    _runtimeAnimations: RuntimeAnimation[];
    /**
     * The set of event that will be linked to this animation
     */
    private _events;
    /**
     * Stores an array of target property paths
     */
    targetPropertyPath: string[];
    /**
     * Stores the blending speed of the animation
     */
    blendingSpeed: number;
    /**
     * Stores the animation ranges for the animation
     */
    private _ranges;
    /** @internal */
    _coreAnimation: Nullable<Animation>;
    /**
     * @internal Internal use
     */
    static _PrepareAnimation(name: string, targetProperty: string, framePerSecond: number, totalFrame: number, from: any, to: any, loopMode?: number, easingFunction?: EasingFunction): Nullable<Animation>;
    /**
     * Sets up an animation
     * @param property The property to animate
     * @param animationType The animation type to apply
     * @param framePerSecond The frames per second of the animation
     * @param easingFunction The easing function used in the animation
     * @returns The created animation
     */
    static CreateAnimation(property: string, animationType: number, framePerSecond: number, easingFunction: EasingFunction): Animation;
    /**
     * Create and start an animation on a node
     * @param name defines the name of the global animation that will be run on all nodes
     * @param target defines the target where the animation will take place
     * @param targetProperty defines property to animate
     * @param framePerSecond defines the number of frame per second yo use
     * @param totalFrame defines the number of frames in total
     * @param from defines the initial value
     * @param to defines the final value
     * @param loopMode defines which loop mode you want to use (off by default)
     * @param easingFunction defines the easing function to use (linear by default)
     * @param onAnimationEnd defines the callback to call when animation end
     * @param scene defines the hosting scene
     * @returns the animatable created for this animation
     */
    static CreateAndStartAnimation(name: string, target: any, targetProperty: string, framePerSecond: number, totalFrame: number, from: any, to: any, loopMode?: number, easingFunction?: EasingFunction, onAnimationEnd?: () => void, scene?: Scene): Nullable<Animatable>;
    /**
     * Create and start an animation on a node and its descendants
     * @param name defines the name of the global animation that will be run on all nodes
     * @param node defines the root node where the animation will take place
     * @param directDescendantsOnly if true only direct descendants will be used, if false direct and also indirect (children of children, an so on in a recursive manner) descendants will be used
     * @param targetProperty defines property to animate
     * @param framePerSecond defines the number of frame per second to use
     * @param totalFrame defines the number of frames in total
     * @param from defines the initial value
     * @param to defines the final value
     * @param loopMode defines which loop mode you want to use (off by default)
     * @param easingFunction defines the easing function to use (linear by default)
     * @param onAnimationEnd defines the callback to call when an animation ends (will be called once per node)
     * @returns the list of animatables created for all nodes
     * @example https://www.babylonjs-playground.com/#MH0VLI
     */
    static CreateAndStartHierarchyAnimation(name: string, node: Node, directDescendantsOnly: boolean, targetProperty: string, framePerSecond: number, totalFrame: number, from: any, to: any, loopMode?: number, easingFunction?: EasingFunction, onAnimationEnd?: () => void): Nullable<Animatable[]>;
    /**
     * Creates a new animation, merges it with the existing animations and starts it
     * @param name Name of the animation
     * @param node Node which contains the scene that begins the animations
     * @param targetProperty Specifies which property to animate
     * @param framePerSecond The frames per second of the animation
     * @param totalFrame The total number of frames
     * @param from The frame at the beginning of the animation
     * @param to The frame at the end of the animation
     * @param loopMode Specifies the loop mode of the animation
     * @param easingFunction (Optional) The easing function of the animation, which allow custom mathematical formulas for animations
     * @param onAnimationEnd Callback to run once the animation is complete
     * @returns Nullable animation
     */
    static CreateMergeAndStartAnimation(name: string, node: Node, targetProperty: string, framePerSecond: number, totalFrame: number, from: any, to: any, loopMode?: number, easingFunction?: EasingFunction, onAnimationEnd?: () => void): Nullable<Animatable>;
    /**
     * Convert the keyframes of an animation to be relative to a given reference frame.
     * @param sourceAnimation defines the Animation containing keyframes to convert
     * @param referenceFrame defines the frame that keyframes in the range will be relative to (default: 0)
     * @param range defines the name of the AnimationRange belonging to the Animation to convert
     * @param cloneOriginal defines whether or not to clone the animation and convert the clone or convert the original animation (default is false)
     * @param clonedName defines the name of the resulting cloned Animation if cloneOriginal is true
     * @returns a new Animation if cloneOriginal is true or the original Animation if cloneOriginal is false
     */
    static MakeAnimationAdditive(sourceAnimation: Animation, referenceFrame?: number, range?: string, cloneOriginal?: boolean, clonedName?: string): Animation;
    /**
     * Convert the keyframes of an animation to be relative to a given reference frame.
     * @param sourceAnimation defines the Animation containing keyframes to convert
     * @param options defines the options to use when converting ey keyframes
     * @returns a new Animation if options.cloneOriginalAnimation is true or the original Animation if options.cloneOriginalAnimation is false
     */
    static MakeAnimationAdditive(sourceAnimation: Animation, options?: IMakeAnimationAdditiveOptions): Animation;
    /**
     * Transition property of an host to the target Value
     * @param property The property to transition
     * @param targetValue The target Value of the property
     * @param host The object where the property to animate belongs
     * @param scene Scene used to run the animation
     * @param frameRate Framerate (in frame/s) to use
     * @param transition The transition type we want to use
     * @param duration The duration of the animation, in milliseconds
     * @param onAnimationEnd Callback trigger at the end of the animation
     * @param stopCurrent If true, will stop the current animation on the property
     * @param customKeys defines custom keys to use for the animation instead of the from-to keys
     * @returns Nullable animation
     */
    static TransitionTo(property: string, targetValue: any, host: any, scene: Scene, frameRate: number, transition: Animation, duration: number, onAnimationEnd?: Nullable<() => void>, stopCurrent?: boolean, customKeys?: IAnimationKey[]): Nullable<Animatable>;
    /**
     * Return the array of runtime animations currently using this animation
     */
    get runtimeAnimations(): RuntimeAnimation[];
    /**
     * Specifies if any of the runtime animations are currently running
     */
    get hasRunningRuntimeAnimations(): boolean;
    /**
     * Initializes the animation
     * @param name Name of the animation
     * @param targetProperty Property to animate
     * @param framePerSecond The frames per second of the animation
     * @param dataType The data type of the animation
     * @param loopMode The loop mode of the animation
     * @param enableBlending Specifies if blending should be enabled
     */
    constructor(
    /**Name of the animation */
    name: string, 
    /**Property to animate */
    targetProperty: string, 
    /**The frames per second of the animation */
    framePerSecond: number, 
    /**The data type of the animation */
    dataType: number, 
    /**The loop mode of the animation */
    loopMode?: number | undefined, 
    /**Specifies if blending should be enabled */
    enableBlending?: boolean | undefined);
    /**
     * Converts the animation to a string
     * @param fullDetails support for multiple levels of logging within scene loading
     * @returns String form of the animation
     */
    toString(fullDetails?: boolean): string;
    /**
     * Add an event to this animation
     * @param event Event to add
     */
    addEvent(event: AnimationEvent): void;
    /**
     * Remove all events found at the given frame
     * @param frame The frame to remove events from
     */
    removeEvents(frame: number): void;
    /**
     * Retrieves all the events from the animation
     * @returns Events from the animation
     */
    getEvents(): AnimationEvent[];
    /**
     * Creates an animation range
     * @param name Name of the animation range
     * @param from Starting frame of the animation range
     * @param to Ending frame of the animation
     */
    createRange(name: string, from: number, to: number): void;
    /**
     * Deletes an animation range by name
     * @param name Name of the animation range to delete
     * @param deleteFrames Specifies if the key frames for the range should also be deleted (true) or not (false)
     */
    deleteRange(name: string, deleteFrames?: boolean): void;
    /**
     * Gets the animation range by name, or null if not defined
     * @param name Name of the animation range
     * @returns Nullable animation range
     */
    getRange(name: string): Nullable<AnimationRange>;
    /**
     * Gets the key frames from the animation
     * @returns The key frames of the animation
     */
    getKeys(): Array<IAnimationKey>;
    /**
     * Gets the highest frame of the animation
     * @returns Highest frame of the animation
     */
    getHighestFrame(): number;
    /**
     * Gets the easing function of the animation
     * @returns Easing function of the animation
     */
    getEasingFunction(): Nullable<IEasingFunction>;
    /**
     * Sets the easing function of the animation
     * @param easingFunction A custom mathematical formula for animation
     */
    setEasingFunction(easingFunction: Nullable<IEasingFunction>): void;
    /**
     * Interpolates a scalar linearly
     * @param startValue Start value of the animation curve
     * @param endValue End value of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns Interpolated scalar value
     */
    floatInterpolateFunction(startValue: number, endValue: number, gradient: number): number;
    /**
     * Interpolates a scalar cubically
     * @param startValue Start value of the animation curve
     * @param outTangent End tangent of the animation
     * @param endValue End value of the animation curve
     * @param inTangent Start tangent of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns Interpolated scalar value
     */
    floatInterpolateFunctionWithTangents(startValue: number, outTangent: number, endValue: number, inTangent: number, gradient: number): number;
    /**
     * Interpolates a quaternion using a spherical linear interpolation
     * @param startValue Start value of the animation curve
     * @param endValue End value of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns Interpolated quaternion value
     */
    quaternionInterpolateFunction(startValue: Quaternion, endValue: Quaternion, gradient: number): Quaternion;
    /**
     * Interpolates a quaternion cubically
     * @param startValue Start value of the animation curve
     * @param outTangent End tangent of the animation curve
     * @param endValue End value of the animation curve
     * @param inTangent Start tangent of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns Interpolated quaternion value
     */
    quaternionInterpolateFunctionWithTangents(startValue: Quaternion, outTangent: Quaternion, endValue: Quaternion, inTangent: Quaternion, gradient: number): Quaternion;
    /**
     * Interpolates a Vector3 linearly
     * @param startValue Start value of the animation curve
     * @param endValue End value of the animation curve
     * @param gradient Scalar amount to interpolate (value between 0 and 1)
     * @returns Interpolated scalar value
     */
    vector3InterpolateFunction(startValue: Vector3, endValue: Vector3, gradient: number): Vector3;
    /**
     * Interpolates a Vector3 cubically
     * @param startValue Start value of the animation curve
     * @param outTangent End tangent of the animation
     * @param endValue End value of the animation curve
     * @param inTangent Start tangent of the animation curve
     * @param gradient Scalar amount to interpolate (value between 0 and 1)
     * @returns InterpolatedVector3 value
     */
    vector3InterpolateFunctionWithTangents(startValue: Vector3, outTangent: Vector3, endValue: Vector3, inTangent: Vector3, gradient: number): Vector3;
    /**
     * Interpolates a Vector2 linearly
     * @param startValue Start value of the animation curve
     * @param endValue End value of the animation curve
     * @param gradient Scalar amount to interpolate (value between 0 and 1)
     * @returns Interpolated Vector2 value
     */
    vector2InterpolateFunction(startValue: Vector2, endValue: Vector2, gradient: number): Vector2;
    /**
     * Interpolates a Vector2 cubically
     * @param startValue Start value of the animation curve
     * @param outTangent End tangent of the animation
     * @param endValue End value of the animation curve
     * @param inTangent Start tangent of the animation curve
     * @param gradient Scalar amount to interpolate (value between 0 and 1)
     * @returns Interpolated Vector2 value
     */
    vector2InterpolateFunctionWithTangents(startValue: Vector2, outTangent: Vector2, endValue: Vector2, inTangent: Vector2, gradient: number): Vector2;
    /**
     * Interpolates a size linearly
     * @param startValue Start value of the animation curve
     * @param endValue End value of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns Interpolated Size value
     */
    sizeInterpolateFunction(startValue: Size, endValue: Size, gradient: number): Size;
    /**
     * Interpolates a Color3 linearly
     * @param startValue Start value of the animation curve
     * @param endValue End value of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns Interpolated Color3 value
     */
    color3InterpolateFunction(startValue: Color3, endValue: Color3, gradient: number): Color3;
    /**
     * Interpolates a Color3 cubically
     * @param startValue Start value of the animation curve
     * @param outTangent End tangent of the animation
     * @param endValue End value of the animation curve
     * @param inTangent Start tangent of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns interpolated value
     */
    color3InterpolateFunctionWithTangents(startValue: Color3, outTangent: Color3, endValue: Color3, inTangent: Color3, gradient: number): Color3;
    /**
     * Interpolates a Color4 linearly
     * @param startValue Start value of the animation curve
     * @param endValue End value of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns Interpolated Color3 value
     */
    color4InterpolateFunction(startValue: Color4, endValue: Color4, gradient: number): Color4;
    /**
     * Interpolates a Color4 cubically
     * @param startValue Start value of the animation curve
     * @param outTangent End tangent of the animation
     * @param endValue End value of the animation curve
     * @param inTangent Start tangent of the animation curve
     * @param gradient Scalar amount to interpolate
     * @returns interpolated value
     */
    color4InterpolateFunctionWithTangents(startValue: Color4, outTangent: Color4, endValue: Color4, inTangent: Color4, gradient: number): Color4;
    /**
     * @internal Internal use only
     */
    _getKeyValue(value: any): any;
    /**
     * Evaluate the animation value at a given frame
     * @param currentFrame defines the frame where we want to evaluate the animation
     * @returns the animation value
     */
    evaluate(currentFrame: number): any;
    /** @internal */
    _key: number;
    /**
     * @internal Internal use only
     */
    _interpolate(currentFrame: number, state: _IAnimationState, searchClosestKeyOnly?: boolean): any;
    /**
     * Defines the function to use to interpolate matrices
     * @param startValue defines the start matrix
     * @param endValue defines the end matrix
     * @param gradient defines the gradient between both matrices
     * @param result defines an optional target matrix where to store the interpolation
     * @returns the interpolated matrix
     */
    matrixInterpolateFunction(startValue: Matrix, endValue: Matrix, gradient: number, result?: Matrix): Matrix;
    /**
     * Makes a copy of the animation
     * @returns Cloned animation
     */
    clone(): Animation;
    /**
     * Sets the key frames of the animation
     * @param values The animation key frames to set
     * @param dontClone Whether to clone the keys or not (default is false, so the array of keys is cloned)
     */
    setKeys(values: Array<IAnimationKey>, dontClone?: boolean): void;
    /**
     * Creates a key for the frame passed as a parameter and adds it to the animation IF a key doesn't already exist for that frame
     * @param frame Frame number
     * @returns The key index if the key was added or the index of the pre existing key if the frame passed as parameter already has a corresponding key
     */
    createKeyForFrame(frame: number): number;
    /**
     * Serializes the animation to an object
     * @returns Serialized object
     */
    serialize(): any;
    /**
     * Float animation type
     */
    static readonly ANIMATIONTYPE_FLOAT = 0;
    /**
     * Vector3 animation type
     */
    static readonly ANIMATIONTYPE_VECTOR3 = 1;
    /**
     * Quaternion animation type
     */
    static readonly ANIMATIONTYPE_QUATERNION = 2;
    /**
     * Matrix animation type
     */
    static readonly ANIMATIONTYPE_MATRIX = 3;
    /**
     * Color3 animation type
     */
    static readonly ANIMATIONTYPE_COLOR3 = 4;
    /**
     * Color3 animation type
     */
    static readonly ANIMATIONTYPE_COLOR4 = 7;
    /**
     * Vector2 animation type
     */
    static readonly ANIMATIONTYPE_VECTOR2 = 5;
    /**
     * Size animation type
     */
    static readonly ANIMATIONTYPE_SIZE = 6;
    /**
     * Relative Loop Mode
     */
    static readonly ANIMATIONLOOPMODE_RELATIVE = 0;
    /**
     * Cycle Loop Mode
     */
    static readonly ANIMATIONLOOPMODE_CYCLE = 1;
    /**
     * Constant Loop Mode
     */
    static readonly ANIMATIONLOOPMODE_CONSTANT = 2;
    /**
     * Yoyo Loop Mode
     */
    static readonly ANIMATIONLOOPMODE_YOYO = 4;
    /**
     * Relative Loop Mode (add to current value of animated object, unlike ANIMATIONLOOPMODE_RELATIVE)
     */
    static readonly ANIMATIONLOOPMODE_RELATIVE_FROM_CURRENT = 5;
    /**
     * @internal
     */
    static _UniversalLerp(left: any, right: any, amount: number): any;
    /**
     * Parses an animation object and creates an animation
     * @param parsedAnimation Parsed animation object
     * @returns Animation object
     */
    static Parse(parsedAnimation: any): Animation;
    /**
     * Appends the serialized animations from the source animations
     * @param source Source containing the animations
     * @param destination Target to store the animations
     */
    static AppendSerializedAnimations(source: IAnimatable, destination: any): void;
    /**
     * Creates a new animation or an array of animations from a snippet saved in a remote file
     * @param name defines the name of the animation to create (can be null or empty to use the one from the json data)
     * @param url defines the url to load from
     * @returns a promise that will resolve to the new animation or an array of animations
     */
    static ParseFromFileAsync(name: Nullable<string>, url: string): Promise<Animation | Array<Animation>>;
    /**
     * Creates an animation or an array of animations from a snippet saved by the Inspector
     * @param snippetId defines the snippet to load
     * @returns a promise that will resolve to the new animation or a new array of animations
     */
    static ParseFromSnippetAsync(snippetId: string): Promise<Animation | Array<Animation>>;
    /**
     * Creates an animation or an array of animations from a snippet saved by the Inspector
     * @deprecated Please use ParseFromSnippetAsync instead
     * @param snippetId defines the snippet to load
     * @returns a promise that will resolve to the new animation or a new array of animations
     */
    static CreateFromSnippetAsync: typeof Animation.ParseFromSnippetAsync;
}

/**
 * Interface containing an array of animations
 */
interface IAnimatable {
    /**
     * Array of animations
     */
    animations: Nullable<Array<Animation>>;
}

/**
 * Define an interface for all classes that will hold resources
 */
interface IDisposable {
    /**
     * Releases all held resources
     */
    dispose(): void;
}
/** Interface defining initialization parameters for Scene class */
interface SceneOptions {
    /**
     * Defines that scene should keep up-to-date a map of geometry to enable fast look-up by uniqueId
     * It will improve performance when the number of geometries becomes important.
     */
    useGeometryUniqueIdsMap?: boolean;
    /**
     * Defines that each material of the scene should keep up-to-date a map of referencing meshes for fast disposing
     * It will improve performance when the number of mesh becomes important, but might consume a bit more memory
     */
    useMaterialMeshMap?: boolean;
    /**
     * Defines that each mesh of the scene should keep up-to-date a map of referencing cloned meshes for fast disposing
     * It will improve performance when the number of mesh becomes important, but might consume a bit more memory
     */
    useClonedMeshMap?: boolean;
    /**
     * @experimental
     * When enabled, the scene can handle large world coordinate rendering without jittering caused by floating point imprecision on the GPU.
     * This mode offsets matrices and position-related attribute values before passing to shaders, centering camera at origin and offsetting other scene objects by camera active position.
     *
     * IMPORTANT: Only use this scene-level option if you intend to enable floating origin on a per-scene basis. Must use in conjunction with engine creation option 'useHighPrecisionMatrix' to fix CPU-side floating point imprecision.
     * HOWEVER if you want largeWorldRendering on ALL scenes, set the useLargeWorldRendering flag on the engine instead of this scene-level flag. Doing so will automatically set useHighPrecisionMatrix on the engine as well.
     */
    useFloatingOrigin?: boolean;
    /** Defines if the creation of the scene should impact the engine (Eg. UtilityLayer's scene) */
    virtual?: boolean;
}
/**
 * Define how the scene should favor performance over ease of use
 */
declare const enum ScenePerformancePriority {
    /** Default mode. No change. Performance will be treated as less important than backward compatibility */
    BackwardCompatible = 0,
    /** Some performance options will be turned on trying to strike a balance between perf and ease of use */
    Intermediate = 1,
    /** Performance will be top priority */
    Aggressive = 2
}
/**
 * Represents a scene to be rendered by the engine.
 * @see https://doc.babylonjs.com/features/featuresDeepDive/scene
 */
declare class Scene implements IAnimatable, IClipPlanesHolder, IAssetContainer {
    /** The fog is deactivated */
    static readonly FOGMODE_NONE: number;
    /** The fog density is following an exponential function */
    static readonly FOGMODE_EXP: number;
    /** The fog density is following an exponential function faster than FOGMODE_EXP */
    static readonly FOGMODE_EXP2: number;
    /** The fog density is following a linear function. */
    static readonly FOGMODE_LINEAR: number;
    /**
     * Gets or sets the minimum deltatime when deterministic lock step is enabled
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
     */
    static MinDeltaTime: number;
    /**
     * Gets or sets the maximum deltatime when deterministic lock step is enabled
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
     */
    static MaxDeltaTime: number;
    /**
     * Factory used to create the default material.
     * @param scene The scene to create the material for
     * @returns The default material
     */
    static DefaultMaterialFactory(scene: Scene): Material;
    private static readonly _OriginalDefaultMaterialFactory;
    /**
     * Factory used to create the a collision coordinator.
     * @returns The collision coordinator
     */
    static CollisionCoordinatorFactory(): ICollisionCoordinator;
    /** @internal */
    _tempPickingRay: Nullable<Ray>;
    /** @internal */
    _cachedRayForTransform: Ray;
    /** @internal */
    _pickWithRayInverseMatrix: Matrix;
    /** @internal */
    _inputManager: InputManager;
    /** Define this parameter if you are using multiple cameras and you want to specify which one should be used for pointer position */
    cameraToUseForPointers: Nullable<Camera>;
    /** @internal */
    readonly _isScene = true;
    /** @internal */
    _blockEntityCollection: boolean;
    /**
     * Gets or sets a boolean that indicates if the scene must clear the render buffer before rendering a frame
     */
    autoClear: boolean;
    /**
     * Gets or sets a boolean that indicates if the scene must clear the depth and stencil buffers before rendering a frame
     */
    autoClearDepthAndStencil: boolean;
    private _clearColor;
    /**
     * Observable triggered when the performance priority is changed
     */
    onClearColorChangedObservable: Observable<Color4>;
    /**
     * Defines the color used to clear the render buffer (Default is (0.2, 0.2, 0.3, 1.0))
     */
    get clearColor(): Color4;
    set clearColor(value: Color4);
    /**
     * Defines the color used to simulate the ambient color (Default is (0, 0, 0))
     */
    ambientColor: Color3;
    /**
     * This is use to store the default BRDF lookup for PBR materials in your scene.
     * It should only be one of the following (if not the default embedded one):
     * * For uncorrelated BRDF (pbr.brdf.useEnergyConservation = false and pbr.brdf.useSmithVisibilityHeightCorrelated = false) : https://assets.babylonjs.com/environments/uncorrelatedBRDF.dds
     * * For correlated BRDF (pbr.brdf.useEnergyConservation = false and pbr.brdf.useSmithVisibilityHeightCorrelated = true) : https://assets.babylonjs.com/environments/correlatedBRDF.dds
     * * For correlated multi scattering BRDF (pbr.brdf.useEnergyConservation = true and pbr.brdf.useSmithVisibilityHeightCorrelated = true) : https://assets.babylonjs.com/environments/correlatedMSBRDF.dds
     * The material properties need to be setup according to the type of texture in use.
     */
    environmentBRDFTexture: BaseTexture;
    /**
     * This stores the brdf lookup for the fuzz layer of PBR materials in your scene.
     */
    environmentFuzzBRDFTexture: BaseTexture;
    /**
     * Intensity of the environment (i.e. all indirect lighting) in all pbr material.
     * This dims or reinforces the indirect lighting overall (reflection and diffuse).
     * As in the majority of the scene they are the same (exception for multi room and so on),
     * this is easier to reference from here than from all the materials.
     * Note that this is more of a debugging parameter and is not physically accurate.
     * If you want to modify the intensity of the IBL texture, you should update iblIntensity instead.
     */
    environmentIntensity: number;
    /**
     * Overall intensity of the IBL texture.
     * This value is multiplied with the reflectionTexture.level value to calculate the final IBL intensity.
     */
    iblIntensity: number;
    /** @internal */
    protected _imageProcessingConfiguration: ImageProcessingConfiguration;
    /**
     * Default image processing configuration used either in the rendering
     * Forward main pass or through the imageProcessingPostProcess if present.
     * As in the majority of the scene they are the same (exception for multi camera),
     * this is easier to reference from here than from all the materials and post process.
     *
     * No setter as we it is a shared configuration, you can set the values instead.
     */
    get imageProcessingConfiguration(): ImageProcessingConfiguration;
    private _performancePriority;
    /**
     * Observable triggered when the performance priority is changed
     */
    onScenePerformancePriorityChangedObservable: Observable<ScenePerformancePriority>;
    /**
     * Gets or sets a value indicating how to treat performance relatively to ease of use and backward compatibility
     */
    get performancePriority(): ScenePerformancePriority;
    set performancePriority(value: ScenePerformancePriority);
    private _forceWireframe;
    /**
     * Gets or sets a boolean indicating if all rendering must be done in wireframe
     */
    set forceWireframe(value: boolean);
    get forceWireframe(): boolean;
    private _skipFrustumClipping;
    /**
     * Gets or sets a boolean indicating if we should skip the frustum clipping part of the active meshes selection
     */
    set skipFrustumClipping(value: boolean);
    get skipFrustumClipping(): boolean;
    private _forcePointsCloud;
    /**
     * Gets or sets a boolean indicating if all rendering must be done in point cloud
     */
    set forcePointsCloud(value: boolean);
    get forcePointsCloud(): boolean;
    /**
     * Gets or sets the active clipplane 1
     */
    clipPlane: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 2
     */
    clipPlane2: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 3
     */
    clipPlane3: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 4
     */
    clipPlane4: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 5
     */
    clipPlane5: Nullable<Plane>;
    /**
     * Gets or sets the active clipplane 6
     */
    clipPlane6: Nullable<Plane>;
    /**
     * Gets the list of root nodes (ie. nodes with no parent)
     */
    rootNodes: Node[];
    /** All of the cameras added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras
     */
    cameras: Camera[];
    /**
     * All of the lights added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/lights/lights_introduction
     */
    lights: Light[];
    /**
     * All of the (abstract) meshes added to this scene
     */
    meshes: AbstractMesh[];
    /**
     * The list of skeletons added to the scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/bonesSkeletons
     */
    skeletons: Skeleton[];
    /**
     * All of the particle systems added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/particles/particle_system/particle_system_intro
     */
    particleSystems: IParticleSystem[];
    /**
     * Gets the current delta time used by animation engine
     */
    deltaTime: number;
    /**
     * Gets a list of Animations associated with the scene
     */
    animations: Animation[];
    /**
     * All of the animation groups added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/groupAnimations
     */
    animationGroups: AnimationGroup[];
    /**
     * All of the multi-materials added to this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/multiMaterials
     */
    multiMaterials: MultiMaterial[];
    /**
     * All of the materials added to this scene
     * In the context of a Scene, it is not supposed to be modified manually.
     * Any addition or removal should be done using the addMaterial and removeMaterial Scene methods.
     * Note also that the order of the Material within the array is not significant and might change.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/materials_introduction
     */
    materials: Material[];
    /**
     * The list of morph target managers added to the scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/dynamicMeshMorph
     */
    morphTargetManagers: MorphTargetManager[];
    /**
     * The list of geometries used in the scene.
     */
    geometries: Geometry[];
    /**
     * All of the transform nodes added to this scene
     * In the context of a Scene, it is not supposed to be modified manually.
     * Any addition or removal should be done using the addTransformNode and removeTransformNode Scene methods.
     * Note also that the order of the TransformNode within the array is not significant and might change.
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/transforms/parent_pivot/transform_node
     */
    transformNodes: TransformNode[];
    /**
     * ActionManagers available on the scene.
     */
    actionManagers: AbstractActionManager[];
    /**
     * Object renderers available on the scene.
     */
    objectRenderers: ObjectRenderer[];
    /**
     * Textures to keep.
     */
    textures: BaseTexture[];
    /** @internal */
    protected _environmentTexture: Nullable<BaseTexture>;
    /**
     * Texture used in all pbr material as the reflection texture.
     * As in the majority of the scene they are the same (exception for multi room and so on),
     * this is easier to reference from here than from all the materials.
     */
    get environmentTexture(): Nullable<BaseTexture>;
    /**
     * Texture used in all pbr material as the reflection texture.
     * As in the majority of the scene they are the same (exception for multi room and so on),
     * this is easier to set here than in all the materials.
     */
    set environmentTexture(value: Nullable<BaseTexture>);
    /**
     * The list of postprocesses added to the scene
     */
    postProcesses: PostProcess[];
    /**
     * The list of effect layers (highlights/glow) added to the scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/highlightLayer
     * @see https://doc.babylonjs.com/features/featuresDeepDive/mesh/glowLayer
     */
    effectLayers: Array<EffectLayer>;
    /**
     * The list of sounds used in the scene.
     * @deprecated please use AudioEngineV2 instead
     */
    sounds: Nullable<Array<Sound>>;
    /**
     * The list of layers (background and foreground) of the scene
     */
    layers: Array<Layer>;
    /**
     * The list of lens flare system added to the scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/lenseFlare
     */
    lensFlareSystems: Array<LensFlareSystem>;
    /**
     * The list of procedural textures added to the scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/proceduralTextures
     */
    proceduralTextures: Array<ProceduralTexture>;
    /**
     * @returns all meshes, lights, cameras, transformNodes and bones
     */
    getNodes(): Array<Node>;
    /**
     * Gets or sets a boolean indicating if animations are enabled
     */
    animationsEnabled: boolean;
    private _animationPropertiesOverride;
    /**
     * Gets or sets the animation properties override
     */
    get animationPropertiesOverride(): Nullable<AnimationPropertiesOverride>;
    set animationPropertiesOverride(value: Nullable<AnimationPropertiesOverride>);
    /**
     * Gets or sets a boolean indicating if a constant deltatime has to be used
     * This is mostly useful for testing purposes when you do not want the animations to scale with the framerate
     */
    useConstantAnimationDeltaTime: boolean;
    /**
     * Gets or sets a boolean indicating if the scene must keep the meshUnderPointer property updated
     * Please note that it requires to run a ray cast through the scene on every frame
     */
    constantlyUpdateMeshUnderPointer: boolean;
    /**
     * Defines the HTML cursor to use when hovering over interactive elements
     */
    hoverCursor: string;
    /**
     * Defines the HTML default cursor to use (empty by default)
     */
    defaultCursor: string;
    /**
     * Defines whether cursors are handled by the scene.
     */
    doNotHandleCursors: boolean;
    /**
     * This is used to call preventDefault() on pointer down
     * in order to block unwanted artifacts like system double clicks
     */
    preventDefaultOnPointerDown: boolean;
    /**
     * This is used to call preventDefault() on pointer up
     * in order to block unwanted artifacts like system double clicks
     */
    preventDefaultOnPointerUp: boolean;
    /**
     * Gets or sets user defined metadata
     */
    metadata: any;
    /**
     * For internal use only. Please do not use.
     */
    reservedDataStore: any;
    /**
     * Gets the name of the plugin used to load this scene (null by default)
     */
    loadingPluginName: string;
    /**
     * Use this array to add regular expressions used to disable offline support for specific urls
     */
    disableOfflineSupportExceptionRules: RegExp[];
    /**
     * An event triggered when the scene is disposed.
     */
    onDisposeObservable: Observable<Scene>;
    private _onDisposeObserver;
    /** Sets a function to be executed when this scene is disposed. */
    set onDispose(callback: () => void);
    /**
     * An event triggered before rendering the scene (right after animations and physics)
     */
    onBeforeRenderObservable: Observable<Scene>;
    private _onBeforeRenderObserver;
    /** Sets a function to be executed before rendering this scene */
    set beforeRender(callback: Nullable<() => void>);
    /**
     * An event triggered after rendering the scene
     */
    onAfterRenderObservable: Observable<Scene>;
    /**
     * An event triggered after rendering the scene for an active camera (When scene.render is called this will be called after each camera)
     * This is triggered for each "sub" camera in a Camera Rig unlike onAfterCameraRenderObservable
     */
    onAfterRenderCameraObservable: Observable<Camera>;
    private _onAfterRenderObserver;
    /** Sets a function to be executed after rendering this scene */
    set afterRender(callback: Nullable<() => void>);
    /**
     * An event triggered before animating the scene
     */
    onBeforeAnimationsObservable: Observable<Scene>;
    /**
     * An event triggered after animations processing
     */
    onAfterAnimationsObservable: Observable<Scene>;
    /**
     * An event triggered before draw calls are ready to be sent
     */
    onBeforeDrawPhaseObservable: Observable<Scene>;
    /**
     * An event triggered after draw calls have been sent
     */
    onAfterDrawPhaseObservable: Observable<Scene>;
    /**
     * An event triggered when the scene is ready
     */
    onReadyObservable: Observable<Scene>;
    /**
     * An event triggered before rendering a camera
     */
    onBeforeCameraRenderObservable: Observable<Camera>;
    private _onBeforeCameraRenderObserver;
    /** Sets a function to be executed before rendering a camera*/
    set beforeCameraRender(callback: () => void);
    /**
     * An event triggered after rendering a camera
     * This is triggered for the full rig Camera only unlike onAfterRenderCameraObservable
     */
    onAfterCameraRenderObservable: Observable<Camera>;
    private _onAfterCameraRenderObserver;
    /** Sets a function to be executed after rendering a camera*/
    set afterCameraRender(callback: () => void);
    /**
     * An event triggered when active meshes evaluation is about to start
     */
    onBeforeActiveMeshesEvaluationObservable: Observable<Scene>;
    /**
     * An event triggered when active meshes evaluation is done
     */
    onAfterActiveMeshesEvaluationObservable: Observable<Scene>;
    /**
     * An event triggered when particles rendering is about to start
     * Note: This event can be trigger more than once per frame (because particles can be rendered by render target textures as well)
     */
    onBeforeParticlesRenderingObservable: Observable<Scene>;
    /**
     * An event triggered when particles rendering is done
     * Note: This event can be trigger more than once per frame (because particles can be rendered by render target textures as well)
     */
    onAfterParticlesRenderingObservable: Observable<Scene>;
    /**
     * An event triggered when SceneLoader.Append or SceneLoader.Load or SceneLoader.ImportMesh were successfully executed
     */
    onDataLoadedObservable: Observable<Scene>;
    /**
     * An event triggered when a camera is created
     */
    onNewCameraAddedObservable: Observable<Camera>;
    /**
     * An event triggered when a camera is removed
     */
    onCameraRemovedObservable: Observable<Camera>;
    /**
     * An event triggered when a light is created
     */
    onNewLightAddedObservable: Observable<Light>;
    /**
     * An event triggered when a light is removed
     */
    onLightRemovedObservable: Observable<Light>;
    /**
     * An event triggered when a geometry is created
     */
    onNewGeometryAddedObservable: Observable<Geometry>;
    /**
     * An event triggered when a geometry is removed
     */
    onGeometryRemovedObservable: Observable<Geometry>;
    /**
     * An event triggered when a transform node is created
     */
    onNewTransformNodeAddedObservable: Observable<TransformNode>;
    /**
     * An event triggered when a transform node is removed
     */
    onTransformNodeRemovedObservable: Observable<TransformNode>;
    /**
     * An event triggered when a mesh is created
     */
    onNewMeshAddedObservable: Observable<AbstractMesh>;
    /**
     * An event triggered when a mesh is removed
     */
    onMeshRemovedObservable: Observable<AbstractMesh>;
    /**
     * An event triggered when a skeleton is created
     */
    onNewSkeletonAddedObservable: Observable<Skeleton>;
    /**
     * An event triggered when a skeleton is removed
     */
    onSkeletonRemovedObservable: Observable<Skeleton>;
    /**
     * An event triggered when a particle system is created
     */
    onNewParticleSystemAddedObservable: Observable<IParticleSystem>;
    /**
     * An event triggered when a particle system is removed
     */
    onParticleSystemRemovedObservable: Observable<IParticleSystem>;
    /**
     * An event triggered when an animation group is created
     */
    onNewAnimationGroupAddedObservable: Observable<AnimationGroup>;
    /**
     * An event triggered when an animation group is removed
     */
    onAnimationGroupRemovedObservable: Observable<AnimationGroup>;
    /**
     * An event triggered when a material is created
     */
    onNewMaterialAddedObservable: Observable<Material>;
    /**
     * An event triggered when a multi material is created
     */
    onNewMultiMaterialAddedObservable: Observable<MultiMaterial>;
    /**
     * An event triggered when a material is removed
     */
    onMaterialRemovedObservable: Observable<Material>;
    /**
     * An event triggered when a multi material is removed
     */
    onMultiMaterialRemovedObservable: Observable<MultiMaterial>;
    /**
     * An event triggered when a texture is created
     */
    onNewTextureAddedObservable: Observable<BaseTexture>;
    /**
     * An event triggered when a texture is removed
     */
    onTextureRemovedObservable: Observable<BaseTexture>;
    /**
     * An event triggered when a frame graph is created
     */
    onNewFrameGraphAddedObservable: Observable<FrameGraph>;
    /**
     * An event triggered when a frame graph is removed
     */
    onFrameGraphRemovedObservable: Observable<FrameGraph>;
    /**
     * An event triggered when an object renderer is created
     */
    onNewObjectRendererAddedObservable: Observable<ObjectRenderer>;
    /**
     * An event triggered when an object renderer is removed
     */
    onObjectRendererRemovedObservable: Observable<ObjectRenderer>;
    /**
     * An event triggered when a post process is created
     */
    onNewPostProcessAddedObservable: Observable<PostProcess>;
    /**
     * An event triggered when a post process is removed
     */
    onPostProcessRemovedObservable: Observable<PostProcess>;
    /**
     * An event triggered when an effect layer is created
     */
    onNewEffectLayerAddedObservable: Observable<EffectLayer>;
    /**
     * An event triggered when an effect layer is removed
     */
    onEffectLayerRemovedObservable: Observable<EffectLayer>;
    /**
     * An event triggered when render targets are about to be rendered
     * Can happen multiple times per frame.
     */
    onBeforeRenderTargetsRenderObservable: Observable<Scene>;
    /**
     * An event triggered when render targets were rendered.
     * Can happen multiple times per frame.
     */
    onAfterRenderTargetsRenderObservable: Observable<Scene>;
    /**
     * An event triggered before calculating deterministic simulation step
     */
    onBeforeStepObservable: Observable<Scene>;
    /**
     * An event triggered after calculating deterministic simulation step
     */
    onAfterStepObservable: Observable<Scene>;
    /**
     * An event triggered when the activeCamera property is updated
     */
    onActiveCameraChanged: Observable<Scene>;
    /**
     * An event triggered when the activeCameras property is updated
     */
    onActiveCamerasChanged: Observable<Scene>;
    /**
     * This Observable will be triggered before rendering each renderingGroup of each rendered camera.
     * The RenderingGroupInfo class contains all the information about the context in which the observable is called
     * If you wish to register an Observer only for a given set of renderingGroup, use the mask with a combination of the renderingGroup index elevated to the power of two (1 for renderingGroup 0, 2 for renderingrOup1, 4 for 2 and 8 for 3)
     */
    onBeforeRenderingGroupObservable: Observable<RenderingGroupInfo>;
    /**
     * This Observable will be triggered after rendering each renderingGroup of each rendered camera.
     * The RenderingGroupInfo class contains all the information about the context in which the observable is called
     * If you wish to register an Observer only for a given set of renderingGroup, use the mask with a combination of the renderingGroup index elevated to the power of two (1 for renderingGroup 0, 2 for renderingrOup1, 4 for 2 and 8 for 3)
     */
    onAfterRenderingGroupObservable: Observable<RenderingGroupInfo>;
    /**
     * This Observable will when a mesh has been imported into the scene.
     */
    onMeshImportedObservable: Observable<AbstractMesh>;
    /**
     * This Observable will when an animation file has been imported into the scene.
     */
    onAnimationFileImportedObservable: Observable<Scene>;
    /**
     * An event triggered when the environmentTexture is changed.
     */
    onEnvironmentTextureChangedObservable: Observable<Nullable<BaseTexture>>;
    /**
     * An event triggered when the state of mesh under pointer, for a specific pointerId, changes.
     */
    onMeshUnderPointerUpdatedObservable: Observable<{
        mesh: Nullable<AbstractMesh>;
        pointerId: number;
    }>;
    /**
     * Gets or sets a user defined funtion to select LOD from a mesh and a camera.
     * By default this function is undefined and Babylon.js will select LOD based on distance to camera
     */
    customLODSelector: (mesh: AbstractMesh, camera: Camera) => Nullable<AbstractMesh>;
    /** @internal */
    _registeredForLateAnimationBindings: SmartArrayNoDuplicate<any>;
    private _pointerPickingConfiguration;
    /**
     * Gets or sets a predicate used to select candidate meshes for a pointer down event
     */
    get pointerDownPredicate(): (Mesh: AbstractMesh) => boolean;
    set pointerDownPredicate(value: (Mesh: AbstractMesh) => boolean);
    /**
     * Gets or sets a predicate used to select candidate meshes for a pointer up event
     */
    get pointerUpPredicate(): (Mesh: AbstractMesh) => boolean;
    set pointerUpPredicate(value: (Mesh: AbstractMesh) => boolean);
    /**
     * Gets or sets a predicate used to select candidate meshes for a pointer move event
     */
    get pointerMovePredicate(): (Mesh: AbstractMesh) => boolean;
    set pointerMovePredicate(value: (Mesh: AbstractMesh) => boolean);
    /**
     * Gets or sets a predicate used to select candidate meshes for a pointer down event
     */
    get pointerDownFastCheck(): boolean;
    set pointerDownFastCheck(value: boolean);
    /**
     * Gets or sets a predicate used to select candidate meshes for a pointer up event
     */
    get pointerUpFastCheck(): boolean;
    set pointerUpFastCheck(value: boolean);
    /**
     * Gets or sets a predicate used to select candidate meshes for a pointer move event
     */
    get pointerMoveFastCheck(): boolean;
    set pointerMoveFastCheck(value: boolean);
    /**
     * Gets or sets a boolean indicating if the user want to entirely skip the picking phase when a pointer move event occurs.
     */
    get skipPointerMovePicking(): boolean;
    set skipPointerMovePicking(value: boolean);
    /**
     * Gets or sets a boolean indicating if the user want to entirely skip the picking phase when a pointer down event occurs.
     */
    get skipPointerDownPicking(): boolean;
    set skipPointerDownPicking(value: boolean);
    /**
     * Gets or sets a boolean indicating if the user want to entirely skip the picking phase when a pointer up event occurs.  Off by default.
     */
    get skipPointerUpPicking(): boolean;
    set skipPointerUpPicking(value: boolean);
    /** Callback called when a pointer move is detected */
    onPointerMove?: (evt: IPointerEvent, pickInfo: PickingInfo, type: PointerEventTypes) => void;
    /** Callback called when a pointer down is detected  */
    onPointerDown?: (evt: IPointerEvent, pickInfo: PickingInfo, type: PointerEventTypes) => void;
    /** Callback called when a pointer up is detected  */
    onPointerUp?: (evt: IPointerEvent, pickInfo: Nullable<PickingInfo>, type: PointerEventTypes) => void;
    /** Callback called when a pointer pick is detected */
    onPointerPick?: (evt: IPointerEvent, pickInfo: PickingInfo) => void;
    /**
     * Gets or sets a predicate used to select candidate faces for a pointer move event
     */
    pointerMoveTrianglePredicate: ((p0: Vector3, p1: Vector3, p2: Vector3, ray: Ray) => boolean) | undefined;
    /**
     * Gets or sets a predicate used to select candidate faces for a pointer down event
     */
    pointerDownTrianglePredicate: ((p0: Vector3, p1: Vector3, p2: Vector3, ray: Ray) => boolean) | undefined;
    /**
     * Gets or sets a predicate used to select candidate faces for a pointer up event
     */
    pointerUpTrianglePredicate: ((p0: Vector3, p1: Vector3, p2: Vector3, ray: Ray) => boolean) | undefined;
    /**
     * This observable event is triggered when any ponter event is triggered. It is registered during Scene.attachControl() and it is called BEFORE the 3D engine process anything (mesh/sprite picking for instance).
     * You have the possibility to skip the process and the call to onPointerObservable by setting PointerInfoPre.skipOnPointerObservable to true
     */
    onPrePointerObservable: Observable<PointerInfoPre>;
    /**
     * Observable event triggered each time an input event is received from the rendering canvas
     */
    onPointerObservable: Observable<PointerInfo>;
    /**
     * Gets the pointer coordinates without any translation (ie. straight out of the pointer event)
     */
    get unTranslatedPointer(): Vector2;
    /**
     * Gets or sets the distance in pixel that you have to move to prevent some events. Default is 10 pixels
     */
    static get DragMovementThreshold(): number;
    static set DragMovementThreshold(value: number);
    /**
     * Time in milliseconds to wait to raise long press events if button is still pressed. Default is 500 ms
     */
    static get LongPressDelay(): number;
    static set LongPressDelay(value: number);
    /**
     * Time in milliseconds to wait to raise long press events if button is still pressed. Default is 300 ms
     */
    static get DoubleClickDelay(): number;
    static set DoubleClickDelay(value: number);
    /** If you need to check double click without raising a single click at first click, enable this flag */
    static get ExclusiveDoubleClickMode(): boolean;
    static set ExclusiveDoubleClickMode(value: boolean);
    /**
     * Gets the current eye position in order of forcedViewPosition, activeCamera world position, Vector3.ZeroReadOnly
     */
    private get _eyePosition();
    /**
     * Bind the current view position to an effect.
     * @param effect The effect to be bound
     * @param variableName name of the shader variable that will hold the eye position
     * @param isVector3 true to indicates that variableName is a Vector3 and not a Vector4
     * @returns the computed eye position in a temp vector, caller can copy values as needed
     */
    bindEyePosition(effect: Nullable<Effect>, variableName?: string, isVector3?: boolean): Vector4;
    /**
     * Update the scene ubo before it can be used in rendering processing
     * @returns the scene UniformBuffer
     */
    finalizeSceneUbo(): UniformBuffer;
    /** @internal */
    _mirroredCameraPosition: Nullable<Vector3>;
    /**
     * This observable event is triggered when any keyboard event si raised and registered during Scene.attachControl()
     * You have the possibility to skip the process and the call to onKeyboardObservable by setting KeyboardInfoPre.skipOnPointerObservable to true
     */
    onPreKeyboardObservable: Observable<KeyboardInfoPre>;
    /**
     * Observable event triggered each time an keyboard event is received from the hosting window
     */
    onKeyboardObservable: Observable<KeyboardInfo>;
    private _useRightHandedSystem;
    /**
     * Gets or sets a boolean indicating if the scene must use right-handed coordinates system
     */
    set useRightHandedSystem(value: boolean);
    get useRightHandedSystem(): boolean;
    private _timeAccumulator;
    private _currentStepId;
    private _currentInternalStep;
    /**
     * Sets the step Id used by deterministic lock step
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
     * @param newStepId defines the step Id
     */
    setStepId(newStepId: number): void;
    /**
     * Gets the step Id used by deterministic lock step
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
     * @returns the step Id
     */
    getStepId(): number;
    /**
     * Gets the internal step used by deterministic lock step
     * @see https://doc.babylonjs.com/features/featuresDeepDive/animation/advanced_animations#deterministic-lockstep
     * @returns the internal step
     */
    getInternalStep(): number;
    private _fogEnabled;
    /**
     * Gets or sets a boolean indicating if fog is enabled on this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/environment_introduction#fog
     * (Default is true)
     */
    set fogEnabled(value: boolean);
    get fogEnabled(): boolean;
    private _fogMode;
    /**
     * Gets or sets the fog mode to use
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/environment_introduction#fog
     * | mode | value |
     * | --- | --- |
     * | FOGMODE_NONE | 0 |
     * | FOGMODE_EXP | 1 |
     * | FOGMODE_EXP2 | 2 |
     * | FOGMODE_LINEAR | 3 |
     */
    set fogMode(value: number);
    get fogMode(): number;
    /**
     * Gets or sets the fog color to use
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/environment_introduction#fog
     * (Default is Color3(0.2, 0.2, 0.3))
     */
    fogColor: Color3;
    /**
     * Gets or sets the fog density to use
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/environment_introduction#fog
     * (Default is 0.1)
     */
    fogDensity: number;
    /**
     * Gets or sets the fog start distance to use
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/environment_introduction#fog
     * (Default is 0)
     */
    fogStart: number;
    /**
     * Gets or sets the fog end distance to use
     * @see https://doc.babylonjs.com/features/featuresDeepDive/environment/environment_introduction#fog
     * (Default is 1000)
     */
    fogEnd: number;
    /**
     * Flag indicating that the frame buffer binding is handled by another component
     */
    get prePass(): boolean;
    /**
     * Flag indicating if we need to store previous matrices when rendering
     */
    needsPreviousWorldMatrices: boolean;
    private _shadowsEnabled;
    /**
     * Gets or sets a boolean indicating if shadows are enabled on this scene
     */
    set shadowsEnabled(value: boolean);
    get shadowsEnabled(): boolean;
    private _lightsEnabled;
    /**
     * Gets or sets a boolean indicating if lights are enabled on this scene
     */
    set lightsEnabled(value: boolean);
    get lightsEnabled(): boolean;
    private _activeCameras;
    private _unObserveActiveCameras;
    /** All of the active cameras added to this scene. */
    get activeCameras(): Nullable<Camera[]>;
    set activeCameras(cameras: Nullable<Camera[]>);
    /** @internal */
    _activeCamera: Nullable<Camera>;
    /** Gets or sets the current active camera */
    get activeCamera(): Nullable<Camera>;
    set activeCamera(value: Nullable<Camera>);
    /** @internal */
    get _hasDefaultMaterial(): boolean;
    private _defaultMaterial;
    /** The default material used on meshes when no material is affected */
    get defaultMaterial(): Material;
    /** The default material used on meshes when no material is affected */
    set defaultMaterial(value: Material);
    private _texturesEnabled;
    /**
     * Gets or sets a boolean indicating if textures are enabled on this scene
     */
    set texturesEnabled(value: boolean);
    get texturesEnabled(): boolean;
    private _frameGraph;
    private _currentCustomRenderFunction?;
    /**
     * Gets or sets the frame graph used to render the scene. If set, the scene will use the frame graph to render the scene instead of the default render loop.
     */
    get frameGraph(): Nullable<FrameGraph>;
    set frameGraph(value: Nullable<FrameGraph>);
    /**
     * List of frame graphs associated with the scene
     */
    frameGraphs: FrameGraph[];
    /**
     * Gets or sets a boolean indicating if physic engines are enabled on this scene
     */
    physicsEnabled: boolean;
    /**
     * Gets or sets a boolean indicating if particles are enabled on this scene
     */
    particlesEnabled: boolean;
    /**
     * Gets or sets a boolean indicating if sprites are enabled on this scene
     */
    spritesEnabled: boolean;
    private _skeletonsEnabled;
    /**
     * Gets or sets a boolean indicating if skeletons are enabled on this scene
     */
    set skeletonsEnabled(value: boolean);
    get skeletonsEnabled(): boolean;
    /**
     * Gets or sets a boolean indicating if lens flares are enabled on this scene
     */
    lensFlaresEnabled: boolean;
    /**
     * Gets or sets a boolean indicating if collisions are enabled on this scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_collisions
     */
    collisionsEnabled: boolean;
    private _collisionCoordinator;
    /** @internal */
    get collisionCoordinator(): ICollisionCoordinator;
    /**
     * Defines the gravity applied to this scene (used only for collisions)
     * @see https://doc.babylonjs.com/features/featuresDeepDive/cameras/camera_collisions
     */
    gravity: Vector3;
    /**
     * Gets or sets a boolean indicating if postprocesses are enabled on this scene
     */
    postProcessesEnabled: boolean;
    /**
     * Gets the current postprocess manager
     */
    postProcessManager: PostProcessManager;
    /**
     * Gets or sets a boolean indicating if render targets are enabled on this scene
     */
    renderTargetsEnabled: boolean;
    /**
     * Gets or sets a boolean indicating if next render targets must be dumped as image for debugging purposes
     * We recommend not using it and instead rely on Spector.js: http://spector.babylonjs.com
     */
    dumpNextRenderTargets: boolean;
    /**
     * The list of user defined render targets added to the scene
     */
    customRenderTargets: RenderTargetTexture[];
    /**
     * Defines if texture loading must be delayed
     * If true, textures will only be loaded when they need to be rendered
     */
    useDelayedTextureLoading: boolean;
    /**
     * Gets the list of meshes imported to the scene through SceneLoader
     */
    importedMeshesFiles: string[];
    /**
     * Gets or sets a boolean indicating if probes are enabled on this scene
     */
    probesEnabled: boolean;
    /**
     * Gets or sets the current offline provider to use to store scene data
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimizeCached
     */
    offlineProvider: IOfflineProvider;
    /**
     * Gets or sets the action manager associated with the scene
     * @see https://doc.babylonjs.com/features/featuresDeepDive/events/actions
     */
    actionManager: AbstractActionManager;
    private _meshesForIntersections;
    /**
     * Gets or sets a boolean indicating if procedural textures are enabled on this scene
     */
    proceduralTexturesEnabled: boolean;
    private _engine;
    private _totalVertices;
    /** @internal */
    _activeIndices: PerfCounter;
    /** @internal */
    _activeParticles: PerfCounter;
    /** @internal */
    _activeBones: PerfCounter;
    private _animationRatio;
    /** @internal */
    _animationTimeLast: number;
    /** @internal */
    _animationTime: number;
    /**
     * Gets or sets a general scale for animation speed
     * @see https://www.babylonjs-playground.com/#IBU2W7#3
     */
    animationTimeScale: number;
    /** @internal */
    _cachedMaterial: Nullable<Material>;
    /** @internal */
    _cachedEffect: Nullable<Effect>;
    /** @internal */
    _cachedVisibility: Nullable<number>;
    private _renderId;
    private _frameId;
    private _executeWhenReadyTimeoutId;
    /** @internal */
    _intermediateRendering: boolean;
    private _defaultFrameBufferCleared;
    private _viewUpdateFlag;
    private _projectionUpdateFlag;
    /** @internal */
    _toBeDisposed: Nullable<IDisposable>[];
    private _activeRequests;
    /** @internal */
    _pendingData: any[];
    private _isDisposed;
    /**
     * Gets or sets a boolean indicating that all submeshes of active meshes must be rendered
     * Use this boolean to avoid computing frustum clipping on submeshes (This could help when you are CPU bound)
     */
    dispatchAllSubMeshesOfActiveMeshes: boolean;
    private _activeMeshes;
    private _processedMaterials;
    private _renderTargets;
    private _materialsRenderTargets;
    /** @internal */
    _activeParticleSystems: SmartArray<IParticleSystem>;
    private _activeSkeletons;
    private _softwareSkinnedMeshes;
    private _renderingManager;
    /**
     * Gets the scene's rendering manager
     */
    get renderingManager(): RenderingManager;
    /** @internal */
    _activeAnimatables: Animatable[];
    private _transformMatrix;
    private _sceneUbo;
    /** @internal */
    _viewMatrix: Matrix;
    /** @internal */
    _projectionMatrix: Matrix;
    /** @internal */
    _forcedViewPosition: Nullable<Vector3>;
    /** @internal */
    _frustumPlanes: Plane[];
    /**
     * Gets the list of frustum planes (built from the active camera)
     */
    get frustumPlanes(): Plane[];
    /**
     * Gets or sets a boolean indicating if lights must be sorted by priority (off by default)
     * This is useful if there are more lights that the maximum simulteanous authorized
     */
    requireLightSorting: boolean;
    /** @internal */
    readonly useMaterialMeshMap: boolean;
    /** @internal */
    readonly useClonedMeshMap: boolean;
    private _externalData;
    private _uid;
    /**
     * @internal
     * Backing store of defined scene components.
     */
    _components: ISceneComponent[];
    /**
     * @internal
     * Backing store of defined scene components.
     */
    _serializableComponents: ISceneSerializableComponent[];
    /**
     * List of components to register on the next registration step.
     */
    private _transientComponents;
    /**
     * Registers the transient components if needed.
     */
    private _registerTransientComponents;
    /**
     * @internal
     * Add a component to the scene.
     * Note that the ccomponent could be registered on th next frame if this is called after
     * the register component stage.
     * @param component Defines the component to add to the scene
     */
    _addComponent(component: ISceneComponent): void;
    /**
     * @internal
     * Gets a component from the scene.
     * @param name defines the name of the component to retrieve
     * @returns the component or null if not present
     */
    _getComponent(name: string): Nullable<ISceneComponent>;
    /**
     * @internal
     * Defines the actions happening before camera updates.
     */
    _beforeCameraUpdateStage: Stage<SimpleStageAction>;
    /**
     * @internal
     * Defines the actions happening before clear the canvas.
     */
    _beforeClearStage: Stage<SimpleStageAction>;
    /**
     * @internal
     * Defines the actions happening before clear the canvas.
     */
    _beforeRenderTargetClearStage: Stage<RenderTargetStageAction>;
    /**
     * @internal
     * Defines the actions when collecting render targets for the frame.
     */
    _gatherRenderTargetsStage: Stage<RenderTargetsStageAction>;
    /**
     * @internal
     * Defines the actions happening for one camera in the frame.
     */
    _gatherActiveCameraRenderTargetsStage: Stage<RenderTargetsStageAction>;
    /**
     * @internal
     * Defines the actions happening during the per mesh ready checks.
     */
    _isReadyForMeshStage: Stage<MeshStageAction>;
    /**
     * @internal
     * Defines the actions happening before evaluate active mesh checks.
     */
    _beforeEvaluateActiveMeshStage: Stage<SimpleStageAction>;
    /**
     * @internal
     * Defines the actions happening during the evaluate sub mesh checks.
     */
    _evaluateSubMeshStage: Stage<EvaluateSubMeshStageAction>;
    /**
     * @internal
     * Defines the actions happening during the active mesh stage.
     */
    _preActiveMeshStage: Stage<PreActiveMeshStageAction>;
    /**
     * @internal
     * Defines the actions happening during the per camera render target step.
     */
    _cameraDrawRenderTargetStage: Stage<CameraStageFrameBufferAction>;
    /**
     * @internal
     * Defines the actions happening just before the active camera is drawing.
     */
    _beforeCameraDrawStage: Stage<CameraStageAction>;
    /**
     * @internal
     * Defines the actions happening just before a render target is drawing.
     */
    _beforeRenderTargetDrawStage: Stage<RenderTargetStageAction>;
    /**
     * @internal
     * Defines the actions happening just before a rendering group is drawing.
     */
    _beforeRenderingGroupDrawStage: Stage<RenderingGroupStageAction>;
    /**
     * @internal
     * Defines the actions happening just before a mesh is drawing.
     */
    _beforeRenderingMeshStage: Stage<RenderingMeshStageAction>;
    /**
     * @internal
     * Defines the actions happening just after a mesh has been drawn.
     */
    _afterRenderingMeshStage: Stage<RenderingMeshStageAction>;
    /**
     * @internal
     * Defines the actions happening just after a rendering group has been drawn.
     */
    _afterRenderingGroupDrawStage: Stage<RenderingGroupStageAction>;
    /**
     * @internal
     * Defines the actions happening just after the active camera has been drawn.
     */
    _afterCameraDrawStage: Stage<CameraStageAction>;
    /**
     * @internal
     * Defines the actions happening just after the post processing
     */
    _afterCameraPostProcessStage: Stage<CameraStageAction>;
    /**
     * @internal
     * Defines the actions happening just after a render target has been drawn.
     */
    _afterRenderTargetDrawStage: Stage<RenderTargetStageAction>;
    /**
     * Defines the actions happening just after the post processing on a render target
     */
    _afterRenderTargetPostProcessStage: Stage<RenderTargetStageAction>;
    /**
     * @internal
     * Defines the actions happening just after rendering all cameras and computing intersections.
     */
    _afterRenderStage: Stage<SimpleStageAction>;
    /**
     * @internal
     * Defines the actions happening when a pointer move event happens.
     */
    _pointerMoveStage: Stage<PointerMoveStageAction>;
    /**
     * @internal
     * Defines the actions happening when a pointer down event happens.
     */
    _pointerDownStage: Stage<PointerUpDownStageAction>;
    /**
     * @internal
     * Defines the actions happening when a pointer up event happens.
     */
    _pointerUpStage: Stage<PointerUpDownStageAction>;
    /**
     * an optional map from Geometry Id to Geometry index in the 'geometries' array
     */
    private _geometriesByUniqueId;
    private _uniqueId;
    /**
     * Gets the unique id of the scene
     */
    get uniqueId(): number;
    /**
     * Creates a new Scene
     * @param engine defines the engine to use to render this scene
     * @param options defines the scene options
     */
    constructor(engine: AbstractEngine, options?: SceneOptions);
    /**
     * Gets a string identifying the name of the class
     * @returns "Scene" string
     */
    getClassName(): string;
    private _defaultMeshCandidates;
    /**
     * @internal
     */
    _getDefaultMeshCandidates(): ISmartArrayLike<AbstractMesh>;
    private _defaultSubMeshCandidates;
    /**
     * @internal
     */
    _getDefaultSubMeshCandidates(mesh: AbstractMesh): ISmartArrayLike<SubMesh>;
    /**
     * Sets the default candidate providers for the scene.
     * This sets the getActiveMeshCandidates, getActiveSubMeshCandidates, getIntersectingSubMeshCandidates
     * and getCollidingSubMeshCandidates to their default function
     */
    setDefaultCandidateProviders(): void;
    /**
     * Gets the mesh that is currently under the pointer
     */
    get meshUnderPointer(): Nullable<AbstractMesh>;
    /**
     * Gets or sets the current on-screen X position of the pointer
     */
    get pointerX(): number;
    set pointerX(value: number);
    /**
     * Gets or sets the current on-screen Y position of the pointer
     */
    get pointerY(): number;
    set pointerY(value: number);
    /**
     * Gets the cached material (ie. the latest rendered one)
     * @returns the cached material
     */
    getCachedMaterial(): Nullable<Material>;
    /**
     * Gets the cached effect (ie. the latest rendered one)
     * @returns the cached effect
     */
    getCachedEffect(): Nullable<Effect>;
    /**
     * Gets the cached visibility state (ie. the latest rendered one)
     * @returns the cached visibility state
     */
    getCachedVisibility(): Nullable<number>;
    /**
     * Gets a boolean indicating if the current material / effect / visibility must be bind again
     * @param material defines the current material
     * @param effect defines the current effect
     * @param visibility defines the current visibility state
     * @returns true if one parameter is not cached
     */
    isCachedMaterialInvalid(material: Material, effect: Effect, visibility?: number): boolean;
    /**
     * Gets the engine associated with the scene
     * @returns an Engine
     */
    getEngine(): AbstractEngine;
    /**
     * Gets the total number of vertices rendered per frame
     * @returns the total number of vertices rendered per frame
     */
    getTotalVertices(): number;
    /**
     * Gets the performance counter for total vertices
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#instrumentation
     */
    get totalVerticesPerfCounter(): PerfCounter;
    /**
     * Gets the total number of active indices rendered per frame (You can deduce the number of rendered triangles by dividing this number by 3)
     * @returns the total number of active indices rendered per frame
     */
    getActiveIndices(): number;
    /**
     * Gets the performance counter for active indices
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#instrumentation
     */
    get totalActiveIndicesPerfCounter(): PerfCounter;
    /**
     * Gets the total number of active particles rendered per frame
     * @returns the total number of active particles rendered per frame
     */
    getActiveParticles(): number;
    /**
     * Gets the performance counter for active particles
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#instrumentation
     */
    get activeParticlesPerfCounter(): PerfCounter;
    /**
     * Gets the total number of active bones rendered per frame
     * @returns the total number of active bones rendered per frame
     */
    getActiveBones(): number;
    /**
     * Gets the performance counter for active bones
     * @see https://doc.babylonjs.com/features/featuresDeepDive/scene/optimize_your_scene#instrumentation
     */
    get activeBonesPerfCounter(): PerfCounter;
    /**
     * Gets the array of active meshes
     * @returns an array of AbstractMesh
     */
    getActiveMeshes(): SmartArray<AbstractMesh>;
    /**
     * Gets the animation ratio (which is 1.0 is the scene renders at 60fps and 2 if the scene renders at 30fps, etc.)
     * @returns a number
     */
    getAnimationRatio(): number;
    /**
     * Gets an unique Id for the current render phase
     * @returns a number
     */
    getRenderId(): number;
    /**
     * Gets an unique Id for the current frame
     * @returns a number
     */
    getFrameId(): number;
    /** Call this function if you want to manually increment the render Id*/
    incrementRenderId(): void;
    private _createUbo;
    /**
     * Use this method to simulate a pointer move on a mesh
     * The pickResult parameter can be obtained from a scene.pick or scene.pickWithRay
     * @param pickResult pickingInfo of the object wished to simulate pointer event on
     * @param pointerEventInit pointer event state to be used when simulating the pointer event (eg. pointer id for multitouch)
     * @returns the current scene
     */
    simulatePointerMove(pickResult: PickingInfo, pointerEventInit?: PointerEventInit): Scene;
    /**
     * Use this method to simulate a pointer down on a mesh
     * The pickResult parameter can be obtained from a scene.pick or scene.pickWithRay
     * @param pickResult pickingInfo of the object wished to simulate pointer event on
     * @param pointerEventInit pointer event state to be used when simulating the pointer event (eg. pointer id for multitouch)
     * @returns the current scene
     */
    simulatePointerDown(pickResult: PickingInfo, pointerEventInit?: PointerEventInit): Scene;
    /**
     * Use this method to simulate a pointer up on a mesh
     * The pickResult parameter can be obtained from a scene.pick or scene.pickWithRay
     * @param pickResult pickingInfo of the object wished to simulate pointer event on
     * @param pointerEventInit pointer event state to be used when simulating the pointer event (eg. pointer id for multitouch)
     * @param doubleTap indicates that the pointer up event should be considered as part of a double click (false by default)
     * @returns the current scene
     */
    simulatePointerUp(pickResult: PickingInfo, pointerEventInit?: PointerEventInit, doubleTap?: boolean): Scene;
    /**
     * Gets a boolean indicating if the current pointer event is captured (meaning that the scene has already handled the pointer down)
     * @param pointerId defines the pointer id to use in a multi-touch scenario (0 by default)
     * @returns true if the pointer was captured
     */
    isPointerCaptured(pointerId?: number): boolean;
    /**
     * Attach events to the canvas (To handle actionManagers triggers and raise onPointerMove, onPointerDown and onPointerUp
     * @param attachUp defines if you want to attach events to pointerup
     * @param attachDown defines if you want to attach events to pointerdown
     * @param attachMove defines if you want to attach events to pointermove
     */
    attachControl(attachUp?: boolean, attachDown?: boolean, attachMove?: boolean): void;
    /** Detaches all event handlers*/
    detachControl(): void;
    /**
     * This function will check if the scene can be rendered (textures are loaded, shaders are compiled)
     * Delay loaded resources are not taking in account
     * @param checkRenderTargets true to also check that the meshes rendered as part of a render target are ready (default: true)
     * @returns true if all required resources are ready
     */
    isReady(checkRenderTargets?: boolean): boolean;
    /** Resets all cached information relative to material (including effect and visibility) */
    resetCachedMaterial(): void;
    /**
     * Registers a function to be called before every frame render
     * @param func defines the function to register
     */
    registerBeforeRender(func: () => void): void;
    /**
     * Unregisters a function called before every frame render
     * @param func defines the function to unregister
     */
    unregisterBeforeRender(func: () => void): void;
    /**
     * Registers a function to be called after every frame render
     * @param func defines the function to register
     */
    registerAfterRender(func: () => void): void;
    /**
     * Unregisters a function called after every frame render
     * @param func defines the function to unregister
     */
    unregisterAfterRender(func: () => void): void;
    private _executeOnceBeforeRender;
    /**
     * The provided function will run before render once and will be disposed afterwards.
     * A timeout delay can be provided so that the function will be executed in N ms.
     * The timeout is using the browser's native setTimeout so time percision cannot be guaranteed.
     * @param func The function to be executed.
     * @param timeout optional delay in ms
     */
    executeOnceBeforeRender(func: () => void, timeout?: number): void;
    /**
     * This function can help adding any object to the list of data awaited to be ready in order to check for a complete scene loading.
     * @param data defines the object to wait for
     */
    addPendingData(data: any): void;
    /**
     * Remove a pending data from the loading list which has previously been added with addPendingData.
     * @param data defines the object to remove from the pending list
     */
    removePendingData(data: any): void;
    /**
     * Returns the number of items waiting to be loaded
     * @returns the number of items waiting to be loaded
     */
    getWaitingItemsCount(): number;
    /**
     * Returns a boolean indicating if the scene is still loading data
     */
    get isLoading(): boolean;
    /**
     * Registers a function to be executed when the scene is ready
     * @param func - the function to be executed
     * @param checkRenderTargets true to also check that the meshes rendered as part of a render target are ready (default: false)
     */
    executeWhenReady(func: () => void, checkRenderTargets?: boolean): void;
    /**
     * Returns a promise that resolves when the scene is ready
     * @param checkRenderTargets true to also check that the meshes rendered as part of a render target are ready (default: false)
     * @returns A promise that resolves when the scene is ready
     */
    whenReadyAsync(checkRenderTargets?: boolean): Promise<void>;
    /**
     * An event triggered when the scene ready checks has timed out.
     */
    onReadyTimeoutObservable: Observable<Scene>;
    /**
     * Duration in milliseconds to wait before triggering the onReadyTimeoutObservable event.
     */
    onReadyTimeoutDuration: number;
    private _timeoutChecksStartTime;
    private _clearReadynessChecksData;
    /**
     * @internal
     */
    _checkIsReady(checkRenderTargets?: boolean): void;
    /**
     * Gets all animatable attached to the scene
     */
    get animatables(): Animatable[];
    /**
     * Resets the last animation time frame.
     * Useful to override when animations start running when loading a scene for the first time.
     */
    resetLastAnimationTimeFrame(): void;
    /**
     * Gets the current view matrix
     * @returns a Matrix
     */
    getViewMatrix(): Matrix;
    /**
     * Gets the current projection matrix
     * @returns a Matrix
     */
    getProjectionMatrix(): Matrix;
    /**
     * Gets the current transform matrix
     * @returns a Matrix made of View * Projection
     */
    getTransformMatrix(): Matrix;
    /**
     * Sets the current transform matrix
     * @param viewL defines the View matrix to use
     * @param projectionL defines the Projection matrix to use
     * @param viewR defines the right View matrix to use (if provided)
     * @param projectionR defines the right Projection matrix to use (if provided)
     */
    setTransformMatrix(viewL: Matrix, projectionL: Matrix, viewR?: Matrix, projectionR?: Matrix): void;
    /**
     * Gets the uniform buffer used to store scene data
     * @returns a UniformBuffer
     */
    getSceneUniformBuffer(): UniformBuffer;
    /**
     * Creates a scene UBO
     * @param name name of the uniform buffer (optional, for debugging purpose only)
     * @param trackUBOsInFrame define if the UBOs should be tracked in the frame (default: undefined - will use the value from Engine._features.trackUbosInFrame)
     * @returns a new ubo
     */
    createSceneUniformBuffer(name?: string, trackUBOsInFrame?: boolean): UniformBuffer;
    /**
     * Sets the scene ubo
     * @param ubo the ubo to set for the scene
     */
    setSceneUniformBuffer(ubo: UniformBuffer): void;
    private _floatingOriginScene;
    /**
     * @experimental
     * True if floatingOriginMode was passed to engine or this scene creation otions.
     * This mode avoids floating point imprecision in huge coordinate system by offsetting uniform values before passing to shader, centering camera at origin and displacing rest of scene by camera position
     */
    get floatingOriginMode(): boolean;
    /**
     * @experimental
     * When floatingOriginMode is enabled, offset is equal to the eye position. Default to ZeroReadonly when mode is disabled.
     */
    get floatingOriginOffset(): Vector3;
    /**
     * Gets an unique (relatively to the current scene) Id
     * @returns an unique number for the scene
     */
    getUniqueId(): number;
    /**
     * Add a mesh to the list of scene's meshes
     * @param newMesh defines the mesh to add
     * @param recursive if all child meshes should also be added to the scene
     */
    addMesh(newMesh: AbstractMesh, recursive?: boolean): void;
    /**
     * Remove a mesh for the list of scene's meshes
     * @param toRemove defines the mesh to remove
     * @param recursive if all child meshes should also be removed from the scene
     * @returns the index where the mesh was in the mesh list
     */
    removeMesh(toRemove: AbstractMesh, recursive?: boolean): number;
    /**
     * Add a transform node to the list of scene's transform nodes
     * @param newTransformNode defines the transform node to add
     */
    addTransformNode(newTransformNode: TransformNode): void;
    /**
     * Remove a transform node for the list of scene's transform nodes
     * @param toRemove defines the transform node to remove
     * @returns the index where the transform node was in the transform node list
     */
    removeTransformNode(toRemove: TransformNode): number;
    /**
     * Remove a skeleton for the list of scene's skeletons
     * @param toRemove defines the skeleton to remove
     * @returns the index where the skeleton was in the skeleton list
     */
    removeSkeleton(toRemove: Skeleton): number;
    /**
     * Remove a morph target for the list of scene's morph targets
     * @param toRemove defines the morph target to remove
     * @returns the index where the morph target was in the morph target list
     */
    removeMorphTargetManager(toRemove: MorphTargetManager): number;
    /**
     * Remove a light for the list of scene's lights
     * @param toRemove defines the light to remove
     * @returns the index where the light was in the light list
     */
    removeLight(toRemove: Light): number;
    /**
     * Remove a camera for the list of scene's cameras
     * @param toRemove defines the camera to remove
     * @returns the index where the camera was in the camera list
     */
    removeCamera(toRemove: Camera): number;
    /**
     * Remove a particle system for the list of scene's particle systems
     * @param toRemove defines the particle system to remove
     * @returns the index where the particle system was in the particle system list
     */
    removeParticleSystem(toRemove: IParticleSystem): number;
    /**
     * Remove a animation for the list of scene's animations
     * @param toRemove defines the animation to remove
     * @returns the index where the animation was in the animation list
     */
    removeAnimation(toRemove: Animation): number;
    /**
     * Will stop the animation of the given target
     * @param target - the target
     * @param animationName - the name of the animation to stop (all animations will be stopped if both this and targetMask are empty)
     * @param targetMask - a function that determines if the animation should be stopped based on its target (all animations will be stopped if both this and animationName are empty)
     */
    stopAnimation(target: any, animationName?: string, targetMask?: (target: any) => boolean): void;
    /**
     * Removes the given animation group from this scene.
     * @param toRemove The animation group to remove
     * @returns The index of the removed animation group
     */
    removeAnimationGroup(toRemove: AnimationGroup): number;
    /**
     * Removes the given multi-material from this scene.
     * @param toRemove The multi-material to remove
     * @returns The index of the removed multi-material
     */
    removeMultiMaterial(toRemove: MultiMaterial): number;
    /**
     * Removes the given material from this scene.
     * @param toRemove The material to remove
     * @returns The index of the removed material
     */
    removeMaterial(toRemove: Material): number;
    /**
     * Removes the given action manager from this scene.
     * @deprecated
     * @param toRemove The action manager to remove
     * @returns The index of the removed action manager
     */
    removeActionManager(toRemove: AbstractActionManager): number;
    /**
     * Removes the given texture from this scene.
     * @param toRemove The texture to remove
     * @returns The index of the removed texture
     */
    removeTexture(toRemove: BaseTexture): number;
    /**
     * Removes the given frame graph from this scene.
     * @param toRemove The frame graph to remove
     * @returns The index of the removed frame graph
     */
    removeFrameGraph(toRemove: FrameGraph): number;
    /**
     * Removes the given object renderer from this scene.
     * @param toRemove The object renderer to remove
     * @returns The index of the removed object renderer
     */
    removeObjectRenderer(toRemove: ObjectRenderer): number;
    /**
     * Removes the given post-process from this scene.
     * @param toRemove The post-process to remove
     * @returns The index of the removed post-process
     */
    removePostProcess(toRemove: PostProcess): number;
    /**
     * Removes the given layer from this scene.
     * @param toRemove The layer to remove
     * @returns The index of the removed layer
     */
    removeEffectLayer(toRemove: EffectLayer): number;
    /**
     * Adds the given light to this scene
     * @param newLight The light to add
     */
    addLight(newLight: Light): void;
    /**
     * Sorts the list list based on light priorities
     */
    sortLightsByPriority(): void;
    /**
     * Adds the given camera to this scene
     * @param newCamera The camera to add
     */
    addCamera(newCamera: Camera): void;
    /**
     * Adds the given skeleton to this scene
     * @param newSkeleton The skeleton to add
     */
    addSkeleton(newSkeleton: Skeleton): void;
    /**
     * Adds the given particle system to this scene
     * @param newParticleSystem The particle system to add
     */
    addParticleSystem(newParticleSystem: IParticleSystem): void;
    /**
     * Adds the given animation to this scene
     * @param newAnimation The animation to add
     */
    addAnimation(newAnimation: Animation): void;
    /**
     * Adds the given animation group to this scene.
     * @param newAnimationGroup The animation group to add
     */
    addAnimationGroup(newAnimationGroup: AnimationGroup): void;
    /**
     * Adds the given multi-material to this scene
     * @param newMultiMaterial The multi-material to add
     */
    addMultiMaterial(newMultiMaterial: MultiMaterial): void;
    /**
     * Adds the given material to this scene
     * @param newMaterial The material to add
     */
    addMaterial(newMaterial: Material): void;
    /**
     * Adds the given morph target to this scene
     * @param newMorphTargetManager The morph target to add
     */
    addMorphTargetManager(newMorphTargetManager: MorphTargetManager): void;
    /**
     * Adds the given geometry to this scene
     * @param newGeometry The geometry to add
     */
    addGeometry(newGeometry: Geometry): void;
    /**
     * Adds the given action manager to this scene
     * @deprecated
     * @param newActionManager The action manager to add
     */
    addActionManager(newActionManager: AbstractActionManager): void;
    /**
     * Adds the given texture to this scene.
     * @param newTexture The texture to add
     */
    addTexture(newTexture: BaseTexture): void;
    /**
     * Adds the given frame graph to this scene.
     * @param newFrameGraph The frame graph to add
     */
    addFrameGraph(newFrameGraph: FrameGraph): void;
    /**
     * Adds the given object renderer to this scene.
     * @param objectRenderer The object renderer to add
     */
    addObjectRenderer(objectRenderer: ObjectRenderer): void;
    /**
     * Adds the given post process to this scene.
     * @param newPostProcess The post process to add
     */
    addPostProcess(newPostProcess: PostProcess): void;
    /**
     * Adds the given effect layer to this scene.
     * @param newEffectLayer The effect layer to add
     */
    addEffectLayer(newEffectLayer: EffectLayer): void;
    /**
     * Switch active camera
     * @param newCamera defines the new active camera
     * @param attachControl defines if attachControl must be called for the new active camera (default: true)
     */
    switchActiveCamera(newCamera: Camera, attachControl?: boolean): void;
    /**
     * sets the active camera of the scene using its Id
     * @param id defines the camera's Id
     * @returns the new active camera or null if none found.
     */
    setActiveCameraById(id: string): Nullable<Camera>;
    /**
     * sets the active camera of the scene using its name
     * @param name defines the camera's name
     * @returns the new active camera or null if none found.
     */
    setActiveCameraByName(name: string): Nullable<Camera>;
    /**
     * get an animation group using its name
     * @param name defines the material's name
     * @returns the animation group or null if none found.
     */
    getAnimationGroupByName(name: string): Nullable<AnimationGroup>;
    private _getMaterial;
    /**
     * Get a material using its unique id
     * @param uniqueId defines the material's unique id
     * @param allowMultiMaterials determines whether multimaterials should be considered
     * @returns the material or null if none found.
     * @deprecated Please use getMaterialByUniqueId instead.
     */
    getMaterialByUniqueID(uniqueId: number, allowMultiMaterials?: boolean): Nullable<Material>;
    /**
     * Get a material using its unique id
     * @param uniqueId defines the material's unique id
     * @param allowMultiMaterials determines whether multimaterials should be considered
     * @returns the material or null if none found.
     */
    getMaterialByUniqueId(uniqueId: number, allowMultiMaterials?: boolean): Nullable<Material>;
    /**
     * get a material using its id
     * @param id defines the material's Id
     * @param allowMultiMaterials determines whether multimaterials should be considered
     * @returns the material or null if none found.
     */
    getMaterialById(id: string, allowMultiMaterials?: boolean): Nullable<Material>;
    /**
     * Gets a material using its name
     * @param name defines the material's name
     * @param allowMultiMaterials determines whether multimaterials should be considered
     * @returns the material or null if none found.
     */
    getMaterialByName(name: string, allowMultiMaterials?: boolean): Nullable<Material>;
    /**
     * Gets a last added material using a given id
     * @param id defines the material's id
     * @param allowMultiMaterials determines whether multimaterials should be considered
     * @returns the last material with the given id or null if none found.
     */
    getLastMaterialById(id: string, allowMultiMaterials?: boolean): Nullable<Material>;
    /**
     * Get a texture using its unique id
     * @param uniqueId defines the texture's unique id
     * @returns the texture or null if none found.
     */
    getTextureByUniqueId(uniqueId: number): Nullable<BaseTexture>;
    /**
     * Gets a texture using its name
     * @param name defines the texture's name
     * @returns the texture or null if none found.
     */
    getTextureByName(name: string): Nullable<BaseTexture>;
    /**
     * Gets a camera using its Id
     * @param id defines the Id to look for
     * @returns the camera or null if not found
     */
    getCameraById(id: string): Nullable<Camera>;
    /**
     * Gets a camera using its unique Id
     * @param uniqueId defines the unique Id to look for
     * @returns the camera or null if not found
     */
    getCameraByUniqueId(uniqueId: number): Nullable<Camera>;
    /**
     * Gets a camera using its name
     * @param name defines the camera's name
     * @returns the camera or null if none found.
     */
    getCameraByName(name: string): Nullable<Camera>;
    /**
     * Gets a bone using its Id
     * @param id defines the bone's Id
     * @returns the bone or null if not found
     */
    getBoneById(id: string): Nullable<Bone>;
    /**
     * Gets a bone using its id
     * @param name defines the bone's name
     * @returns the bone or null if not found
     */
    getBoneByName(name: string): Nullable<Bone>;
    /**
     * Gets a light node using its name
     * @param name defines the light's name
     * @returns the light or null if none found.
     */
    getLightByName(name: string): Nullable<Light>;
    /**
     * Gets a light node using its Id
     * @param id defines the light's Id
     * @returns the light or null if none found.
     */
    getLightById(id: string): Nullable<Light>;
    /**
     * Gets a light node using its scene-generated unique Id
     * @param uniqueId defines the light's unique Id
     * @returns the light or null if none found.
     */
    getLightByUniqueId(uniqueId: number): Nullable<Light>;
    /**
     * Gets a particle system by Id
     * @param id defines the particle system Id
     * @returns the corresponding system or null if none found
     */
    getParticleSystemById(id: string): Nullable<IParticleSystem>;
    /**
     * Gets a geometry using its Id
     * @param id defines the geometry's Id
     * @returns the geometry or null if none found.
     */
    getGeometryById(id: string): Nullable<Geometry>;
    private _getGeometryByUniqueId;
    /**
     * Gets a frame graph using its name
     * @param name defines the frame graph's name
     * @returns the frame graph or null if none found.
     */
    getFrameGraphByName(name: string): Nullable<FrameGraph>;
    /**
     * Add a new geometry to this scene
     * @param geometry defines the geometry to be added to the scene.
     * @param force defines if the geometry must be pushed even if a geometry with this id already exists
     * @returns a boolean defining if the geometry was added or not
     */
    pushGeometry(geometry: Geometry, force?: boolean): boolean;
    /**
     * Removes an existing geometry
     * @param geometry defines the geometry to be removed from the scene
     * @returns a boolean defining if the geometry was removed or not
     */
    removeGeometry(geometry: Geometry): boolean;
    /**
     * Gets the list of geometries attached to the scene
     * @returns an array of Geometry
     */
    getGeometries(): Geometry[];
    /**
     * Gets the first added mesh found of a given Id
     * @param id defines the Id to search for
     * @returns the mesh found or null if not found at all
     */
    getMeshById(id: string): Nullable<AbstractMesh>;
    /**
     * Gets a list of meshes using their Id
     * @param id defines the Id to search for
     * @returns a list of meshes
     */
    getMeshesById(id: string): Array<AbstractMesh>;
    /**
     * Gets the first added transform node found of a given Id
     * @param id defines the Id to search for
     * @returns the found transform node or null if not found at all.
     */
    getTransformNodeById(id: string): Nullable<TransformNode>;
    /**
     * Gets a transform node with its auto-generated unique Id
     * @param uniqueId defines the unique Id to search for
     * @returns the found transform node or null if not found at all.
     */
    getTransformNodeByUniqueId(uniqueId: number): Nullable<TransformNode>;
    /**
     * Gets a list of transform nodes using their Id
     * @param id defines the Id to search for
     * @returns a list of transform nodes
     */
    getTransformNodesById(id: string): Array<TransformNode>;
    /**
     * Gets a mesh with its auto-generated unique Id
     * @param uniqueId defines the unique Id to search for
     * @returns the found mesh or null if not found at all.
     */
    getMeshByUniqueId(uniqueId: number): Nullable<AbstractMesh>;
    /**
     * Gets a the last added mesh using a given Id
     * @param id defines the Id to search for
     * @returns the found mesh or null if not found at all.
     */
    getLastMeshById(id: string): Nullable<AbstractMesh>;
    /**
     * Gets a the last transform node using a given Id
     * @param id defines the Id to search for
     * @returns the found mesh or null if not found at all.
     */
    getLastTransformNodeById(id: string): Nullable<TransformNode>;
    /**
     * Gets a the last added node (Mesh, Camera, Light) using a given Id
     * @param id defines the Id to search for
     * @returns the found node or null if not found at all
     */
    getLastEntryById(id: string): Nullable<Node>;
    /**
     * Gets a node (Mesh, Camera, Light) using a given Id
     * @param id defines the Id to search for
     * @returns the found node or null if not found at all
     */
    getNodeById(id: string): Nullable<Node>;
    /**
     * Gets a node (Mesh, Camera, Light) using a given name
     * @param name defines the name to search for
     * @returns the found node or null if not found at all.
     */
    getNodeByName(name: string): Nullable<Node>;
    /**
     * Gets a mesh using a given name
     * @param name defines the name to search for
     * @returns the found mesh or null if not found at all.
     */
    getMeshByName(name: string): Nullable<AbstractMesh>;
    /**
     * Gets a transform node using a given name
     * @param name defines the name to search for
     * @returns the found transform node or null if not found at all.
     */
    getTransformNodeByName(name: string): Nullable<TransformNode>;
    /**
     * Gets a skeleton using a given Id (if many are found, this function will pick the last one)
     * @param id defines the Id to search for
     * @returns the found skeleton or null if not found at all.
     */
    getLastSkeletonById(id: string): Nullable<Skeleton>;
    /**
     * Gets a skeleton using a given auto generated unique id
     * @param  uniqueId defines the unique id to search for
     * @returns the found skeleton or null if not found at all.
     */
    getSkeletonByUniqueId(uniqueId: number): Nullable<Skeleton>;
    /**
     * Gets a skeleton using a given id (if many are found, this function will pick the first one)
     * @param id defines the id to search for
     * @returns the found skeleton or null if not found at all.
     */
    getSkeletonById(id: string): Nullable<Skeleton>;
    /**
     * Gets a skeleton using a given name
     * @param name defines the name to search for
     * @returns the found skeleton or null if not found at all.
     */
    getSkeletonByName(name: string): Nullable<Skeleton>;
    /**
     * Gets a morph target manager  using a given id (if many are found, this function will pick the last one)
     * @param id defines the id to search for
     * @returns the found morph target manager or null if not found at all.
     */
    getMorphTargetManagerById(id: number): Nullable<MorphTargetManager>;
    /**
     * Gets a morph target using a given id (if many are found, this function will pick the first one)
     * @param id defines the id to search for
     * @returns the found morph target or null if not found at all.
     */
    getMorphTargetById(id: string): Nullable<MorphTarget>;
    /**
     * Gets a morph target using a given name (if many are found, this function will pick the first one)
     * @param name defines the name to search for
     * @returns the found morph target or null if not found at all.
     */
    getMorphTargetByName(name: string): Nullable<MorphTarget>;
    /**
     * Gets a post process using a given name (if many are found, this function will pick the first one)
     * @param name defines the name to search for
     * @returns the found post process or null if not found at all.
     */
    getPostProcessByName(name: string): Nullable<PostProcess>;
    /**
     * Gets a boolean indicating if the given mesh is active
     * @param mesh defines the mesh to look for
     * @returns true if the mesh is in the active list
     */
    isActiveMesh(mesh: AbstractMesh): boolean;
    /**
     * Return a unique id as a string which can serve as an identifier for the scene
     */
    get uid(): string;
    /**
     * Add an externally attached data from its key.
     * This method call will fail and return false, if such key already exists.
     * If you don't care and just want to get the data no matter what, use the more convenient getOrAddExternalDataWithFactory() method.
     * @param key the unique key that identifies the data
     * @param data the data object to associate to the key for this Engine instance
     * @returns true if no such key were already present and the data was added successfully, false otherwise
     */
    addExternalData<T extends object>(key: string, data: T): boolean;
    /**
     * Get an externally attached data from its key
     * @param key the unique key that identifies the data
     * @returns the associated data, if present (can be null), or undefined if not present
     */
    getExternalData<T>(key: string): Nullable<T>;
    /**
     * Get an externally attached data from its key, create it using a factory if it's not already present
     * @param key the unique key that identifies the data
     * @param factory the factory that will be called to create the instance if and only if it doesn't exists
     * @returns the associated data, can be null if the factory returned null.
     */
    getOrAddExternalDataWithFactory<T extends object>(key: string, factory: (k: string) => T): T;
    /**
     * Remove an externally attached data from the Engine instance
     * @param key the unique key that identifies the data
     * @returns true if the data was successfully removed, false if it doesn't exist
     */
    removeExternalData(key: string): boolean;
    private _evaluateSubMesh;
    /**
     * Clear the processed materials smart array preventing retention point in material dispose.
     */
    freeProcessedMaterials(): void;
    private _preventFreeActiveMeshesAndRenderingGroups;
    /** Gets or sets a boolean blocking all the calls to freeActiveMeshes and freeRenderingGroups
     * It can be used in order to prevent going through methods freeRenderingGroups and freeActiveMeshes several times to improve performance
     * when disposing several meshes in a row or a hierarchy of meshes.
     * When used, it is the responsibility of the user to blockfreeActiveMeshesAndRenderingGroups back to false.
     */
    get blockfreeActiveMeshesAndRenderingGroups(): boolean;
    set blockfreeActiveMeshesAndRenderingGroups(value: boolean);
    /**
     * Clear the active meshes smart array preventing retention point in mesh dispose.
     */
    freeActiveMeshes(): void;
    /**
     * Clear the info related to rendering groups preventing retention points during dispose.
     */
    freeRenderingGroups(): void;
    /** @internal */
    _isInIntermediateRendering(): boolean;
    /**
     * Lambda returning the list of potentially active meshes.
     */
    getActiveMeshCandidates: () => ISmartArrayLike<AbstractMesh>;
    /**
     * Lambda returning the list of potentially active sub meshes.
     */
    getActiveSubMeshCandidates: (mesh: AbstractMesh) => ISmartArrayLike<SubMesh>;
    /**
     * Lambda returning the list of potentially intersecting sub meshes.
     */
    getIntersectingSubMeshCandidates: (mesh: AbstractMesh, localRay: Ray) => ISmartArrayLike<SubMesh>;
    /**
     * Lambda returning the list of potentially colliding sub meshes.
     */
    getCollidingSubMeshCandidates: (mesh: AbstractMesh, collider: Collider) => ISmartArrayLike<SubMesh>;
    /** @internal */
    _activeMeshesFrozen: boolean;
    /** @internal */
    _activeMeshesFrozenButKeepClipping: boolean;
    private _skipEvaluateActiveMeshesCompletely;
    private _freezeActiveMeshesCancel;
    /**
     * Use this function to stop evaluating active meshes. The current list will be keep alive between frames
     * @param skipEvaluateActiveMeshes defines an optional boolean indicating that the evaluate active meshes step must be completely skipped
     * @param onSuccess optional success callback
     * @param onError optional error callback
     * @param freezeMeshes defines if meshes should be frozen (true by default)
     * @param keepFrustumCulling defines if you want to keep running the frustum clipping (false by default)
     * @returns the current scene
     */
    freezeActiveMeshes(skipEvaluateActiveMeshes?: boolean, onSuccess?: () => void, onError?: (message: string) => void, freezeMeshes?: boolean, keepFrustumCulling?: boolean): Scene;
    /**
     * Use this function to restart evaluating active meshes on every frame
     * @returns the current scene
     */
    unfreezeActiveMeshes(): Scene;
    private _executeActiveContainerCleanup;
    private _evaluateActiveMeshes;
    /** @internal */
    _prepareSkeleton(mesh: AbstractMesh): void;
    private _activeMesh;
    /**
     * Update the transform matrix to update from the current active camera
     * @param force defines a boolean used to force the update even if cache is up to date
     */
    updateTransformMatrix(force?: boolean): void;
    /** @internal */
    _useCurrentFrameBuffer: boolean;
    private _bindFrameBuffer;
    private _clearFrameBuffer;
    /** @internal */
    _allowPostProcessClearColor: boolean;
    /**
     * @internal
     */
    _renderForCamera(camera: Camera, rigParent?: Camera, bindFrameBuffer?: boolean): void;
    private _processSubCameras;
    private _checkIntersections;
    /**
     * @internal
     */
    _advancePhysicsEngineStep(step: number): void;
    /**
     * User updatable function that will return a deterministic frame time when engine is in deterministic lock step mode
     * @returns the frame time
     */
    getDeterministicFrameTime: () => number;
    /** @internal */
    _animate(customDeltaTime?: number): void;
    /** Execute all animations (for a frame) */
    animate(): void;
    private _clear;
    private _checkCameraRenderTarget;
    /**
     * Resets the draw wrappers cache of all meshes
     * @param passId If provided, releases only the draw wrapper corresponding to this render pass id
     */
    resetDrawCache(passId?: number): void;
    /**
     * If this function is defined it will take precedence over the standard render() function.
     */
    customRenderFunction?: (updateCameras: boolean, ignoreAnimations: boolean) => void;
    private _renderWithFrameGraph;
    /**
     * @internal
     */
    _renderRenderTarget(renderTarget: RenderTargetTexture, activeCamera: Nullable<Camera>, useCameraPostProcess?: boolean, dumpForDebug?: boolean): void;
    private _getFloatingOriginScene;
    /**
     * Render the scene
     * @param updateCameras defines a boolean indicating if cameras must update according to their inputs (true by default)
     * @param ignoreAnimations defines a boolean indicating if animations should not be executed (false by default)
     */
    render(updateCameras?: boolean, ignoreAnimations?: boolean): void;
    /**
     * Freeze all materials
     * A frozen material will not be updatable but should be faster to render
     * Note: multimaterials will not be frozen, but their submaterials will
     */
    freezeMaterials(): void;
    /**
     * Unfreeze all materials
     * A frozen material will not be updatable but should be faster to render
     */
    unfreezeMaterials(): void;
    /**
     * Releases all held resources
     */
    dispose(): void;
    private _disposeList;
    /**
     * Gets if the scene is already disposed
     */
    get isDisposed(): boolean;
    /**
     * Call this function to reduce memory footprint of the scene.
     * Vertex buffers will not store CPU data anymore (this will prevent picking, collisions or physics to work correctly)
     */
    clearCachedVertexData(): void;
    /**
     * This function will remove the local cached buffer data from texture.
     * It will save memory but will prevent the texture from being rebuilt
     */
    cleanCachedTextureBuffer(): void;
    /**
     * Get the world extend vectors with an optional filter
     *
     * @param filterPredicate the predicate - which meshes should be included when calculating the world size
     * @returns {{ min: Vector3; max: Vector3 }} min and max vectors
     */
    getWorldExtends(filterPredicate?: (mesh: AbstractMesh) => boolean): {
        min: Vector3;
        max: Vector3;
    };
    /**
     * Creates a ray that can be used to pick in the scene
     * @param x defines the x coordinate of the origin (on-screen)
     * @param y defines the y coordinate of the origin (on-screen)
     * @param world defines the world matrix to use if you want to pick in object space (instead of world space)
     * @param camera defines the camera to use for the picking
     * @param cameraViewSpace defines if picking will be done in view space (false by default)
     * @returns a Ray
     */
    createPickingRay(x: number, y: number, world: Nullable<Matrix>, camera: Nullable<Camera>, cameraViewSpace?: boolean): Ray;
    /**
     * Creates a ray that can be used to pick in the scene
     * @param x defines the x coordinate of the origin (on-screen)
     * @param y defines the y coordinate of the origin (on-screen)
     * @param world defines the world matrix to use if you want to pick in object space (instead of world space)
     * @param result defines the ray where to store the picking ray
     * @param camera defines the camera to use for the picking
     * @param cameraViewSpace defines if picking will be done in view space (false by default)
     * @param enableDistantPicking defines if picking should handle large values for mesh position/scaling (false by default)
     * @returns the current scene
     */
    createPickingRayToRef(x: number, y: number, world: Nullable<Matrix>, result: Ray, camera: Nullable<Camera>, cameraViewSpace?: boolean, enableDistantPicking?: boolean): Scene;
    /**
     * Creates a ray that can be used to pick in the scene
     * @param x defines the x coordinate of the origin (on-screen)
     * @param y defines the y coordinate of the origin (on-screen)
     * @param camera defines the camera to use for the picking
     * @returns a Ray
     */
    createPickingRayInCameraSpace(x: number, y: number, camera?: Camera): Ray;
    /**
     * Creates a ray that can be used to pick in the scene
     * @param x defines the x coordinate of the origin (on-screen)
     * @param y defines the y coordinate of the origin (on-screen)
     * @param result defines the ray where to store the picking ray
     * @param camera defines the camera to use for the picking
     * @returns the current scene
     */
    createPickingRayInCameraSpaceToRef(x: number, y: number, result: Ray, camera?: Camera): Scene;
    /** @internal */
    _registeredActions: number;
    /** Launch a ray to try to pick a mesh in the scene
     * @param x position on screen
     * @param y position on screen
     * @param predicate Predicate function used to determine eligible meshes. Can be set to null. In this case, a mesh must be enabled, visible and with isPickable set to true. thinInstanceIndex is -1 when the mesh is non-instanced
     * @param fastCheck defines if the first intersection will be used (and not the closest)
     * @param camera to use for computing the picking ray. Can be set to null. In this case, the scene.activeCamera will be used
     * @param trianglePredicate defines an optional predicate used to select faces when a mesh intersection is detected
     * @returns a PickingInfo
     */
    pick(x: number, y: number, predicate?: MeshPredicate, fastCheck?: boolean, camera?: Nullable<Camera>, trianglePredicate?: TrianglePickingPredicate): PickingInfo;
    /** Launch a ray to try to pick a mesh in the scene using only bounding information of the main mesh (not using submeshes)
     * @param x position on screen
     * @param y position on screen
     * @param predicate Predicate function used to determine eligible meshes. Can be set to null. In this case, a mesh must be enabled, visible and with isPickable set to true. thinInstanceIndex is -1 when the mesh is non-instanced
     * @param fastCheck defines if the first intersection will be used (and not the closest)
     * @param camera to use for computing the picking ray. Can be set to null. In this case, the scene.activeCamera will be used
     * @returns a PickingInfo (Please note that some info will not be set like distance, bv, bu and everything that cannot be capture by only using bounding infos)
     */
    pickWithBoundingInfo(x: number, y: number, predicate?: MeshPredicate, fastCheck?: boolean, camera?: Nullable<Camera>): Nullable<PickingInfo>;
    /**
     * Use the given ray to pick a mesh in the scene. A mesh triangle can be picked both from its front and back sides,
     * irrespective of orientation.
     * @param ray The ray to use to pick meshes
     * @param predicate Predicate function used to determine eligible meshes. Can be set to null. In this case, a mesh must have isPickable set to true. thinInstanceIndex is -1 when the mesh is non-instanced
     * @param fastCheck defines if the first intersection will be used (and not the closest)
     * @param trianglePredicate defines an optional predicate used to select faces when a mesh intersection is detected
     * @returns a PickingInfo
     */
    pickWithRay(ray: Ray, predicate?: MeshPredicate, fastCheck?: boolean, trianglePredicate?: TrianglePickingPredicate): Nullable<PickingInfo>;
    /**
     * Launch a ray to try to pick a mesh in the scene. A mesh triangle can be picked both from its front and back sides,
     * irrespective of orientation.
     * @param x X position on screen
     * @param y Y position on screen
     * @param predicate Predicate function used to determine eligible meshes and instances. Can be set to null. In this case, a mesh must be enabled, visible and with isPickable set to true. thinInstanceIndex is -1 when the mesh is non-instanced
     * @param camera camera to use for computing the picking ray. Can be set to null. In this case, the scene.activeCamera will be used
     * @param trianglePredicate defines an optional predicate used to select faces when a mesh intersection is detected
     * @returns an array of PickingInfo
     */
    multiPick(x: number, y: number, predicate?: MeshPredicate, camera?: Camera, trianglePredicate?: TrianglePickingPredicate): Nullable<PickingInfo[]>;
    /**
     * Launch a ray to try to pick a mesh in the scene
     * @param ray Ray to use
     * @param predicate Predicate function used to determine eligible meshes and instances. Can be set to null. In this case, a mesh must be enabled, visible and with isPickable set to true. thinInstanceIndex is -1 when the mesh is non-instanced
     * @param trianglePredicate defines an optional predicate used to select faces when a mesh intersection is detected
     * @returns an array of PickingInfo
     */
    multiPickWithRay(ray: Ray, predicate?: MeshPredicate, trianglePredicate?: TrianglePickingPredicate): Nullable<PickingInfo[]>;
    /**
     * Force the value of meshUnderPointer
     * @param mesh defines the mesh to use
     * @param pointerId optional pointer id when using more than one pointer
     * @param pickResult optional pickingInfo data used to find mesh
     */
    setPointerOverMesh(mesh: Nullable<AbstractMesh>, pointerId?: number, pickResult?: Nullable<PickingInfo>): void;
    /**
     * Gets the mesh under the pointer
     * @returns a Mesh or null if no mesh is under the pointer
     */
    getPointerOverMesh(): Nullable<AbstractMesh>;
    /** @internal */
    _rebuildGeometries(): void;
    /** @internal */
    _rebuildTextures(): void;
    /**
     * Get from a list of objects by tags
     * @param list the list of objects to use
     * @param tagsQuery the query to use
     * @param filter a predicate to filter for tags
     * @returns
     */
    private _getByTags;
    /**
     * Get a list of meshes by tags
     * @param tagsQuery defines the tags query to use
     * @param filter defines a predicate used to filter results
     * @returns an array of Mesh
     */
    getMeshesByTags(tagsQuery: string, filter?: (mesh: AbstractMesh) => boolean): AbstractMesh[];
    /**
     * Get a list of cameras by tags
     * @param tagsQuery defines the tags query to use
     * @param filter defines a predicate used to filter results
     * @returns an array of Camera
     */
    getCamerasByTags(tagsQuery: string, filter?: (camera: Camera) => boolean): Camera[];
    /**
     * Get a list of lights by tags
     * @param tagsQuery defines the tags query to use
     * @param filter defines a predicate used to filter results
     * @returns an array of Light
     */
    getLightsByTags(tagsQuery: string, filter?: (light: Light) => boolean): Light[];
    /**
     * Get a list of materials by tags
     * @param tagsQuery defines the tags query to use
     * @param filter defines a predicate used to filter results
     * @returns an array of Material
     */
    getMaterialByTags(tagsQuery: string, filter?: (material: Material) => boolean): Material[];
    /**
     * Get a list of transform nodes by tags
     * @param tagsQuery defines the tags query to use
     * @param filter defines a predicate used to filter results
     * @returns an array of TransformNode
     */
    getTransformNodesByTags(tagsQuery: string, filter?: (transform: TransformNode) => boolean): TransformNode[];
    /**
     * Overrides the default sort function applied in the rendering group to prepare the meshes.
     * This allowed control for front to back rendering or reversly depending of the special needs.
     *
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param opaqueSortCompareFn The opaque queue comparison function use to sort.
     * @param alphaTestSortCompareFn The alpha test queue comparison function use to sort.
     * @param transparentSortCompareFn The transparent queue comparison function use to sort.
     */
    setRenderingOrder(renderingGroupId: number, opaqueSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, alphaTestSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>, transparentSortCompareFn?: Nullable<(a: SubMesh, b: SubMesh) => number>): void;
    /**
     * Specifies whether or not the stencil and depth buffer are cleared between two rendering groups.
     *
     * @param renderingGroupId The rendering group id corresponding to its index
     * @param autoClearDepthStencil Automatically clears depth and stencil between groups if true.
     * @param depth Automatically clears depth between groups if true and autoClear is true.
     * @param stencil Automatically clears stencil between groups if true and autoClear is true.
     */
    setRenderingAutoClearDepthStencil(renderingGroupId: number, autoClearDepthStencil: boolean, depth?: boolean, stencil?: boolean): void;
    /**
     * Gets the current auto clear configuration for one rendering group of the rendering
     * manager.
     * @param index the rendering group index to get the information for
     * @returns The auto clear setup for the requested rendering group
     */
    getAutoClearDepthStencilSetup(index: number): IRenderingManagerAutoClearSetup;
    private _blockMaterialDirtyMechanism;
    /** @internal */
    _forceBlockMaterialDirtyMechanism(value: boolean): void;
    /** Gets or sets a boolean blocking all the calls to markAllMaterialsAsDirty (ie. the materials won't be updated if they are out of sync) */
    get blockMaterialDirtyMechanism(): boolean;
    set blockMaterialDirtyMechanism(value: boolean);
    /**
     * Will flag all materials as dirty to trigger new shader compilation
     * @param flag defines the flag used to specify which material part must be marked as dirty
     * @param predicate If not null, it will be used to specify if a material has to be marked as dirty
     */
    markAllMaterialsAsDirty(flag: number, predicate?: (mat: Material) => boolean): void;
    /**
     * @internal
     */
    _loadFile(fileOrUrl: File | string, onSuccess: (data: string | ArrayBuffer, responseURL?: string) => void, onProgress?: (ev: ProgressEvent) => void, useOfflineSupport?: boolean, useArrayBuffer?: boolean, onError?: (request?: WebRequest, exception?: LoadFileError) => void, onOpened?: (request: WebRequest) => void): IFileRequest;
    _loadFileAsync(fileOrUrl: File | string, onProgress?: (data: any) => void, useOfflineSupport?: boolean, useArrayBuffer?: false, onOpened?: (request: WebRequest) => void): Promise<string>;
    _loadFileAsync(fileOrUrl: File | string, onProgress?: (data: any) => void, useOfflineSupport?: boolean, useArrayBuffer?: true, onOpened?: (request: WebRequest) => void): Promise<ArrayBuffer>;
    /**
     * @internal
     */
    _requestFile(url: string, onSuccess: (data: string | ArrayBuffer, request?: WebRequest) => void, onProgress?: (ev: ProgressEvent) => void, useOfflineSupport?: boolean, useArrayBuffer?: boolean, onError?: (error: RequestFileError) => void, onOpened?: (request: WebRequest) => void): IFileRequest;
    /**
     * @internal
     */
    _requestFileAsync(url: string, onProgress?: (ev: ProgressEvent) => void, useOfflineSupport?: boolean, useArrayBuffer?: boolean, onOpened?: (request: WebRequest) => void): Promise<string | ArrayBuffer>;
    /**
     * @internal
     */
    _readFile(file: File, onSuccess: (data: string | ArrayBuffer) => void, onProgress?: (ev: ProgressEvent) => any, useArrayBuffer?: boolean, onError?: (error: ReadFileError) => void): IFileRequest;
    /**
     * @internal
     */
    _readFileAsync(file: File, onProgress?: (ev: ProgressEvent) => any, useArrayBuffer?: boolean): Promise<string | ArrayBuffer>;
    /**
     * Internal perfCollector instance used for sharing between inspector and playground.
     * Marked as protected to allow sharing between prototype extensions, but disallow access at toplevel.
     */
    protected _perfCollector: Nullable<PerformanceViewerCollector>;
    /**
     * This method gets the performance collector belonging to the scene, which is generally shared with the inspector.
     * @returns the perf collector belonging to the scene.
     */
    getPerfCollector(): PerformanceViewerCollector;
    /**
     * Sets the active camera of the scene using its Id
     * @param id defines the camera's Id
     * @returns the new active camera or null if none found.
     * @deprecated Please use setActiveCameraById instead
     */
    setActiveCameraByID(id: string): Nullable<Camera>;
    /**
     * Get a material using its id
     * @param id defines the material's Id
     * @returns the material or null if none found.
     * @deprecated Please use getMaterialById instead
     */
    getMaterialByID(id: string): Nullable<Material>;
    /**
     * Gets a the last added material using a given id
     * @param id defines the material's Id
     * @returns the last material with the given id or null if none found.
     * @deprecated Please use getLastMaterialById instead
     */
    getLastMaterialByID(id: string): Nullable<Material>;
    /**
     * Get a texture using its unique id
     * @param uniqueId defines the texture's unique id
     * @returns the texture or null if none found.
     * @deprecated Please use getTextureByUniqueId instead
     */
    getTextureByUniqueID(uniqueId: number): Nullable<BaseTexture>;
    /**
     * Gets a camera using its Id
     * @param id defines the Id to look for
     * @returns the camera or null if not found
     * @deprecated Please use getCameraById instead
     */
    getCameraByID(id: string): Nullable<Camera>;
    /**
     * Gets a camera using its unique Id
     * @param uniqueId defines the unique Id to look for
     * @returns the camera or null if not found
     * @deprecated Please use getCameraByUniqueId instead
     */
    getCameraByUniqueID(uniqueId: number): Nullable<Camera>;
    /**
     * Gets a bone using its Id
     * @param id defines the bone's Id
     * @returns the bone or null if not found
     * @deprecated Please use getBoneById instead
     */
    getBoneByID(id: string): Nullable<Bone>;
    /**
     * Gets a light node using its Id
     * @param id defines the light's Id
     * @returns the light or null if none found.
     * @deprecated Please use getLightById instead
     */
    getLightByID(id: string): Nullable<Light>;
    /**
     * Gets a light node using its scene-generated unique Id
     * @param uniqueId defines the light's unique Id
     * @returns the light or null if none found.
     * @deprecated Please use getLightByUniqueId instead
     */
    getLightByUniqueID(uniqueId: number): Nullable<Light>;
    /**
     * Gets a particle system by Id
     * @param id defines the particle system Id
     * @returns the corresponding system or null if none found
     * @deprecated Please use getParticleSystemById instead
     */
    getParticleSystemByID(id: string): Nullable<IParticleSystem>;
    /**
     * Gets a geometry using its Id
     * @param id defines the geometry's Id
     * @returns the geometry or null if none found.
     * @deprecated Please use getGeometryById instead
     */
    getGeometryByID(id: string): Nullable<Geometry>;
    /**
     * Gets the first added mesh found of a given Id
     * @param id defines the Id to search for
     * @returns the mesh found or null if not found at all
     * @deprecated Please use getMeshById instead
     */
    getMeshByID(id: string): Nullable<AbstractMesh>;
    /**
     * Gets a mesh with its auto-generated unique Id
     * @param uniqueId defines the unique Id to search for
     * @returns the found mesh or null if not found at all.
     * @deprecated Please use getMeshByUniqueId instead
     */
    getMeshByUniqueID(uniqueId: number): Nullable<AbstractMesh>;
    /**
     * Gets a the last added mesh using a given Id
     * @param id defines the Id to search for
     * @returns the found mesh or null if not found at all.
     * @deprecated Please use getLastMeshById instead
     */
    getLastMeshByID(id: string): Nullable<AbstractMesh>;
    /**
     * Gets a list of meshes using their Id
     * @param id defines the Id to search for
     * @returns a list of meshes
     * @deprecated Please use getMeshesById instead
     */
    getMeshesByID(id: string): Array<AbstractMesh>;
    /**
     * Gets the first added transform node found of a given Id
     * @param id defines the Id to search for
     * @returns the found transform node or null if not found at all.
     * @deprecated Please use getTransformNodeById instead
     */
    getTransformNodeByID(id: string): Nullable<TransformNode>;
    /**
     * Gets a transform node with its auto-generated unique Id
     * @param uniqueId defines the unique Id to search for
     * @returns the found transform node or null if not found at all.
     * @deprecated Please use getTransformNodeByUniqueId instead
     */
    getTransformNodeByUniqueID(uniqueId: number): Nullable<TransformNode>;
    /**
     * Gets a list of transform nodes using their Id
     * @param id defines the Id to search for
     * @returns a list of transform nodes
     * @deprecated Please use getTransformNodesById instead
     */
    getTransformNodesByID(id: string): Array<TransformNode>;
    /**
     * Gets a node (Mesh, Camera, Light) using a given Id
     * @param id defines the Id to search for
     * @returns the found node or null if not found at all
     * @deprecated Please use getNodeById instead
     */
    getNodeByID(id: string): Nullable<Node>;
    /**
     * Gets a the last added node (Mesh, Camera, Light) using a given Id
     * @param id defines the Id to search for
     * @returns the found node or null if not found at all
     * @deprecated Please use getLastEntryById instead
     */
    getLastEntryByID(id: string): Nullable<Node>;
    /**
     * Gets a skeleton using a given Id (if many are found, this function will pick the last one)
     * @param id defines the Id to search for
     * @returns the found skeleton or null if not found at all.
     * @deprecated Please use getLastSkeletonById instead
     */
    getLastSkeletonByID(id: string): Nullable<Skeleton>;
}

/**
 * Options to be used when creating a pipeline
 */
interface IPipelineGenerationOptions {
    /**
     * The definition of the shader content.
     * Can be either a unified name, name per vertex and frament or the shader code content itself
     */
    shaderNameOrContent: string | IShaderPath;
    /**
     * Unique key to identify the pipeline.
     * Note that though not mandatory, it's recommended to provide a key to be able to use the automated pipeline loading system.
     */
    key?: string;
    /**
     * The list of defines to be used in the shader
     */
    defines?: string[];
    /**
     * If true, the global defines will be added to the defines array
     */
    addGlobalDefines?: boolean;
    /**
     * The shader language.
     * Defaults to the language suiting the platform name (GLSL for WEBGL2, WGSL for WEBGPU)
     */
    shaderLanguage?: ShaderLanguage;
    /**
     * The name of the platform to be used when processing the shader
     * defaults to WEBGL2
     */
    platformName?: string;
    /**
     * extend the processing options when running code processing
     */
    extendedProcessingOptions?: Partial<_IProcessingOptions>;
    /**
     * extend the pipeline generation options
     */
    extendedCreatePipelineOptions?: Partial<ICreateAndPreparePipelineContextOptions>;
    /**
     * If true, generating a new pipeline will return when the pipeline is ready to be used
     */
    waitForIsReady?: boolean;
    /**
     * If true, the pipeline will be created synchronously, even if parallel shader compilation is available
     */
    disableParallelCompilation?: boolean;
}
/**
 * @internal
 */
interface ICreateAndPreparePipelineContextOptions {
    parallelShaderCompile?: {
        COMPLETION_STATUS_KHR: number;
    };
    shaderProcessingContext: Nullable<_IShaderProcessingContext>;
    existingPipelineContext?: Nullable<IPipelineContext>;
    name?: string;
    rebuildRebind?: (vertexSourceCode: string, fragmentSourceCode: string, onCompiled: (pipelineContext: IPipelineContext) => void, onError: (message: string) => void) => void;
    onRenderingStateCompiled?: (pipelineContext?: IPipelineContext) => void;
    context?: WebGL2RenderingContext | WebGLRenderingContext;
    createAsRaw?: boolean;
    vertex: string;
    fragment: string;
    defines: Nullable<string>;
    transformFeedbackVaryings: Nullable<string[]>;
    disableParallelCompilation?: boolean;
}

/**
 * Defines the route to the shader code. The priority is as follows:
 *  * object: `{ vertexSource: "vertex shader code string", fragmentSource: "fragment shader code string" }` for directly passing the shader code
 *  * object: `{ vertexElement: "vertexShaderCode", fragmentElement: "fragmentShaderCode" }`, used with shader code in script tags
 *  * object: `{ vertex: "custom", fragment: "custom" }`, used with `Effect.ShadersStore["customVertexShader"]` and `Effect.ShadersStore["customFragmentShader"]`
 *  * string: `"./COMMON_NAME"`, used with external files COMMON_NAME.vertex.fx and COMMON_NAME.fragment.fx in index.html folder.
 */
type IShaderPath = {
    /**
     * Directly pass the shader code
     */
    vertexSource?: string;
    /**
     * Directly pass the shader code
     */
    fragmentSource?: string;
    /**
     * Used with Effect.ShadersStore. If the `vertex` is set to `"custom`, then
     * Babylon.js will read from Effect.ShadersStore["customVertexShader"]
     */
    vertex?: string;
    /**
     * Used with Effect.ShadersStore. If the `fragment` is set to `"custom`, then
     * Babylon.js will read from Effect.ShadersStore["customFragmentShader"]
     */
    fragment?: string;
    /**
     * Used with shader code in script tags
     */
    vertexElement?: string;
    /**
     * Used with shader code in script tags
     */
    fragmentElement?: string;
    /**
     * Defines the name appearing in spector when framgent/vertex...source are being used
     */
    spectorName?: string;
};
/**
 * Options to be used when creating an effect.
 */
interface IEffectCreationOptions {
    /**
     * Attributes that will be used in the shader.
     */
    attributes: string[];
    /**
     * Uniform variable names that will be set in the shader.
     */
    uniformsNames: string[];
    /**
     * Uniform buffer variable names that will be set in the shader.
     */
    uniformBuffersNames?: string[];
    /**
     * Sampler texture variable names that will be set in the shader.
     */
    samplers: string[];
    /**
     * Define statements that will be set in the shader.
     */
    defines: any;
    /**
     * Possible fallbacks for this effect to improve performance when needed.
     */
    fallbacks: Nullable<IEffectFallbacks>;
    /**
     * Callback that will be called when the shader is compiled.
     */
    onCompiled: Nullable<(effect: Effect) => void>;
    /**
     * Callback that will be called if an error occurs during shader compilation.
     */
    onError: Nullable<(effect: Effect, errors: string) => void>;
    /**
     * Parameters to be used with Babylons include syntax to iterate over an array (eg. \{lights: 10\})
     */
    indexParameters?: any;
    /**
     * Max number of lights that can be used in the shader.
     */
    maxSimultaneousLights?: number;
    /**
     * See https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/transformFeedbackVaryings
     */
    transformFeedbackVaryings?: Nullable<string[]>;
    /**
     * If provided, will be called two times with the vertex and fragment code so that this code can be updated before it is compiled by the GPU
     */
    processFinalCode?: Nullable<ShaderCustomProcessingFunction>;
    /**
     * If provided, will be called two times with the vertex and fragment code so that this code can be updated after the #include have been processed
     */
    processCodeAfterIncludes?: Nullable<ShaderCustomProcessingFunction>;
    /**
     * Is this effect rendering to several color attachments ?
     */
    multiTarget?: boolean;
    /**
     * The language the shader is written in (default: GLSL)
     */
    shaderLanguage?: ShaderLanguage;
    /**
     * Provide an existing pipeline context to avoid creating a new one
     */
    existingPipelineContext?: IPipelineContext;
    /**
     * Additional async code to run before preparing the effect
     */
    extraInitializationsAsync?: () => Promise<void>;
    /**
     * If set to true the shader will not be compiles asynchronously, even if the engine allows it.
     */
    disableParallelShaderCompilation?: boolean;
}
/**
 * Effect containing vertex and fragment shader that can be executed on an object.
 */
declare class Effect implements IDisposable {
    /**
     * Gets or sets the relative url used to load shaders if using the engine in non-minified mode
     */
    static get ShadersRepository(): string;
    static set ShadersRepository(repo: string);
    /**
     * Enable logging of the shader code when a compilation error occurs
     */
    static LogShaderCodeOnCompilationError: boolean;
    /**
     * Gets or sets a boolean indicating that effect ref counting is disabled
     * If true, the effect will persist in memory until engine is disposed
     */
    static PersistentMode: boolean;
    /**
     * Use this with caution
     * See ClearCodeCache function comments
     */
    static AutomaticallyClearCodeCache: boolean;
    /**
     * Name of the effect.
     */
    name: IShaderPath | string;
    /**
     * String container all the define statements that should be set on the shader.
     */
    defines: string;
    /**
     * Callback that will be called when the shader is compiled.
     */
    onCompiled: Nullable<(effect: Effect) => void>;
    /**
     * Callback that will be called if an error occurs during shader compilation.
     */
    onError: Nullable<(effect: Effect, errors: string) => void>;
    /**
     * Callback that will be called when effect is bound.
     */
    onBind: Nullable<(effect: Effect) => void>;
    /**
     * Unique ID of the effect.
     */
    uniqueId: number;
    /**
     * Observable that will be called when the shader is compiled.
     * It is recommended to use executeWhenCompile() or to make sure that scene.isReady() is called to get this observable raised.
     */
    onCompileObservable: Observable<Effect>;
    /**
     * Observable that will be called if an error occurs during shader compilation.
     */
    onErrorObservable: Observable<Effect>;
    /** @internal */
    _onBindObservable: Nullable<Observable<Effect>>;
    private _isDisposed;
    /**
     * Gets a boolean indicating that the effect was already disposed
     */
    get isDisposed(): boolean;
    /** @internal */
    _refCount: number;
    /**
     * Observable that will be called when effect is bound.
     */
    get onBindObservable(): Observable<Effect>;
    /** @internal */
    _bonesComputationForcedToCPU: boolean;
    /** @internal */
    _uniformBuffersNames: {
        [key: string]: number;
    };
    /** @internal */
    _samplerList: string[];
    /** @internal */
    _multiTarget: boolean;
    private static _UniqueIdSeed;
    /** @internal */
    _engine: AbstractEngine;
    private _uniformBuffersNamesList;
    private _uniformsNames;
    /** @internal */
    _samplers: {
        [key: string]: number;
    };
    private _isReady;
    private _compilationError;
    private _allFallbacksProcessed;
    private _attributesNames;
    private _attributes;
    private _attributeLocationByName;
    /** @internal */
    _uniforms: {
        [key: string]: Nullable<WebGLUniformLocation>;
    };
    /**
     * Key for the effect.
     * @internal
     */
    _key: string;
    private _indexParameters;
    private _fallbacks;
    private _vertexSourceCodeOverride;
    private _fragmentSourceCodeOverride;
    private _transformFeedbackVaryings;
    private _shaderLanguage;
    private _disableParallelShaderCompilation;
    /**
     * Compiled shader to webGL program.
     * @internal
     */
    _pipelineContext: Nullable<IPipelineContext>;
    /** @internal */
    _vertexSourceCode: string;
    /** @internal */
    _fragmentSourceCode: string;
    /** @internal */
    _vertexSourceCodeBeforeMigration: string;
    /** @internal */
    _fragmentSourceCodeBeforeMigration: string;
    /** @internal */
    _rawVertexSourceCode: string;
    /** @internal */
    _rawFragmentSourceCode: string;
    private static _BaseCache;
    private _processingContext;
    private _processCodeAfterIncludes;
    private _processFinalCode;
    private _onReleaseEffectsObserver;
    /**
     * Gets the shader language type used to write vertex and fragment source code.
     */
    get shaderLanguage(): ShaderLanguage;
    /**
     * Instantiates an effect.
     * An effect can be used to create/manage/execute vertex and fragment shaders.
     * @param baseName Name of the effect.
     * @param attributesNamesOrOptions List of attribute names that will be passed to the shader or set of all options to create the effect.
     * @param uniformsNamesOrEngine List of uniform variable names that will be passed to the shader or the engine that will be used to render effect.
     * @param samplers List of sampler variables that will be passed to the shader.
     * @param engine Engine to be used to render the effect
     * @param defines Define statements to be added to the shader.
     * @param fallbacks Possible fallbacks for this effect to improve performance when needed.
     * @param onCompiled Callback that will be called when the shader is compiled.
     * @param onError Callback that will be called if an error occurs during shader compilation.
     * @param indexParameters Parameters to be used with Babylons include syntax to iterate over an array (eg. \{lights: 10\})
     * @param key Effect Key identifying uniquely compiled shader variants
     * @param shaderLanguage the language the shader is written in (default: GLSL)
     * @param extraInitializationsAsync additional async code to run before preparing the effect
     */
    constructor(baseName: IShaderPath | string, attributesNamesOrOptions: string[] | IEffectCreationOptions, uniformsNamesOrEngine: string[] | AbstractEngine, samplers?: Nullable<string[]>, engine?: AbstractEngine, defines?: Nullable<string>, fallbacks?: Nullable<IEffectFallbacks>, onCompiled?: Nullable<(effect: Effect) => void>, onError?: Nullable<(effect: Effect, errors: string) => void>, indexParameters?: any, key?: string, shaderLanguage?: ShaderLanguage, extraInitializationsAsync?: () => Promise<void>);
    /** @internal */
    _processShaderCodeAsync(shaderProcessor?: Nullable<IShaderProcessor>, keepExistingPipelineContext?: boolean, shaderProcessingContext?: Nullable<_IShaderProcessingContext>, extraInitializationsAsync?: () => Promise<void>): Promise<void>;
    /**
     * Unique key for this effect
     */
    get key(): string;
    /**
     * If the effect has been compiled and prepared.
     * @returns if the effect is compiled and prepared.
     */
    isReady(): boolean;
    private _isReadyInternal;
    /**
     * The engine the effect was initialized with.
     * @returns the engine.
     */
    getEngine(): AbstractEngine;
    /**
     * The pipeline context for this effect
     * @returns the associated pipeline context
     */
    getPipelineContext(): Nullable<IPipelineContext>;
    /**
     * The set of names of attribute variables for the shader.
     * @returns An array of attribute names.
     */
    getAttributesNames(): string[];
    /**
     * Returns the attribute at the given index.
     * @param index The index of the attribute.
     * @returns The location of the attribute.
     */
    getAttributeLocation(index: number): number;
    /**
     * Returns the attribute based on the name of the variable.
     * @param name of the attribute to look up.
     * @returns the attribute location.
     */
    getAttributeLocationByName(name: string): number;
    /**
     * The number of attributes.
     * @returns the number of attributes.
     */
    getAttributesCount(): number;
    /**
     * Gets the index of a uniform variable.
     * @param uniformName of the uniform to look up.
     * @returns the index.
     */
    getUniformIndex(uniformName: string): number;
    /**
     * Returns the attribute based on the name of the variable.
     * @param uniformName of the uniform to look up.
     * @returns the location of the uniform.
     */
    getUniform(uniformName: string): Nullable<WebGLUniformLocation>;
    /**
     * Returns an array of sampler variable names
     * @returns The array of sampler variable names.
     */
    getSamplers(): string[];
    /**
     * Returns an array of uniform variable names
     * @returns The array of uniform variable names.
     */
    getUniformNames(): string[];
    /**
     * Returns an array of uniform buffer variable names
     * @returns The array of uniform buffer variable names.
     */
    getUniformBuffersNames(): string[];
    /**
     * Returns the index parameters used to create the effect
     * @returns The index parameters object
     */
    getIndexParameters(): any;
    /**
     * The error from the last compilation.
     * @returns the error string.
     */
    getCompilationError(): string;
    /**
     * Gets a boolean indicating that all fallbacks were used during compilation
     * @returns true if all fallbacks were used
     */
    allFallbacksProcessed(): boolean;
    /**
     * Wait until compilation before fulfilling.
     * @returns a promise to wait for completion.
     */
    whenCompiledAsync(): Promise<Effect>;
    /**
     * Adds a callback to the onCompiled observable and call the callback immediately if already ready.
     * @param func The callback to be used.
     */
    executeWhenCompiled(func: (effect: Effect) => void): void;
    private _checkIsReady;
    /**
     * Gets the vertex shader source code of this effect
     * This is the final source code that will be compiled, after all the processing has been done (pre-processing applied, code injection/replacement, etc)
     */
    get vertexSourceCode(): string;
    /**
     * Gets the fragment shader source code of this effect
     * This is the final source code that will be compiled, after all the processing has been done (pre-processing applied, code injection/replacement, etc)
     */
    get fragmentSourceCode(): string;
    /**
     * Gets the vertex shader source code before migration.
     * This is the source code after the include directives have been replaced by their contents but before the code is migrated, i.e. before ShaderProcess._ProcessShaderConversion is executed.
     * This method is, among other things, responsible for parsing #if/#define directives as well as converting GLES2 syntax to GLES3 (in the case of WebGL).
     */
    get vertexSourceCodeBeforeMigration(): string;
    /**
     * Gets the fragment shader source code before migration.
     * This is the source code after the include directives have been replaced by their contents but before the code is migrated, i.e. before ShaderProcess._ProcessShaderConversion is executed.
     * This method is, among other things, responsible for parsing #if/#define directives as well as converting GLES2 syntax to GLES3 (in the case of WebGL).
     */
    get fragmentSourceCodeBeforeMigration(): string;
    /**
     * Gets the vertex shader source code before it has been modified by any processing
     */
    get rawVertexSourceCode(): string;
    /**
     * Gets the fragment shader source code before it has been modified by any processing
     */
    get rawFragmentSourceCode(): string;
    getPipelineGenerationOptions(): IPipelineGenerationOptions;
    /**
     * Recompiles the webGL program
     * @param vertexSourceCode The source code for the vertex shader.
     * @param fragmentSourceCode The source code for the fragment shader.
     * @param onCompiled Callback called when completed.
     * @param onError Callback called on error.
     * @internal
     */
    _rebuildProgram(vertexSourceCode: string, fragmentSourceCode: string, onCompiled: (pipelineContext: IPipelineContext) => void, onError: (message: string) => void): void;
    private _onRenderingStateCompiled;
    /**
     * Prepares the effect
     * @internal
     */
    _prepareEffect(keepExistingPipelineContext?: boolean): void;
    private _getShaderCodeAndErrorLine;
    private _processCompilationErrors;
    /**
     * Checks if the effect is supported. (Must be called after compilation)
     */
    get isSupported(): boolean;
    /**
     * Binds a texture to the engine to be used as output of the shader.
     * @param channel Name of the output variable.
     * @param texture Texture to bind.
     * @internal
     */
    _bindTexture(channel: string, texture: Nullable<InternalTexture>): void;
    /**
     * Sets a texture on the engine to be used in the shader.
     * @param channel Name of the sampler variable.
     * @param texture Texture to set.
     */
    setTexture(channel: string, texture: Nullable<ThinTexture>): void;
    /**
     * Sets an array of textures on the engine to be used in the shader.
     * @param channel Name of the variable.
     * @param textures Textures to set.
     */
    setTextureArray(channel: string, textures: ThinTexture[]): void;
    /**
     * Binds a buffer to a uniform.
     * @param buffer Buffer to bind.
     * @param name Name of the uniform variable to bind to.
     */
    bindUniformBuffer(buffer: DataBuffer, name: string): void;
    /**
     * Binds block to a uniform.
     * @param blockName Name of the block to bind.
     * @param index Index to bind.
     */
    bindUniformBlock(blockName: string, index: number): void;
    /**
     * Sets an integer value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value Value to be set.
     * @returns this effect.
     */
    setInt(uniformName: string, value: number): Effect;
    /**
     * Sets an int2 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int2.
     * @param y Second int in int2.
     * @returns this effect.
     */
    setInt2(uniformName: string, x: number, y: number): Effect;
    /**
     * Sets an int3 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int3.
     * @param y Second int in int3.
     * @param z Third int in int3.
     * @returns this effect.
     */
    setInt3(uniformName: string, x: number, y: number, z: number): Effect;
    /**
     * Sets an int4 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First int in int4.
     * @param y Second int in int4.
     * @param z Third int in int4.
     * @param w Fourth int in int4.
     * @returns this effect.
     */
    setInt4(uniformName: string, x: number, y: number, z: number, w: number): Effect;
    /**
     * Sets an int array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setIntArray(uniformName: string, array: Int32Array): Effect;
    /**
     * Sets an int array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setIntArray2(uniformName: string, array: Int32Array): Effect;
    /**
     * Sets an int array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setIntArray3(uniformName: string, array: Int32Array): Effect;
    /**
     * Sets an int array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setIntArray4(uniformName: string, array: Int32Array): Effect;
    /**
     * Sets an unsigned integer value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value Value to be set.
     * @returns this effect.
     */
    setUInt(uniformName: string, value: number): Effect;
    /**
     * Sets an unsigned int2 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint2.
     * @param y Second unsigned int in uint2.
     * @returns this effect.
     */
    setUInt2(uniformName: string, x: number, y: number): Effect;
    /**
     * Sets an unsigned int3 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint3.
     * @param y Second unsigned int in uint3.
     * @param z Third unsigned int in uint3.
     * @returns this effect.
     */
    setUInt3(uniformName: string, x: number, y: number, z: number): Effect;
    /**
     * Sets an unsigned int4 value on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First unsigned int in uint4.
     * @param y Second unsigned int in uint4.
     * @param z Third unsigned int in uint4.
     * @param w Fourth unsigned int in uint4.
     * @returns this effect.
     */
    setUInt4(uniformName: string, x: number, y: number, z: number, w: number): Effect;
    /**
     * Sets an unsigned int array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setUIntArray(uniformName: string, array: Uint32Array): Effect;
    /**
     * Sets an unsigned int array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setUIntArray2(uniformName: string, array: Uint32Array): Effect;
    /**
     * Sets an unsigned int array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setUIntArray3(uniformName: string, array: Uint32Array): Effect;
    /**
     * Sets an unsigned int array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setUIntArray4(uniformName: string, array: Uint32Array): Effect;
    /**
     * Sets an float array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setFloatArray(uniformName: string, array: FloatArray): Effect;
    /**
     * Sets an float array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setFloatArray2(uniformName: string, array: FloatArray): Effect;
    /**
     * Sets an float array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setFloatArray3(uniformName: string, array: FloatArray): Effect;
    /**
     * Sets an float array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setFloatArray4(uniformName: string, array: FloatArray): Effect;
    /**
     * Sets an array on a uniform variable.
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setArray(uniformName: string, array: number[]): Effect;
    /**
     * Sets an array 2 on a uniform variable. (Array is specified as single array eg. [1,2,3,4] will result in [[1,2],[3,4]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setArray2(uniformName: string, array: number[]): Effect;
    /**
     * Sets an array 3 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6] will result in [[1,2,3],[4,5,6]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setArray3(uniformName: string, array: number[]): Effect;
    /**
     * Sets an array 4 on a uniform variable. (Array is specified as single array eg. [1,2,3,4,5,6,7,8] will result in [[1,2,3,4],[5,6,7,8]] in the shader)
     * @param uniformName Name of the variable.
     * @param array array to be set.
     * @returns this effect.
     */
    setArray4(uniformName: string, array: number[]): Effect;
    /**
     * Sets matrices on a uniform variable.
     * @param uniformName Name of the variable.
     * @param matrices matrices to be set.
     * @returns this effect.
     */
    setMatrices(uniformName: string, matrices: Float32Array | Array<number>): Effect;
    /**
     * Sets matrix on a uniform variable.
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     * @returns this effect.
     */
    setMatrix(uniformName: string, matrix: IMatrixLike): Effect;
    /**
     * Sets a 3x3 matrix on a uniform variable. (Specified as [1,2,3,4,5,6,7,8,9] will result in [1,2,3][4,5,6][7,8,9] matrix)
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     * @returns this effect.
     */
    setMatrix3x3(uniformName: string, matrix: Float32Array | Array<number>): Effect;
    /**
     * Sets a 2x2 matrix on a uniform variable. (Specified as [1,2,3,4] will result in [1,2][3,4] matrix)
     * @param uniformName Name of the variable.
     * @param matrix matrix to be set.
     * @returns this effect.
     */
    setMatrix2x2(uniformName: string, matrix: Float32Array | Array<number>): Effect;
    /**
     * Sets a float on a uniform variable.
     * @param uniformName Name of the variable.
     * @param value value to be set.
     * @returns this effect.
     */
    setFloat(uniformName: string, value: number): Effect;
    /**
     * Sets a boolean on a uniform variable.
     * @param uniformName Name of the variable.
     * @param bool value to be set.
     * @returns this effect.
     */
    setBool(uniformName: string, bool: boolean): Effect;
    /**
     * Sets a Vector2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector2 vector2 to be set.
     * @returns this effect.
     */
    setVector2(uniformName: string, vector2: IVector2Like): Effect;
    /**
     * Sets a float2 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float2.
     * @param y Second float in float2.
     * @returns this effect.
     */
    setFloat2(uniformName: string, x: number, y: number): Effect;
    /**
     * Sets a Vector3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector3 Value to be set.
     * @returns this effect.
     */
    setVector3(uniformName: string, vector3: IVector3Like): Effect;
    /**
     * Sets a float3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float3.
     * @param y Second float in float3.
     * @param z Third float in float3.
     * @returns this effect.
     */
    setFloat3(uniformName: string, x: number, y: number, z: number): Effect;
    /**
     * Sets a Vector4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param vector4 Value to be set.
     * @returns this effect.
     */
    setVector4(uniformName: string, vector4: IVector4Like): Effect;
    /**
     * Sets a Quaternion on a uniform variable.
     * @param uniformName Name of the variable.
     * @param quaternion Value to be set.
     * @returns this effect.
     */
    setQuaternion(uniformName: string, quaternion: IQuaternionLike): Effect;
    /**
     * Sets a float4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param x First float in float4.
     * @param y Second float in float4.
     * @param z Third float in float4.
     * @param w Fourth float in float4.
     * @returns this effect.
     */
    setFloat4(uniformName: string, x: number, y: number, z: number, w: number): Effect;
    /**
     * Sets a Color3 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param color3 Value to be set.
     * @returns this effect.
     */
    setColor3(uniformName: string, color3: IColor3Like): Effect;
    /**
     * Sets a Color4 on a uniform variable.
     * @param uniformName Name of the variable.
     * @param color3 Value to be set.
     * @param alpha Alpha value to be set.
     * @returns this effect.
     */
    setColor4(uniformName: string, color3: IColor3Like, alpha: number): Effect;
    /**
     * Sets a Color4 on a uniform variable
     * @param uniformName defines the name of the variable
     * @param color4 defines the value to be set
     * @returns this effect.
     */
    setDirectColor4(uniformName: string, color4: IColor4Like): Effect;
    /**
     * Use this wisely: It will remove the cached code from this effect
     * It is probably ok to call it if you are not using ShadowDepthWrapper or if everything is already up and running
     * DO NOT CALL IT if you want to have support for context lost recovery
     */
    clearCodeCache(): void;
    /**
     * Release all associated resources.
     * @param force specifies if the effect must be released no matter what
     **/
    dispose(force?: boolean): void;
    /**
     * This function will add a new shader to the shader store
     * @param name the name of the shader
     * @param pixelShader optional pixel shader content
     * @param vertexShader optional vertex shader content
     * @param shaderLanguage the language the shader is written in (default: GLSL)
     */
    static RegisterShader(name: string, pixelShader?: string, vertexShader?: string, shaderLanguage?: ShaderLanguage): void;
    /**
     * Store of each shader (The can be looked up using effect.key)
     */
    static ShadersStore: {
        [key: string]: string;
    };
    /**
     * Store of each included file for a shader (The can be looked up using effect.key)
     */
    static IncludesShadersStore: {
        [key: string]: string;
    };
    /**
     * Resets the cache of effects.
     */
    static ResetCache(): void;
}

/**
 * Block used to expose an input value
 */
declare class InputBlock extends NodeMaterialBlock {
    private _mode;
    private _associatedVariableName;
    private _storedValue;
    private _valueCallback;
    private _type;
    private _animationType;
    private _prefix;
    /** Gets or set a value used to limit the range of float values */
    min: number;
    /** Gets or set a value used to limit the range of float values */
    max: number;
    /** Gets or set a value indicating that this input can only get 0 and 1 values */
    isBoolean: boolean;
    /** Gets or sets a value used by the Node Material editor to determine how to configure the current value if it is a matrix */
    matrixMode: number;
    /** @internal */
    _systemValue: Nullable<NodeMaterialSystemValues>;
    /** Gets or sets a boolean indicating that the value of this input will not change after a build */
    isConstant: boolean;
    /** Gets or sets the group to use to display this block in the Inspector */
    groupInInspector: string;
    /** Gets an observable raised when the value is changed */
    onValueChangedObservable: Observable<InputBlock>;
    /** Gets or sets a boolean indicating if content needs to be converted to gamma space (for color3/4 only) */
    convertToGammaSpace: boolean;
    /** Gets or sets a boolean indicating if content needs to be converted to linear space (for color3/4 only) */
    convertToLinearSpace: boolean;
    /**
     * Gets or sets the connection point type (default is float)
     */
    get type(): NodeMaterialBlockConnectionPointTypes;
    /**
     * Creates a new InputBlock
     * @param name defines the block name
     * @param target defines the target of that block (Vertex by default)
     * @param type defines the type of the input (can be set to NodeMaterialBlockConnectionPointTypes.AutoDetect)
     */
    constructor(name: string, target?: NodeMaterialBlockTargets, type?: NodeMaterialBlockConnectionPointTypes);
    /**
     * Validates if a name is a reserve word.
     * @param newName the new name to be given to the node.
     * @returns false if the name is a reserve word, else true.
     */
    validateBlockName(newName: string): boolean;
    /**
     * Gets the output component
     */
    get output(): NodeMaterialConnectionPoint;
    /**
     * Set the source of this connection point to a vertex attribute
     * @param attributeName defines the attribute name (position, uv, normal, etc...). If not specified it will take the connection point name
     * @returns the current connection point
     */
    setAsAttribute(attributeName?: string): InputBlock;
    /**
     * Set the source of this connection point to a system value
     * @param value define the system value to use (world, view, etc...) or null to switch to manual value
     * @returns the current connection point
     */
    setAsSystemValue(value: Nullable<NodeMaterialSystemValues>): InputBlock;
    /**
     * Gets or sets the value of that point.
     * Please note that this value will be ignored if valueCallback is defined
     */
    get value(): any;
    set value(value: any);
    /**
     * Gets or sets a callback used to get the value of that point.
     * Please note that setting this value will force the connection point to ignore the value property
     */
    get valueCallback(): () => any;
    set valueCallback(value: () => any);
    /**
     * Gets the declaration variable name in the shader
     */
    get declarationVariableName(): string;
    /**
     * Gets or sets the associated variable name in the shader
     */
    get associatedVariableName(): string;
    set associatedVariableName(value: string);
    /** Gets or sets the type of animation applied to the input */
    get animationType(): AnimatedInputBlockTypes;
    set animationType(value: AnimatedInputBlockTypes);
    /**
     * Gets a boolean indicating that this connection point not defined yet
     */
    get isUndefined(): boolean;
    /**
     * Gets or sets a boolean indicating that this connection point is coming from an uniform.
     * In this case the connection point name must be the name of the uniform to use.
     * Can only be set on inputs
     */
    get isUniform(): boolean;
    set isUniform(value: boolean);
    /**
     * Gets or sets a boolean indicating that this connection point is coming from an attribute.
     * In this case the connection point name must be the name of the attribute to use
     * Can only be set on inputs
     */
    get isAttribute(): boolean;
    set isAttribute(value: boolean);
    /**
     * Gets or sets a boolean indicating that this connection point is generating a varying variable.
     * Can only be set on exit points
     */
    get isVarying(): boolean;
    set isVarying(value: boolean);
    /**
     * Gets a boolean indicating that the current connection point is a system value
     */
    get isSystemValue(): boolean;
    /**
     * Gets or sets the current well known value or null if not defined as a system value
     */
    get systemValue(): Nullable<NodeMaterialSystemValues>;
    set systemValue(value: Nullable<NodeMaterialSystemValues>);
    /**
     * Gets the current class name
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Animate the input if animationType !== None
     * @param scene defines the rendering scene
     */
    animate(scene: Scene): void;
    private _emitDefine;
    initialize(): void;
    /**
     * Set the input block to its default value (based on its type)
     */
    setDefaultValue(): void;
    private _emitConstant;
    /** @internal */
    get _noContextSwitch(): boolean;
    private _emit;
    /**
     * @internal
     */
    _transmitWorld(effect: Effect, world: Matrix, worldView: Matrix, worldViewProjection: Matrix): void;
    /**
     * @internal
     */
    _transmit(effect: Effect, scene: Scene, material: NodeMaterial): void;
    protected _buildBlock(state: NodeMaterialBuildState): void;
    protected _dumpPropertiesCode(): string;
    dispose(): void;
    serialize(): any;
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string): void;
}

/**
 * Enum used to define the compatibility state between two connection points
 */
declare const enum NodeMaterialConnectionPointCompatibilityStates {
    /** Points are compatibles */
    Compatible = 0,
    /** Points are incompatible because of their types */
    TypeIncompatible = 1,
    /** Points are incompatible because of their targets (vertex vs fragment) */
    TargetIncompatible = 2,
    /** Points are incompatible because they are in the same hierarchy **/
    HierarchyIssue = 3
}
/**
 * Defines the direction of a connection point
 */
declare const enum NodeMaterialConnectionPointDirection {
    /** Input */
    Input = 0,
    /** Output */
    Output = 1
}
/**
 * Defines a connection point for a block
 */
declare class NodeMaterialConnectionPoint {
    /**
     * Checks if two types are equivalent
     * @param type1 type 1 to check
     * @param type2 type 2 to check
     * @returns true if both types are equivalent, else false
     */
    static AreEquivalentTypes(type1: number, type2: number): boolean;
    /** @internal */
    _isInactive: boolean;
    /**
     * Boolean used to provide visual clue to users when some ports are not active in the current block configuration
     */
    get isInactive(): boolean;
    /** @internal */
    _preventBubbleUp: boolean;
    /** @internal */
    readonly _ownerBlock: NodeMaterialBlock;
    private _connectedPointBackingField;
    private _connectedPointTypeChangedObserver;
    private get _connectedPoint();
    private set _connectedPoint(value);
    private readonly _endpoints;
    private _associatedVariableName;
    private readonly _direction;
    /** @internal */
    _redirectedSource: Nullable<NodeMaterialConnectionPoint>;
    private _typeConnectionSourceBackingField;
    private _typeConnectionSourceTypeChangedObserver;
    /** @internal */
    get _typeConnectionSource(): Nullable<NodeMaterialConnectionPoint>;
    /** @internal */
    set _typeConnectionSource(value: Nullable<NodeMaterialConnectionPoint>);
    private _defaultConnectionPointTypeBackingField;
    /** @internal */
    get _defaultConnectionPointType(): Nullable<NodeMaterialBlockConnectionPointTypes>;
    /** @internal */
    set _defaultConnectionPointType(value: Nullable<NodeMaterialBlockConnectionPointTypes>);
    /** @internal */
    _isMainLinkSource: boolean;
    private _linkedConnectionSourceBackingField;
    private _linkedConnectionSourceTypeChangedObserver;
    /** @internal */
    get _linkedConnectionSource(): Nullable<NodeMaterialConnectionPoint>;
    /** @internal */
    set _linkedConnectionSource(value: Nullable<NodeMaterialConnectionPoint>);
    /** @internal */
    _acceptedConnectionPointType: Nullable<NodeMaterialConnectionPoint>;
    private _type;
    /** @internal */
    _enforceAssociatedVariableName: boolean;
    /** @internal */
    _forPostBuild: boolean;
    /** Gets the direction of the point */
    get direction(): NodeMaterialConnectionPointDirection;
    /** Indicates that this connection point needs dual validation before being connected to another point */
    needDualDirectionValidation: boolean;
    /**
     * Gets or sets the additional types supported by this connection point
     */
    acceptedConnectionPointTypes: NodeMaterialBlockConnectionPointTypes[];
    /**
     * Gets or sets the additional types excluded by this connection point
     */
    excludedConnectionPointTypes: NodeMaterialBlockConnectionPointTypes[];
    /**
     * Observable triggered when this point is connected
     */
    readonly onConnectionObservable: Observable<NodeMaterialConnectionPoint>;
    /**
     * Observable triggered when this point is disconnected
     */
    readonly onDisconnectionObservable: Observable<NodeMaterialConnectionPoint>;
    /**
     * Observable triggered when the type of the connection point is changed
     */
    readonly onTypeChangedObservable: Observable<NodeMaterialBlockConnectionPointTypes>;
    private _isTypeChangeObservableNotifying;
    /**
     * Gets the declaration variable name in the shader
     */
    get declarationVariableName(): string;
    /**
     * Gets or sets the associated variable name in the shader
     */
    get associatedVariableName(): string;
    set associatedVariableName(value: string);
    /** Get the inner type (ie AutoDetect for instance instead of the inferred one) */
    get innerType(): NodeMaterialBlockConnectionPointTypes;
    /**
     * Gets or sets the connection point type (default is float)
     */
    get type(): NodeMaterialBlockConnectionPointTypes;
    set type(value: NodeMaterialBlockConnectionPointTypes);
    /**
     * Gets or sets the connection point name
     */
    readonly name: string;
    /**
     * Gets or sets the connection point name
     */
    displayName: string;
    /**
     * Gets or sets a boolean indicating that this connection point can be omitted
     */
    isOptional: boolean;
    /**
     * Gets or sets a boolean indicating that this connection point is exposed on a frame
     */
    isExposedOnFrame: boolean;
    /**
     * Gets or sets number indicating the position that the port is exposed to on a frame
     */
    exposedPortPosition: number;
    /**
     * Gets or sets a string indicating that this uniform must be defined under a #ifdef
     */
    define: string;
    /** @internal */
    _prioritizeVertex: boolean;
    private _target;
    /** Gets or sets the target of that connection point */
    get target(): NodeMaterialBlockTargets;
    set target(value: NodeMaterialBlockTargets);
    /**
     * Gets a boolean indicating that the current point is connected to another NodeMaterialBlock
     */
    get isConnected(): boolean;
    /**
     * Gets a boolean indicating that the current point is connected to an input block
     */
    get isConnectedToInputBlock(): boolean;
    /**
     * Gets a the connected input block (if any)
     */
    get connectInputBlock(): Nullable<InputBlock>;
    /** Get the other side of the connection (if any) */
    get connectedPoint(): Nullable<NodeMaterialConnectionPoint>;
    /** Get the block that owns this connection point */
    get ownerBlock(): NodeMaterialBlock;
    /** Get the block connected on the other side of this connection (if any) */
    get sourceBlock(): Nullable<NodeMaterialBlock>;
    /** Get the block connected on the endpoints of this connection (if any) */
    get connectedBlocks(): Array<NodeMaterialBlock>;
    /** Gets the list of connected endpoints */
    get endpoints(): NodeMaterialConnectionPoint[];
    /** Gets a boolean indicating if that output point is connected to at least one input */
    get hasEndpoints(): boolean;
    /** Gets a boolean indicating that this connection has a path to the vertex output*/
    get isDirectlyConnectedToVertexOutput(): boolean;
    /** Gets a boolean indicating that this connection will be used in the vertex shader */
    get isConnectedInVertexShader(): boolean;
    /** Gets a boolean indicating that this connection will be used in the fragment shader */
    get isConnectedInFragmentShader(): boolean;
    /**
     * Creates a block suitable to be used as an input for this input point.
     * If null is returned, a block based on the point type will be created.
     * @returns The returned string parameter is the name of the output point of NodeMaterialBlock (first parameter of the returned array) that can be connected to the input
     */
    createCustomInputBlock(): Nullable<[NodeMaterialBlock, string]>;
    /**
     * Creates a new connection point
     * @param name defines the connection point name
     * @param ownerBlock defines the block hosting this connection point
     * @param direction defines the direction of the connection point
     */
    constructor(name: string, ownerBlock: NodeMaterialBlock, direction: NodeMaterialConnectionPointDirection);
    /**
     * Gets the current class name e.g. "NodeMaterialConnectionPoint"
     * @returns the class name
     */
    getClassName(): string;
    /**
     * Gets a boolean indicating if the current point can be connected to another point
     * @param connectionPoint defines the other connection point
     * @returns a boolean
     */
    canConnectTo(connectionPoint: NodeMaterialConnectionPoint): boolean;
    /**
     * Gets a number indicating if the current point can be connected to another point
     * @param connectionPoint defines the other connection point
     * @returns a number defining the compatibility state
     */
    checkCompatibilityState(connectionPoint: NodeMaterialConnectionPoint): NodeMaterialConnectionPointCompatibilityStates;
    /**
     * Connect this point to another connection point
     * @param connectionPoint defines the other connection point
     * @param ignoreConstraints defines if the system will ignore connection type constraints (default is false)
     * @returns the current connection point
     */
    connectTo(connectionPoint: NodeMaterialConnectionPoint, ignoreConstraints?: boolean): NodeMaterialConnectionPoint;
    /**
     * Disconnect this point from one of his endpoint
     * @param endpoint defines the other connection point
     * @returns the current connection point
     */
    disconnectFrom(endpoint: NodeMaterialConnectionPoint): NodeMaterialConnectionPoint;
    /**
     * Fill the list of excluded connection point types with all types other than those passed in the parameter
     * @param mask Types (ORed values of NodeMaterialBlockConnectionPointTypes) that are allowed, and thus will not be pushed to the excluded list
     */
    addExcludedConnectionPointFromAllowedTypes(mask: number): void;
    /**
     * Serializes this point in a JSON representation
     * @param isInput defines if the connection point is an input (default is true)
     * @returns the serialized point object
     */
    serialize(isInput?: boolean): any;
    /**
     * Release resources
     */
    dispose(): void;
    private _updateTypeDependentState;
    private _notifyTypeChanged;
}

/**
 * Class used to store shared data between 2 NodeMaterialBuildState
 */
declare class NodeMaterialBuildStateSharedData {
    /**
     * The node material we are currently building
     */
    nodeMaterial: NodeMaterial;
    /**
     * Gets the list of emitted varyings
     */
    temps: string[];
    /**
     * Gets the list of emitted varyings
     */
    varyings: string[];
    /**
     * Gets the varying declaration string (for vertex shader)
     */
    varyingDeclaration: string;
    /**
     * Gets the varying declaration string (for fragment shader)
     * This is potentially different from varyingDeclaration only in WebGPU
     */
    varyingDeclarationFragment: string;
    /**
     * Gets the varying initialization string (for fragment shader)
     * Only used in WebGPU, to reconstruct the varying values from the vertex shader if their types is mat4x4f
     */
    varyingInitializationsFragment: string;
    /**
     * List of the fragment output nodes
     */
    fragmentOutputNodes: Immutable<Array<NodeMaterialBlock>>;
    /**
     * Input blocks
     */
    inputBlocks: InputBlock[];
    /**
     * Input blocks
     */
    textureBlocks: NodeMaterialTextureBlocks[];
    /**
     * Bindable blocks (Blocks that need to set data to the effect)
     */
    bindableBlocks: NodeMaterialBlock[];
    /**
     * Bindable blocks (Blocks that need to set data to the effect) that will always be called (by bindForSubMesh), contrary to bindableBlocks that won't be called if _mustRebind() returns false
     */
    forcedBindableBlocks: NodeMaterialBlock[];
    /**
     * List of blocks that can provide a compilation fallback
     */
    blocksWithFallbacks: NodeMaterialBlock[];
    /**
     * List of blocks that can provide a define update
     */
    blocksWithDefines: NodeMaterialBlock[];
    /**
     * List of blocks that can provide a repeatable content
     */
    repeatableContentBlocks: NodeMaterialBlock[];
    /**
     * List of blocks that can provide a dynamic list of uniforms
     */
    dynamicUniformBlocks: NodeMaterialBlock[];
    /**
     * List of blocks that can block the isReady function for the material
     */
    blockingBlocks: NodeMaterialBlock[];
    /**
     * Gets the list of animated inputs
     */
    animatedInputs: InputBlock[];
    /**
     * Defines to inject in the vertex and fragment shaders
     */
    defines: {
        [key: string]: string;
    };
    /**
     * Configurations used to format the generated code
     */
    formatConfig: {
        getUniformAnnotation: Nullable<(name: string) => string>;
        formatVariablename: (name: string) => string;
    };
    /**
     * Build Id used to avoid multiple recompilations
     */
    buildId: number;
    /** List of emitted variables */
    variableNames: {
        [key: string]: number;
    };
    /** List of emitted defines */
    defineNames: {
        [key: string]: number;
    };
    /** Should emit comments? */
    emitComments: boolean;
    /** Emit build activity */
    verbose: boolean;
    /** Gets or sets the hosting scene */
    scene: Scene;
    /**
     * Gets the compilation hints emitted at compilation time
     */
    hints: {
        needWorldViewMatrix: boolean;
        needWorldViewProjectionMatrix: boolean;
        needAlphaBlending: boolean;
        needAlphaTesting: boolean;
    };
    /**
     * List of compilation checks
     */
    checks: {
        emitVertex: boolean;
        emitFragment: boolean;
        notConnectedNonOptionalInputs: NodeMaterialConnectionPoint[];
        customErrors: string[];
    };
    /**
     * Is vertex program allowed to be empty?
     */
    allowEmptyVertexProgram: boolean;
    /** Creates a new shared data */
    constructor();
    /**
     * Push a new error to the build state, avoiding exceptions that can break the build process
     * @param message defines the error message to push
     */
    raiseBuildError(message: string): void;
    /**
     * Emits console errors and exceptions if there is a failing check
     * @returns true if all checks pass
     */
    emitErrors(): boolean;
}

/**
 * Class used to store node based material build state
 */
declare class NodeMaterialBuildState {
    /** Gets or sets a boolean indicating if the current state can emit uniform buffers */
    supportUniformBuffers: boolean;
    /**
     * Gets the list of emitted attributes
     */
    attributes: string[];
    /**
     * Gets the list of emitted uniforms
     */
    uniforms: string[];
    /**
     * Gets the list of emitted constants
     */
    constants: string[];
    /**
     * Gets the list of emitted samplers
     */
    samplers: string[];
    /**
     * Gets the list of emitted functions
     */
    functions: {
        [key: string]: string;
    };
    /**
     * Gets the list of emitted extensions
     */
    extensions: {
        [key: string]: string;
    };
    /**
     * Gets the list of emitted prePass outputs - if using the prepass
     */
    prePassOutput: {
        [key: string]: string;
    };
    /**
     * Gets the target of the compilation state
     */
    target: NodeMaterialBlockTargets;
    /**
     * Gets the list of emitted counters
     */
    counters: {
        [key: string]: number;
    };
    /**
     * Shared data between multiple NodeMaterialBuildState instances
     */
    sharedData: NodeMaterialBuildStateSharedData;
    /** @internal */
    _terminalBlocks: Set<NodeMaterialBlock>;
    /** @internal */
    _vertexState: NodeMaterialBuildState;
    /** @internal */
    _attributeDeclaration: string;
    /** @internal */
    _uniformDeclaration: string;
    /** @internal */
    _constantDeclaration: string;
    /** @internal */
    _samplerDeclaration: string;
    /** @internal */
    _varyingTransfer: string;
    /** @internal */
    _injectAtEnd: string;
    /** @internal */
    _injectAtTop: string;
    /** @internal */
    _customEntryHeader: string;
    /** @internal */
    private _repeatableContentAnchorIndex;
    /** @internal */
    _builtCompilationString: string;
    /**
     * Gets the emitted compilation strings
     */
    compilationString: string;
    /**
     * Gets the current shader language to use
     */
    get shaderLanguage(): ShaderLanguage;
    /** Gets suffix to add behind type casting */
    get fSuffix(): "" | "f";
    /**
     * Returns the processed, compiled shader code
     * @param defines defines to use for the shader processing
     * @returns the raw shader code used by the engine
     */
    getProcessedShaderAsync(defines: string): Promise<string>;
    /**
     * Finalize the compilation strings
     * @param state defines the current compilation state
     */
    finalize(state: NodeMaterialBuildState): void;
    /** @internal */
    get _repeatableContentAnchor(): string;
    /**
     * @internal
     */
    _getFreeVariableName(prefix: string): string;
    /**
     * @internal
     */
    _getFreeDefineName(prefix: string): string;
    /**
     * @internal
     */
    _excludeVariableName(name: string): void;
    /**
     * @internal
     */
    _emit2DSampler(name: string, define?: string, force?: boolean, annotation?: string, unsignedSampler?: boolean, precision?: string): void;
    /**
     * @internal
     */
    _emitCubeSampler(name: string, define?: string, force?: boolean): void;
    /**
     * @internal
     */
    _emit2DArraySampler(name: string): void;
    /**
     * @internal
     */
    _getGLType(type: NodeMaterialBlockConnectionPointTypes): string;
    /**
     * @internal
     */
    _getShaderType(type: NodeMaterialBlockConnectionPointTypes): "" | "f32" | "float" | "i32" | "int" | "vec2f" | "vec2" | "vec3f" | "vec3" | "vec4f" | "vec4" | "mat4x4f" | "mat4";
    /**
     * @internal
     */
    _emitExtension(name: string, extension: string, define?: string): void;
    /**
     * @internal
     */
    _emitFunction(name: string, code: string, comments: string): void;
    /**
     * @internal
     */
    _emitCodeFromInclude(includeName: string, comments: string, options?: {
        replaceStrings?: {
            search: RegExp;
            replace: string;
        }[];
        repeatKey?: string;
        substitutionVars?: string;
    }): string;
    /**
     * @internal
     */
    _emitFunctionFromInclude(includeName: string, comments: string, options?: {
        repeatKey?: string;
        substitutionVars?: string;
        removeAttributes?: boolean;
        removeUniforms?: boolean;
        removeVaryings?: boolean;
        removeIfDef?: boolean;
        replaceStrings?: {
            search: RegExp;
            replace: string;
        }[];
    }, storeKey?: string): void;
    /**
     * @internal
     */
    _registerTempVariable(name: string): boolean;
    private _emitDefineStart;
    private _emitDefineEnd;
    /**
     * @internal
     */
    _emitVaryingFromString(name: string, type: NodeMaterialBlockConnectionPointTypes, define?: string, notDefine?: boolean): boolean;
    /**
     * @internal
     */
    _getVaryingName(name: string): string;
    /**
     * @internal
     */
    _emitUniformFromString(name: string, type: NodeMaterialBlockConnectionPointTypes, define?: string, notDefine?: boolean): void;
    /**
     * @internal
     */
    _generateTernary(trueStatement: string, falseStatement: string, condition: string): string;
    /**
     * @internal
     */
    _emitFloat(value: number): string;
    /**
     * @internal
     */
    _declareOutput(output: NodeMaterialConnectionPoint, isConst?: boolean): string;
    /**
     * @internal
     */
    _declareLocalVar(name: string, type: NodeMaterialBlockConnectionPointTypes, isConst?: boolean, isVarPrivate?: boolean): string;
    /**
     * @internal
     */
    _samplerCubeFunc(): "textureSample" | "textureCube";
    /**
     * @internal
     */
    _samplerFunc(): "textureSample" | "texture2D";
    /**
     * @internal
     */
    _samplerLODFunc(): "textureSampleLevel" | "texture2DLodEXT";
    _toLinearSpace(output: NodeMaterialConnectionPoint): string;
    /**
     * @internal
     */
    _generateTextureSample(uv: string, samplerName: string): string;
    /**
     * @internal
     */
    _generateTextureSampleLOD(uv: string, samplerName: string, lod: string): string;
    /**
     * @internal
     */
    _generateTextureSampleCube(uv: string, samplerName: string): string;
    /**
     * @internal
     */
    _generateTextureSampleCubeLOD(uv: string, samplerName: string, lod: string): string;
    private _convertVariableDeclarationToWGSL;
    private _convertVariableConstructorsToWGSL;
    private _convertOutParametersToWGSL;
    private _convertTernaryOperandsToWGSL;
    private _convertModOperatorsToWGSL;
    private _convertConstToWGSL;
    private _convertInnerFunctionsToWGSL;
    private _convertFunctionsToWGSL;
    _babylonSLtoWGSL(code: string): string;
    private _convertTernaryOperandsToGLSL;
    _babylonSLtoGLSL(code: string): string;
}

/**
 * Defines a block that can be used inside a node based material
 */
declare class NodeMaterialBlock {
    private _buildId;
    private _buildTarget;
    protected _target: NodeMaterialBlockTargets;
    private _isFinalMerger;
    private _isInput;
    private _isLoop;
    private _isTeleportOut;
    private _isTeleportIn;
    private _name;
    protected _isUnique: boolean;
    protected _codeIsReady: boolean;
    /** @internal */
    _isFinalOutput: boolean;
    /** @internal */
    get _isFinalOutputAndActive(): boolean;
    /** @internal */
    get _hasPrecedence(): boolean;
    /**
     * Observable raised when the block code is ready (if the code loading is async)
     */
    onCodeIsReadyObservable: Observable<NodeMaterialBlock>;
    /** Gets or sets a boolean indicating that only one input can be connected at a time */
    inputsAreExclusive: boolean;
    /** @internal */
    _codeVariableName: string;
    /** @internal */
    _inputs: NodeMaterialConnectionPoint[];
    /** @internal */
    _outputs: NodeMaterialConnectionPoint[];
    /** @internal */
    _preparationId: number;
    /** @internal */
    readonly _originalTargetIsNeutral: boolean;
    /**
     * Gets the name of the block
     */
    get name(): string;
    /**
     * Gets a boolean indicating that this block has is code ready to be used
     */
    get codeIsReady(): boolean;
    /**
     * Sets the name of the block. Will check if the name is valid.
     */
    set name(newName: string);
    /**
     * Gets or sets the unique id of the node
     */
    uniqueId: number;
    /**
     * Gets or sets the comments associated with this block
     */
    comments: string;
    /**
     * Gets a boolean indicating that this block can only be used once per NodeMaterial
     */
    get isUnique(): boolean;
    /**
     * Gets a boolean indicating that this block is an end block (e.g. it is generating a system value)
     */
    get isFinalMerger(): boolean;
    /**
     * Gets a boolean indicating that this block is an input (e.g. it sends data to the shader)
     */
    get isInput(): boolean;
    /**
     * Gets a boolean indicating if this block is a teleport out
     */
    get isTeleportOut(): boolean;
    /**
     * Gets a boolean indicating if this block is a teleport in
     */
    get isTeleportIn(): boolean;
    /**
     * Gets a boolean indicating if this block is a loop
     */
    get isLoop(): boolean;
    /**
     * Gets or sets the build Id
     */
    get buildId(): number;
    set buildId(value: number);
    /**
     * Gets or sets the target of the block
     */
    get target(): NodeMaterialBlockTargets;
    set target(value: NodeMaterialBlockTargets);
    /**
     * Gets the list of input points
     */
    get inputs(): NodeMaterialConnectionPoint[];
    /** Gets the list of output points */
    get outputs(): NodeMaterialConnectionPoint[];
    /**
     * Find an input by its name
     * @param name defines the name of the input to look for
     * @returns the input or null if not found
     */
    getInputByName(name: string): NodeMaterialConnectionPoint | null;
    /**
     * Find an output by its name
     * @param name defines the name of the output to look for
     * @returns the output or null if not found
     */
    getOutputByName(name: string): NodeMaterialConnectionPoint | null;
    /** Gets or sets a boolean indicating that this input can be edited in the Inspector (false by default) */
    visibleInInspector: boolean;
    /** Gets or sets a boolean indicating that this input can be edited from a collapsed frame */
    visibleOnFrame: boolean;
    /**
     * Creates a new NodeMaterialBlock
     * @param name defines the block name
     * @param target defines the target of that block (Vertex by default)
     * @param isFinalMerger defines a boolean indicating that this block is an end block (e.g. it is generating a system value). Default is false
     * @param isFinalOutput defines a boolean indicating that this block is generating a final output and no other block should be generated after
     */
    constructor(name: string, target?: NodeMaterialBlockTargets, isFinalMerger?: boolean, isFinalOutput?: boolean);
    /** @internal */
    _setInitialTarget(target: NodeMaterialBlockTargets): void;
    /**
     * Initialize the block and prepare the context for build
     * @param state defines the state that will be used for the build
     */
    initialize(state: NodeMaterialBuildState): void;
    /**
     * Bind data to effect. Will only be called for blocks with isBindable === true
     * @param effect defines the effect to bind data to
     * @param nodeMaterial defines the hosting NodeMaterial
     * @param mesh defines the mesh that will be rendered
     * @param subMesh defines the submesh that will be rendered
     */
    bind(effect: Effect, nodeMaterial: NodeMaterial, mesh?: Mesh, subMesh?: SubMesh): void;
    protected _writeVariable(currentPoint: NodeMaterialConnectionPoint): string;
    protected _writeFloat(value: number): string;
    /**
     * Gets the current class name e.g. "NodeMaterialBlock"
     * @returns the class name
     */
    getClassName(): string;
    /** Gets a boolean indicating that this connection will be used in the fragment shader
     * @returns true if connected in fragment shader
     */
    isConnectedInFragmentShader(): boolean;
    /**
     * Register a new input. Must be called inside a block constructor
     * @param name defines the connection point name
     * @param type defines the connection point type
     * @param isOptional defines a boolean indicating that this input can be omitted
     * @param target defines the target to use to limit the connection point (will be VertexAndFragment by default)
     * @param point an already created connection point. If not provided, create a new one
     * @returns the current block
     */
    registerInput(name: string, type: NodeMaterialBlockConnectionPointTypes, isOptional?: boolean, target?: NodeMaterialBlockTargets, point?: NodeMaterialConnectionPoint): this;
    /**
     * Register a new output. Must be called inside a block constructor
     * @param name defines the connection point name
     * @param type defines the connection point type
     * @param target defines the target to use to limit the connection point (will be VertexAndFragment by default)
     * @param point an already created connection point. If not provided, create a new one
     * @returns the current block
     */
    registerOutput(name: string, type: NodeMaterialBlockConnectionPointTypes, target?: NodeMaterialBlockTargets, point?: NodeMaterialConnectionPoint): this;
    /**
     * Will return the first available input e.g. the first one which is not an uniform or an attribute
     * @param forOutput defines an optional connection point to check compatibility with
     * @returns the first available input or null
     */
    getFirstAvailableInput(forOutput?: Nullable<NodeMaterialConnectionPoint>): NodeMaterialConnectionPoint | null;
    /**
     * Will return the first available output e.g. the first one which is not yet connected and not a varying
     * @param forBlock defines an optional block to check compatibility with
     * @returns the first available input or null
     */
    getFirstAvailableOutput(forBlock?: Nullable<NodeMaterialBlock>): NodeMaterialConnectionPoint | null;
    /**
     * Gets the sibling of the given output
     * @param current defines the current output
     * @returns the next output in the list or null
     */
    getSiblingOutput(current: NodeMaterialConnectionPoint): NodeMaterialConnectionPoint | null;
    /**
     * Checks if the current block is an ancestor of a given block
     * @param block defines the potential descendant block to check
     * @returns true if block is a descendant
     */
    isAnAncestorOf(block: NodeMaterialBlock): boolean;
    /**
     * Connect current block with another block
     * @param other defines the block to connect with
     * @param options define the various options to help pick the right connections
     * @param options.input
     * @param options.output
     * @param options.outputSwizzle
     * @returns the current block
     */
    connectTo(other: NodeMaterialBlock, options?: {
        input?: string;
        output?: string;
        outputSwizzle?: string;
    }): this | undefined;
    protected _buildBlock(state: NodeMaterialBuildState): void;
    protected _postBuildBlock(state: NodeMaterialBuildState): void;
    /**
     * Add uniforms, samplers and uniform buffers at compilation time
     * @param state defines the state to update
     * @param nodeMaterial defines the node material requesting the update
     * @param defines defines the material defines to update
     * @param uniformBuffers defines the list of uniform buffer names
     */
    updateUniformsAndSamples(state: NodeMaterialBuildState, nodeMaterial: NodeMaterial, defines: NodeMaterialDefines, uniformBuffers: string[]): void;
    /**
     * Add potential fallbacks if shader compilation fails
     * @param fallbacks defines the current prioritized list of fallbacks
     * @param mesh defines the mesh to be rendered
     */
    provideFallbacks(fallbacks: EffectFallbacks, mesh?: AbstractMesh): void;
    /**
     * Initialize defines for shader compilation
     * @param defines defines the material defines to update
     */
    initializeDefines(defines: NodeMaterialDefines): void;
    /**
     * Update defines for shader compilation
     * @param defines defines the material defines to update
     * @param nodeMaterial defines the node material requesting the update
     * @param mesh defines the mesh to be rendered
     * @param useInstances specifies that instances should be used
     * @param subMesh defines which submesh to render
     */
    prepareDefines(defines: NodeMaterialDefines, nodeMaterial: NodeMaterial, mesh?: AbstractMesh, useInstances?: boolean, subMesh?: SubMesh): void;
    /**
     * Lets the block try to connect some inputs automatically
     * @param material defines the hosting NodeMaterial
     * @param additionalFilteringInfo optional additional filtering condition when looking for compatible blocks
     */
    autoConfigure(material: NodeMaterial, additionalFilteringInfo?: (node: NodeMaterialBlock) => boolean): void;
    /**
     * Function called when a block is declared as repeatable content generator
     * @param vertexShaderState defines the current compilation state for the vertex shader
     * @param defines defines the material defines to update
     * @param mesh defines the mesh to be rendered
     */
    replaceRepeatableContent(vertexShaderState: NodeMaterialBuildState, defines: NodeMaterialDefines, mesh?: AbstractMesh): void;
    /** Gets a boolean indicating that the code of this block will be promoted to vertex shader even if connected to fragment output */
    get willBeGeneratedIntoVertexShaderFromFragmentShader(): boolean;
    /**
     * Checks if the block is ready
     * @param mesh defines the mesh to be rendered
     * @param nodeMaterial defines the node material requesting the update
     * @param defines defines the material defines to update
     * @param useInstances specifies that instances should be used
     * @returns true if the block is ready
     */
    isReady(mesh: AbstractMesh, nodeMaterial: NodeMaterial, defines: NodeMaterialDefines, useInstances?: boolean): boolean;
    protected _linkConnectionTypes(inputIndex0: number, inputIndex1: number, looseCoupling?: boolean): void;
    private _processBuild;
    /**
     * Validates the new name for the block node.
     * @param newName the new name to be given to the node.
     * @returns false if the name is a reserve word, else true.
     */
    validateBlockName(newName: string): boolean;
    protected _customBuildStep(state: NodeMaterialBuildState, activeBlocks: NodeMaterialBlock[]): void;
    /**
     * Compile the current node and generate the shader code
     * @param state defines the current compilation state (uniforms, samplers, current string)
     * @param activeBlocks defines the list of active blocks (i.e. blocks to compile)
     * @returns true if already built
     */
    build(state: NodeMaterialBuildState, activeBlocks: NodeMaterialBlock[]): boolean;
    protected _inputRename(name: string): string;
    protected _outputRename(name: string): string;
    protected _dumpPropertiesCode(): string;
    /**
     * @internal
     */
    _dumpCode(uniqueNames: string[], alreadyDumped: NodeMaterialBlock[]): string;
    /**
     * @internal
     */
    _dumpCodeForOutputConnections(alreadyDumped: NodeMaterialBlock[]): string;
    /**
     * Clone the current block to a new identical block
     * @param scene defines the hosting scene
     * @param rootUrl defines the root URL to use to load textures and relative dependencies
     * @returns a copy of the current block
     */
    clone(scene: Scene, rootUrl?: string): NodeMaterialBlock | null;
    /**
     * Serializes this block in a JSON representation
     * @returns the serialized block object
     */
    serialize(): any;
    /**
     * @internal
     */
    _deserialize(serializationObject: any, scene: Scene, rootUrl: string, urlRewriter?: (url: string) => string): void;
    private _deserializePortDisplayNamesAndExposedOnFrame;
    /**
     * Release resources
     */
    dispose(): void;
}

/**
 * Class used to store a color step for the GradientBlock
 */
declare class GradientBlockColorStep {
    private _step;
    /**
     * Gets value indicating which step this color is associated with (between 0 and 1)
     */
    get step(): number;
    /**
     * Sets a value indicating which step this color is associated with (between 0 and 1)
     */
    set step(val: number);
    private _color;
    /**
     * Gets the color associated with this step
     */
    get color(): Color3;
    /**
     * Sets the color associated with this step
     */
    set color(val: Color3);
    /**
     * Creates a new GradientBlockColorStep
     * @param step defines a value indicating which step this color is associated with (between 0 and 1)
     * @param color defines the color associated with this step
     */
    constructor(step: number, color: Color3);
}

/**
 * Component wrapper for FactorGradient that provides slider inputs for factor1, factor2, and gradient step
 * @param props - Component props containing FactorGradient value and change handler
 * @returns A React component
 */
declare const FactorGradientComponent: FunctionComponent<PrimitiveProps<FactorGradient>>;
/**
 * Component wrapper for Color3Gradient that provides color picker and gradient step slider
 * @param props - Component props containing Color3Gradient value and change handler
 * @returns A React component
 */
declare const Color3GradientComponent: FunctionComponent<PrimitiveProps<Color3Gradient>>;
/**
 * Component wrapper for Color4Gradient that provides color pickers for color1, color2, and gradient step slider
 * @param props - Component props containing Color4Gradient value and change handler
 * @returns A React component
 */
declare const Color4GradientComponent: FunctionComponent<PrimitiveProps<ColorGradient>>;
/**
 * Component wrapper for GradientBlockColorStep that provides color picker and step slider
 * @param props - Component props containing GradientBlockColorStep value and change handler
 * @returns A React component
 */
declare const ColorStepGradientComponent: FunctionComponent<PrimitiveProps<GradientBlockColorStep>>;

type LazyComponentProps = {
    spinnerSize?: SpinnerProps["size"];
    spinnerLabel?: string;
};
/**
 * Creates a lazy component wrapper that only calls the async function to get the underlying component when the lazy component is actually mounted.
 * This allows deferring imports until they are needed. While the underlying component is being loaded, a spinner is displayed.
 * @param getComponentAsync A function that returns a promise resolving to the component.
 * @param defaultProps Options for the loading spinner.
 * @returns A React component that displays a spinner while loading the async component.
 */
declare function MakeLazyComponent<ComponentT extends ComponentType<any>>(getComponentAsync: () => Promise<ComponentT>, defaultProps?: LazyComponentProps): react.ForwardRefExoticComponent<react.PropsWithoutRef<ComponentProps<ComponentT> & LazyComponentProps> & react.RefAttributes<ElementRef<_fluentui_react_utilities.ForwardRefComponent<SpinnerProps> | ComponentT>>>;

type LinkProps = ImmutablePrimitiveProps<string> & {
    /**
     * Used if you want to handle the link click yourself
     */
    onLink?: () => void;
    /**
     * The URL the link points to
     */
    url?: string;
    /**
     * Defines whether to open the link in current tab or new tab. Default is new
     */
    target?: "current" | "new";
    /**Force link size */
    size?: "small" | "medium";
};
declare const Link: react.ForwardRefExoticComponent<BasePrimitiveProps & {
    value: string;
    infoLabel?: InfoLabelParentProps;
} & {
    /**
     * Used if you want to handle the link click yourself
     */
    onLink?: () => void;
    /**
     * The URL the link points to
     */
    url?: string;
    /**
     * Defines whether to open the link in current tab or new tab. Default is new
     */
    target?: "current" | "new";
    /**Force link size */
    size?: "small" | "medium";
} & {
    children?: react.ReactNode | undefined;
} & react.RefAttributes<HTMLAnchorElement>>;

/**
 * Represents an item in a list
 */
type ListItem<T> = {
    /** Unique identifier for the item */
    id: number;
    /** The data associated with the item */
    data: T;
    /** Value to use for sorting the list */
    sortBy: number;
};
type ListProps<T> = {
    items: ListItem<T>[];
    renderItem: (item: ListItem<T>, index: number) => ReactNode;
    onDelete?: (item: ListItem<T>, index: number) => void;
    onAdd?: (item?: ListItem<T>) => void;
    addButtonLabel?: string;
};
/**
 * For cases where you may want to add / remove items from a list via a trash can button / copy button, this HOC can be used
 * @returns A React component that renders a list of items with add/delete functionality
 * @param props - The properties for the List component
 */
declare function List<T>(props: ListProps<T>): ReactElement;

type MessageBarProps = {
    message: string;
    title?: string;
    docLink?: string;
    intent: "info" | "success" | "warning" | "error";
};
declare const MessageBar: FunctionComponent<MessageBarProps>;

type PositionedPopoverProps = {
    x: number;
    y: number;
    visible: boolean;
    hide: () => void;
};
/**
 * PositionedPopover component that shows a popover at specific coordinates
 * @param props - The component props
 * @returns The positioned popover component
 */
declare const PositionedPopover: FunctionComponent<PropsWithChildren<PositionedPopoverProps>>;

type SearchProps = {
    onChange: (val: string) => void;
    placeholder?: string;
};
declare const SearchBar: react.ForwardRefExoticComponent<SearchProps & react.RefAttributes<HTMLInputElement>>;

type SearchBoxProps = {
    items: string[];
    onItemSelected: (item: string) => void;
    title?: string;
};
/**
 * SearchBox component that displays a popup with search functionality
 * @param props - The component props
 * @returns The search box component
 */
declare const SearchBox: FunctionComponent<SearchBoxProps>;

type SpinButtonProps = PrimitiveProps<number> & {
    min?: number;
    max?: number;
    /** Determines how much the spinbutton increments with the arrow keys. Note this also determines the precision value (# of decimals in display value)
     * i.e. if step = 1, precision = 0. step = 0.0089, precision = 4. step = 300, precision = 2. step = 23.00, precision = 2. */
    step?: number;
    unit?: string;
    forceInt?: boolean;
    validator?: (value: number) => boolean;
    /** Optional className for the input element */
    inputClassName?: string;
};
declare const SpinButton: react.ForwardRefExoticComponent<BasePrimitiveProps & {
    value: number;
    infoLabel?: InfoLabelParentProps;
} & {
    onChange: (value: number) => void;
} & {
    min?: number;
    max?: number;
    /** Determines how much the spinbutton increments with the arrow keys. Note this also determines the precision value (# of decimals in display value)
     * i.e. if step = 1, precision = 0. step = 0.0089, precision = 4. step = 300, precision = 2. step = 23.00, precision = 2. */
    step?: number;
    unit?: string;
    forceInt?: boolean;
    validator?: (value: number) => boolean;
    /** Optional className for the input element */
    inputClassName?: string;
} & react.RefAttributes<HTMLInputElement>>;

type SwitchProps = PrimitiveProps<boolean>;
/**
 * This is a primitive fluent boolean switch component whose only knowledge is the shared styling across all tools
 * @param props
 * @returns Switch component
 */
declare const Switch: FunctionComponent<SwitchProps>;

type SyncedSliderProps = PrimitiveProps<number> & {
    /** Minimum value for the slider */
    min?: number;
    /** Maximum value for the slider */
    max?: number;
    /** Step size for the slider */
    step?: number;
    /** Displayed in the ux to indicate unit of measurement */
    unit?: string;
    /** When true, onChange is only called when the user releases the slider, not during drag */
    notifyOnlyOnRelease?: boolean;
    /** When true, slider grows to fill space and SpinButton is fixed at 65px */
    compact?: boolean;
    /** When true, slider grows to fill all available space (no maxWidth constraint) */
    growSlider?: boolean;
};
/**
 * Component which synchronizes a slider and an input field, allowing the user to change the value using either control
 * @param props
 * @returns SyncedSlider component
 */
declare const SyncedSliderInput: FunctionComponent<SyncedSliderProps>;

type TextareaProps = PrimitiveProps<string> & {
    placeholder?: string;
};
/**
 * This is a texarea box that stops propagation of change/keydown events
 * @param props
 * @returns
 */
declare const Textarea: FunctionComponent<TextareaProps>;

type TextInputProps = PrimitiveProps<string> & {
    validator?: (value: string) => boolean;
    validateOnlyOnBlur?: boolean;
};
declare const TextInput: FunctionComponent<TextInputProps>;

type ToggleButtonProps = Omit<ButtonProps, "icon" | "onClick"> & {
    value: boolean;
    checkedIcon: FluentIcon;
    uncheckedIcon?: FluentIcon;
    onChange: (checked: boolean) => void;
};
/**
 * Toggles between two states using a button with icons.
 * If no disabledIcon is provided, the button will toggle between visual enabled/disabled states without an icon change
 *
 * @param props
 * @returns
 */
declare const ToggleButton: FunctionComponent<ToggleButtonProps>;

type ButtonLineProps = Omit<ButtonProps, "label"> & {
    label: string;
};
/**
 * Wraps a button with a label in a line container
 * @param props Button props plus a label
 * @returns A button inside a line
 */
declare const ButtonLine: FunctionComponent<ButtonLineProps>;

type ChildWindowOptions = {
    /**
     * The default width of the child window in pixels.
     * @remarks Ignored if the ChildWindow was passed an id and previous bounds were saved.
     */
    defaultWidth?: number;
    /**
     * The default height of the child window in pixels.
     * @remarks Ignored if the ChildWindow was passed an id and previous bounds were saved.
     */
    defaultHeight?: number;
    /**
     * The default left position of the child window in pixels.
     * @remarks Ignored if the ChildWindow was passed an id and previous bounds were saved.
     */
    defaultLeft?: number;
    /**
     * The default top position of the child window in pixels.
     * @remarks Ignored if the ChildWindow was passed an id and previous bounds were saved.
     */
    defaultTop?: number;
    /**
     * The title of the child window.
     * @remarks If not provided, the id will be used instead (if any).
     */
    title?: string;
};
type ChildWindowProps = {
    /**
     * An optional unique identity for the child window.
     * @remarks If provided, the child window's bounds will be saved/restored using this identity.
     */
    id?: string;
    /**
     * Called when the open state of the child window changes.
     * @param isOpen Whether the child window is open.
     */
    onOpenChange?: (isOpen: boolean) => void;
    /**
     * A ref that exposes the ChildWindow imperative API.
     */
    imperativeRef?: Ref<ChildWindow>;
};
type ChildWindow = {
    /**
     * Opens the child window.
     * @param options Options for opening the child window.
     */
    open: (options?: ChildWindowOptions) => void;
    /**
     * Closes the child window.
     */
    close: () => void;
};
/**
 * Allows displaying a child window that can contain child components.
 * @param props Props for the child window.
 * @returns The child window component.
 */
declare const ChildWindow: FunctionComponent<PropsWithChildren<ChildWindowProps>>;

type FileUploadLineProps = Omit<ButtonProps, "onClick" | "label"> & {
    onClick: (files: FileList) => void;
    label: string;
    accept: string;
};
/**
 * A full-width line with an upload button.
 * For just the button without the line wrapper, use UploadButton directly.
 * @returns An UploadButton wrapped in a LineContainer
 */
declare const FileUploadLine: FunctionComponent<FileUploadLineProps>;

type GradientListProps<T extends FactorGradient | Color3Gradient | ColorGradient> = {
    label: string;
    gradients: Nullable<Array<T>>;
    addGradient: (step?: T) => void;
    removeGradient: (step: T, index: number) => void;
    onChange: (newGradient: T, index: number) => void;
};
declare const FactorGradientList: FunctionComponent<GradientListProps<FactorGradient>>;
declare const Color3GradientList: FunctionComponent<GradientListProps<Color3Gradient>>;
declare const Color4GradientList: FunctionComponent<GradientListProps<ColorGradient>>;

type PaneProps = {
    title: string;
    icon?: FluentIcon;
};
declare const Pane: FunctionComponent<PropsWithChildren<PaneProps>>;

/**
 * Displays an icon indicating enabled (green check) or disabled (red cross) state
 * @param props - The properties for the PropertyLine, including the boolean value to display.
 * @returns A PropertyLine component with a PresenceBadge indicating the boolean state.
 */
declare const BooleanBadgePropertyLine: FunctionComponent<PropertyLineProps<boolean> & ImmutablePrimitiveProps<boolean>>;

/**
 * Wraps a checkbox in a property line
 * @param props - PropertyLineProps and CheckboxProps
 * @returns property-line wrapped checkbox
 */
declare const CheckboxPropertyLine: FunctionComponent<PropertyLineProps<boolean> & PrimitiveProps<boolean>>;

type ColorPropertyLineProps = ColorPickerProps<Color3 | Color4> & PropertyLineProps<Color3 | Color4>;
declare const Color3PropertyLine: FunctionComponent<ColorPickerProps<Color3> & PropertyLineProps<Color3>>;
declare const Color4PropertyLine: FunctionComponent<ColorPickerProps<Color4> & PropertyLineProps<Color4>>;

type DropdownPropertyLineProps<V extends AcceptedDropdownValue> = DropdownProps<V> & PropertyLineProps<V>;
/**
 * Dropdown component for number values.
 */
declare const NumberDropdownPropertyLine: FunctionComponent<DropdownPropertyLineProps<number>>;
/**
 * Dropdown component for string values
 */
declare const StringDropdownPropertyLine: FunctionComponent<DropdownPropertyLineProps<string>>;

/**
 * Wraps a text input in a property line
 * @param props - PropertyLineProps and InputProps
 * @returns property-line wrapped input component
 */
declare const TextInputPropertyLine: FunctionComponent<TextInputProps & PropertyLineProps<string>>;
type NumberInputPropertyLineProps = SpinButtonProps & PropertyLineProps<number>;
/**
 * Wraps a number input in a property line
 * To force integer values, use forceInt param (this is distinct from the 'step' param, which will still allow submitting an integer value. forceInt will not)
 * @param props - PropertyLineProps and InputProps
 * @returns property-line wrapped input component
 */
declare const NumberInputPropertyLine: FunctionComponent<NumberInputPropertyLineProps>;

type HexPropertyLineProps = NumberInputPropertyLineProps & {
    numBits?: 32 | 24 | 16 | 8;
};
/**
 * Takes a number representing a Hex value and converts it to a hex string then wraps the TextInput in a PropertyLine
 * @param props - PropertyLineProps
 * @returns property-line wrapped textbox that converts to/from hex number representation
 */
declare const HexPropertyLine: FunctionComponent<HexPropertyLineProps>;

/**
 * Wraps a link in a property line
 * @param props - PropertyLineProps and LinkProps
 * @returns property-line wrapped link
 */
declare const LinkPropertyLine: FunctionComponent<PropertyLineProps<string> & LinkProps>;

declare const SpinButtonPropertyLine: FunctionComponent<PropertyLineProps<number> & SpinButtonProps>;

type StringifiedPropertyLineProps = PropertyLineProps<number> & ImmutablePrimitiveProps<number> & {
    precision?: number;
    units?: string;
};
/**
 * Expects a numerical value and converts it toFixed(if precision is supplied) or toLocaleString
 * Can pass optional units to be appending to the end of the string
 * @param props
 * @returns
 */
declare const StringifiedPropertyLine: FunctionComponent<StringifiedPropertyLineProps>;

/**
 * Wraps a switch in a property line
 * @param props - The properties for the switch and property line
 * @returns A React element representing the property line with a switch
 */
declare const SwitchPropertyLine: FunctionComponent<PropertyLineProps<boolean> & SwitchProps>;

type SyncedSliderPropertyProps = SyncedSliderProps & PropertyLineProps<number>;
/**
 * Renders a simple wrapper around the SyncedSliderInput
 * @param props
 * @returns
 */
declare const SyncedSliderPropertyLine: react.ForwardRefExoticComponent<SyncedSliderPropertyProps & react.RefAttributes<HTMLDivElement>>;

/**
 * Wraps textarea in a property line
 * @param props - PropertyLineProps and TextProps
 * @returns property-line wrapped text
 */
declare const TextAreaPropertyLine: FunctionComponent<PropertyLineProps<string> & TextareaProps>;

/**
 * Wraps text in a property line
 * @param props - PropertyLineProps and TextProps
 * @returns property-line wrapped text
 */
declare const TextPropertyLine: FunctionComponent<PropertyLineProps<string> & ImmutablePrimitiveProps<string>>;

type TensorPropertyLineProps<V extends Vector2 | Vector3 | Vector4 | Quaternion> = PropertyLineProps<V> & PrimitiveProps<V> & {
    /**
     * If passed, all sliders will use this for the min value
     */
    min?: number;
    /**
     * If passed, all sliders will use this for the max value
     */
    max?: number;
    /**
     * Will be displayed in the input UI to indicate the unit of measurement
     */
    unit?: string;
    /**
     * Internal spinbutton's step
     */
    step?: number;
    /**
     * If passed, the UX will use the conversion functions to display/update values
     */
    valueConverter?: {
        /**
         * Will call from(val) before displaying in the UX
         */
        from: (val: number) => number;
        /**
         * Will call to(val) before calling onChange
         */
        to: (val: number) => number;
    };
};
type RotationVectorPropertyLineProps = TensorPropertyLineProps<Vector3> & {
    /**
     * Display angles as degrees instead of radians
     */
    useDegrees?: boolean;
};
declare const RotationVectorPropertyLine: FunctionComponent<RotationVectorPropertyLineProps>;
type QuaternionPropertyLineProps = TensorPropertyLineProps<Quaternion> & {
    /**
     * Display angles as degrees instead of radians
     */
    useDegrees?: boolean;
    /**
     * Display angles as Euler angles instead of quaternions
     */
    useEuler?: boolean;
};
declare const QuaternionPropertyLine: FunctionComponent<QuaternionPropertyLineProps>;
declare const Vector2PropertyLine: FunctionComponent<TensorPropertyLineProps<Vector2>>;
declare const Vector3PropertyLine: FunctionComponent<TensorPropertyLineProps<Vector3>>;
declare const Vector4PropertyLine: FunctionComponent<TensorPropertyLineProps<Vector4>>;

export { Accordion, AccordionSection, AttachDebugLayer, BooleanBadgePropertyLine, BoundProperty, BuiltInsExtensionFeed, Button, ButtonLine, Checkbox, CheckboxPropertyLine, ChildWindow, Collapse, Color3GradientComponent, Color3GradientList, Color3PropertyLine, Color4GradientComponent, Color4GradientList, Color4PropertyLine, ColorPickerPopup, ColorStepGradientComponent, ComboBox, ConstructorFactory, ConvertOptions, DebugServiceIdentity, DetachDebugLayer, DraggableLine, Dropdown, ExtensibleAccordion, FactorGradientComponent, FactorGradientList, FileUploadLine, GetPropertyDescriptor, HexPropertyLine, InfoLabel, InputHexField, InputHsvField, Inspector, InterceptFunction, InterceptProperty, IsPropertyReadonly, LineContainer, Link, LinkPropertyLine, LinkToEntityPropertyLine, List, MakeDialogTeachingMoment, MakeLazyComponent, MakePopoverTeachingMoment, MakePropertyHook, MakeTeachingMoment, MessageBar, NumberDropdown, NumberDropdownPropertyLine, NumberInputPropertyLine, ObservableCollection, Pane, PlaceholderPropertyLine, PositionedPopover, PropertiesServiceIdentity, Property, PropertyLine, QuaternionPropertyLine, RotationVectorPropertyLine, SceneContextIdentity, SceneExplorerServiceIdentity, SearchBar, SearchBox, SelectionServiceDefinition, SelectionServiceIdentity, SettingsContextIdentity, SettingsServiceIdentity, ShellServiceIdentity, ShowInspector, SidePaneContainer, SpinButton, SpinButtonPropertyLine, StatsServiceIdentity, StringDropdown, StringDropdownPropertyLine, StringifiedPropertyLine, Switch, SwitchPropertyLine, SyncedSliderInput, SyncedSliderPropertyLine, TeachingMoment, TextAreaPropertyLine, TextInput, TextInputPropertyLine, TextPropertyLine, Textarea, Theme, ToggleButton, ToolsServiceIdentity, Vector2PropertyLine, Vector3PropertyLine, Vector4PropertyLine, useAngleConverters, useAsyncResource, useColor3Property, useColor4Property, useCompactMode, useDisableCopy, useEventfulState, useInterceptObservable, useObservableCollection, useObservableState, useOrderedObservableCollection, usePollingObservable, useProperty, useQuaternionProperty, useResource, useSidePaneDockOverrides, useVector3Property };
export type { AcceptedDropdownValue, AccordionProps, AccordionSectionProps, BasePrimitiveProps, BoundPropertyProps, BuiltInExtension, ButtonProps, CentralContentDefinition, ChildWindowOptions, ChildWindowProps, ColorPickerProps, ColorPropertyLineProps, ComboBoxOption, ComboBoxProps, DraggableLineProps, DropdownOption, DropdownProps, DynamicAccordionSection, DynamicAccordionSectionContent, EntityDisplayInfo, ExtensionMetadata, ExtensionModule, FunctionHooks, HexPropertyLineProps, IDebugService, IExtensionFeed, IExtensionMetadataQuery, IPropertiesService, ISceneContext, ISceneExplorerService, ISelectionService, IService, ISettingsContext, ISettingsService, IShellService, IStatsService, IToolsService, ImmutablePrimitiveProps, InfoLabelParentProps, InfoLabelProps, InputHexProps, InspectorOptions, InspectorToken, LinkProps, ListItem, NumberInputPropertyLineProps, PaneProps, PersonMetadata, PrimitiveProps, PropertyHooks, PropertyLineProps, PropertyProps, SceneExplorerCommand, SceneExplorerCommandProvider, SceneExplorerSection, SectionsImperativeRef, ServiceDefinition, ServiceFactory, SidePaneDefinition, SpinButtonProps, SwitchProps, SyncedSliderProps, TensorPropertyLineProps, TextInputProps, TextareaProps, ToolbarItemDefinition };
